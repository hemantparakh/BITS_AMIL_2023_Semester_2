{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8741062c-0e69-43f0-9487-6889c8513b77",
   "metadata": {
    "id": "8741062c-0e69-43f0-9487-6889c8513b77"
   },
   "source": [
    "### Group ID:\n",
    "### Group Members Name with Student ID:\n",
    "\n",
    "1. HEMANT KUMAR PARAKH (2023AA05741)\n",
    "2. SUSHIL KUMAR (2023aa05849)\n",
    "3. NAGINENI SATISH BABU (2023aa05585)\n",
    "4. JITENDRA KUMAR (2023aa05198)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebde8947-7ed3-4347-9ab9-04ce825100a7",
   "metadata": {
    "id": "ebde8947-7ed3-4347-9ab9-04ce825100a7"
   },
   "source": [
    "# Problem Statement\n",
    "\n",
    "The objective of the problem is to implement an Actor-Critic reinforcement learning algorithm to optimize energy consumption in a building. The agent should learn to adjust the temperature settings dynamically to minimize energy usage while maintaining comfortable indoor conditions."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29da66c9-875c-4994-80da-376e6da938ce",
   "metadata": {
    "id": "29da66c9-875c-4994-80da-376e6da938ce"
   },
   "source": [
    "#### Dataset Details\n",
    "Dataset: https://archive.ics.uci.edu/dataset/374/appliances+energy+prediction\n",
    "\n",
    "This dataset contains energy consumption data for a residential building, along with various environmental and operational factors.\n",
    "\n",
    "Data Dictionary:\n",
    "* Appliances:       Energy use in Wh\n",
    "* lights:           Energy use of light fixtures in the house in Wh\n",
    "* T1 - T9:          Temperatures in various rooms and outside\n",
    "* RH_1 to RH_9:     Humidity measurements in various rooms and outside\n",
    "* Visibility:       Visibility in km\n",
    "* Tdewpoint:       Dew point temperature\n",
    "* Pressure_mm_hgg:  Pressure in mm Hg\n",
    "* Windspeed:        Wind speed in m/s"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "294b0609-22d6-4453-b23d-2de22a5241bd",
   "metadata": {
    "id": "294b0609-22d6-4453-b23d-2de22a5241bd"
   },
   "source": [
    "## Environment Details\n",
    "**State Space:**\n",
    "The state space consists of various features from the dataset that impact energy consumption and comfort levels.\n",
    "\n",
    "* Current Temperature (T1 to T9): Temperatures in various rooms and outside.\n",
    "* Current Humidity (RH_1 to RH_9): Humidity measurements in different locations.\n",
    "* Visibility (Visibility): Visibility in meters.\n",
    "* Dew Point (Tdewpoint): Dew point temperature.\n",
    "* Pressure (Press_mm_hg): Atmospheric pressure in mm Hg.\n",
    "* Windspeed (Windspeed): Wind speed in m/s.\n",
    "\n",
    "Total State Vector Dimension: Number of features = 9 (temperature) + 9 (humidity) + 1 (visibility) + 1 (dew point) + 1 (pressure) + 1 (windspeed) = 22 features\n",
    "\n",
    "**Target Variable:** Appliances (energy consumption in Wh).\n",
    "\n",
    "**Action Space:**\n",
    "The action space consists of discrete temperature adjustments:\n",
    "* Action 0: Decrease temperature by 1°C\n",
    "* Action 1: Maintain current temperature\n",
    "* Action 2: Increase temperature by 1°C\n",
    "\n",
    "\n",
    "- If the action is to decrease the temperature by 1°C, you'll adjust each temperature feature (T1 to T9) down by 1°C.\n",
    "- If the action is to increase the temperature by 1°C, you'll adjust each temperature feature (T1 to T9) up by 1°C.\n",
    "- Other features remain unchanged.\n",
    "\n",
    "**Policy (Actor):** A neural network that outputs a probability distribution over possible temperature adjustments.\n",
    "\n",
    "**Value function (Critic):** A neural network that estimates the expected cumulative reward (energy savings) from a given state.\n",
    "\n",
    "**Reward function:**\n",
    "The reward function should reflect the overall comfort and energy efficiency based on all temperature readings. i.e., balance between minimising temperature deviations and minimizing energy consumption.\n",
    "\n",
    "* Calculate the penalty based on the deviation of each temperature from the target temperature and then aggregate these penalties.\n",
    "* Measure the change in energy consumption before and after applying the RL action.\n",
    "* Combine the comfort penalty and energy savings to get the final reward.\n",
    "\n",
    "*Example:*\n",
    "\n",
    "Target temperature=22°C\n",
    "\n",
    "Initial Temperatures: T1=23, T2=22, T3=21, T4=23, T5=22, T6=21, T7=24, T8=22, T9=23\n",
    "\n",
    "Action Taken: Decrease temperature by 1°C for each room\n",
    "\n",
    "Resulting Temperatures: T1 = 22, T2 = 21, T3 = 20, T4 = 22, T5 = 21, T6 = 20, T7 = 23, T8 = 21, T9 = 22\n",
    "\n",
    "Energy Consumption: 50 Wh (before RL adjustment) and 48 Wh (after RL adjustment)\n",
    "* Energy Before (50 Wh): Use the energy consumption from the dataset at the current time step.\n",
    "* Energy After (48 Wh): Use the energy consumption from the dataset at the next time step (if available).\n",
    "\n",
    "Consider only temperature features for deviation calculation.\n",
    "\n",
    "Deviation = abs (Ti− Ttarget )\n",
    "\n",
    "Deviations=[ abs(22−22), abs(21−22), abs(20−22), abs(22−22),  abs(21−22), abs(20−22), abs(23−22), abs(21−22), abs(22−22) ]\n",
    "\n",
    "Deviations = [0, 1, 2, 0, 1, 2, 1, 1, 0], Sum of deviations = 8\n",
    "\n",
    "Energy Savings = Energy Before−Energy After = 50 – 48 = 2Wh\n",
    "\n",
    "Reward= −Sum of Deviations + Energy Savings = -8+2 = -6"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a95be925",
   "metadata": {
    "id": "a95be925"
   },
   "source": [
    "#### Expected Outcomes\n",
    "1. Pre-process the dataset to handle any missing values and create training and testing sets.\n",
    "2. Implement the Actor-Critic algorithm using TensorFlow.\n",
    "3. Train the model over 500 episodes to minimize energy consumption while maintaining an indoor temperature of 22°C.\n",
    "4. Plot the total reward obtained in each episode to evaluate the learning progress.\n",
    "5. Evaluate the performance of the model on test set to measure its performance\n",
    "6. Provide graphs showing the convergence of the Actor and Critic losses.\n",
    "7. Plot the learned policy by showing the action probabilities across different state values (e.g., temperature settings).\n",
    "8. Provide an analysis on a comparison of the energy consumption before and after applying the reinforcement learning algorithm.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fb68ad3",
   "metadata": {
    "id": "4fb68ad3"
   },
   "source": [
    "#### Code Execution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "786f8197",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ff5452f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tensorflow in /home/jitendra/anaconda3/lib/python3.11/site-packages (2.17.0)\n",
      "Requirement already satisfied: absl-py>=1.0.0 in /home/jitendra/anaconda3/lib/python3.11/site-packages (from tensorflow) (2.1.0)\n",
      "Requirement already satisfied: astunparse>=1.6.0 in /home/jitendra/anaconda3/lib/python3.11/site-packages (from tensorflow) (1.6.3)\n",
      "Requirement already satisfied: flatbuffers>=24.3.25 in /home/jitendra/anaconda3/lib/python3.11/site-packages (from tensorflow) (24.3.25)\n",
      "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /home/jitendra/anaconda3/lib/python3.11/site-packages (from tensorflow) (0.6.0)\n",
      "Requirement already satisfied: google-pasta>=0.1.1 in /home/jitendra/anaconda3/lib/python3.11/site-packages (from tensorflow) (0.2.0)\n",
      "Requirement already satisfied: h5py>=3.10.0 in /home/jitendra/anaconda3/lib/python3.11/site-packages (from tensorflow) (3.11.0)\n",
      "Requirement already satisfied: libclang>=13.0.0 in /home/jitendra/anaconda3/lib/python3.11/site-packages (from tensorflow) (18.1.1)\n",
      "Requirement already satisfied: ml-dtypes<0.5.0,>=0.3.1 in /home/jitendra/anaconda3/lib/python3.11/site-packages (from tensorflow) (0.4.0)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in /home/jitendra/anaconda3/lib/python3.11/site-packages (from tensorflow) (3.3.0)\n",
      "Requirement already satisfied: packaging in /home/jitendra/anaconda3/lib/python3.11/site-packages (from tensorflow) (24.1)\n",
      "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in /home/jitendra/anaconda3/lib/python3.11/site-packages (from tensorflow) (4.25.4)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in /home/jitendra/anaconda3/lib/python3.11/site-packages (from tensorflow) (2.32.3)\n",
      "Requirement already satisfied: setuptools in /home/jitendra/anaconda3/lib/python3.11/site-packages (from tensorflow) (68.0.0)\n",
      "Requirement already satisfied: six>=1.12.0 in /home/jitendra/anaconda3/lib/python3.11/site-packages (from tensorflow) (1.16.0)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in /home/jitendra/anaconda3/lib/python3.11/site-packages (from tensorflow) (2.4.0)\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in /home/jitendra/anaconda3/lib/python3.11/site-packages (from tensorflow) (4.12.2)\n",
      "Requirement already satisfied: wrapt>=1.11.0 in /home/jitendra/anaconda3/lib/python3.11/site-packages (from tensorflow) (1.16.0)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /home/jitendra/anaconda3/lib/python3.11/site-packages (from tensorflow) (1.65.4)\n",
      "Requirement already satisfied: tensorboard<2.18,>=2.17 in /home/jitendra/anaconda3/lib/python3.11/site-packages (from tensorflow) (2.17.1)\n",
      "Requirement already satisfied: keras>=3.2.0 in /home/jitendra/anaconda3/lib/python3.11/site-packages (from tensorflow) (3.5.0)\n",
      "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /home/jitendra/anaconda3/lib/python3.11/site-packages (from tensorflow) (0.37.1)\n",
      "Requirement already satisfied: numpy<2.0.0,>=1.23.5 in /home/jitendra/anaconda3/lib/python3.11/site-packages (from tensorflow) (1.24.4)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in /home/jitendra/anaconda3/lib/python3.11/site-packages (from astunparse>=1.6.0->tensorflow) (0.38.4)\n",
      "Requirement already satisfied: rich in /home/jitendra/anaconda3/lib/python3.11/site-packages (from keras>=3.2.0->tensorflow) (13.7.1)\n",
      "Requirement already satisfied: namex in /home/jitendra/anaconda3/lib/python3.11/site-packages (from keras>=3.2.0->tensorflow) (0.0.8)\n",
      "Requirement already satisfied: optree in /home/jitendra/anaconda3/lib/python3.11/site-packages (from keras>=3.2.0->tensorflow) (0.12.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /home/jitendra/anaconda3/lib/python3.11/site-packages (from requests<3,>=2.21.0->tensorflow) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/jitendra/anaconda3/lib/python3.11/site-packages (from requests<3,>=2.21.0->tensorflow) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /home/jitendra/anaconda3/lib/python3.11/site-packages (from requests<3,>=2.21.0->tensorflow) (2.2.2)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/jitendra/anaconda3/lib/python3.11/site-packages (from requests<3,>=2.21.0->tensorflow) (2024.7.4)\n",
      "Requirement already satisfied: markdown>=2.6.8 in /home/jitendra/anaconda3/lib/python3.11/site-packages (from tensorboard<2.18,>=2.17->tensorflow) (3.4.1)\n",
      "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /home/jitendra/anaconda3/lib/python3.11/site-packages (from tensorboard<2.18,>=2.17->tensorflow) (0.7.2)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in /home/jitendra/anaconda3/lib/python3.11/site-packages (from tensorboard<2.18,>=2.17->tensorflow) (2.2.3)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in /home/jitendra/anaconda3/lib/python3.11/site-packages (from werkzeug>=1.0.1->tensorboard<2.18,>=2.17->tensorflow) (2.1.5)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in /home/jitendra/anaconda3/lib/python3.11/site-packages (from rich->keras>=3.2.0->tensorflow) (3.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /home/jitendra/anaconda3/lib/python3.11/site-packages (from rich->keras>=3.2.0->tensorflow) (2.18.0)\n",
      "Requirement already satisfied: mdurl~=0.1 in /home/jitendra/anaconda3/lib/python3.11/site-packages (from markdown-it-py>=2.2.0->rich->keras>=3.2.0->tensorflow) (0.1.2)\n"
     ]
    }
   ],
   "source": [
    "!pip install tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "64dc5646",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-09-14 10:10:10.221905: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-09-14 10:10:10.231806: I external/local_xla/xla/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-09-14 10:10:10.299535: I external/local_xla/xla/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-09-14 10:10:10.352227: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:485] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-09-14 10:10:10.405625: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:8454] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-09-14 10:10:10.422577: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1452] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-09-14 10:10:10.517696: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-09-14 10:10:11.476418: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5b497301",
   "metadata": {
    "id": "5b497301"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                  date  Appliances  lights     T1       RH_1    T2     RH_2     T3   RH_3    T4       RH_4         T5  RH_5        T6       RH_6    T7       RH_7    T8       RH_8         T9   RH_9     T_out  Press_mm_hg  RH_out  Windspeed  Visibility  Tdewpoint        rv1        rv2\n",
      "0  2016-01-11 17:00:00          60      30  19.89  47.596667  19.2  44.7900  19.79  44.73  19.0  45.566667  17.166667  55.2  7.026667  84.256667  17.2  41.626667  18.2  48.900000  17.033333  45.53  6.600000        733.5    92.0   7.000000   63.000000        5.3  13.275433  13.275433\n",
      "1  2016-01-11 17:10:00          60      30  19.89  46.693333  19.2  44.7225  19.79  44.79  19.0  45.992500  17.166667  55.2  6.833333  84.063333  17.2  41.560000  18.2  48.863333  17.066667  45.56  6.483333        733.6    92.0   6.666667   59.166667        5.2  18.606195  18.606195\n",
      "Sample dataSet : --------\n",
      "      T1       RH_1    T2     RH_2     T3   RH_3    T4       RH_4         T5  \\\n",
      "0  19.89  47.596667  19.2  44.7900  19.79  44.73  19.0  45.566667  17.166667   \n",
      "1  19.89  46.693333  19.2  44.7225  19.79  44.79  19.0  45.992500  17.166667   \n",
      "\n",
      "   RH_5  ...    T7       RH_7    T8       RH_8         T9   RH_9  Windspeed  \\\n",
      "0  55.2  ...  17.2  41.626667  18.2  48.900000  17.033333  45.53   7.000000   \n",
      "1  55.2  ...  17.2  41.560000  18.2  48.863333  17.066667  45.56   6.666667   \n",
      "\n",
      "   Visibility  Tdewpoint  Press_mm_hg  \n",
      "0   63.000000        5.3        733.5  \n",
      "1   59.166667        5.2        733.6  \n",
      "\n",
      "[2 rows x 22 columns]\n",
      "Target dataSet : --------\n",
      "   Appliances\n",
      "0          60\n",
      "1          60\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_6310/3533180326.py:9: FutureWarning: The default value of numeric_only in DataFrame.mean is deprecated. In a future version, it will default to False. In addition, specifying 'numeric_only=None' is deprecated. Select only valid columns or specify the value of numeric_only to silence this warning.\n",
      "  data.fillna(data.mean(), inplace=True)\n"
     ]
    }
   ],
   "source": [
    "#### Load the dataset\n",
    "file_path = \"appliancesEnergyPrediction/energydata_complete.csv\"\n",
    "data=pd.read_csv(file_path)\n",
    "print(data.head(2).to_string())\n",
    "\n",
    "# Pre process the data set to get the features and target and scale them\n",
    "\n",
    "# Check and relace missing values\n",
    "data.fillna(data.mean(), inplace=True)\n",
    "\n",
    "# selected only the feature which is mentioned in explanation.\n",
    "features = ['T1','RH_1','T2','RH_2','T3','RH_3','T4','RH_4','T5','RH_5','T6','RH_6','T7','RH_7'\n",
    "            ,'T8','RH_8','T9','RH_9','Windspeed','Visibility','Tdewpoint','Press_mm_hg']\n",
    "target=['Appliances']\n",
    "\n",
    "X=data[features]\n",
    "Y=data[target]\n",
    "#data.drop(['date','Appliances','lights','T_out','RH_out','rv1','rv2'], axis = 1, inplace = True)\n",
    "print('Sample dataSet : --------')\n",
    "print(X.head(2))\n",
    "print('Target dataSet : --------')\n",
    "print(Y.head(2))\n",
    "\n",
    "# Normalize them with Standard Scaler\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "# Split the data to training and testing sets (80% for training, 20% for testing)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_scaled,Y,test_size=0.2,random_state=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e9f6b9c",
   "metadata": {
    "id": "9e9f6b9c"
   },
   "source": [
    "#### Defining Actor Critic Model using tensorflow (1 M)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "00acc2a9",
   "metadata": {
    "id": "00acc2a9"
   },
   "outputs": [],
   "source": [
    "state_space = 22  # 9 temperatures + 9 humidities + 4 external factors\n",
    "action_space = 3  # Decrease, Maintain, Increase\n",
    "\n",
    "### Define Actor Model\n",
    "\n",
    "def build_actor_model():\n",
    "    \n",
    "    # define the NN model to give probability distribution over actions\n",
    "    model = tf.keras.Sequential([\n",
    "        layers.InputLayer(shape=(state_space,)),\n",
    "        layers.Dense(128, activation='relu'),\n",
    "        layers.Dense(64, activation='relu'),\n",
    "        layers.Dense(32, activation='relu'),\n",
    "        layers.Dense(action_space, activation='softmax')  # Output probabilities for actions\n",
    "    ])\n",
    "    model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.001), loss='categorical_crossentropy')\n",
    "    return model\n",
    "\n",
    "### Define Critic Model\n",
    "\n",
    "def build_critic_model():\n",
    "    # define the NN model for value function estimation\n",
    "    model = tf.keras.Sequential([\n",
    "       layers.InputLayer(shape=(state_space,)),\n",
    "       layers.Dense(128, activation='relu'),\n",
    "       layers.Dense(64, activation='relu'),\n",
    "       layers.Dense(32, activation='relu'),\n",
    "       layers.Dense(1)  # Output is a single value representing the expected reward\n",
    "    ])\n",
    "    model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.001), loss='mse')\n",
    "\n",
    "    return model\n",
    "\n",
    "\n",
    "# activating this models\n",
    "actor_model = build_actor_model()\n",
    "critic_model = build_critic_model()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27777860",
   "metadata": {
    "id": "27777860"
   },
   "source": [
    "### Reward Function (0.5 M)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "005044e9",
   "metadata": {
    "id": "005044e9"
   },
   "outputs": [],
   "source": [
    "### Calculate Reward Function\n",
    "\n",
    "# consider only temperature features for deviation calculation with target temperature as 22C\n",
    "target_temperature = 22 #As given\n",
    "\n",
    "# Reward Function\n",
    "def calculate_reward(current_temperatures, next_temperatures, energy_before, energy_after):\n",
    "       \n",
    "    # Calculate deviation from target temperature\n",
    "    deviation = np.abs(current_temperatures - target_temperature)\n",
    "    sum_deviation = np.sum(deviation)\n",
    "    \n",
    "    # calculate energy savings by taking difference between energy before and after\n",
    "    energy_savings = energy_before - energy_after\n",
    "    \n",
    "    # calculate and return the reward\n",
    "    reward = -sum_deviation + energy_savings\n",
    "    return reward"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bf34260",
   "metadata": {
    "id": "3bf34260"
   },
   "source": [
    "#### Environment Simulation (0.5 M)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e86b7850",
   "metadata": {
    "id": "e86b7850"
   },
   "outputs": [],
   "source": [
    "### Environment Simulation\n",
    "\n",
    "TEMP_MIN = -10  # Minimum temperature limit\n",
    "TEMP_MAX = 30   # Maximum temperature limit\n",
    "\n",
    "def simulate_environment(state, action, current_index):\n",
    "    # Action is either decrease (-1), maintain (0), or increase (+1)\n",
    "    temp_adjustment = action - 1  # -1 for decrease, 0 for maintain, +1 for increase\n",
    "    current_temperatures = state[:9]  # Extract the temperature features (T1 to T9)\n",
    "    \n",
    "    # Increase of decrease each temperature by 1C based on action\n",
    "    #The temperatures are clipped to stay within the bounds [−10°C,30°C][−10°C,30°C] after every action\n",
    "    next_temperatures = np.clip(current_temperatures + temp_adjustment, TEMP_MIN, TEMP_MAX)\n",
    "    \n",
    "    # Get energy consumption before from current index\n",
    "    energy_before = y_train.iloc[current_index][0]  # Use actual energy consumption\n",
    "    \n",
    "    # get the energy after from next index\n",
    "    energy_after = y_train.iloc[current_index + 1][0]  # Use energy consumption at the next time step\n",
    "    \n",
    "    # get the respective reward\n",
    "    reward = calculate_reward(current_temperatures, next_temperatures, energy_before, energy_after)\n",
    "    print(\"action :\", action, \" next_temperatures : \", next_temperatures, \" energy_before : \", energy_before,\n",
    "          \" energy_after : \", energy_after,\" reward : \", reward )\n",
    "    # Create the next state (update temperatures and leave other features the same)\n",
    "    next_state = np.copy(state)\n",
    "    next_state[:9] = next_temperatures  # Update temperature features\n",
    "    \n",
    "    return next_state, reward"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8330a3c2",
   "metadata": {
    "id": "8330a3c2"
   },
   "source": [
    "#### Implementation of Training Function (2 M)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1e974279",
   "metadata": {
    "id": "1e974279"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 68ms/step\n",
      "action : 0  next_temperatures :  [-2.47148277 -0.71344459 -1.97642479 -0.75929987 -2.32977646 -0.58595717\n",
      " -2.0110151  -1.16974615 -2.09353355]  energy_before :  30  energy_after :  50  reward :  -223.11068044863305\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step\n",
      "action : 2  next_temperatures :  [-1.47148277  0.28655541 -0.97642479  0.24070013 -1.32977646  0.41404283\n",
      " -1.0110151  -0.16974615 -1.09353355]  energy_before :  50  energy_after :  40  reward :  -202.11068044863305\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step\n",
      "action : 1  next_temperatures :  [-1.47148277  0.28655541 -0.97642479  0.24070013 -1.32977646  0.41404283\n",
      " -1.0110151  -0.16974615 -1.09353355]  energy_before :  40  energy_after :  50  reward :  -213.11068044863305\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step\n",
      "action : 1  next_temperatures :  [-1.47148277  0.28655541 -0.97642479  0.24070013 -1.32977646  0.41404283\n",
      " -1.0110151  -0.16974615 -1.09353355]  energy_before :  50  energy_after :  50  reward :  -203.11068044863305\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "WARNING:tensorflow:5 out of the last 7 calls to <function TensorFlowTrainer.make_train_function.<locals>.one_step_on_iterator at 0x761dca093a60> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step\n",
      "action : 2  next_temperatures :  [-0.47148277  1.28655541  0.02357521  1.24070013 -0.32977646  1.41404283\n",
      " -0.0110151   0.83025385 -0.09353355]  energy_before :  50  energy_after :  50  reward :  -203.11068044863305\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "WARNING:tensorflow:6 out of the last 9 calls to <function TensorFlowTrainer.make_train_function.<locals>.one_step_on_iterator at 0x761dca093a60> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "Episode 1/500, Total Reward: -1044.5534022431652\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step\n",
      "action : 2  next_temperatures :  [0.81533824 0.75629781 0.29262312 1.64122012 1.09756556 0.76161167\n",
      " 0.92396111 0.87862745 1.16149705]  energy_before :  30  energy_after :  50  reward :  -218.6712578470326\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step\n",
      "action : 0  next_temperatures :  [-0.18466176 -0.24370219 -0.70737688  0.64122012  0.09756556 -0.23838833\n",
      " -0.07603889 -0.12137255  0.16149705]  energy_before :  50  energy_after :  40  reward :  -179.67125784703262\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step\n",
      "action : 2  next_temperatures :  [0.81533824 0.75629781 0.29262312 1.64122012 1.09756556 0.76161167\n",
      " 0.92396111 0.87862745 1.16149705]  energy_before :  40  energy_after :  50  reward :  -208.67125784703262\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step\n",
      "action : 2  next_temperatures :  [1.81533824 1.75629781 1.29262312 2.64122012 2.09756556 1.76161167\n",
      " 1.92396111 1.87862745 2.16149705]  energy_before :  50  energy_after :  50  reward :  -189.67125784703262\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step\n",
      "action : 1  next_temperatures :  [1.81533824 1.75629781 1.29262312 2.64122012 2.09756556 1.76161167\n",
      " 1.92396111 1.87862745 2.16149705]  energy_before :  50  energy_after :  50  reward :  -180.67125784703262\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step\n",
      "Episode 2/500, Total Reward: -977.3562892351631\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "action : 1  next_temperatures :  [ 1.25367206 -1.77416134  1.19571908 -2.31476487  0.55949931 -1.31382432\n",
      "  1.19180844 -1.55184908  0.92047884]  energy_before :  30  energy_after :  50  reward :  -219.83342188254835\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "action : 0  next_temperatures :  [ 0.25367206 -2.77416134  0.19571908 -3.31476487 -0.44050069 -2.31382432\n",
      "  0.19180844 -2.55184908 -0.07952116]  energy_before :  50  energy_after :  40  reward :  -189.83342188254835\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "action : 1  next_temperatures :  [ 0.25367206 -2.77416134  0.19571908 -3.31476487 -0.44050069 -2.31382432\n",
      "  0.19180844 -2.55184908 -0.07952116]  energy_before :  40  energy_after :  50  reward :  -218.83342188254835\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step\n",
      "action : 2  next_temperatures :  [ 1.25367206 -1.77416134  1.19571908 -2.31476487  0.55949931 -1.31382432\n",
      "  1.19180844 -1.55184908  0.92047884]  energy_before :  50  energy_after :  50  reward :  -208.83342188254835\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step\n",
      "action : 1  next_temperatures :  [ 1.25367206 -1.77416134  1.19571908 -2.31476487  0.55949931 -1.31382432\n",
      "  1.19180844 -1.55184908  0.92047884]  energy_before :  50  energy_after :  50  reward :  -199.83342188254835\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step\n",
      "Episode 3/500, Total Reward: -1037.1671094127419\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "action : 1  next_temperatures :  [ 0.195158    0.16090195 -0.67697598  1.48567026  0.91342696  0.01459518\n",
      " -0.03198241  0.36005998  0.60062223]  energy_before :  30  energy_after :  50  reward :  -214.97852384943448\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step\n",
      "action : 1  next_temperatures :  [ 0.195158    0.16090195 -0.67697598  1.48567026  0.91342696  0.01459518\n",
      " -0.03198241  0.36005998  0.60062223]  energy_before :  50  energy_after :  40  reward :  -184.97852384943448\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step\n",
      "action : 1  next_temperatures :  [ 0.195158    0.16090195 -0.67697598  1.48567026  0.91342696  0.01459518\n",
      " -0.03198241  0.36005998  0.60062223]  energy_before :  40  energy_after :  50  reward :  -204.97852384943448\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "action : 2  next_temperatures :  [1.195158   1.16090195 0.32302402 2.48567026 1.91342696 1.01459518\n",
      " 0.96801759 1.36005998 1.60062223]  energy_before :  50  energy_after :  50  reward :  -194.97852384943448\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "action : 2  next_temperatures :  [2.195158   2.16090195 1.32302402 3.48567026 2.91342696 2.01459518\n",
      " 1.96801759 2.36005998 2.60062223]  energy_before :  50  energy_after :  50  reward :  -185.97852384943448\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "Episode 4/500, Total Reward: -985.8926192471724\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "action : 0  next_temperatures :  [-3.1522526  -0.30381431 -2.39139699 -0.1450054  -2.56240497 -0.08203859\n",
      " -2.83829772  0.04420093 -2.51910548]  energy_before :  30  energy_after :  50  reward :  -222.95011512552406\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "action : 1  next_temperatures :  [-3.1522526  -0.30381431 -2.39139699 -0.1450054  -2.56240497 -0.08203859\n",
      " -2.83829772  0.04420093 -2.51910548]  energy_before :  50  energy_after :  40  reward :  -201.95011512552406\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "action : 1  next_temperatures :  [-3.1522526  -0.30381431 -2.39139699 -0.1450054  -2.56240497 -0.08203859\n",
      " -2.83829772  0.04420093 -2.51910548]  energy_before :  40  energy_after :  50  reward :  -221.95011512552406\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "action : 1  next_temperatures :  [-3.1522526  -0.30381431 -2.39139699 -0.1450054  -2.56240497 -0.08203859\n",
      " -2.83829772  0.04420093 -2.51910548]  energy_before :  50  energy_after :  50  reward :  -211.95011512552406\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step\n",
      "action : 1  next_temperatures :  [-3.1522526  -0.30381431 -2.39139699 -0.1450054  -2.56240497 -0.08203859\n",
      " -2.83829772  0.04420093 -2.51910548]  energy_before :  50  energy_after :  50  reward :  -211.95011512552406\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "Episode 5/500, Total Reward: -1070.7505756276203\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step\n",
      "action : 1  next_temperatures :  [-1.82224528  1.54309002 -0.97642479  1.40212621 -1.32977646  1.58473172\n",
      " -1.34878137  1.64388004 -1.2778577 ]  energy_before :  30  energy_after :  50  reward :  -218.58125761916338\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step\n",
      "action : 1  next_temperatures :  [-1.82224528  1.54309002 -0.97642479  1.40212621 -1.32977646  1.58473172\n",
      " -1.34878137  1.64388004 -1.2778577 ]  energy_before :  50  energy_after :  40  reward :  -188.58125761916338\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "action : 0  next_temperatures :  [-2.82224528  0.54309002 -1.97642479  0.40212621 -2.32977646  0.58473172\n",
      " -2.34878137  0.64388004 -2.2778577 ]  energy_before :  40  energy_after :  50  reward :  -208.58125761916338\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "action : 1  next_temperatures :  [-2.82224528  0.54309002 -1.97642479  0.40212621 -2.32977646  0.58473172\n",
      " -2.34878137  0.64388004 -2.2778577 ]  energy_before :  50  energy_after :  50  reward :  -207.58125761916338\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step\n",
      "action : 1  next_temperatures :  [-2.82224528  0.54309002 -1.97642479  0.40212621 -2.32977646  0.58473172\n",
      " -2.34878137  0.64388004 -2.2778577 ]  energy_before :  50  energy_after :  50  reward :  -207.58125761916338\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step\n",
      "Episode 6/500, Total Reward: -1030.906288095817\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step\n",
      "action : 0  next_temperatures :  [-1.3652318  -2.84955342 -1.38360736 -2.83151989 -1.98581861 -2.42956172\n",
      " -1.64714128 -2.58102681 -2.17394948]  energy_before :  30  energy_after :  50  reward :  -228.2474103551624\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step\n",
      "action : 0  next_temperatures :  [-2.3652318  -3.84955342 -2.38360736 -3.83151989 -2.98581861 -3.42956172\n",
      " -2.64714128 -3.58102681 -3.17394948]  energy_before :  50  energy_after :  40  reward :  -207.2474103551624\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "action : 1  next_temperatures :  [-2.3652318  -3.84955342 -2.38360736 -3.83151989 -2.98581861 -3.42956172\n",
      " -2.64714128 -3.58102681 -3.17394948]  energy_before :  40  energy_after :  50  reward :  -236.2474103551624\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step\n",
      "action : 1  next_temperatures :  [-2.3652318  -3.84955342 -2.38360736 -3.83151989 -2.98581861 -3.42956172\n",
      " -2.64714128 -3.58102681 -3.17394948]  energy_before :  50  energy_after :  50  reward :  -226.2474103551624\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "action : 1  next_temperatures :  [-2.3652318  -3.84955342 -2.38360736 -3.83151989 -2.98581861 -3.42956172\n",
      " -2.64714128 -3.58102681 -3.17394948]  energy_before :  50  energy_after :  50  reward :  -226.2474103551624\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "Episode 7/500, Total Reward: -1124.237051775812\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "action : 2  next_temperatures :  [0.98760622 1.05200228 0.32302402 1.96884384 1.29363816 1.06887909\n",
      " 0.72325941 0.87862745 1.17342391]  energy_before :  30  energy_after :  50  reward :  -217.53069560708715\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "action : 1  next_temperatures :  [0.98760622 1.05200228 0.32302402 1.96884384 1.29363816 1.06887909\n",
      " 0.72325941 0.87862745 1.17342391]  energy_before :  50  energy_after :  40  reward :  -178.53069560708715\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "action : 1  next_temperatures :  [0.98760622 1.05200228 0.32302402 1.96884384 1.29363816 1.06887909\n",
      " 0.72325941 0.87862745 1.17342391]  energy_before :  40  energy_after :  50  reward :  -198.53069560708715\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "action : 2  next_temperatures :  [1.98760622 2.05200228 1.32302402 2.96884384 2.29363816 2.06887909\n",
      " 1.72325941 1.87862745 2.17342391]  energy_before :  50  energy_after :  50  reward :  -188.53069560708715\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "action : 2  next_temperatures :  [2.98760622 3.05200228 2.32302402 3.96884384 3.29363816 3.06887909\n",
      " 2.72325941 2.87862745 3.17342391]  energy_before :  50  energy_after :  50  reward :  -179.53069560708715\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "Episode 8/500, Total Reward: -962.6534780354358\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "action : 0  next_temperatures :  [-0.93559962 -0.58779113 -1.36840691  0.19654233 -0.03672408 -0.79797169\n",
      " -0.63547418 -0.72977671 -0.35058608]  energy_before :  30  energy_after :  50  reward :  -214.24578807921833\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step\n",
      "action : 1  next_temperatures :  [-0.93559962 -0.58779113 -1.36840691  0.19654233 -0.03672408 -0.79797169\n",
      " -0.63547418 -0.72977671 -0.35058608]  energy_before :  50  energy_after :  40  reward :  -193.24578807921833\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "action : 2  next_temperatures :  [ 0.06440038  0.41220887 -0.36840691  1.19654233  0.96327592  0.20202831\n",
      "  0.36452582  0.27022329  0.64941392]  energy_before :  40  energy_after :  50  reward :  -213.24578807921833\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step\n",
      "action : 1  next_temperatures :  [ 0.06440038  0.41220887 -0.36840691  1.19654233  0.96327592  0.20202831\n",
      "  0.36452582  0.27022329  0.64941392]  energy_before :  50  energy_after :  50  reward :  -194.24578807921833\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "action : 2  next_temperatures :  [1.06440038 1.41220887 0.63159309 2.19654233 1.96327592 1.20202831\n",
      " 1.36452582 1.27022329 1.64941392]  energy_before :  50  energy_after :  50  reward :  -194.24578807921833\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "Episode 9/500, Total Reward: -1009.2289403960916\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "action : 2  next_temperatures :  [ 0.44174505  1.99607862  1.07240605  1.64859166 -0.03068267  2.70456601\n",
      "  0.14073497  2.50490191 -0.02576732]  energy_before :  30  energy_after :  50  reward :  -216.54742572633614\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step\n",
      "action : 1  next_temperatures :  [ 0.44174505  1.99607862  1.07240605  1.64859166 -0.03068267  2.70456601\n",
      "  0.14073497  2.50490191 -0.02576732]  energy_before :  50  energy_after :  40  reward :  -177.54742572633614\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step\n",
      "action : 1  next_temperatures :  [ 0.44174505  1.99607862  1.07240605  1.64859166 -0.03068267  2.70456601\n",
      "  0.14073497  2.50490191 -0.02576732]  energy_before :  40  energy_after :  50  reward :  -197.54742572633614\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "action : 0  next_temperatures :  [-0.55825495  0.99607862  0.07240605  0.64859166 -1.03068267  1.70456601\n",
      " -0.85926503  1.50490191 -1.02576732]  energy_before :  50  energy_after :  50  reward :  -187.54742572633614\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "action : 1  next_temperatures :  [-0.55825495  0.99607862  0.07240605  0.64859166 -1.03068267  1.70456601\n",
      " -0.85926503  1.50490191 -1.02576732]  energy_before :  50  energy_after :  50  reward :  -196.54742572633614\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "Episode 10/500, Total Reward: -975.7371286316807\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "action : 1  next_temperatures :  [-0.738825    0.07629529 -0.33800601 -0.17702011 -0.83128681  0.06375797\n",
      " -0.27674059 -0.37475808 -0.80891538]  energy_before :  30  energy_after :  50  reward :  -221.40549873338745\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step\n",
      "action : 2  next_temperatures :  [0.261175   1.07629529 0.66199399 0.82297989 0.16871319 1.06375797\n",
      " 0.72325941 0.62524192 0.19108462]  energy_before :  50  energy_after :  40  reward :  -191.40549873338745\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "action : 0  next_temperatures :  [-0.738825    0.07629529 -0.33800601 -0.17702011 -0.83128681  0.06375797\n",
      " -0.27674059 -0.37475808 -0.80891538]  energy_before :  40  energy_after :  50  reward :  -202.40549873338745\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step\n",
      "action : 0  next_temperatures :  [-1.738825   -0.92370471 -1.33800601 -1.17702011 -1.83128681 -0.93624203\n",
      " -1.27674059 -1.37475808 -1.80891538]  energy_before :  50  energy_after :  50  reward :  -201.40549873338745\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "action : 1  next_temperatures :  [-1.738825   -0.92370471 -1.33800601 -1.17702011 -1.83128681 -0.93624203\n",
      " -1.27674059 -1.37475808 -1.80891538]  energy_before :  50  energy_after :  50  reward :  -210.40549873338745\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step\n",
      "Episode 11/500, Total Reward: -1027.0274936669373\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "action : 1  next_temperatures :  [-3.04887628  1.26413933 -1.93405295  1.21456163 -2.52615162  1.02857768\n",
      " -2.8173304   1.313711   -2.28621922]  energy_before :  30  energy_after :  50  reward :  -225.7916408176363\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step\n",
      "action : 1  next_temperatures :  [-3.04887628  1.26413933 -1.93405295  1.21456163 -2.52615162  1.02857768\n",
      " -2.8173304   1.313711   -2.28621922]  energy_before :  50  energy_after :  40  reward :  -195.7916408176363\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "action : 1  next_temperatures :  [-3.04887628  1.26413933 -1.93405295  1.21456163 -2.52615162  1.02857768\n",
      " -2.8173304   1.313711   -2.28621922]  energy_before :  40  energy_after :  50  reward :  -215.7916408176363\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step\n",
      "action : 2  next_temperatures :  [-2.04887628  2.26413933 -0.93405295  2.21456163 -1.52615162  2.02857768\n",
      " -1.8173304   2.313711   -1.28621922]  energy_before :  50  energy_after :  50  reward :  -205.7916408176363\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step\n",
      "action : 1  next_temperatures :  [-2.04887628  2.26413933 -0.93405295  2.21456163 -1.52615162  2.02857768\n",
      " -1.8173304   2.313711   -1.28621922]  energy_before :  50  energy_after :  50  reward :  -196.7916408176363\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step\n",
      "Episode 12/500, Total Reward: -1039.9582040881814\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step\n",
      "action : 0  next_temperatures :  [-1.05390414 -1.41961704 -1.46416972 -0.76830952 -1.03370338 -1.59993967\n",
      " -1.26042337 -1.21581625 -1.04993359]  energy_before :  30  energy_after :  50  reward :  -219.86581667558247\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step\n",
      "action : 0  next_temperatures :  [-2.05390414 -2.41961704 -2.46416972 -1.76830952 -2.03370338 -2.59993967\n",
      " -2.26042337 -2.21581625 -2.04993359]  energy_before :  50  energy_after :  40  reward :  -198.86581667558247\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step\n",
      "action : 1  next_temperatures :  [-2.05390414 -2.41961704 -2.46416972 -1.76830952 -2.03370338 -2.59993967\n",
      " -2.26042337 -2.21581625 -2.04993359]  energy_before :  40  energy_after :  50  reward :  -227.86581667558247\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step\n",
      "action : 0  next_temperatures :  [-3.05390414 -3.41961704 -3.46416972 -2.76830952 -3.03370338 -3.59993967\n",
      " -3.26042337 -3.21581625 -3.04993359]  energy_before :  50  energy_after :  50  reward :  -217.86581667558247\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "action : 1  next_temperatures :  [-3.05390414 -3.41961704 -3.46416972 -2.76830952 -3.03370338 -3.59993967\n",
      " -3.26042337 -3.21581625 -3.04993359]  energy_before :  50  energy_after :  50  reward :  -226.86581667558247\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "Episode 13/500, Total Reward: -1091.3290833779124\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "action : 1  next_temperatures :  [-0.18466176  0.88131512  0.39161544  0.40287387 -0.13340131  0.01459518\n",
      "  0.01696922 -0.07530245  0.27534432]  energy_before :  30  energy_after :  50  reward :  -216.41065235679656\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "action : 1  next_temperatures :  [-0.18466176  0.88131512  0.39161544  0.40287387 -0.13340131  0.01459518\n",
      "  0.01696922 -0.07530245  0.27534432]  energy_before :  50  energy_after :  40  reward :  -186.41065235679656\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "action : 1  next_temperatures :  [-0.18466176  0.88131512  0.39161544  0.40287387 -0.13340131  0.01459518\n",
      "  0.01696922 -0.07530245  0.27534432]  energy_before :  40  energy_after :  50  reward :  -206.41065235679656\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "action : 0  next_temperatures :  [-1.18466176 -0.11868488 -0.60838456 -0.59712613 -1.13340131 -0.98540482\n",
      " -0.98303078 -1.07530245 -0.72465568]  energy_before :  50  energy_after :  50  reward :  -196.41065235679656\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "action : 2  next_temperatures :  [-0.18466176  0.88131512  0.39161544  0.40287387 -0.13340131  0.01459518\n",
      "  0.01696922 -0.07530245  0.27534432]  energy_before :  50  energy_after :  50  reward :  -205.41065235679656\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "Episode 14/500, Total Reward: -1011.0532617839829\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "action : 0  next_temperatures :  [-0.74257647 -1.42715624 -0.92759395 -1.49645324 -1.38264613 -1.10523912\n",
      " -1.76625693 -0.95398452 -1.67880421]  energy_before :  30  energy_after :  50  reward :  -220.48071080887163\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "action : 2  next_temperatures :  [ 0.25742353 -0.42715624  0.07240605 -0.49645324 -0.38264613 -0.10523912\n",
      " -0.76625693  0.04601548 -0.67880421]  energy_before :  50  energy_after :  40  reward :  -199.48071080887163\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "action : 1  next_temperatures :  [ 0.25742353 -0.42715624  0.07240605 -0.49645324 -0.38264613 -0.10523912\n",
      " -0.76625693  0.04601548 -0.67880421]  energy_before :  40  energy_after :  50  reward :  -210.48071080887163\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "action : 0  next_temperatures :  [-0.74257647 -1.42715624 -0.92759395 -1.49645324 -1.38264613 -1.10523912\n",
      " -1.76625693 -0.95398452 -1.67880421]  energy_before :  50  energy_after :  50  reward :  -200.48071080887163\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step\n",
      "action : 0  next_temperatures :  [-1.74257647 -2.42715624 -1.92759395 -2.49645324 -2.38264613 -2.10523912\n",
      " -2.76625693 -1.95398452 -2.67880421]  energy_before :  50  energy_after :  50  reward :  -209.48071080887163\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step\n",
      "Episode 15/500, Total Reward: -1040.403554044358\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "action : 1  next_temperatures :  [1.93236637 1.76675318 1.28279593 2.08358354 2.09152416 1.22522883\n",
      " 1.91978917 1.41111635 2.38965073]  energy_before :  30  energy_after :  50  reward :  -201.89719173205262\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step\n",
      "action : 2  next_temperatures :  [2.93236637 2.76675318 2.28279593 3.08358354 3.09152416 2.22522883\n",
      " 2.91978917 2.41111635 3.38965073]  energy_before :  50  energy_after :  40  reward :  -171.89719173205262\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step\n",
      "action : 1  next_temperatures :  [2.93236637 2.76675318 2.28279593 3.08358354 3.09152416 2.22522883\n",
      " 2.91978917 2.41111635 3.38965073]  energy_before :  40  energy_after :  50  reward :  -182.89719173205262\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step\n",
      "action : 2  next_temperatures :  [3.93236637 3.76675318 3.28279593 4.08358354 4.09152416 3.22522883\n",
      " 3.91978917 3.41111635 4.38965073]  energy_before :  50  energy_after :  50  reward :  -172.89719173205262\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "action : 2  next_temperatures :  [4.93236637 4.76675318 4.28279593 5.08358354 5.09152416 4.22522883\n",
      " 4.91978917 4.41111635 5.38965073]  energy_before :  50  energy_after :  50  reward :  -163.89719173205262\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step\n",
      "Episode 16/500, Total Reward: -893.4859586602631\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "action : 1  next_temperatures :  [0.81781333 0.15168736 0.07240605 0.82919423 1.12943914 0.01459518\n",
      " 1.01395084 0.27022329 0.81747417]  energy_before :  30  energy_after :  50  reward :  -212.88321641328162\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "action : 1  next_temperatures :  [0.81781333 0.15168736 0.07240605 0.82919423 1.12943914 0.01459518\n",
      " 1.01395084 0.27022329 0.81747417]  energy_before :  50  energy_after :  40  reward :  -182.88321641328162\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step\n",
      "action : 1  next_temperatures :  [0.81781333 0.15168736 0.07240605 0.82919423 1.12943914 0.01459518\n",
      " 1.01395084 0.27022329 0.81747417]  energy_before :  40  energy_after :  50  reward :  -202.88321641328162\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "action : 0  next_temperatures :  [-0.18218667 -0.84831264 -0.92759395 -0.17080577  0.12943914 -0.98540482\n",
      "  0.01395084 -0.72977671 -0.18252583]  energy_before :  50  energy_after :  50  reward :  -192.88321641328162\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step\n",
      "action : 0  next_temperatures :  [-1.18218667 -1.84831264 -1.92759395 -1.17080577 -0.87056086 -1.98540482\n",
      " -0.98604916 -1.72977671 -1.18252583]  energy_before :  50  energy_after :  50  reward :  -201.88321641328162\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "Episode 17/500, Total Reward: -993.4160820664081\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "action : 1  next_temperatures :  [-1.56903211 -0.19930464 -1.20443149 -0.06317087 -1.66542616 -0.05710055\n",
      " -1.45157981 -0.37475808 -1.77812307]  energy_before :  30  energy_after :  50  reward :  -226.36292678434538\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step\n",
      "action : 1  next_temperatures :  [-1.56903211 -0.19930464 -1.20443149 -0.06317087 -1.66542616 -0.05710055\n",
      " -1.45157981 -0.37475808 -1.77812307]  energy_before :  50  energy_after :  40  reward :  -196.36292678434538\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step\n",
      "action : 2  next_temperatures :  [-0.56903211  0.80069536 -0.20443149  0.93682913 -0.66542616  0.94289945\n",
      " -0.45157981  0.62524192 -0.77812307]  energy_before :  40  energy_after :  50  reward :  -216.36292678434538\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "action : 2  next_temperatures :  [0.43096789 1.80069536 0.79556851 1.93682913 0.33457384 1.94289945\n",
      " 0.54842019 1.62524192 0.22187693]  energy_before :  50  energy_after :  50  reward :  -197.36292678434538\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step\n",
      "action : 1  next_temperatures :  [0.43096789 1.80069536 0.79556851 1.93682913 0.33457384 1.94289945\n",
      " 0.54842019 1.62524192 0.22187693]  energy_before :  50  energy_after :  50  reward :  -188.36292678434538\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "Episode 18/500, Total Reward: -1024.814633921727\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "action : 1  next_temperatures :  [-1.23694927 -0.57626502 -1.29563417 -0.24336391 -0.70167951  0.02586165\n",
      " -0.96206346 -0.83545906 -0.80891538]  energy_before :  30  energy_after :  50  reward :  -224.6344681296481\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "action : 0  next_temperatures :  [-2.23694927 -1.57626502 -2.29563417 -1.24336391 -1.70167951 -0.97413835\n",
      " -1.96206346 -1.83545906 -1.80891538]  energy_before :  50  energy_after :  40  reward :  -194.6344681296481\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "action : 1  next_temperatures :  [-2.23694927 -1.57626502 -2.29563417 -1.24336391 -1.70167951 -0.97413835\n",
      " -1.96206346 -1.83545906 -1.80891538]  energy_before :  40  energy_after :  50  reward :  -223.6344681296481\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "action : 1  next_temperatures :  [-2.23694927 -1.57626502 -2.29563417 -1.24336391 -1.70167951 -0.97413835\n",
      " -1.96206346 -1.83545906 -1.80891538]  energy_before :  50  energy_after :  50  reward :  -213.6344681296481\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step\n",
      "action : 1  next_temperatures :  [-2.23694927 -1.57626502 -2.29563417 -1.24336391 -1.70167951 -0.97413835\n",
      " -1.96206346 -1.83545906 -1.80891538]  energy_before :  50  energy_after :  50  reward :  -213.6344681296481\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "Episode 19/500, Total Reward: -1070.1723406482406\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "action : 0  next_temperatures :  [-2.52959727 -1.30904199 -2.16339028 -1.22616367 -2.2799275  -0.59287069\n",
      " -2.1040232  -1.19892388 -2.35104523]  energy_before :  30  energy_after :  50  reward :  -224.7549837086332\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "action : 1  next_temperatures :  [-2.52959727 -1.30904199 -2.16339028 -1.22616367 -2.2799275  -0.59287069\n",
      " -2.1040232  -1.19892388 -2.35104523]  energy_before :  50  energy_after :  40  reward :  -203.75498370863318\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "action : 1  next_temperatures :  [-2.52959727 -1.30904199 -2.16339028 -1.22616367 -2.2799275  -0.59287069\n",
      " -2.1040232  -1.19892388 -2.35104523]  energy_before :  40  energy_after :  50  reward :  -223.75498370863318\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "action : 1  next_temperatures :  [-2.52959727 -1.30904199 -2.16339028 -1.22616367 -2.2799275  -0.59287069\n",
      " -2.1040232  -1.19892388 -2.35104523]  energy_before :  50  energy_after :  50  reward :  -213.75498370863318\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "action : 2  next_temperatures :  [-1.52959727 -0.30904199 -1.16339028 -0.22616367 -1.2799275   0.40712931\n",
      " -1.1040232  -0.19892388 -1.35104523]  energy_before :  50  energy_after :  50  reward :  -213.75498370863318\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "Episode 20/500, Total Reward: -1079.7749185431658\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "action : 2  next_temperatures :  [2.44046866 0.40698119 1.75642617 0.64278684 2.05798895 0.49224056\n",
      " 2.39251014 0.46399657 1.81747417]  energy_before :  30  energy_after :  50  reward :  -214.52912674499086\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "action : 0  next_temperatures :  [ 1.44046866 -0.59301881  0.75642617 -0.35721316  1.05798895 -0.50775944\n",
      "  1.39251014 -0.53600343  0.81747417]  energy_before :  50  energy_after :  40  reward :  -175.52912674499086\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "action : 2  next_temperatures :  [2.44046866 0.40698119 1.75642617 0.64278684 2.05798895 0.49224056\n",
      " 2.39251014 0.46399657 1.81747417]  energy_before :  40  energy_after :  50  reward :  -204.52912674499086\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step\n",
      "action : 1  next_temperatures :  [2.44046866 0.40698119 1.75642617 0.64278684 2.05798895 0.49224056\n",
      " 2.39251014 0.46399657 1.81747417]  energy_before :  50  energy_after :  50  reward :  -185.52912674499086\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "action : 2  next_temperatures :  [3.44046866 1.40698119 2.75642617 1.64278684 3.05798895 1.49224056\n",
      " 3.39251014 1.46399657 2.81747417]  energy_before :  50  energy_after :  50  reward :  -185.52912674499086\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "Episode 21/500, Total Reward: -965.6456337249543\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "action : 2  next_temperatures :  [ 2.06064891 -0.47259304  2.75965567 -1.55311112  1.46478627 -0.64157624\n",
      "  2.19180844 -0.32840911  1.54640924]  energy_before :  30  energy_after :  50  reward :  -219.97238097648685\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "action : 0  next_temperatures :  [ 1.06064891 -1.47259304  1.75965567 -2.55311112  0.46478627 -1.64157624\n",
      "  1.19180844 -1.32840911  0.54640924]  energy_before :  50  energy_after :  40  reward :  -180.97238097648685\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step\n",
      "action : 0  next_temperatures :  [ 0.06064891 -2.47259304  0.75965567 -3.55311112 -0.53521373 -2.64157624\n",
      "  0.19180844 -2.32840911 -0.45359076]  energy_before :  40  energy_after :  50  reward :  -209.97238097648685\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step\n",
      "action : 1  next_temperatures :  [ 0.06064891 -2.47259304  0.75965567 -3.55311112 -0.53521373 -2.64157624\n",
      "  0.19180844 -2.32840911 -0.45359076]  energy_before :  50  energy_after :  50  reward :  -208.97238097648685\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step\n",
      "action : 1  next_temperatures :  [ 0.06064891 -2.47259304  0.75965567 -3.55311112 -0.53521373 -2.64157624\n",
      "  0.19180844 -2.32840911 -0.45359076]  energy_before :  50  energy_after :  50  reward :  -208.97238097648685\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "Episode 22/500, Total Reward: -1028.8619048824341\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "action : 1  next_temperatures :  [ 0.12666591  0.38456511 -0.38360736  1.19654233  0.96327592  0.17949536\n",
      "  0.41347746  0.29095483  0.64941392]  energy_before :  30  energy_after :  50  reward :  -214.17921652053369\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "action : 0  next_temperatures :  [-0.87333409 -0.61543489 -1.38360736  0.19654233 -0.03672408 -0.82050464\n",
      " -0.58652254 -0.70904517 -0.35058608]  energy_before :  50  energy_after :  40  reward :  -184.17921652053369\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "action : 2  next_temperatures :  [ 0.12666591  0.38456511 -0.38360736  1.19654233  0.96327592  0.17949536\n",
      "  0.41347746  0.29095483  0.64941392]  energy_before :  40  energy_after :  50  reward :  -213.17921652053369\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "action : 2  next_temperatures :  [1.12666591 1.38456511 0.61639264 2.19654233 1.96327592 1.17949536\n",
      " 1.41347746 1.29095483 1.64941392]  energy_before :  50  energy_after :  50  reward :  -194.17921652053369\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "action : 1  next_temperatures :  [1.12666591 1.38456511 0.61639264 2.19654233 1.96327592 1.17949536\n",
      " 1.41347746 1.29095483 1.64941392]  energy_before :  50  energy_after :  50  reward :  -185.17921652053369\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "Episode 23/500, Total Reward: -990.8960826026685\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "action : 2  next_temperatures :  [-0.8596046   2.48361404 -0.11778894  2.42014551 -0.32977646  2.64311253\n",
      " -0.54458791  2.76750147 -0.283279  ]  energy_before :  30  energy_after :  50  reward :  -218.82066335808253\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "action : 1  next_temperatures :  [-0.8596046   2.48361404 -0.11778894  2.42014551 -0.32977646  2.64311253\n",
      " -0.54458791  2.76750147 -0.283279  ]  energy_before :  50  energy_after :  40  reward :  -179.82066335808253\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step\n",
      "action : 0  next_temperatures :  [-1.8596046   1.48361404 -1.11778894  1.42014551 -1.32977646  1.64311253\n",
      " -1.54458791  1.76750147 -1.283279  ]  energy_before :  40  energy_after :  50  reward :  -199.82066335808253\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "action : 0  next_temperatures :  [-2.8596046   0.48361404 -2.11778894  0.42014551 -2.32977646  0.64311253\n",
      " -2.54458791  0.76750147 -2.283279  ]  energy_before :  50  energy_after :  50  reward :  -198.82066335808253\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step\n",
      "action : 1  next_temperatures :  [-2.8596046   0.48361404 -2.11778894  0.42014551 -2.32977646  0.64311253\n",
      " -2.54458791  0.76750147 -2.283279  ]  energy_before :  50  energy_after :  50  reward :  -207.82066335808253\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "Episode 24/500, Total Reward: -1005.1033167904127\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step\n",
      "action : 2  next_temperatures :  [ 2.06064891  0.59797445  2.07563555 -1.06167555  1.50965034  0.15424639\n",
      "  2.0498487   0.04091951  2.10661009]  energy_before :  30  energy_after :  50  reward :  -217.46614160939896\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "action : 1  next_temperatures :  [ 2.06064891  0.59797445  2.07563555 -1.06167555  1.50965034  0.15424639\n",
      "  2.0498487   0.04091951  2.10661009]  energy_before :  50  energy_after :  40  reward :  -178.46614160939896\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step\n",
      "action : 1  next_temperatures :  [ 2.06064891  0.59797445  2.07563555 -1.06167555  1.50965034  0.15424639\n",
      "  2.0498487   0.04091951  2.10661009]  energy_before :  40  energy_after :  50  reward :  -198.46614160939896\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step\n",
      "action : 1  next_temperatures :  [ 2.06064891  0.59797445  2.07563555 -1.06167555  1.50965034  0.15424639\n",
      "  2.0498487   0.04091951  2.10661009]  energy_before :  50  energy_after :  50  reward :  -188.46614160939896\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step\n",
      "action : 1  next_temperatures :  [ 2.06064891  0.59797445  2.07563555 -1.06167555  1.50965034  0.15424639\n",
      "  2.0498487   0.04091951  2.10661009]  energy_before :  50  energy_after :  50  reward :  -188.46614160939896\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "Episode 25/500, Total Reward: -971.3307080469948\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step\n",
      "action : 1  next_temperatures :  [ 0.50648566 -1.24892988 -0.1404002  -1.03703237  0.06100966 -1.12229429\n",
      "  0.10345044 -1.09805862  0.31148631]  energy_before :  30  energy_after :  50  reward :  -221.66428329214403\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step\n",
      "action : 1  next_temperatures :  [ 0.50648566 -1.24892988 -0.1404002  -1.03703237  0.06100966 -1.12229429\n",
      "  0.10345044 -1.09805862  0.31148631]  energy_before :  50  energy_after :  40  reward :  -191.66428329214403\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "action : 1  next_temperatures :  [ 0.50648566 -1.24892988 -0.1404002  -1.03703237  0.06100966 -1.12229429\n",
      "  0.10345044 -1.09805862  0.31148631]  energy_before :  40  energy_after :  50  reward :  -211.66428329214403\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "action : 1  next_temperatures :  [ 0.50648566 -1.24892988 -0.1404002  -1.03703237  0.06100966 -1.12229429\n",
      "  0.10345044 -1.09805862  0.31148631]  energy_before :  50  energy_after :  50  reward :  -201.66428329214403\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "action : 1  next_temperatures :  [ 0.50648566 -1.24892988 -0.1404002  -1.03703237  0.06100966 -1.12229429\n",
      "  0.10345044 -1.09805862  0.31148631]  energy_before :  50  energy_after :  50  reward :  -201.66428329214403\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "Episode 26/500, Total Reward: -1028.3214164607202\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "action : 1  next_temperatures :  [-0.24692729 -0.42715624 -1.20443149  0.8549946   0.01116069 -0.68904722\n",
      "  0.50648556 -0.70712093  0.37834899]  energy_before :  30  energy_after :  50  reward :  -219.5236933342937\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "action : 2  next_temperatures :  [ 0.75307271  0.57284376 -0.20443149  1.8549946   1.01116069  0.31095278\n",
      "  1.50648556  0.29287907  1.37834899]  energy_before :  50  energy_after :  40  reward :  -189.5236933342937\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step\n",
      "action : 1  next_temperatures :  [ 0.75307271  0.57284376 -0.20443149  1.8549946   1.01116069  0.31095278\n",
      "  1.50648556  0.29287907  1.37834899]  energy_before :  40  energy_after :  50  reward :  -200.5236933342937\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step\n",
      "action : 2  next_temperatures :  [1.75307271 1.57284376 0.79556851 2.8549946  2.01116069 1.31095278\n",
      " 2.50648556 1.29287907 2.37834899]  energy_before :  50  energy_after :  50  reward :  -190.5236933342937\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "action : 1  next_temperatures :  [1.75307271 1.57284376 0.79556851 2.8549946  2.01116069 1.31095278\n",
      " 2.50648556 1.29287907 2.37834899]  energy_before :  50  energy_after :  50  reward :  -181.5236933342937\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step\n",
      "Episode 27/500, Total Reward: -981.6184666714686\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "action : 1  next_temperatures :  [-0.738825   -1.14589404 -0.88978224 -0.76019033 -1.1303806  -0.56614025\n",
      " -1.27045876 -0.82010236 -0.53785045]  energy_before :  30  energy_after :  50  reward :  -225.85962404050957\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "action : 1  next_temperatures :  [-0.738825   -1.14589404 -0.88978224 -0.76019033 -1.1303806  -0.56614025\n",
      " -1.27045876 -0.82010236 -0.53785045]  energy_before :  50  energy_after :  40  reward :  -195.85962404050957\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "action : 1  next_temperatures :  [-0.738825   -1.14589404 -0.88978224 -0.76019033 -1.1303806  -0.56614025\n",
      " -1.27045876 -0.82010236 -0.53785045]  energy_before :  40  energy_after :  50  reward :  -215.85962404050957\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "action : 1  next_temperatures :  [-0.738825   -1.14589404 -0.88978224 -0.76019033 -1.1303806  -0.56614025\n",
      " -1.27045876 -0.82010236 -0.53785045]  energy_before :  50  energy_after :  50  reward :  -205.85962404050957\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "action : 1  next_temperatures :  [-0.738825   -1.14589404 -0.88978224 -0.76019033 -1.1303806  -0.56614025\n",
      " -1.27045876 -0.82010236 -0.53785045]  energy_before :  50  energy_after :  50  reward :  -205.85962404050957\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "Episode 28/500, Total Reward: -1049.2981202025478\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "action : 1  next_temperatures :  [ 1.6280739  -0.53678481  1.4002638  -0.99650489  1.29991828 -0.65452952\n",
      "  1.58405725 -0.14261266  0.96272272]  energy_before :  30  energy_after :  50  reward :  -213.45539591510354\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "action : 1  next_temperatures :  [ 1.6280739  -0.53678481  1.4002638  -0.99650489  1.29991828 -0.65452952\n",
      "  1.58405725 -0.14261266  0.96272272]  energy_before :  50  energy_after :  40  reward :  -183.45539591510354\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "action : 2  next_temperatures :  [2.6280739  0.46321519 2.4002638  0.00349511 2.29991828 0.34547048\n",
      " 2.58405725 0.85738734 1.96272272]  energy_before :  40  energy_after :  50  reward :  -203.45539591510354\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step\n",
      "action : 0  next_temperatures :  [ 1.6280739  -0.53678481  1.4002638  -0.99650489  1.29991828 -0.65452952\n",
      "  1.58405725 -0.14261266  0.96272272]  energy_before :  50  energy_after :  50  reward :  -184.45539591510354\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "action : 1  next_temperatures :  [ 1.6280739  -0.53678481  1.4002638  -0.99650489  1.29991828 -0.65452952\n",
      "  1.58405725 -0.14261266  0.96272272]  energy_before :  50  energy_after :  50  reward :  -193.45539591510354\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "Episode 29/500, Total Reward: -978.2769795755177\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "action : 1  next_temperatures :  [2.18765506 1.9602595  3.08209455 0.15540095 1.86055729 1.76294682\n",
      " 2.56734936 1.20051019 2.33001645]  energy_before :  30  energy_after :  50  reward :  -200.89320981613008\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "action : 0  next_temperatures :  [ 1.18765506  0.9602595   2.08209455 -0.84459905  0.86055729  0.76294682\n",
      "  1.56734936  0.20051019  1.33001645]  energy_before :  50  energy_after :  40  reward :  -170.89320981613008\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "action : 1  next_temperatures :  [ 1.18765506  0.9602595   2.08209455 -0.84459905  0.86055729  0.76294682\n",
      "  1.56734936  0.20051019  1.33001645]  energy_before :  40  energy_after :  50  reward :  -199.89320981613008\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step\n",
      "action : 1  next_temperatures :  [ 1.18765506  0.9602595   2.08209455 -0.84459905  0.86055729  0.76294682\n",
      "  1.56734936  0.20051019  1.33001645]  energy_before :  50  energy_after :  50  reward :  -189.89320981613008\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "action : 1  next_temperatures :  [ 1.18765506  0.9602595   2.08209455 -0.84459905  0.86055729  0.76294682\n",
      "  1.56734936  0.20051019  1.33001645]  energy_before :  50  energy_after :  50  reward :  -189.89320981613008\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "Episode 30/500, Total Reward: -951.4660490806505\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "action : 1  next_temperatures :  [-0.98788713 -0.01501289 -0.62833455 -0.54559679 -0.98581861 -0.56614025\n",
      " -0.85926503 -1.10496913 -1.02576732]  energy_before :  30  energy_after :  50  reward :  -224.71879171610112\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step\n",
      "action : 1  next_temperatures :  [-0.98788713 -0.01501289 -0.62833455 -0.54559679 -0.98581861 -0.56614025\n",
      " -0.85926503 -1.10496913 -1.02576732]  energy_before :  50  energy_after :  40  reward :  -194.71879171610112\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "action : 1  next_temperatures :  [-0.98788713 -0.01501289 -0.62833455 -0.54559679 -0.98581861 -0.56614025\n",
      " -0.85926503 -1.10496913 -1.02576732]  energy_before :  40  energy_after :  50  reward :  -214.71879171610112\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step\n",
      "action : 1  next_temperatures :  [-0.98788713 -0.01501289 -0.62833455 -0.54559679 -0.98581861 -0.56614025\n",
      " -0.85926503 -1.10496913 -1.02576732]  energy_before :  50  energy_after :  50  reward :  -204.71879171610112\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step\n",
      "action : 1  next_temperatures :  [-0.98788713 -0.01501289 -0.62833455 -0.54559679 -0.98581861 -0.56614025\n",
      " -0.85926503 -1.10496913 -1.02576732]  energy_before :  50  energy_after :  50  reward :  -204.71879171610112\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step\n",
      "Episode 31/500, Total Reward: -1043.5939585805056\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "action : 2  next_temperatures :  [-0.2992148   0.23106634  0.25158192  0.05142603  0.35614529  0.53034172\n",
      " -0.20682164  0.08622177 -0.0908229 ]  energy_before :  30  energy_after :  50  reward :  -226.09007625710757\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step\n",
      "action : 1  next_temperatures :  [-0.2992148   0.23106634  0.25158192  0.05142603  0.35614529  0.53034172\n",
      " -0.20682164  0.08622177 -0.0908229 ]  energy_before :  50  energy_after :  40  reward :  -187.09007625710757\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "action : 2  next_temperatures :  [0.7007852  1.23106634 1.25158192 1.05142603 1.35614529 1.53034172\n",
      " 0.79317836 1.08622177 0.9091771 ]  energy_before :  40  energy_after :  50  reward :  -207.09007625710757\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "action : 2  next_temperatures :  [1.7007852  2.23106634 2.25158192 2.05142603 2.35614529 2.53034172\n",
      " 1.79317836 2.08622177 1.9091771 ]  energy_before :  50  energy_after :  50  reward :  -188.09007625710757\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "action : 1  next_temperatures :  [1.7007852  2.23106634 2.25158192 2.05142603 2.35614529 2.53034172\n",
      " 1.79317836 2.08622177 1.9091771 ]  energy_before :  50  energy_after :  50  reward :  -179.09007625710757\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "Episode 32/500, Total Reward: -987.4503812855378\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "action : 1  next_temperatures :  [-0.18466176 -0.36935565 -0.61161406  0.3881308  -0.08355234 -0.5886732\n",
      " -0.32079706 -0.21581625 -0.10956787]  energy_before :  30  energy_after :  50  reward :  -220.09590737952945\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "action : 2  next_temperatures :  [0.81533824 0.63064435 0.38838594 1.3881308  0.91644766 0.4113268\n",
      " 0.67920294 0.78418375 0.89043213]  energy_before :  50  energy_after :  40  reward :  -190.09590737952945\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "action : 1  next_temperatures :  [0.81533824 0.63064435 0.38838594 1.3881308  0.91644766 0.4113268\n",
      " 0.67920294 0.78418375 0.89043213]  energy_before :  40  energy_after :  50  reward :  -201.09590737952945\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "action : 1  next_temperatures :  [0.81533824 0.63064435 0.38838594 1.3881308  0.91644766 0.4113268\n",
      " 0.67920294 0.78418375 0.89043213]  energy_before :  50  energy_after :  50  reward :  -191.09590737952945\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "action : 0  next_temperatures :  [-0.18466176 -0.36935565 -0.61161406  0.3881308  -0.08355234 -0.5886732\n",
      " -0.32079706 -0.21581625 -0.10956787]  energy_before :  50  energy_after :  50  reward :  -191.09590737952945\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "Episode 33/500, Total Reward: -993.4795368976472\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "action : 0  next_temperatures :  [ 1.16689988 -0.98318068  1.98633174 -2.54648725  1.03502867 -1.45736759\n",
      "  1.07783302 -1.021554    1.00473854]  energy_before :  30  energy_after :  50  reward :  -208.73775767921904\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "action : 1  next_temperatures :  [ 1.16689988 -0.98318068  1.98633174 -2.54648725  1.03502867 -1.45736759\n",
      "  1.07783302 -1.021554    1.00473854]  energy_before :  50  energy_after :  40  reward :  -187.73775767921904\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "action : 1  next_temperatures :  [ 1.16689988 -0.98318068  1.98633174 -2.54648725  1.03502867 -1.45736759\n",
      "  1.07783302 -1.021554    1.00473854]  energy_before :  40  energy_after :  50  reward :  -207.73775767921904\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step\n",
      "action : 1  next_temperatures :  [ 1.16689988 -0.98318068  1.98633174 -2.54648725  1.03502867 -1.45736759\n",
      "  1.07783302 -1.021554    1.00473854]  energy_before :  50  energy_after :  50  reward :  -197.73775767921904\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "action : 1  next_temperatures :  [ 1.16689988 -0.98318068  1.98633174 -2.54648725  1.03502867 -1.45736759\n",
      "  1.07783302 -1.021554    1.00473854]  energy_before :  50  energy_after :  50  reward :  -197.73775767921904\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "Episode 34/500, Total Reward: -999.6887883960952\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step\n",
      "action : 0  next_temperatures :  [ 1.78955521 -0.24601372  2.00305223 -1.58736882  2.271283   -1.15010016\n",
      "  1.37154283 -0.20655203  1.54686839]  energy_before :  30  energy_after :  50  reward :  -203.20773307660556\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "action : 1  next_temperatures :  [ 1.78955521 -0.24601372  2.00305223 -1.58736882  2.271283   -1.15010016\n",
      "  1.37154283 -0.20655203  1.54686839]  energy_before :  50  energy_after :  40  reward :  -182.20773307660556\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "action : 1  next_temperatures :  [ 1.78955521 -0.24601372  2.00305223 -1.58736882  2.271283   -1.15010016\n",
      "  1.37154283 -0.20655203  1.54686839]  energy_before :  40  energy_after :  50  reward :  -202.20773307660556\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "action : 1  next_temperatures :  [ 1.78955521 -0.24601372  2.00305223 -1.58736882  2.271283   -1.15010016\n",
      "  1.37154283 -0.20655203  1.54686839]  energy_before :  50  energy_after :  50  reward :  -192.20773307660556\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "action : 1  next_temperatures :  [ 1.78955521 -0.24601372  2.00305223 -1.58736882  2.271283   -1.15010016\n",
      "  1.37154283 -0.20655203  1.54686839]  energy_before :  50  energy_after :  50  reward :  -192.20773307660556\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step\n",
      "Episode 35/500, Total Reward: -972.0386653830278\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "action : 1  next_temperatures :  [-0.738825   -0.78568745 -1.07066756  0.23250954 -0.65016891 -1.7142962\n",
      " -0.47254712 -1.55184908 -0.3806328 ]  energy_before :  30  energy_after :  50  reward :  -225.1321645823501\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "action : 1  next_temperatures :  [-0.738825   -0.78568745 -1.07066756  0.23250954 -0.65016891 -1.7142962\n",
      " -0.47254712 -1.55184908 -0.3806328 ]  energy_before :  50  energy_after :  40  reward :  -195.1321645823501\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "action : 2  next_temperatures :  [ 0.261175    0.21431255 -0.07066756  1.23250954  0.34983109 -0.7142962\n",
      "  0.52745288 -0.55184908  0.6193672 ]  energy_before :  40  energy_after :  50  reward :  -215.1321645823501\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step\n",
      "action : 0  next_temperatures :  [-0.738825   -0.78568745 -1.07066756  0.23250954 -0.65016891 -1.7142962\n",
      " -0.47254712 -1.55184908 -0.3806328 ]  energy_before :  50  energy_after :  50  reward :  -196.1321645823501\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "action : 2  next_temperatures :  [ 0.261175    0.21431255 -0.07066756  1.23250954  0.34983109 -0.7142962\n",
      "  0.52745288 -0.55184908  0.6193672 ]  energy_before :  50  energy_after :  50  reward :  -205.1321645823501\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "Episode 36/500, Total Reward: -1036.6608229117505\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "action : 1  next_temperatures :  [ 0.68705571 -0.09040497  0.0876065   0.5109897   0.8991844  -0.71977397\n",
      "  0.9029938  -0.100641   -0.10956787]  energy_before :  30  energy_after :  50  reward :  -215.93255770992263\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "action : 1  next_temperatures :  [ 0.68705571 -0.09040497  0.0876065   0.5109897   0.8991844  -0.71977397\n",
      "  0.9029938  -0.100641   -0.10956787]  energy_before :  50  energy_after :  40  reward :  -185.93255770992263\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step\n",
      "action : 2  next_temperatures :  [1.68705571 0.90959503 1.0876065  1.5109897  1.8991844  0.28022603\n",
      " 1.9029938  0.899359   0.89043213]  energy_before :  40  energy_after :  50  reward :  -205.93255770992263\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "action : 1  next_temperatures :  [1.68705571 0.90959503 1.0876065  1.5109897  1.8991844  0.28022603\n",
      " 1.9029938  0.899359   0.89043213]  energy_before :  50  energy_after :  50  reward :  -186.93255770992263\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "action : 1  next_temperatures :  [1.68705571 0.90959503 1.0876065  1.5109897  1.8991844  0.28022603\n",
      " 1.9029938  0.899359   0.89043213]  energy_before :  50  energy_after :  50  reward :  -186.93255770992263\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step\n",
      "Episode 37/500, Total Reward: -981.6627885496132\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "action : 1  next_temperatures :  [-0.18466176 -0.1167922  -0.79401942  1.01716834  0.31025448 -0.62759374\n",
      " -0.40238311  0.25333092  1.21322896]  energy_before :  30  energy_after :  50  reward :  -217.33146752941943\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "action : 0  next_temperatures :  [-1.18466176 -1.1167922  -1.79401942  0.01716834 -0.68974552 -1.62759374\n",
      " -1.40238311 -0.74666908  0.21322896]  energy_before :  50  energy_after :  40  reward :  -187.33146752941943\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "action : 0  next_temperatures :  [-2.18466176 -2.1167922  -2.79401942 -0.98283166 -1.68974552 -2.62759374\n",
      " -2.40238311 -1.74666908 -0.78677104]  energy_before :  40  energy_after :  50  reward :  -216.33146752941943\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step\n",
      "action : 0  next_temperatures :  [-3.18466176 -3.1167922  -3.79401942 -1.98283166 -2.68974552 -3.62759374\n",
      " -3.40238311 -2.74666908 -1.78677104]  energy_before :  50  energy_after :  50  reward :  -215.33146752941943\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "action : 1  next_temperatures :  [-3.18466176 -3.1167922  -3.79401942 -1.98283166 -2.68974552 -3.62759374\n",
      " -3.40238311 -2.74666908 -1.78677104]  energy_before :  50  energy_after :  50  reward :  -224.33146752941943\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "Episode 38/500, Total Reward: -1060.6573376470972\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "action : 1  next_temperatures :  [-0.18466176 -0.29396358 -0.56601272  0.49460851  0.06100966 -0.47396003\n",
      " -0.22778895  0.07749671  0.66748491]  energy_before :  30  energy_after :  50  reward :  -218.44578723917124\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "action : 0  next_temperatures :  [-1.18466176 -1.29396358 -1.56601272 -0.50539149 -0.93899034 -1.47396003\n",
      " -1.22778895 -0.92250329 -0.33251509]  energy_before :  50  energy_after :  40  reward :  -188.44578723917124\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "action : 1  next_temperatures :  [-1.18466176 -1.29396358 -1.56601272 -0.50539149 -0.93899034 -1.47396003\n",
      " -1.22778895 -0.92250329 -0.33251509]  energy_before :  40  energy_after :  50  reward :  -217.44578723917124\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "action : 1  next_temperatures :  [-1.18466176 -1.29396358 -1.56601272 -0.50539149 -0.93899034 -1.47396003\n",
      " -1.22778895 -0.92250329 -0.33251509]  energy_before :  50  energy_after :  50  reward :  -207.44578723917124\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "action : 1  next_temperatures :  [-1.18466176 -1.29396358 -1.56601272 -0.50539149 -0.93899034 -1.47396003\n",
      " -1.22778895 -0.92250329 -0.33251509]  energy_before :  50  energy_after :  50  reward :  -207.44578723917124\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "Episode 39/500, Total Reward: -1039.2289361958562\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "action : 1  next_temperatures :  [-1.42997242  1.01283241 -0.82442032  0.95082454 -1.23506343  1.51201176\n",
      " -1.3814158   1.21235679 -1.30887957]  energy_before :  30  energy_after :  50  reward :  -219.4917260365205\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "action : 1  next_temperatures :  [-1.42997242  1.01283241 -0.82442032  0.95082454 -1.23506343  1.51201176\n",
      " -1.3814158   1.21235679 -1.30887957]  energy_before :  50  energy_after :  40  reward :  -189.4917260365205\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "action : 1  next_temperatures :  [-1.42997242  1.01283241 -0.82442032  0.95082454 -1.23506343  1.51201176\n",
      " -1.3814158   1.21235679 -1.30887957]  energy_before :  40  energy_after :  50  reward :  -209.4917260365205\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "action : 1  next_temperatures :  [-1.42997242  1.01283241 -0.82442032  0.95082454 -1.23506343  1.51201176\n",
      " -1.3814158   1.21235679 -1.30887957]  energy_before :  50  energy_after :  50  reward :  -199.4917260365205\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "action : 1  next_temperatures :  [-1.42997242  1.01283241 -0.82442032  0.95082454 -1.23506343  1.51201176\n",
      " -1.3814158   1.21235679 -1.30887957]  energy_before :  50  energy_after :  50  reward :  -199.4917260365205\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "Episode 40/500, Total Reward: -1017.4586301826025\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "action : 1  next_temperatures :  [-0.42749733 -1.19615542 -1.4324382   0.10883158 -0.33279717 -1.12229429\n",
      " -0.47254712 -1.29616004 -0.10956787]  energy_before :  30  energy_after :  50  reward :  -224.2806258634883\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "action : 1  next_temperatures :  [-0.42749733 -1.19615542 -1.4324382   0.10883158 -0.33279717 -1.12229429\n",
      " -0.47254712 -1.29616004 -0.10956787]  energy_before :  50  energy_after :  40  reward :  -194.2806258634883\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "action : 2  next_temperatures :  [ 0.57250267 -0.19615542 -0.4324382   1.10883158  0.66720283 -0.12229429\n",
      "  0.52745288 -0.29616004  0.89043213]  energy_before :  40  energy_after :  50  reward :  -214.2806258634883\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "action : 1  next_temperatures :  [ 0.57250267 -0.19615542 -0.4324382   1.10883158  0.66720283 -0.12229429\n",
      "  0.52745288 -0.29616004  0.89043213]  energy_before :  50  energy_after :  50  reward :  -195.2806258634883\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "action : 1  next_temperatures :  [ 0.57250267 -0.19615542 -0.4324382   1.10883158  0.66720283 -0.12229429\n",
      "  0.52745288 -0.29616004  0.89043213]  energy_before :  50  energy_after :  50  reward :  -195.2806258634883\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "Episode 41/500, Total Reward: -1023.4031293174414\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "action : 0  next_temperatures :  [ 1.37445166 -0.41438935  1.07430492 -0.91655926  1.1658822  -0.96005526\n",
      "  1.37154283 -0.34662707  1.11858581]  energy_before :  30  energy_after :  50  reward :  -205.5328635257248\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "action : 0  next_temperatures :  [ 0.37445166 -1.41438935  0.07430492 -1.91655926  0.1658822  -1.96005526\n",
      "  0.37154283 -1.34662707  0.11858581]  energy_before :  50  energy_after :  40  reward :  -184.5328635257248\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "action : 0  next_temperatures :  [-0.62554834 -2.41438935 -0.92569508 -2.91655926 -0.8341178  -2.96005526\n",
      " -0.62845717 -2.34662707 -0.88141419]  energy_before :  40  energy_after :  50  reward :  -213.5328635257248\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "action : 0  next_temperatures :  [-1.62554834 -3.41438935 -1.92569508 -3.91655926 -1.8341178  -3.96005526\n",
      " -1.62845717 -3.34662707 -1.88141419]  energy_before :  50  energy_after :  50  reward :  -212.5328635257248\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "action : 1  next_temperatures :  [-1.62554834 -3.41438935 -1.92569508 -3.91655926 -1.8341178  -3.96005526\n",
      " -1.62845717 -3.34662707 -1.88141419]  energy_before :  50  energy_after :  50  reward :  -221.5328635257248\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "Episode 42/500, Total Reward: -1037.6643176286238\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "action : 1  next_temperatures :  [-0.86958262  0.66351579 -0.47937017  0.6739825  -0.88113578  1.79674624\n",
      " -1.64249118  1.84351713 -1.0799803 ]  energy_before :  30  energy_after :  50  reward :  -217.97479839530223\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "action : 1  next_temperatures :  [-0.86958262  0.66351579 -0.47937017  0.6739825  -0.88113578  1.79674624\n",
      " -1.64249118  1.84351713 -1.0799803 ]  energy_before :  50  energy_after :  40  reward :  -187.97479839530223\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "action : 1  next_temperatures :  [-0.86958262  0.66351579 -0.47937017  0.6739825  -0.88113578  1.79674624\n",
      " -1.64249118  1.84351713 -1.0799803 ]  energy_before :  40  energy_after :  50  reward :  -207.97479839530223\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "action : 1  next_temperatures :  [-0.86958262  0.66351579 -0.47937017  0.6739825  -0.88113578  1.79674624\n",
      " -1.64249118  1.84351713 -1.0799803 ]  energy_before :  50  energy_after :  50  reward :  -197.97479839530223\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "action : 1  next_temperatures :  [-0.86958262  0.66351579 -0.47937017  0.6739825  -0.88113578  1.79674624\n",
      " -1.64249118  1.84351713 -1.0799803 ]  energy_before :  50  energy_after :  50  reward :  -197.97479839530223\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "Episode 43/500, Total Reward: -1009.8739919765112\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "action : 1  next_temperatures :  [ 1.49707369 -0.23776221  1.2611501  -0.48528425  1.31856309 -0.43904327\n",
      "  1.4810681  -0.01876187  0.95004956]  energy_before :  30  energy_after :  50  reward :  -212.672947066405\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "action : 0  next_temperatures :  [ 0.49707369 -1.23776221  0.2611501  -1.48528425  0.31856309 -1.43904327\n",
      "  0.4810681  -1.01876187 -0.04995044]  energy_before :  50  energy_after :  40  reward :  -182.672947066405\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "action : 1  next_temperatures :  [ 0.49707369 -1.23776221  0.2611501  -1.48528425  0.31856309 -1.43904327\n",
      "  0.4810681  -1.01876187 -0.04995044]  energy_before :  40  energy_after :  50  reward :  -211.672947066405\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "action : 2  next_temperatures :  [ 1.49707369 -0.23776221  1.2611501  -0.48528425  1.31856309 -0.43904327\n",
      "  1.4810681  -0.01876187  0.95004956]  energy_before :  50  energy_after :  50  reward :  -201.672947066405\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "action : 0  next_temperatures :  [ 0.49707369 -1.23776221  0.2611501  -1.48528425  0.31856309 -1.43904327\n",
      "  0.4810681  -1.01876187 -0.04995044]  energy_before :  50  energy_after :  50  reward :  -192.672947066405\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "Episode 44/500, Total Reward: -1001.3647353320249\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "action : 1  next_temperatures :  [-0.738825    0.11064057 -0.40032785  0.12603183 -0.73657378  2.33241578\n",
      " -0.3550632  -0.21351274 -0.69506811]  energy_before :  30  energy_after :  50  reward :  -218.57028250097497\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "action : 1  next_temperatures :  [-0.738825    0.11064057 -0.40032785  0.12603183 -0.73657378  2.33241578\n",
      " -0.3550632  -0.21351274 -0.69506811]  energy_before :  50  energy_after :  40  reward :  -188.57028250097497\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "action : 1  next_temperatures :  [-0.738825    0.11064057 -0.40032785  0.12603183 -0.73657378  2.33241578\n",
      " -0.3550632  -0.21351274 -0.69506811]  energy_before :  40  energy_after :  50  reward :  -208.57028250097497\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "action : 1  next_temperatures :  [-0.738825    0.11064057 -0.40032785  0.12603183 -0.73657378  2.33241578\n",
      " -0.3550632  -0.21351274 -0.69506811]  energy_before :  50  energy_after :  50  reward :  -198.57028250097497\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "action : 1  next_temperatures :  [-0.738825    0.11064057 -0.40032785  0.12603183 -0.73657378  2.33241578\n",
      " -0.3550632  -0.21351274 -0.69506811]  energy_before :  50  energy_after :  50  reward :  -198.57028250097497\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "Episode 45/500, Total Reward: -1012.8514125048748\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "action : 1  next_temperatures :  [-1.54827693 -0.07365118 -1.11778894 -0.00501766 -1.61225393  0.11804188\n",
      " -1.29982974 -0.35940138 -1.67632314]  energy_before :  30  energy_after :  50  reward :  -225.57450102370183\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "action : 1  next_temperatures :  [-1.54827693 -0.07365118 -1.11778894 -0.00501766 -1.61225393  0.11804188\n",
      " -1.29982974 -0.35940138 -1.67632314]  energy_before :  50  energy_after :  40  reward :  -195.57450102370183\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "action : 1  next_temperatures :  [-1.54827693 -0.07365118 -1.11778894 -0.00501766 -1.61225393  0.11804188\n",
      " -1.29982974 -0.35940138 -1.67632314]  energy_before :  40  energy_after :  50  reward :  -215.57450102370183\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "action : 1  next_temperatures :  [-1.54827693 -0.07365118 -1.11778894 -0.00501766 -1.61225393  0.11804188\n",
      " -1.29982974 -0.35940138 -1.67632314]  energy_before :  50  energy_after :  50  reward :  -205.57450102370183\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "action : 1  next_temperatures :  [-1.54827693 -0.07365118 -1.11778894 -0.00501766 -1.61225393  0.11804188\n",
      " -1.29982974 -0.35940138 -1.67632314]  energy_before :  50  energy_after :  50  reward :  -205.57450102370183\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "Episode 46/500, Total Reward: -1047.8725051185093\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n",
      "action : 0  next_temperatures :  [-1.42749733  0.15775274 -1.33800601 -1.61931213 -1.75152847 -1.60710924\n",
      " -1.96206346 -1.50759353 -2.13419329]  energy_before :  30  energy_after :  50  reward :  -222.189550740399\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "action : 1  next_temperatures :  [-1.42749733  0.15775274 -1.33800601 -1.61931213 -1.75152847 -1.60710924\n",
      " -1.96206346 -1.50759353 -2.13419329]  energy_before :  50  energy_after :  40  reward :  -201.189550740399\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "action : 2  next_temperatures :  [-0.42749733  1.15775274 -0.33800601 -0.61931213 -0.75152847 -0.60710924\n",
      " -0.96206346 -0.50759353 -1.13419329]  energy_before :  40  energy_after :  50  reward :  -221.189550740399\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "action : 1  next_temperatures :  [-0.42749733  1.15775274 -0.33800601 -0.61931213 -0.75152847 -0.60710924\n",
      " -0.96206346 -0.50759353 -1.13419329]  energy_before :  50  energy_after :  50  reward :  -202.189550740399\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "action : 1  next_temperatures :  [-0.42749733  1.15775274 -0.33800601 -0.61931213 -0.75152847 -0.60710924\n",
      " -0.96206346 -0.50759353 -1.13419329]  energy_before :  50  energy_after :  50  reward :  -202.189550740399\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "Episode 47/500, Total Reward: -1048.947753701995\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "action : 0  next_temperatures :  [-1.55825495 -0.23847451 -1.66177553  0.46928907 -1.33279717 -0.78772944\n",
      " -1.61450686 -0.13316895 -1.21257254]  energy_before :  30  energy_after :  50  reward :  -217.06999088833305\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "action : 1  next_temperatures :  [-1.55825495 -0.23847451 -1.66177553  0.46928907 -1.33279717 -0.78772944\n",
      " -1.61450686 -0.13316895 -1.21257254]  energy_before :  50  energy_after :  40  reward :  -196.06999088833305\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "action : 1  next_temperatures :  [-1.55825495 -0.23847451 -1.66177553  0.46928907 -1.33279717 -0.78772944\n",
      " -1.61450686 -0.13316895 -1.21257254]  energy_before :  40  energy_after :  50  reward :  -216.06999088833305\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "action : 1  next_temperatures :  [-1.55825495 -0.23847451 -1.66177553  0.46928907 -1.33279717 -0.78772944\n",
      " -1.61450686 -0.13316895 -1.21257254]  energy_before :  50  energy_after :  50  reward :  -206.06999088833305\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "action : 1  next_temperatures :  [-1.55825495 -0.23847451 -1.66177553  0.46928907 -1.33279717 -0.78772944\n",
      " -1.61450686 -0.13316895 -1.21257254]  energy_before :  50  energy_after :  50  reward :  -206.06999088833305\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "Episode 48/500, Total Reward: -1041.3499544416652\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "action : 1  next_temperatures :  [-1.11864475 -1.20453232 -1.61940369 -0.11149537 -1.1303806  -0.89594062\n",
      " -0.63898268 -0.73295309 -0.92276265]  energy_before :  30  energy_after :  50  reward :  -226.37509577905945\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "action : 2  next_temperatures :  [-0.11864475 -0.20453232 -0.61940369  0.88850463 -0.1303806   0.10405938\n",
      "  0.36101732  0.26704691  0.07723735]  energy_before :  50  energy_after :  40  reward :  -196.37509577905945\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "action : 2  next_temperatures :  [0.88135525 0.79546768 0.38059631 1.88850463 0.8696194  1.10405938\n",
      " 1.36101732 1.26704691 1.07723735]  energy_before :  40  energy_after :  50  reward :  -207.37509577905945\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "action : 1  next_temperatures :  [0.88135525 0.79546768 0.38059631 1.88850463 0.8696194  1.10405938\n",
      " 1.36101732 1.26704691 1.07723735]  energy_before :  50  energy_after :  50  reward :  -188.37509577905945\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "action : 1  next_temperatures :  [0.88135525 0.79546768 0.38059631 1.88850463 0.8696194  1.10405938\n",
      " 1.36101732 1.26704691 1.07723735]  energy_before :  50  energy_after :  50  reward :  -188.37509577905945\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "Episode 49/500, Total Reward: -1006.8754788952972\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "action : 1  next_temperatures :  [1.56499973 1.11586825 0.66066335 1.55037594 1.80572343 0.93639745\n",
      " 1.43656661 0.84609951 2.00473854]  energy_before :  30  energy_after :  50  reward :  -206.0785671905657\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "action : 1  next_temperatures :  [1.56499973 1.11586825 0.66066335 1.55037594 1.80572343 0.93639745\n",
      " 1.43656661 0.84609951 2.00473854]  energy_before :  50  energy_after :  40  reward :  -176.0785671905657\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "action : 1  next_temperatures :  [1.56499973 1.11586825 0.66066335 1.55037594 1.80572343 0.93639745\n",
      " 1.43656661 0.84609951 2.00473854]  energy_before :  40  energy_after :  50  reward :  -196.0785671905657\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "action : 1  next_temperatures :  [1.56499973 1.11586825 0.66066335 1.55037594 1.80572343 0.93639745\n",
      " 1.43656661 0.84609951 2.00473854]  energy_before :  50  energy_after :  50  reward :  -186.0785671905657\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "action : 0  next_temperatures :  [ 0.56499973  0.11586825 -0.33933665  0.55037594  0.80572343 -0.06360255\n",
      "  0.43656661 -0.15390049  1.00473854]  energy_before :  50  energy_after :  50  reward :  -186.0785671905657\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "Episode 50/500, Total Reward: -950.3928359528286\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "action : 1  next_temperatures :  [ 0.88007886 -1.5002368   0.52841946 -1.612012    0.41493731 -0.98940113\n",
      "  0.9029938  -1.27312499  1.15901597]  energy_before :  30  energy_after :  50  reward :  -219.4893295099585\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "action : 2  next_temperatures :  [ 1.88007886 -0.5002368   1.52841946 -0.612012    1.41493731  0.01059887\n",
      "  1.9029938  -0.27312499  2.15901597]  energy_before :  50  energy_after :  40  reward :  -189.4893295099585\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "action : 2  next_temperatures :  [2.88007886 0.4997632  2.52841946 0.387988   2.41493731 1.01059887\n",
      " 2.9029938  0.72687501 3.15901597]  energy_before :  40  energy_after :  50  reward :  -200.4893295099585\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "action : 1  next_temperatures :  [2.88007886 0.4997632  2.52841946 0.387988   2.41493731 1.01059887\n",
      " 2.9029938  0.72687501 3.15901597]  energy_before :  50  energy_after :  50  reward :  -181.4893295099585\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "action : 0  next_temperatures :  [ 1.88007886 -0.5002368   1.52841946 -0.612012    1.41493731  0.01059887\n",
      "  1.9029938  -0.27312499  2.15901597]  energy_before :  50  energy_after :  50  reward :  -181.4893295099585\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "Episode 51/500, Total Reward: -972.4466475497925\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "action : 1  next_temperatures :  [-0.67655947 -0.67092396 -0.74841808 -0.44976686 -0.63189095 -0.10523912\n",
      " -0.71730529 -0.5221824  -0.86312836]  energy_before :  30  energy_after :  50  reward :  -223.3854144883033\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "action : 2  next_temperatures :  [0.32344053 0.32907604 0.25158192 0.55023314 0.36810905 0.89476088\n",
      " 0.28269471 0.4778176  0.13687164]  energy_before :  50  energy_after :  40  reward :  -193.3854144883033\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "action : 1  next_temperatures :  [0.32344053 0.32907604 0.25158192 0.55023314 0.36810905 0.89476088\n",
      " 0.28269471 0.4778176  0.13687164]  energy_before :  40  energy_after :  50  reward :  -204.3854144883033\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "action : 0  next_temperatures :  [-0.67655947 -0.67092396 -0.74841808 -0.44976686 -0.63189095 -0.10523912\n",
      " -0.71730529 -0.5221824  -0.86312836]  energy_before :  50  energy_after :  50  reward :  -194.3854144883033\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "action : 2  next_temperatures :  [0.32344053 0.32907604 0.25158192 0.55023314 0.36810905 0.89476088\n",
      " 0.28269471 0.4778176  0.13687164]  energy_before :  50  energy_after :  50  reward :  -203.3854144883033\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "Episode 52/500, Total Reward: -1018.9270724415164\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "action : 1  next_temperatures :  [ 0.21591317  0.19357185  0.52841946  0.03429719 -0.66844686  1.00092361\n",
      " -0.17394215  0.76010199  0.3295573 ]  energy_before :  30  energy_after :  50  reward :  -215.77960443160268\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "action : 1  next_temperatures :  [ 0.21591317  0.19357185  0.52841946  0.03429719 -0.66844686  1.00092361\n",
      " -0.17394215  0.76010199  0.3295573 ]  energy_before :  50  energy_after :  40  reward :  -185.77960443160268\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "action : 2  next_temperatures :  [1.21591317 1.19357185 1.52841946 1.03429719 0.33155314 2.00092361\n",
      " 0.82605785 1.76010199 1.3295573 ]  energy_before :  40  energy_after :  50  reward :  -205.77960443160268\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "action : 1  next_temperatures :  [1.21591317 1.19357185 1.52841946 1.03429719 0.33155314 2.00092361\n",
      " 0.82605785 1.76010199 1.3295573 ]  energy_before :  50  energy_after :  50  reward :  -186.77960443160268\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "action : 1  next_temperatures :  [1.21591317 1.19357185 1.52841946 1.03429719 0.33155314 2.00092361\n",
      " 0.82605785 1.76010199 1.3295573 ]  energy_before :  50  energy_after :  50  reward :  -186.77960443160268\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "Episode 53/500, Total Reward: -980.8980221580134\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "action : 1  next_temperatures :  [-0.18466176  1.41743656  0.20464994  0.8549946   0.06100966  1.79674624\n",
      " -0.61450686  1.81357156 -0.49267297]  energy_before :  30  energy_after :  50  reward :  -213.143433022551\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "action : 1  next_temperatures :  [-0.18466176  1.41743656  0.20464994  0.8549946   0.06100966  1.79674624\n",
      " -0.61450686  1.81357156 -0.49267297]  energy_before :  50  energy_after :  40  reward :  -183.143433022551\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "action : 1  next_temperatures :  [-0.18466176  1.41743656  0.20464994  0.8549946   0.06100966  1.79674624\n",
      " -0.61450686  1.81357156 -0.49267297]  energy_before :  40  energy_after :  50  reward :  -203.143433022551\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "action : 1  next_temperatures :  [-0.18466176  1.41743656  0.20464994  0.8549946   0.06100966  1.79674624\n",
      " -0.61450686  1.81357156 -0.49267297]  energy_before :  50  energy_after :  50  reward :  -193.143433022551\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "action : 1  next_temperatures :  [-0.18466176  1.41743656  0.20464994  0.8549946   0.06100966  1.79674624\n",
      " -0.61450686  1.81357156 -0.49267297]  energy_before :  50  energy_after :  50  reward :  -193.143433022551\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "Episode 54/500, Total Reward: -985.717165112755\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "action : 1  next_temperatures :  [ 0.99838337 -0.43469545  0.60659319 -0.59474035  1.00813999 -0.93486116\n",
      "  1.09880034 -0.90686771  1.32862517]  energy_before :  30  energy_after :  50  reward :  -215.8306226204345\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "action : 0  next_temperatures :  [-1.61662510e-03 -1.43469545e+00 -3.93406810e-01 -1.59474035e+00\n",
      "  8.13998993e-03 -1.93486116e+00  9.88003361e-02 -1.90686771e+00\n",
      "  3.28625169e-01]  energy_before :  50  energy_after :  40  reward :  -185.8306226204345\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "action : 2  next_temperatures :  [ 0.99838337 -0.43469545  0.60659319 -0.59474035  1.00813999 -0.93486116\n",
      "  1.09880034 -0.90686771  1.32862517]  energy_before :  40  energy_after :  50  reward :  -214.8306226204345\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "action : 0  next_temperatures :  [-1.61662510e-03 -1.43469545e+00 -3.93406810e-01 -1.59474035e+00\n",
      "  8.13998993e-03 -1.93486116e+00  9.88003361e-02 -1.90686771e+00\n",
      "  3.28625169e-01]  energy_before :  50  energy_after :  50  reward :  -195.8306226204345\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "action : 1  next_temperatures :  [-1.61662510e-03 -1.43469545e+00 -3.93406810e-01 -1.59474035e+00\n",
      "  8.13998993e-03 -1.93486116e+00  9.88003361e-02 -1.90686771e+00\n",
      "  3.28625169e-01]  energy_before :  50  energy_after :  50  reward :  -204.8306226204345\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "Episode 55/500, Total Reward: -1017.1531131021725\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "action : 1  next_temperatures :  [ 0.43799358 -0.9448485   1.51644852 -1.97075997  0.31025448 -0.94612763\n",
      "  1.0498487  -0.946488    0.27534432]  energy_before :  30  energy_after :  50  reward :  -219.21833450649189\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "action : 2  next_temperatures :  [ 1.43799358  0.0551515   2.51644852 -0.97075997  1.31025448  0.05387237\n",
      "  2.0498487   0.053512    1.27534432]  energy_before :  50  energy_after :  40  reward :  -189.21833450649189\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "action : 0  next_temperatures :  [ 0.43799358 -0.9448485   1.51644852 -1.97075997  0.31025448 -0.94612763\n",
      "  1.0498487  -0.946488    0.27534432]  energy_before :  40  energy_after :  50  reward :  -200.21833450649189\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "action : 0  next_temperatures :  [-0.56200642 -1.9448485   0.51644852 -2.97075997 -0.68974552 -1.94612763\n",
      "  0.0498487  -1.946488   -0.72465568]  energy_before :  50  energy_after :  50  reward :  -199.21833450649189\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "action : 2  next_temperatures :  [ 0.43799358 -0.9448485   1.51644852 -1.97075997  0.31025448 -0.94612763\n",
      "  1.0498487  -0.946488    0.27534432]  energy_before :  50  energy_after :  50  reward :  -208.21833450649189\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "Episode 56/500, Total Reward: -1016.0916725324594\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "action : 1  next_temperatures :  [-0.30296627  0.85534674  0.25025128  0.27264344 -0.63189095  0.94766392\n",
      " -0.8103134   1.30680049  1.09757459]  energy_before :  30  energy_after :  50  reward :  -215.01489015094438\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "action : 1  next_temperatures :  [-0.30296627  0.85534674  0.25025128  0.27264344 -0.63189095  0.94766392\n",
      " -0.8103134   1.30680049  1.09757459]  energy_before :  50  energy_after :  40  reward :  -185.01489015094438\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "action : 1  next_temperatures :  [-0.30296627  0.85534674  0.25025128  0.27264344 -0.63189095  0.94766392\n",
      " -0.8103134   1.30680049  1.09757459]  energy_before :  40  energy_after :  50  reward :  -205.01489015094438\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "action : 1  next_temperatures :  [-0.30296627  0.85534674  0.25025128  0.27264344 -0.63189095  0.94766392\n",
      " -0.8103134   1.30680049  1.09757459]  energy_before :  50  energy_after :  50  reward :  -195.01489015094438\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "action : 1  next_temperatures :  [-0.30296627  0.85534674  0.25025128  0.27264344 -0.63189095  0.94766392\n",
      " -0.8103134   1.30680049  1.09757459]  energy_before :  50  energy_after :  50  reward :  -195.01489015094438\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "Episode 57/500, Total Reward: -995.074450754722\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "action : 2  next_temperatures :  [-0.672808    0.70603642 -0.19417119  0.71670695 -0.68370411  0.98694111\n",
      " -0.52255968  0.83025385 -0.35104523]  energy_before :  30  energy_after :  50  reward :  -226.18434987298912\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "action : 2  next_temperatures :  [0.327192   1.70603642 0.80582881 1.71670695 0.31629589 1.98694111\n",
      " 0.47744032 1.83025385 0.64895477]  energy_before :  50  energy_after :  40  reward :  -187.18434987298912\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "action : 1  next_temperatures :  [0.327192   1.70603642 0.80582881 1.71670695 0.31629589 1.98694111\n",
      " 0.47744032 1.83025385 0.64895477]  energy_before :  40  energy_after :  50  reward :  -198.18434987298912\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "action : 1  next_temperatures :  [0.327192   1.70603642 0.80582881 1.71670695 0.31629589 1.98694111\n",
      " 0.47744032 1.83025385 0.64895477]  energy_before :  50  energy_after :  50  reward :  -188.18434987298912\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "action : 1  next_temperatures :  [0.327192   1.70603642 0.80582881 1.71670695 0.31629589 1.98694111\n",
      " 0.47744032 1.83025385 0.64895477]  energy_before :  50  energy_after :  50  reward :  -188.18434987298912\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "Episode 58/500, Total Reward: -987.9217493649455\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "action : 0  next_temperatures :  [ 1.12538953 -1.55280971  2.00305223 -3.12720029  0.96025522 -1.35412573\n",
      "  1.07783302 -1.48993333  1.11858581]  energy_before :  30  energy_after :  50  reward :  -210.23895325643443\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "action : 0  next_temperatures :  [ 0.12538953 -2.55280971  1.00305223 -4.12720029 -0.03974478 -2.35412573\n",
      "  0.07783302 -2.48993333  0.11858581]  energy_before :  50  energy_after :  40  reward :  -189.23895325643443\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "action : 1  next_temperatures :  [ 0.12538953 -2.55280971  1.00305223 -4.12720029 -0.03974478 -2.35412573\n",
      "  0.07783302 -2.48993333  0.11858581]  energy_before :  40  energy_after :  50  reward :  -218.23895325643443\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "action : 1  next_temperatures :  [ 0.12538953 -2.55280971  1.00305223 -4.12720029 -0.03974478 -2.35412573\n",
      "  0.07783302 -2.48993333  0.11858581]  energy_before :  50  energy_after :  50  reward :  -208.23895325643443\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "action : 2  next_temperatures :  [ 1.12538953 -1.55280971  2.00305223 -3.12720029  0.96025522 -1.35412573\n",
      "  1.07783302 -1.48993333  1.11858581]  energy_before :  50  energy_after :  50  reward :  -208.23895325643443\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "Episode 59/500, Total Reward: -1034.1947662821722\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "action : 2  next_temperatures :  [1.37572804 2.09827677 1.0809563  1.50638249 0.36810905 1.47549632\n",
      " 1.31557419 0.51006667 0.81995525]  energy_before :  30  energy_after :  50  reward :  -216.44945493028186\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "action : 0  next_temperatures :  [ 0.37572804  1.09827677  0.0809563   0.50638249 -0.63189095  0.47549632\n",
      "  0.31557419 -0.48993333 -0.18004475]  energy_before :  50  energy_after :  40  reward :  -177.44945493028186\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "action : 1  next_temperatures :  [ 0.37572804  1.09827677  0.0809563   0.50638249 -0.63189095  0.47549632\n",
      "  0.31557419 -0.48993333 -0.18004475]  energy_before :  40  energy_after :  50  reward :  -206.44945493028186\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "action : 1  next_temperatures :  [ 0.37572804  1.09827677  0.0809563   0.50638249 -0.63189095  0.47549632\n",
      "  0.31557419 -0.48993333 -0.18004475]  energy_before :  50  energy_after :  50  reward :  -196.44945493028186\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "action : 2  next_temperatures :  [1.37572804 2.09827677 1.0809563  1.50638249 0.36810905 1.47549632\n",
      " 1.31557419 0.51006667 0.81995525]  energy_before :  50  energy_after :  50  reward :  -196.44945493028186\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "Episode 60/500, Total Reward: -993.2472746514093\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "action : 2  next_temperatures :  [-0.23694927  2.35796058  0.33822447  1.95082454 -0.1303806   2.73836543\n",
      "  0.14073497  2.30526482  0.13687164]  energy_before :  30  energy_after :  50  reward :  -217.39908342931756\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "action : 1  next_temperatures :  [-0.23694927  2.35796058  0.33822447  1.95082454 -0.1303806   2.73836543\n",
      "  0.14073497  2.30526482  0.13687164]  energy_before :  50  energy_after :  40  reward :  -178.39908342931756\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "action : 1  next_temperatures :  [-0.23694927  2.35796058  0.33822447  1.95082454 -0.1303806   2.73836543\n",
      "  0.14073497  2.30526482  0.13687164]  energy_before :  40  energy_after :  50  reward :  -198.39908342931756\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "action : 2  next_temperatures :  [0.76305073 3.35796058 1.33822447 2.95082454 0.8696194  3.73836543\n",
      " 1.14073497 3.30526482 1.13687164]  energy_before :  50  energy_after :  50  reward :  -188.39908342931756\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "action : 1  next_temperatures :  [0.76305073 3.35796058 1.33822447 2.95082454 0.8696194  3.73836543\n",
      " 1.14073497 3.30526482 1.13687164]  energy_before :  50  energy_after :  50  reward :  -179.39908342931756\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "Episode 61/500, Total Reward: -961.9954171465878\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "action : 0  next_temperatures :  [ 0.37197657 -1.28474899  0.80069687 -2.20903482  0.05798895 -1.63725071\n",
      "  0.46920104 -1.24422614 -0.45359076]  energy_before :  30  energy_after :  50  reward :  -214.1289879846715\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "action : 1  next_temperatures :  [ 0.37197657 -1.28474899  0.80069687 -2.20903482  0.05798895 -1.63725071\n",
      "  0.46920104 -1.24422614 -0.45359076]  energy_before :  50  energy_after :  40  reward :  -193.1289879846715\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "action : 1  next_temperatures :  [ 0.37197657 -1.28474899  0.80069687 -2.20903482  0.05798895 -1.63725071\n",
      "  0.46920104 -1.24422614 -0.45359076]  energy_before :  40  energy_after :  50  reward :  -213.1289879846715\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "action : 0  next_temperatures :  [-0.62802343 -2.28474899 -0.19930313 -3.20903482 -0.94201105 -2.63725071\n",
      " -0.53079896 -2.24422614 -1.45359076]  energy_before :  50  energy_after :  50  reward :  -203.1289879846715\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "action : 1  next_temperatures :  [-0.62802343 -2.28474899 -0.19930313 -3.20903482 -0.94201105 -2.63725071\n",
      " -0.53079896 -2.24422614 -1.45359076]  energy_before :  50  energy_after :  50  reward :  -212.1289879846715\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "Episode 62/500, Total Reward: -1035.6449399233575\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "action : 1  next_temperatures :  [ 0.27817871 -1.14589404 -0.47937017 -0.54559679  0.50965034 -0.62759374\n",
      "  0.60928399 -1.25239345  0.60062223]  energy_before :  30  energy_after :  50  reward :  -220.05311291740003\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "action : 1  next_temperatures :  [ 0.27817871 -1.14589404 -0.47937017 -0.54559679  0.50965034 -0.62759374\n",
      "  0.60928399 -1.25239345  0.60062223]  energy_before :  50  energy_after :  40  reward :  -190.05311291740003\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "action : 2  next_temperatures :  [ 1.27817871 -0.14589404  0.52062983  0.45440321  1.50965034  0.37240626\n",
      "  1.60928399 -0.25239345  1.60062223]  energy_before :  40  energy_after :  50  reward :  -210.05311291740003\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "action : 0  next_temperatures :  [ 0.27817871 -1.14589404 -0.47937017 -0.54559679  0.50965034 -0.62759374\n",
      "  0.60928399 -1.25239345  0.60062223]  energy_before :  50  energy_after :  50  reward :  -191.05311291740003\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "action : 1  next_temperatures :  [ 0.27817871 -1.14589404 -0.47937017 -0.54559679  0.50965034 -0.62759374\n",
      "  0.60928399 -1.25239345  0.60062223]  energy_before :  50  energy_after :  50  reward :  -200.05311291740003\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "Episode 63/500, Total Reward: -1011.2655645870002\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "action : 0  next_temperatures :  [ 0.64179388  0.13848587 -0.27701482  0.56511901  0.80572343 -0.05233608\n",
      "  0.48551825 -0.10783039  1.05895152]  energy_before :  30  energy_after :  50  reward :  -205.741589321054\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "action : 2  next_temperatures :  [1.64179388 1.13848587 0.72298518 1.56511901 1.80572343 0.94766392\n",
      " 1.48551825 0.89216961 2.05895152]  energy_before :  50  energy_after :  40  reward :  -184.741589321054\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "action : 0  next_temperatures :  [ 0.64179388  0.13848587 -0.27701482  0.56511901  0.80572343 -0.05233608\n",
      "  0.48551825 -0.10783039  1.05895152]  energy_before :  40  energy_after :  50  reward :  -195.741589321054\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "action : 1  next_temperatures :  [ 0.64179388  0.13848587 -0.27701482  0.56511901  0.80572343 -0.05233608\n",
      "  0.48551825 -0.10783039  1.05895152]  energy_before :  50  energy_after :  50  reward :  -194.741589321054\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "action : 1  next_temperatures :  [ 0.64179388  0.13848587 -0.27701482  0.56511901  0.80572343 -0.05233608\n",
      "  0.48551825 -0.10783039  1.05895152]  energy_before :  50  energy_after :  50  reward :  -194.741589321054\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "Episode 64/500, Total Reward: -975.70794660527\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "action : 1  next_temperatures :  [ 0.37572804 -0.71029538  1.53164896 -1.70866099  0.26040552 -0.96866058\n",
      "  1.0498487  -0.88152916  0.27534432]  energy_before :  30  energy_after :  50  reward :  -218.77617056352216\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "action : 1  next_temperatures :  [ 0.37572804 -0.71029538  1.53164896 -1.70866099  0.26040552 -0.96866058\n",
      "  1.0498487  -0.88152916  0.27534432]  energy_before :  50  energy_after :  40  reward :  -188.77617056352216\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "action : 2  next_temperatures :  [ 1.37572804  0.28970462  2.53164896 -0.70866099  1.26040552  0.03133942\n",
      "  2.0498487   0.11847084  1.27534432]  energy_before :  40  energy_after :  50  reward :  -208.77617056352216\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "action : 0  next_temperatures :  [ 0.37572804 -0.71029538  1.53164896 -1.70866099  0.26040552 -0.96866058\n",
      "  1.0498487  -0.88152916  0.27534432]  energy_before :  50  energy_after :  50  reward :  -189.77617056352216\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "action : 1  next_temperatures :  [ 0.37572804 -0.71029538  1.53164896 -1.70866099  0.26040552 -0.96866058\n",
      "  1.0498487  -0.88152916  0.27534432]  energy_before :  50  energy_after :  50  reward :  -198.77617056352216\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "Episode 65/500, Total Reward: -1004.8808528176107\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "action : 2  next_temperatures :  [ 1.25742353 -0.24892988  0.20598058  0.60613394  0.61735387 -0.11102782\n",
      "  1.45753393 -0.43667384  0.56515422]  energy_before :  30  energy_after :  50  reward :  -223.08705147213186\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "action : 1  next_temperatures :  [ 1.25742353 -0.24892988  0.20598058  0.60613394  0.61735387 -0.11102782\n",
      "  1.45753393 -0.43667384  0.56515422]  energy_before :  50  energy_after :  40  reward :  -184.08705147213186\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "action : 1  next_temperatures :  [ 1.25742353 -0.24892988  0.20598058  0.60613394  0.61735387 -0.11102782\n",
      "  1.45753393 -0.43667384  0.56515422]  energy_before :  40  energy_after :  50  reward :  -204.08705147213186\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "action : 2  next_temperatures :  [2.25742353 0.75107012 1.20598058 1.60613394 1.61735387 0.88897218\n",
      " 2.45753393 0.56332616 1.56515422]  energy_before :  50  energy_after :  50  reward :  -194.08705147213186\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "action : 0  next_temperatures :  [ 1.25742353 -0.24892988  0.20598058  0.60613394  0.61735387 -0.11102782\n",
      "  1.45753393 -0.43667384  0.56515422]  energy_before :  50  energy_after :  50  reward :  -185.08705147213186\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "Episode 66/500, Total Reward: -990.4352573606593\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "action : 2  next_temperatures :  [1.23666835 0.62226745 0.95612263 0.56374762 0.86659869 0.15731906\n",
      " 1.18340478 0.46399657 0.78742746]  energy_before :  30  energy_after :  50  reward :  -220.1624473766244\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "action : 0  next_temperatures :  [ 0.23666835 -0.37773255 -0.04387737 -0.43625238 -0.13340131 -0.84268094\n",
      "  0.18340478 -0.53600343 -0.21257254]  energy_before :  50  energy_after :  40  reward :  -181.1624473766244\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "action : 2  next_temperatures :  [1.23666835 0.62226745 0.95612263 0.56374762 0.86659869 0.15731906\n",
      " 1.18340478 0.46399657 0.78742746]  energy_before :  40  energy_after :  50  reward :  -210.1624473766244\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "action : 0  next_temperatures :  [ 0.23666835 -0.37773255 -0.04387737 -0.43625238 -0.13340131 -0.84268094\n",
      "  0.18340478 -0.53600343 -0.21257254]  energy_before :  50  energy_after :  50  reward :  -191.1624473766244\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "action : 2  next_temperatures :  [1.23666835 0.62226745 0.95612263 0.56374762 0.86659869 0.15731906\n",
      " 1.18340478 0.46399657 0.78742746]  energy_before :  50  energy_after :  50  reward :  -200.1624473766244\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "Episode 67/500, Total Reward: -1002.8122368831221\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "action : 2  next_temperatures :  [ 0.6347682  -0.78337593  0.61639264 -0.86592038  1.55949931 -0.03830786\n",
      "  0.77221105 -0.78219957  0.75128547]  energy_before :  30  energy_after :  50  reward :  -225.1356470764568\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "action : 1  next_temperatures :  [ 0.6347682  -0.78337593  0.61639264 -0.86592038  1.55949931 -0.03830786\n",
      "  0.77221105 -0.78219957  0.75128547]  energy_before :  50  energy_after :  40  reward :  -186.1356470764568\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "action : 0  next_temperatures :  [-0.3652318  -1.78337593 -0.38360736 -1.86592038  0.55949931 -1.03830786\n",
      " -0.22778895 -1.78219957 -0.24871453]  energy_before :  40  energy_after :  50  reward :  -206.1356470764568\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "action : 2  next_temperatures :  [ 0.6347682  -0.78337593  0.61639264 -0.86592038  1.55949931 -0.03830786\n",
      "  0.77221105 -0.78219957  0.75128547]  energy_before :  50  energy_after :  50  reward :  -205.1356470764568\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "action : 1  next_temperatures :  [ 0.6347682  -0.78337593  0.61639264 -0.86592038  1.55949931 -0.03830786\n",
      "  0.77221105 -0.78219957  0.75128547]  energy_before :  50  energy_after :  50  reward :  -196.1356470764568\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "Episode 68/500, Total Reward: -1018.6782353822839\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "action : 1  next_temperatures :  [ 0.63101673  0.86456133  0.88867006  0.5331043   0.06100966  1.2737088\n",
      " -0.17394215  1.65923674 -0.51977946]  energy_before :  30  energy_after :  50  reward :  -212.78241400414342\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "action : 1  next_temperatures :  [ 0.63101673  0.86456133  0.88867006  0.5331043   0.06100966  1.2737088\n",
      " -0.17394215  1.65923674 -0.51977946]  energy_before :  50  energy_after :  40  reward :  -182.78241400414342\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "action : 1  next_temperatures :  [ 0.63101673  0.86456133  0.88867006  0.5331043   0.06100966  1.2737088\n",
      " -0.17394215  1.65923674 -0.51977946]  energy_before :  40  energy_after :  50  reward :  -202.78241400414342\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "action : 1  next_temperatures :  [ 0.63101673  0.86456133  0.88867006  0.5331043   0.06100966  1.2737088\n",
      " -0.17394215  1.65923674 -0.51977946]  energy_before :  50  energy_after :  50  reward :  -192.78241400414342\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "action : 1  next_temperatures :  [ 0.63101673  0.86456133  0.88867006  0.5331043   0.06100966  1.2737088\n",
      " -0.17394215  1.65923674 -0.51977946]  energy_before :  50  energy_after :  50  reward :  -192.78241400414342\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "Episode 69/500, Total Reward: -983.9120700207171\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "action : 1  next_temperatures :  [-0.49598942 -0.5452705  -0.69217643 -0.36540375 -0.73657378  0.14979285\n",
      " -0.85926503  0.06060434 -0.2044406 ]  energy_before :  30  energy_after :  50  reward :  -221.6887223192802\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "action : 1  next_temperatures :  [-0.49598942 -0.5452705  -0.69217643 -0.36540375 -0.73657378  0.14979285\n",
      " -0.85926503  0.06060434 -0.2044406 ]  energy_before :  50  energy_after :  40  reward :  -191.6887223192802\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "action : 1  next_temperatures :  [-0.49598942 -0.5452705  -0.69217643 -0.36540375 -0.73657378  0.14979285\n",
      " -0.85926503  0.06060434 -0.2044406 ]  energy_before :  40  energy_after :  50  reward :  -211.6887223192802\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "action : 1  next_temperatures :  [-0.49598942 -0.5452705  -0.69217643 -0.36540375 -0.73657378  0.14979285\n",
      " -0.85926503  0.06060434 -0.2044406 ]  energy_before :  50  energy_after :  50  reward :  -201.6887223192802\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "action : 1  next_temperatures :  [-0.49598942 -0.5452705  -0.69217643 -0.36540375 -0.73657378  0.14979285\n",
      " -0.85926503  0.06060434 -0.2044406 ]  energy_before :  50  energy_after :  50  reward :  -201.6887223192802\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "Episode 70/500, Total Reward: -1028.443611596401\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "action : 1  next_temperatures :  [ 0.31968906 -0.6432802  -0.15560065 -0.16227704  0.36508834 -0.78122745\n",
      "  0.85404217 -0.86909023  0.43256198]  energy_before :  30  energy_after :  50  reward :  -218.6400940280969\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "action : 1  next_temperatures :  [ 0.31968906 -0.6432802  -0.15560065 -0.16227704  0.36508834 -0.78122745\n",
      "  0.85404217 -0.86909023  0.43256198]  energy_before :  50  energy_after :  40  reward :  -188.6400940280969\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "action : 1  next_temperatures :  [ 0.31968906 -0.6432802  -0.15560065 -0.16227704  0.36508834 -0.78122745\n",
      "  0.85404217 -0.86909023  0.43256198]  energy_before :  40  energy_after :  50  reward :  -208.6400940280969\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "action : 1  next_temperatures :  [ 0.31968906 -0.6432802  -0.15560065 -0.16227704  0.36508834 -0.78122745\n",
      "  0.85404217 -0.86909023  0.43256198]  energy_before :  50  energy_after :  50  reward :  -198.6400940280969\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "action : 1  next_temperatures :  [ 0.31968906 -0.6432802  -0.15560065 -0.16227704  0.36508834 -0.78122745\n",
      "  0.85404217 -0.86909023  0.43256198]  energy_before :  50  energy_after :  50  reward :  -198.6400940280969\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "Episode 71/500, Total Reward: -1013.2004701404845\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "action : 1  next_temperatures :  [ 0.21591317 -0.80244125  0.19096954 -0.84045814 -0.68672482 -0.20049202\n",
      " -0.0156652  -0.84467308 -0.43484578]  energy_before :  30  energy_after :  50  reward :  -221.41841757302765\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "action : 2  next_temperatures :  [1.21591317 0.19755875 1.19096954 0.15954186 0.31327518 0.79950798\n",
      " 0.9843348  0.15532692 0.56515422]  energy_before :  50  energy_after :  40  reward :  -191.41841757302765\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "action : 1  next_temperatures :  [1.21591317 0.19755875 1.19096954 0.15954186 0.31327518 0.79950798\n",
      " 0.9843348  0.15532692 0.56515422]  energy_before :  40  energy_after :  50  reward :  -202.41841757302765\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "action : 1  next_temperatures :  [1.21591317 0.19755875 1.19096954 0.15954186 0.31327518 0.79950798\n",
      " 0.9843348  0.15532692 0.56515422]  energy_before :  50  energy_after :  50  reward :  -192.41841757302765\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "action : 1  next_temperatures :  [1.21591317 0.19755875 1.19096954 0.15954186 0.31327518 0.79950798\n",
      " 0.9843348  0.15532692 0.56515422]  energy_before :  50  energy_after :  50  reward :  -192.41841757302765\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "Episode 72/500, Total Reward: -1000.0920878651383\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "action : 2  next_temperatures :  [1.31968906 0.60802672 1.0876065  0.77383633 1.140768   0.58749346\n",
      " 1.18340478 0.45401472 1.3295573 ]  energy_before :  30  energy_after :  50  reward :  -218.51560312039035\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "action : 0  next_temperatures :  [ 0.31968906 -0.39197328  0.0876065  -0.22616367  0.140768   -0.41250654\n",
      "  0.18340478 -0.54598528  0.3295573 ]  energy_before :  50  energy_after :  40  reward :  -179.51560312039035\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "action : 1  next_temperatures :  [ 0.31968906 -0.39197328  0.0876065  -0.22616367  0.140768   -0.41250654\n",
      "  0.18340478 -0.54598528  0.3295573 ]  energy_before :  40  energy_after :  50  reward :  -208.51560312039035\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "action : 2  next_temperatures :  [1.31968906 0.60802672 1.0876065  0.77383633 1.140768   0.58749346\n",
      " 1.18340478 0.45401472 1.3295573 ]  energy_before :  50  energy_after :  50  reward :  -198.51560312039035\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "action : 0  next_temperatures :  [ 0.31968906 -0.39197328  0.0876065  -0.22616367  0.140768   -0.41250654\n",
      "  0.18340478 -0.54598528  0.3295573 ]  energy_before :  50  energy_after :  50  reward :  -189.51560312039035\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "Episode 73/500, Total Reward: -994.5780156019517\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "action : 2  next_temperatures :  [ 0.52684127  0.63064435  1.3460141  -0.20248235  0.66720283  0.09279291\n",
      "  1.07081602  0.03247332  0.19108462]  energy_before :  30  energy_after :  50  reward :  -222.64461292404502\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "action : 1  next_temperatures :  [ 0.52684127  0.63064435  1.3460141  -0.20248235  0.66720283  0.09279291\n",
      "  1.07081602  0.03247332  0.19108462]  energy_before :  50  energy_after :  40  reward :  -183.64461292404502\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "action : 1  next_temperatures :  [ 0.52684127  0.63064435  1.3460141  -0.20248235  0.66720283  0.09279291\n",
      "  1.07081602  0.03247332  0.19108462]  energy_before :  40  energy_after :  50  reward :  -203.64461292404502\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "action : 0  next_temperatures :  [-0.47315873 -0.36935565  0.3460141  -1.20248235 -0.33279717 -0.90720709\n",
      "  0.07081602 -0.96752668 -0.80891538]  energy_before :  50  energy_after :  50  reward :  -193.64461292404502\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "action : 2  next_temperatures :  [ 0.52684127  0.63064435  1.3460141  -0.20248235  0.66720283  0.09279291\n",
      "  1.07081602  0.03247332  0.19108462]  energy_before :  50  energy_after :  50  reward :  -202.64461292404502\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "Episode 74/500, Total Reward: -1006.2230646202252\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "action : 0  next_temperatures :  [-0.4312488  -0.40517477  0.39028481 -1.43174755 -0.93899034 -0.53372171\n",
      " -0.63547418 -0.33818088 -1.04993359]  energy_before :  30  energy_after :  50  reward :  -214.37418701486763\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "action : 1  next_temperatures :  [-0.4312488  -0.40517477  0.39028481 -1.43174755 -0.93899034 -0.53372171\n",
      " -0.63547418 -0.33818088 -1.04993359]  energy_before :  50  energy_after :  40  reward :  -193.37418701486763\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "action : 1  next_temperatures :  [-0.4312488  -0.40517477  0.39028481 -1.43174755 -0.93899034 -0.53372171\n",
      " -0.63547418 -0.33818088 -1.04993359]  energy_before :  40  energy_after :  50  reward :  -213.37418701486763\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "action : 1  next_temperatures :  [-0.4312488  -0.40517477  0.39028481 -1.43174755 -0.93899034 -0.53372171\n",
      " -0.63547418 -0.33818088 -1.04993359]  energy_before :  50  energy_after :  50  reward :  -203.37418701486763\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "action : 1  next_temperatures :  [-0.4312488  -0.40517477  0.39028481 -1.43174755 -0.93899034 -0.53372171\n",
      " -0.63547418 -0.33818088 -1.04993359]  energy_before :  50  energy_after :  50  reward :  -203.37418701486763\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "Episode 75/500, Total Reward: -1027.8709350743381\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "action : 2  next_temperatures :  [ 0.88383033  0.0467746   0.02357521  0.94583878  1.44816995 -0.43877974\n",
      "  1.31557419 -0.29932736  1.49219626]  energy_before :  30  energy_after :  50  reward :  -221.58214777152332\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "action : 0  next_temperatures :  [-0.11616967 -0.9532254  -0.97642479 -0.05416122  0.44816995 -1.43877974\n",
      "  0.31557419 -1.29932736  0.49219626]  energy_before :  50  energy_after :  40  reward :  -182.58214777152332\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "action : 2  next_temperatures :  [ 0.88383033  0.0467746   0.02357521  0.94583878  1.44816995 -0.43877974\n",
      "  1.31557419 -0.29932736  1.49219626]  energy_before :  40  energy_after :  50  reward :  -211.58214777152332\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "action : 0  next_temperatures :  [-0.11616967 -0.9532254  -0.97642479 -0.05416122  0.44816995 -1.43877974\n",
      "  0.31557419 -1.29932736  0.49219626]  energy_before :  50  energy_after :  50  reward :  -192.58214777152332\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "action : 2  next_temperatures :  [ 0.88383033  0.0467746   0.02357521  0.94583878  1.44816995 -0.43877974\n",
      "  1.31557419 -0.29932736  1.49219626]  energy_before :  50  energy_after :  50  reward :  -201.58214777152332\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "Episode 76/500, Total Reward: -1009.9107388576166\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "action : 1  next_temperatures :  [-0.30296627 -0.51762674  0.51017893 -0.47433863 -0.20485149 -0.82424489\n",
      "  0.34820861 -0.67651722 -0.32099851]  energy_before :  30  energy_after :  50  reward :  -220.46315621933468\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "action : 2  next_temperatures :  [0.69703373 0.48237326 1.51017893 0.52566137 0.79514851 0.17575511\n",
      " 1.34820861 0.32348278 0.67900149]  energy_before :  50  energy_after :  40  reward :  -190.46315621933468\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "action : 0  next_temperatures :  [-0.30296627 -0.51762674  0.51017893 -0.47433863 -0.20485149 -0.82424489\n",
      "  0.34820861 -0.67651722 -0.32099851]  energy_before :  40  energy_after :  50  reward :  -201.46315621933468\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "action : 2  next_temperatures :  [0.69703373 0.48237326 1.51017893 0.52566137 0.79514851 0.17575511\n",
      " 1.34820861 0.32348278 0.67900149]  energy_before :  50  energy_after :  50  reward :  -200.46315621933468\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "action : 0  next_temperatures :  [-0.30296627 -0.51762674  0.51017893 -0.47433863 -0.20485149 -0.82424489\n",
      "  0.34820861 -0.67651722 -0.32099851]  energy_before :  50  energy_after :  50  reward :  -191.46315621933468\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "Episode 77/500, Total Reward: -1004.3157810966734\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "action : 1  next_temperatures :  [-0.86958262  0.66351579 -0.29240467  0.16452762 -0.68672482  0.75510967\n",
      " -0.90821667  0.89216961 -0.26678553]  energy_before :  30  energy_after :  50  reward :  -218.54839161898988\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "action : 1  next_temperatures :  [-0.86958262  0.66351579 -0.29240467  0.16452762 -0.68672482  0.75510967\n",
      " -0.90821667  0.89216961 -0.26678553]  energy_before :  50  energy_after :  40  reward :  -188.54839161898988\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "action : 1  next_temperatures :  [-0.86958262  0.66351579 -0.29240467  0.16452762 -0.68672482  0.75510967\n",
      " -0.90821667  0.89216961 -0.26678553]  energy_before :  40  energy_after :  50  reward :  -208.54839161898988\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "action : 2  next_temperatures :  [0.13041738 1.66351579 0.70759533 1.16452762 0.31327518 1.75510967\n",
      " 0.09178333 1.89216961 0.73321447]  energy_before :  50  energy_after :  50  reward :  -198.54839161898988\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "action : 1  next_temperatures :  [0.13041738 1.66351579 0.70759533 1.16452762 0.31327518 1.75510967\n",
      " 0.09178333 1.89216961 0.73321447]  energy_before :  50  energy_after :  50  reward :  -189.54839161898988\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "Episode 78/500, Total Reward: -1003.7419580949494\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "action : 0  next_temperatures :  [ 0.37197657 -0.27114441  2.08209455 -2.44590677  0.86055729 -0.9516054\n",
      "  0.78412322 -0.56853137  0.03432611]  energy_before :  30  energy_after :  50  reward :  -209.1041102149849\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "action : 1  next_temperatures :  [ 0.37197657 -0.27114441  2.08209455 -2.44590677  0.86055729 -0.9516054\n",
      "  0.78412322 -0.56853137  0.03432611]  energy_before :  50  energy_after :  40  reward :  -188.1041102149849\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "action : 1  next_temperatures :  [ 0.37197657 -0.27114441  2.08209455 -2.44590677  0.86055729 -0.9516054\n",
      "  0.78412322 -0.56853137  0.03432611]  energy_before :  40  energy_after :  50  reward :  -208.1041102149849\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "action : 1  next_temperatures :  [ 0.37197657 -0.27114441  2.08209455 -2.44590677  0.86055729 -0.9516054\n",
      "  0.78412322 -0.56853137  0.03432611]  energy_before :  50  energy_after :  50  reward :  -198.1041102149849\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "action : 1  next_temperatures :  [ 0.37197657 -0.27114441  2.08209455 -2.44590677  0.86055729 -0.9516054\n",
      "  0.78412322 -0.56853137  0.03432611]  energy_before :  50  energy_after :  50  reward :  -198.1041102149849\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "Episode 79/500, Total Reward: -1001.5205510749245\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "action : 1  next_temperatures :  [-0.05390414  0.00760473 -0.74841808  0.99423468  0.26040552  0.01459518\n",
      " -0.27674059 -0.12137255  0.16149705]  energy_before :  30  energy_after :  50  reward :  -217.76209819274797\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "action : 1  next_temperatures :  [-0.05390414  0.00760473 -0.74841808  0.99423468  0.26040552  0.01459518\n",
      " -0.27674059 -0.12137255  0.16149705]  energy_before :  50  energy_after :  40  reward :  -187.76209819274797\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "action : 1  next_temperatures :  [-0.05390414  0.00760473 -0.74841808  0.99423468  0.26040552  0.01459518\n",
      " -0.27674059 -0.12137255  0.16149705]  energy_before :  40  energy_after :  50  reward :  -207.76209819274797\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "action : 1  next_temperatures :  [-0.05390414  0.00760473 -0.74841808  0.99423468  0.26040552  0.01459518\n",
      " -0.27674059 -0.12137255  0.16149705]  energy_before :  50  energy_after :  50  reward :  -197.76209819274797\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "action : 1  next_temperatures :  [-0.05390414  0.00760473 -0.74841808  0.99423468  0.26040552  0.01459518\n",
      " -0.27674059 -0.12137255  0.16149705]  energy_before :  50  energy_after :  50  reward :  -197.76209819274797\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "Episode 80/500, Total Reward: -1008.8104909637399\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "action : 1  next_temperatures :  [ 0.21591317 -0.51008753 -0.66177553  0.63384859  0.36508834 -0.41250654\n",
      " -0.29142608 -0.08374863  0.22113133]  energy_before :  30  energy_after :  50  reward :  -218.52356286893252\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "action : 1  next_temperatures :  [ 0.21591317 -0.51008753 -0.66177553  0.63384859  0.36508834 -0.41250654\n",
      " -0.29142608 -0.08374863  0.22113133]  energy_before :  50  energy_after :  40  reward :  -188.52356286893252\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "action : 1  next_temperatures :  [ 0.21591317 -0.51008753 -0.66177553  0.63384859  0.36508834 -0.41250654\n",
      " -0.29142608 -0.08374863  0.22113133]  energy_before :  40  energy_after :  50  reward :  -208.52356286893252\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "action : 1  next_temperatures :  [ 0.21591317 -0.51008753 -0.66177553  0.63384859  0.36508834 -0.41250654\n",
      " -0.29142608 -0.08374863  0.22113133]  energy_before :  50  energy_after :  50  reward :  -198.52356286893252\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "action : 2  next_temperatures :  [1.21591317 0.48991247 0.33822447 1.63384859 1.36508834 0.58749346\n",
      " 0.70857392 0.91625137 1.22113133]  energy_before :  50  energy_after :  50  reward :  -198.52356286893252\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "Episode 81/500, Total Reward: -1012.6178143446625\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "action : 2  next_temperatures :  [ 0.79458307 -0.43238393  0.74863653 -0.66197461  1.06100966 -0.37732625\n",
      "  1.45753393 -0.42822765  0.48022054]  energy_before :  30  energy_after :  50  reward :  -224.35792872281976\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "action : 0  next_temperatures :  [-0.20541693 -1.43238393 -0.25136347 -1.66197461  0.06100966 -1.37732625\n",
      "  0.45753393 -1.42822765 -0.51977946]  energy_before :  50  energy_after :  40  reward :  -185.35792872281976\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "action : 2  next_temperatures :  [ 0.79458307 -0.43238393  0.74863653 -0.66197461  1.06100966 -0.37732625\n",
      "  1.45753393 -0.42822765  0.48022054]  energy_before :  40  energy_after :  50  reward :  -214.35792872281976\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "action : 1  next_temperatures :  [ 0.79458307 -0.43238393  0.74863653 -0.66197461  1.06100966 -0.37732625\n",
      "  1.45753393 -0.42822765  0.48022054]  energy_before :  50  energy_after :  50  reward :  -195.35792872281976\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "action : 1  next_temperatures :  [ 0.79458307 -0.43238393  0.74863653 -0.66197461  1.06100966 -0.37732625\n",
      "  1.45753393 -0.42822765  0.48022054]  energy_before :  50  energy_after :  50  reward :  -195.35792872281976\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "Episode 82/500, Total Reward: -1014.7896436140988\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "action : 1  next_temperatures :  [-0.18466176 -0.49500911 -0.74841808  0.34553972  0.26040552 -0.33159279\n",
      " -0.45459819 -0.0061973   0.16149705]  energy_before :  30  energy_after :  50  reward :  -219.45303494028457\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "action : 1  next_temperatures :  [-0.18466176 -0.49500911 -0.74841808  0.34553972  0.26040552 -0.33159279\n",
      " -0.45459819 -0.0061973   0.16149705]  energy_before :  50  energy_after :  40  reward :  -189.45303494028457\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "action : 0  next_temperatures :  [-1.18466176 -1.49500911 -1.74841808 -0.65446028 -0.73959448 -1.33159279\n",
      " -1.45459819 -1.0061973  -0.83850295]  energy_before :  40  energy_after :  50  reward :  -209.45303494028457\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "action : 2  next_temperatures :  [-0.18466176 -0.49500911 -0.74841808  0.34553972  0.26040552 -0.33159279\n",
      " -0.45459819 -0.0061973   0.16149705]  energy_before :  50  energy_after :  50  reward :  -208.45303494028457\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "action : 1  next_temperatures :  [-0.18466176 -0.49500911 -0.74841808  0.34553972  0.26040552 -0.33159279\n",
      " -0.45459819 -0.0061973   0.16149705]  energy_before :  50  energy_after :  50  reward :  -199.45303494028457\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "Episode 83/500, Total Reward: -1026.265174701423\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "action : 2  next_temperatures :  [ 0.19268291  0.19588337  0.63159309  0.07681687 -0.37962543  1.2511911\n",
      " -0.88724935  0.77036272 -0.0799803 ]  energy_before :  30  energy_after :  50  reward :  -225.22832501109986\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "action : 2  next_temperatures :  [1.19268291 1.19588337 1.63159309 1.07681687 0.62037457 2.2511911\n",
      " 0.11275065 1.77036272 0.9200197 ]  energy_before :  50  energy_after :  40  reward :  -186.22832501109986\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "action : 1  next_temperatures :  [1.19268291 1.19588337 1.63159309 1.07681687 0.62037457 2.2511911\n",
      " 0.11275065 1.77036272 0.9200197 ]  energy_before :  40  energy_after :  50  reward :  -197.22832501109986\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "action : 1  next_temperatures :  [1.19268291 1.19588337 1.63159309 1.07681687 0.62037457 2.2511911\n",
      " 0.11275065 1.77036272 0.9200197 ]  energy_before :  50  energy_after :  50  reward :  -187.22832501109986\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "action : 1  next_temperatures :  [1.19268291 1.19588337 1.63159309 1.07681687 0.62037457 2.2511911\n",
      " 0.11275065 1.77036272 0.9200197 ]  energy_before :  50  energy_after :  50  reward :  -187.22832501109986\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "Episode 84/500, Total Reward: -983.1416250554993\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "action : 2  next_temperatures :  [0.75307271 0.40698119 0.52062983 0.46914627 0.16871319 0.8333074\n",
      " 1.39716025 0.38644524 0.51636253]  energy_before :  30  energy_after :  50  reward :  -221.54818139479863\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "action : 1  next_temperatures :  [0.75307271 0.40698119 0.52062983 0.46914627 0.16871319 0.8333074\n",
      " 1.39716025 0.38644524 0.51636253]  energy_before :  50  energy_after :  40  reward :  -182.54818139479863\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "action : 1  next_temperatures :  [0.75307271 0.40698119 0.52062983 0.46914627 0.16871319 0.8333074\n",
      " 1.39716025 0.38644524 0.51636253]  energy_before :  40  energy_after :  50  reward :  -202.54818139479863\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "action : 1  next_temperatures :  [0.75307271 0.40698119 0.52062983 0.46914627 0.16871319 0.8333074\n",
      " 1.39716025 0.38644524 0.51636253]  energy_before :  50  energy_after :  50  reward :  -192.54818139479863\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "action : 1  next_temperatures :  [0.75307271 0.40698119 0.52062983 0.46914627 0.16871319 0.8333074\n",
      " 1.39716025 0.38644524 0.51636253]  energy_before :  50  energy_after :  50  reward :  -192.54818139479863\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "Episode 85/500, Total Reward: -991.7409069739931\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "action : 0  next_temperatures :  [ 1.41596201 -0.38674559  1.31903211 -1.26711663  1.15965108 -1.10523912\n",
      "  1.37154283 -0.45335613  1.22701178]  energy_before :  30  energy_after :  50  reward :  -205.71925765991628\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "action : 1  next_temperatures :  [ 1.41596201 -0.38674559  1.31903211 -1.26711663  1.15965108 -1.10523912\n",
      "  1.37154283 -0.45335613  1.22701178]  energy_before :  50  energy_after :  40  reward :  -184.71925765991628\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "action : 0  next_temperatures :  [ 0.41596201 -1.38674559  0.31903211 -2.26711663  0.15965108 -2.10523912\n",
      "  0.37154283 -1.45335613  0.22701178]  energy_before :  40  energy_after :  50  reward :  -204.71925765991628\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "action : 1  next_temperatures :  [ 0.41596201 -1.38674559  0.31903211 -2.26711663  0.15965108 -2.10523912\n",
      "  0.37154283 -1.45335613  0.22701178]  energy_before :  50  energy_after :  50  reward :  -203.71925765991628\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "action : 1  next_temperatures :  [ 0.41596201 -1.38674559  0.31903211 -2.26711663  0.15965108 -2.10523912\n",
      "  0.37154283 -1.45335613  0.22701178]  energy_before :  50  energy_after :  50  reward :  -203.71925765991628\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "Episode 86/500, Total Reward: -1002.5962882995814\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "action : 1  next_temperatures :  [ 0.54799602  1.38979279  0.81722795  0.69773522  0.49469565  2.40308729\n",
      " -0.61450686  2.35719872  0.64670327]  energy_before :  30  energy_after :  50  reward :  -209.26006994950276\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "action : 1  next_temperatures :  [ 0.54799602  1.38979279  0.81722795  0.69773522  0.49469565  2.40308729\n",
      " -0.61450686  2.35719872  0.64670327]  energy_before :  50  energy_after :  40  reward :  -179.26006994950276\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "action : 1  next_temperatures :  [ 0.54799602  1.38979279  0.81722795  0.69773522  0.49469565  2.40308729\n",
      " -0.61450686  2.35719872  0.64670327]  energy_before :  40  energy_after :  50  reward :  -199.26006994950276\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "action : 1  next_temperatures :  [ 0.54799602  1.38979279  0.81722795  0.69773522  0.49469565  2.40308729\n",
      " -0.61450686  2.35719872  0.64670327]  energy_before :  50  energy_after :  50  reward :  -189.26006994950276\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "action : 1  next_temperatures :  [ 0.54799602  1.38979279  0.81722795  0.69773522  0.49469565  2.40308729\n",
      " -0.61450686  2.35719872  0.64670327]  energy_before :  50  energy_after :  50  reward :  -189.26006994950276\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "Episode 87/500, Total Reward: -966.3003497475138\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "action : 1  next_temperatures :  [-1.2992148   1.19126033 -0.66177553  0.98604409 -1.23506343  1.64311253\n",
      " -1.25577327  1.24460586 -1.29683224]  energy_before :  30  energy_after :  50  reward :  -218.68363647673655\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "action : 1  next_temperatures :  [-1.2992148   1.19126033 -0.66177553  0.98604409 -1.23506343  1.64311253\n",
      " -1.25577327  1.24460586 -1.29683224]  energy_before :  50  energy_after :  40  reward :  -188.68363647673655\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "action : 1  next_temperatures :  [-1.2992148   1.19126033 -0.66177553  0.98604409 -1.23506343  1.64311253\n",
      " -1.25577327  1.24460586 -1.29683224]  energy_before :  40  energy_after :  50  reward :  -208.68363647673655\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "action : 1  next_temperatures :  [-1.2992148   1.19126033 -0.66177553  0.98604409 -1.23506343  1.64311253\n",
      " -1.25577327  1.24460586 -1.29683224]  energy_before :  50  energy_after :  50  reward :  -198.68363647673655\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "action : 1  next_temperatures :  [-1.2992148   1.19126033 -0.66177553  0.98604409 -1.23506343  1.64311253\n",
      " -1.25577327  1.24460586 -1.29683224]  energy_before :  50  energy_after :  50  reward :  -198.68363647673655\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "Episode 88/500, Total Reward: -1013.4181823836827\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "action : 0  next_temperatures :  [0.90123361 1.12285508 0.90467615 0.37194646 1.22096531 0.22522883\n",
      " 0.56229734 0.70682175 0.83750857]  energy_before :  30  energy_after :  50  reward :  -202.14646690402992\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "action : 0  next_temperatures :  [-0.09876639  0.12285508 -0.09532385 -0.62805354  0.22096531 -0.77477117\n",
      " -0.43770266 -0.29317825 -0.16249143]  energy_before :  50  energy_after :  40  reward :  -181.14646690402992\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "action : 1  next_temperatures :  [-0.09876639  0.12285508 -0.09532385 -0.62805354  0.22096531 -0.77477117\n",
      " -0.43770266 -0.29317825 -0.16249143]  energy_before :  40  energy_after :  50  reward :  -210.14646690402992\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "action : 1  next_temperatures :  [-0.09876639  0.12285508 -0.09532385 -0.62805354  0.22096531 -0.77477117\n",
      " -0.43770266 -0.29317825 -0.16249143]  energy_before :  50  energy_after :  50  reward :  -200.14646690402992\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "action : 1  next_temperatures :  [-0.09876639  0.12285508 -0.09532385 -0.62805354  0.22096531 -0.77477117\n",
      " -0.43770266 -0.29317825 -0.16249143]  energy_before :  50  energy_after :  50  reward :  -200.14646690402992\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "Episode 89/500, Total Reward: -993.7323345201496\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "action : 2  next_temperatures :  [0.42306539 0.50499089 0.70759533 0.46177474 0.16871319 1.75510967\n",
      " 1.10345044 0.4471042  0.05555216]  energy_before :  30  energy_after :  50  reward :  -221.3726439986817\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "action : 1  next_temperatures :  [0.42306539 0.50499089 0.70759533 0.46177474 0.16871319 1.75510967\n",
      " 1.10345044 0.4471042  0.05555216]  energy_before :  50  energy_after :  40  reward :  -182.3726439986817\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "action : 1  next_temperatures :  [0.42306539 0.50499089 0.70759533 0.46177474 0.16871319 1.75510967\n",
      " 1.10345044 0.4471042  0.05555216]  energy_before :  40  energy_after :  50  reward :  -202.3726439986817\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "action : 1  next_temperatures :  [0.42306539 0.50499089 0.70759533 0.46177474 0.16871319 1.75510967\n",
      " 1.10345044 0.4471042  0.05555216]  energy_before :  50  energy_after :  50  reward :  -192.3726439986817\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "action : 1  next_temperatures :  [0.42306539 0.50499089 0.70759533 0.46177474 0.16871319 1.75510967\n",
      " 1.10345044 0.4471042  0.05555216]  energy_before :  50  energy_after :  50  reward :  -192.3726439986817\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "Episode 90/500, Total Reward: -990.8632199934085\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "action : 0  next_temperatures :  [-0.49351434 -0.63805251  0.28844181 -1.63733143 -0.49034966 -0.9516054\n",
      "  0.19180844 -1.02923235 -0.14864272]  energy_before :  30  energy_after :  50  reward :  -213.90847816147974\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "action : 1  next_temperatures :  [-0.49351434 -0.63805251  0.28844181 -1.63733143 -0.49034966 -0.9516054\n",
      "  0.19180844 -1.02923235 -0.14864272]  energy_before :  50  energy_after :  40  reward :  -192.90847816147974\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "action : 2  next_temperatures :  [ 0.50648566  0.36194749  1.28844181 -0.63733143  0.50965034  0.0483946\n",
      "  1.19180844 -0.02923235  0.85135728]  energy_before :  40  energy_after :  50  reward :  -212.90847816147974\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "action : 0  next_temperatures :  [-0.49351434 -0.63805251  0.28844181 -1.63733143 -0.49034966 -0.9516054\n",
      "  0.19180844 -1.02923235 -0.14864272]  energy_before :  50  energy_after :  50  reward :  -193.90847816147974\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "action : 1  next_temperatures :  [-0.49351434 -0.63805251  0.28844181 -1.63733143 -0.49034966 -0.9516054\n",
      "  0.19180844 -1.02923235 -0.14864272]  energy_before :  50  energy_after :  50  reward :  -202.90847816147974\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "Episode 91/500, Total Reward: -1016.5423908073986\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "action : 2  next_temperatures :  [1.0083614  0.55776534 0.61639264 1.13422242 1.01116069 0.43385975\n",
      " 0.77221105 0.74809551 0.95006641]  energy_before :  30  energy_after :  50  reward :  -219.7678647878936\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "action : 2  next_temperatures :  [2.0083614  1.55776534 1.61639264 2.13422242 2.01116069 1.43385975\n",
      " 1.77221105 1.74809551 1.95006641]  energy_before :  50  energy_after :  40  reward :  -180.7678647878936\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "action : 0  next_temperatures :  [1.0083614  0.55776534 0.61639264 1.13422242 1.01116069 0.43385975\n",
      " 0.77221105 0.74809551 0.95006641]  energy_before :  40  energy_after :  50  reward :  -191.7678647878936\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "action : 0  next_temperatures :  [ 0.0083614  -0.44223466 -0.38360736  0.13422242  0.01116069 -0.56614025\n",
      " -0.22778895 -0.25190449 -0.04993359]  energy_before :  50  energy_after :  50  reward :  -190.7678647878936\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "action : 2  next_temperatures :  [1.0083614  0.55776534 0.61639264 1.13422242 1.01116069 0.43385975\n",
      " 0.77221105 0.74809551 0.95006641]  energy_before :  50  energy_after :  50  reward :  -199.7678647878936\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "Episode 92/500, Total Reward: -982.8393239394679\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "action : 1  next_temperatures :  [-0.24692729 -0.25878061 -0.96274438  0.69937333 -0.03370338 -0.3817798\n",
      " -0.52149876 -0.100641    0.0042794 ]  energy_before :  30  energy_after :  50  reward :  -219.80242248367247\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "action : 1  next_temperatures :  [-0.24692729 -0.25878061 -0.96274438  0.69937333 -0.03370338 -0.3817798\n",
      " -0.52149876 -0.100641    0.0042794 ]  energy_before :  50  energy_after :  40  reward :  -189.80242248367247\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "action : 1  next_temperatures :  [-0.24692729 -0.25878061 -0.96274438  0.69937333 -0.03370338 -0.3817798\n",
      " -0.52149876 -0.100641    0.0042794 ]  energy_before :  40  energy_after :  50  reward :  -209.80242248367247\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "action : 2  next_temperatures :  [0.75307271 0.74121939 0.03725562 1.69937333 0.96629662 0.6182202\n",
      " 0.47850124 0.899359   1.0042794 ]  energy_before :  50  energy_after :  50  reward :  -199.80242248367247\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step\n",
      "action : 0  next_temperatures :  [-0.24692729 -0.25878061 -0.96274438  0.69937333 -0.03370338 -0.3817798\n",
      " -0.52149876 -0.100641    0.0042794 ]  energy_before :  50  energy_after :  50  reward :  -190.80242248367247\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "Episode 93/500, Total Reward: -1010.0121124183623\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "action : 1  next_temperatures :  [ 0.99838337 -1.55049818  0.72298518 -1.97976962  0.50965034 -1.07005883\n",
      "  0.94705027 -1.29616004  1.30268038]  energy_before :  30  energy_after :  50  reward :  -219.41573711713212\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "action : 1  next_temperatures :  [ 0.99838337 -1.55049818  0.72298518 -1.97976962  0.50965034 -1.07005883\n",
      "  0.94705027 -1.29616004  1.30268038]  energy_before :  50  energy_after :  40  reward :  -189.41573711713212\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "action : 1  next_temperatures :  [ 0.99838337 -1.55049818  0.72298518 -1.97976962  0.50965034 -1.07005883\n",
      "  0.94705027 -1.29616004  1.30268038]  energy_before :  40  energy_after :  50  reward :  -209.41573711713212\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "action : 1  next_temperatures :  [ 0.99838337 -1.55049818  0.72298518 -1.97976962  0.50965034 -1.07005883\n",
      "  0.94705027 -1.29616004  1.30268038]  energy_before :  50  energy_after :  50  reward :  -199.41573711713212\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "action : 1  next_temperatures :  [ 0.99838337 -1.55049818  0.72298518 -1.97976962  0.50965034 -1.07005883\n",
      "  0.94705027 -1.29616004  1.30268038]  energy_before :  50  energy_after :  50  reward :  -199.41573711713212\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "Episode 94/500, Total Reward: -1017.0786855856607\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "action : 1  next_temperatures :  [-0.55825495  2.74768786  0.00704413  0.8549946  -0.68672482  0.84421723\n",
      " -0.85926503  1.33521038 -0.43484578]  energy_before :  30  energy_after :  50  reward :  -214.74993638952307\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "action : 1  next_temperatures :  [-0.55825495  2.74768786  0.00704413  0.8549946  -0.68672482  0.84421723\n",
      " -0.85926503  1.33521038 -0.43484578]  energy_before :  50  energy_after :  40  reward :  -184.74993638952307\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "action : 1  next_temperatures :  [-0.55825495  2.74768786  0.00704413  0.8549946  -0.68672482  0.84421723\n",
      " -0.85926503  1.33521038 -0.43484578]  energy_before :  40  energy_after :  50  reward :  -204.74993638952307\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "action : 1  next_temperatures :  [-0.55825495  2.74768786  0.00704413  0.8549946  -0.68672482  0.84421723\n",
      " -0.85926503  1.33521038 -0.43484578]  energy_before :  50  energy_after :  50  reward :  -194.74993638952307\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "action : 1  next_temperatures :  [-0.55825495  2.74768786  0.00704413  0.8549946  -0.68672482  0.84421723\n",
      " -0.85926503  1.33521038 -0.43484578]  energy_before :  50  energy_after :  50  reward :  -194.74993638952307\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "Episode 95/500, Total Reward: -993.7496819476154\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "action : 1  next_temperatures :  [-0.49598942  1.15607736 -0.10999931  0.70510675 -0.41920204  1.28770654\n",
      "  0.21277576  0.87316569 -0.32099851]  energy_before :  30  energy_after :  50  reward :  -215.11135718626895\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "action : 1  next_temperatures :  [-0.49598942  1.15607736 -0.10999931  0.70510675 -0.41920204  1.28770654\n",
      "  0.21277576  0.87316569 -0.32099851]  energy_before :  50  energy_after :  40  reward :  -185.11135718626895\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "action : 1  next_temperatures :  [-0.49598942  1.15607736 -0.10999931  0.70510675 -0.41920204  1.28770654\n",
      "  0.21277576  0.87316569 -0.32099851]  energy_before :  40  energy_after :  50  reward :  -205.11135718626895\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "action : 1  next_temperatures :  [-0.49598942  1.15607736 -0.10999931  0.70510675 -0.41920204  1.28770654\n",
      "  0.21277576  0.87316569 -0.32099851]  energy_before :  50  energy_after :  50  reward :  -195.11135718626895\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "action : 1  next_temperatures :  [-0.49598942  1.15607736 -0.10999931  0.70510675 -0.41920204  1.28770654\n",
      "  0.21277576  0.87316569 -0.32099851]  energy_before :  50  energy_after :  50  reward :  -195.11135718626895\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "Episode 96/500, Total Reward: -995.5567859313447\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "action : 0  next_temperatures :  [-0.0576556  -0.69669079  0.71405433 -1.66272227  0.02475631 -0.99462284\n",
      "  0.29460687 -0.87720103 -0.15929169]  energy_before :  30  energy_after :  50  reward :  -212.4147667274247\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "action : 1  next_temperatures :  [-0.0576556  -0.69669079  0.71405433 -1.66272227  0.02475631 -0.99462284\n",
      "  0.29460687 -0.87720103 -0.15929169]  energy_before :  50  energy_after :  40  reward :  -191.4147667274247\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "action : 1  next_temperatures :  [-0.0576556  -0.69669079  0.71405433 -1.66272227  0.02475631 -0.99462284\n",
      "  0.29460687 -0.87720103 -0.15929169]  energy_before :  40  energy_after :  50  reward :  -211.4147667274247\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "action : 1  next_temperatures :  [-0.0576556  -0.69669079  0.71405433 -1.66272227  0.02475631 -0.99462284\n",
      "  0.29460687 -0.87720103 -0.15929169]  energy_before :  50  energy_after :  50  reward :  -201.4147667274247\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "action : 1  next_temperatures :  [-0.0576556  -0.69669079  0.71405433 -1.66272227  0.02475631 -0.99462284\n",
      "  0.29460687 -0.87720103 -0.15929169]  energy_before :  50  energy_after :  50  reward :  -201.4147667274247\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "Episode 97/500, Total Reward: -1018.0738336371235\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "action : 2  next_temperatures :  [ 1.06440038 -0.29919126  0.02357521  0.78120787  0.63397019 -0.06084081\n",
      "  1.29762526 -0.37447921  0.49829154]  energy_before :  30  energy_after :  50  reward :  -223.43544083519353\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "action : 0  next_temperatures :  [ 0.06440038 -1.29919126 -0.97642479 -0.21879213 -0.36602981 -1.06084081\n",
      "  0.29762526 -1.37447921 -0.50170846]  energy_before :  50  energy_after :  40  reward :  -184.43544083519353\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "action : 2  next_temperatures :  [ 1.06440038 -0.29919126  0.02357521  0.78120787  0.63397019 -0.06084081\n",
      "  1.29762526 -0.37447921  0.49829154]  energy_before :  40  energy_after :  50  reward :  -213.43544083519353\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "action : 0  next_temperatures :  [ 0.06440038 -1.29919126 -0.97642479 -0.21879213 -0.36602981 -1.06084081\n",
      "  0.29762526 -1.37447921 -0.50170846]  energy_before :  50  energy_after :  50  reward :  -194.43544083519353\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "action : 2  next_temperatures :  [ 1.06440038 -0.29919126  0.02357521  0.78120787  0.63397019 -0.06084081\n",
      "  1.29762526 -0.37447921  0.49829154]  energy_before :  50  energy_after :  50  reward :  -203.43544083519353\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "Episode 98/500, Total Reward: -1019.1772041759676\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "action : 1  next_temperatures :  [ 0.31968906 -0.63574099 -0.52041138  0.36355902  0.52626666 -0.13903853\n",
      " -0.27674059 -0.100641    0.22113133]  energy_before :  30  energy_after :  50  reward :  -218.24192640267256\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "action : 1  next_temperatures :  [ 0.31968906 -0.63574099 -0.52041138  0.36355902  0.52626666 -0.13903853\n",
      " -0.27674059 -0.100641    0.22113133]  energy_before :  50  energy_after :  40  reward :  -188.24192640267256\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "action : 1  next_temperatures :  [ 0.31968906 -0.63574099 -0.52041138  0.36355902  0.52626666 -0.13903853\n",
      " -0.27674059 -0.100641    0.22113133]  energy_before :  40  energy_after :  50  reward :  -208.24192640267256\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "action : 1  next_temperatures :  [ 0.31968906 -0.63574099 -0.52041138  0.36355902  0.52626666 -0.13903853\n",
      " -0.27674059 -0.100641    0.22113133]  energy_before :  50  energy_after :  50  reward :  -198.24192640267256\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "action : 1  next_temperatures :  [ 0.31968906 -0.63574099 -0.52041138  0.36355902  0.52626666 -0.13903853\n",
      " -0.27674059 -0.100641    0.22113133]  energy_before :  50  energy_after :  50  reward :  -198.24192640267256\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "Episode 99/500, Total Reward: -1011.2096320133628\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "action : 2  next_temperatures :  [0.81533824 1.65513889 0.99184368 0.38887846 0.31327518 1.16105932\n",
      " 0.52745288 0.51774502 0.13687164]  energy_before :  30  energy_after :  50  reward :  -220.49239667490951\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "action : 1  next_temperatures :  [0.81533824 1.65513889 0.99184368 0.38887846 0.31327518 1.16105932\n",
      " 0.52745288 0.51774502 0.13687164]  energy_before :  50  energy_after :  40  reward :  -181.49239667490951\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "action : 1  next_temperatures :  [0.81533824 1.65513889 0.99184368 0.38887846 0.31327518 1.16105932\n",
      " 0.52745288 0.51774502 0.13687164]  energy_before :  40  energy_after :  50  reward :  -201.49239667490951\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "action : 1  next_temperatures :  [0.81533824 1.65513889 0.99184368 0.38887846 0.31327518 1.16105932\n",
      " 0.52745288 0.51774502 0.13687164]  energy_before :  50  energy_after :  50  reward :  -191.49239667490951\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "action : 1  next_temperatures :  [0.81533824 1.65513889 0.99184368 0.38887846 0.31327518 1.16105932\n",
      " 0.52745288 0.51774502 0.13687164]  energy_before :  50  energy_after :  50  reward :  -191.49239667490951\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "Episode 100/500, Total Reward: -986.4619833745476\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "action : 2  next_temperatures :  [ 1.37572804 -0.07050196  0.84439935  0.42737425  0.9496803  -0.30358207\n",
      "  1.10345044 -0.15794975  0.46214955]  energy_before :  30  energy_after :  50  reward :  -222.36925185072275\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "action : 1  next_temperatures :  [ 1.37572804 -0.07050196  0.84439935  0.42737425  0.9496803  -0.30358207\n",
      "  1.10345044 -0.15794975  0.46214955]  energy_before :  50  energy_after :  40  reward :  -183.36925185072275\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "action : 1  next_temperatures :  [ 1.37572804 -0.07050196  0.84439935  0.42737425  0.9496803  -0.30358207\n",
      "  1.10345044 -0.15794975  0.46214955]  energy_before :  40  energy_after :  50  reward :  -203.36925185072275\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "action : 1  next_temperatures :  [ 1.37572804 -0.07050196  0.84439935  0.42737425  0.9496803  -0.30358207\n",
      "  1.10345044 -0.15794975  0.46214955]  energy_before :  50  energy_after :  50  reward :  -193.36925185072275\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "action : 1  next_temperatures :  [ 1.37572804 -0.07050196  0.84439935  0.42737425  0.9496803  -0.30358207\n",
      "  1.10345044 -0.15794975  0.46214955]  energy_before :  50  energy_after :  50  reward :  -193.36925185072275\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "Episode 101/500, Total Reward: -995.8462592536138\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "action : 1  next_temperatures :  [-0.18466176 -0.14066635  0.88867006 -0.66272227 -0.13340131 -0.66139315\n",
      "  0.50648556 -0.40009664  0.12535506]  energy_before :  30  energy_after :  50  reward :  -218.66243080185455\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "action : 1  next_temperatures :  [-0.18466176 -0.14066635  0.88867006 -0.66272227 -0.13340131 -0.66139315\n",
      "  0.50648556 -0.40009664  0.12535506]  energy_before :  50  energy_after :  40  reward :  -188.66243080185455\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "action : 1  next_temperatures :  [-0.18466176 -0.14066635  0.88867006 -0.66272227 -0.13340131 -0.66139315\n",
      "  0.50648556 -0.40009664  0.12535506]  energy_before :  40  energy_after :  50  reward :  -208.66243080185455\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "action : 1  next_temperatures :  [-0.18466176 -0.14066635  0.88867006 -0.66272227 -0.13340131 -0.66139315\n",
      "  0.50648556 -0.40009664  0.12535506]  energy_before :  50  energy_after :  50  reward :  -198.66243080185455\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "action : 1  next_temperatures :  [-0.18466176 -0.14066635  0.88867006 -0.66272227 -0.13340131 -0.66139315\n",
      "  0.50648556 -0.40009664  0.12535506]  energy_before :  50  energy_after :  50  reward :  -198.66243080185455\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "Episode 102/500, Total Reward: -1013.3121540092727\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "action : 1  next_temperatures :  [-1.80356562  0.86456133 -1.11778894  0.90168098 -1.32977646  1.18221139\n",
      " -1.59353955  1.1225201  -1.40525821]  energy_before :  30  energy_after :  50  reward :  -221.17895498406847\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step\n",
      "action : 1  next_temperatures :  [-1.80356562  0.86456133 -1.11778894  0.90168098 -1.32977646  1.18221139\n",
      " -1.59353955  1.1225201  -1.40525821]  energy_before :  50  energy_after :  40  reward :  -191.17895498406847\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "action : 1  next_temperatures :  [-1.80356562  0.86456133 -1.11778894  0.90168098 -1.32977646  1.18221139\n",
      " -1.59353955  1.1225201  -1.40525821]  energy_before :  40  energy_after :  50  reward :  -211.17895498406847\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "action : 1  next_temperatures :  [-1.80356562  0.86456133 -1.11778894  0.90168098 -1.32977646  1.18221139\n",
      " -1.59353955  1.1225201  -1.40525821]  energy_before :  50  energy_after :  50  reward :  -201.17895498406847\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "action : 1  next_temperatures :  [-1.80356562  0.86456133 -1.11778894  0.90168098 -1.32977646  1.18221139\n",
      " -1.59353955  1.1225201  -1.40525821]  energy_before :  50  energy_after :  50  reward :  -201.17895498406847\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "Episode 103/500, Total Reward: -1025.8947749203423\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "action : 0  next_temperatures :  [ 1.30595957 -1.33333499  1.80848651 -2.40560905  1.10980211 -1.46842921\n",
      "  1.25569062 -0.97701957  1.11858581]  energy_before :  30  energy_after :  50  reward :  -208.58586820857292\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "action : 1  next_temperatures :  [ 1.30595957 -1.33333499  1.80848651 -2.40560905  1.10980211 -1.46842921\n",
      "  1.25569062 -0.97701957  1.11858581]  energy_before :  50  energy_after :  40  reward :  -187.5858682085729\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "action : 1  next_temperatures :  [ 1.30595957 -1.33333499  1.80848651 -2.40560905  1.10980211 -1.46842921\n",
      "  1.25569062 -0.97701957  1.11858581]  energy_before :  40  energy_after :  50  reward :  -207.5858682085729\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "action : 0  next_temperatures :  [ 0.30595957 -2.33333499  0.80848651 -3.40560905  0.10980211 -2.46842921\n",
      "  0.25569062 -1.97701957  0.11858581]  energy_before :  50  energy_after :  50  reward :  -197.5858682085729\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "action : 1  next_temperatures :  [ 0.30595957 -2.33333499  0.80848651 -3.40560905  0.10980211 -2.46842921\n",
      "  0.25569062 -1.97701957  0.11858581]  energy_before :  50  energy_after :  50  reward :  -206.5858682085729\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "Episode 104/500, Total Reward: -1007.9293410428645\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "action : 1  next_temperatures :  [-0.18466176  0.36194749 -0.73473768  1.00242527  0.31025448  0.09755738\n",
      "  0.07081602  0.10897794  0.49219626]  energy_before :  30  energy_after :  50  reward :  -216.47522458901145\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "action : 1  next_temperatures :  [-0.18466176  0.36194749 -0.73473768  1.00242527  0.31025448  0.09755738\n",
      "  0.07081602  0.10897794  0.49219626]  energy_before :  50  energy_after :  40  reward :  -186.47522458901145\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "action : 2  next_temperatures :  [0.81533824 1.36194749 0.26526232 2.00242527 1.31025448 1.09755738\n",
      " 1.07081602 1.10897794 1.49219626]  energy_before :  40  energy_after :  50  reward :  -206.47522458901145\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "action : 0  next_temperatures :  [-0.18466176  0.36194749 -0.73473768  1.00242527  0.31025448  0.09755738\n",
      "  0.07081602  0.10897794  0.49219626]  energy_before :  50  energy_after :  50  reward :  -187.47522458901145\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "action : 1  next_temperatures :  [-0.18466176  0.36194749 -0.73473768  1.00242527  0.31025448  0.09755738\n",
      "  0.07081602  0.10897794  0.49219626]  energy_before :  50  energy_after :  50  reward :  -196.47522458901145\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "Episode 105/500, Total Reward: -993.3761229450572\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "action : 2  next_temperatures :  [1.12666591 0.58959755 1.39161544 0.33891585 1.11584352 0.46458649\n",
      " 1.21277576 0.64827697 1.23920233]  energy_before :  30  energy_after :  50  reward :  -218.87252019415294\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "action : 0  next_temperatures :  [ 0.12666591 -0.41040245  0.39161544 -0.66108415  0.11584352 -0.53541351\n",
      "  0.21277576 -0.35172303  0.23920233]  energy_before :  50  energy_after :  40  reward :  -179.87252019415294\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "action : 1  next_temperatures :  [ 0.12666591 -0.41040245  0.39161544 -0.66108415  0.11584352 -0.53541351\n",
      "  0.21277576 -0.35172303  0.23920233]  energy_before :  40  energy_after :  50  reward :  -208.87252019415294\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "action : 1  next_temperatures :  [ 0.12666591 -0.41040245  0.39161544 -0.66108415  0.11584352 -0.53541351\n",
      "  0.21277576 -0.35172303  0.23920233]  energy_before :  50  energy_after :  50  reward :  -198.87252019415294\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "action : 1  next_temperatures :  [ 0.12666591 -0.41040245  0.39161544 -0.66108415  0.11584352 -0.53541351\n",
      "  0.21277576 -0.35172303  0.23920233]  energy_before :  50  energy_after :  50  reward :  -198.87252019415294\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "Episode 106/500, Total Reward: -1005.3626009707647\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "action : 0  next_temperatures :  [ 0.25367206 -0.14465326 -0.03563172 -0.41775214  0.05798895 -0.76724495\n",
      "  0.43656661 -0.33127037 -0.18252583]  energy_before :  30  energy_after :  50  reward :  -210.130850641706\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "action : 0  next_temperatures :  [-0.74632794 -1.14465326 -1.03563172 -1.41775214 -0.94201105 -1.76724495\n",
      " -0.56343339 -1.33127037 -1.18252583]  energy_before :  50  energy_after :  40  reward :  -189.130850641706\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "action : 2  next_temperatures :  [ 0.25367206 -0.14465326 -0.03563172 -0.41775214  0.05798895 -0.76724495\n",
      "  0.43656661 -0.33127037 -0.18252583]  energy_before :  40  energy_after :  50  reward :  -218.130850641706\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "action : 1  next_temperatures :  [ 0.25367206 -0.14465326 -0.03563172 -0.41775214  0.05798895 -0.76724495\n",
      "  0.43656661 -0.33127037 -0.18252583]  energy_before :  50  energy_after :  50  reward :  -199.130850641706\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "action : 1  next_temperatures :  [ 0.25367206 -0.14465326 -0.03563172 -0.41775214  0.05798895 -0.76724495\n",
      "  0.43656661 -0.33127037 -0.18252583]  energy_before :  50  energy_after :  50  reward :  -199.130850641706\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "Episode 107/500, Total Reward: -1015.65425320853\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "action : 2  next_temperatures :  [ 1.37572804 -0.24892988  0.33822447  0.59200517  0.56252001 -0.14994836\n",
      "  1.62560121 -0.40365694  0.6193672 ]  energy_before :  30  energy_after :  50  reward :  -222.6890890793379\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "action : 1  next_temperatures :  [ 1.37572804 -0.24892988  0.33822447  0.59200517  0.56252001 -0.14994836\n",
      "  1.62560121 -0.40365694  0.6193672 ]  energy_before :  50  energy_after :  40  reward :  -183.6890890793379\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "action : 1  next_temperatures :  [ 1.37572804 -0.24892988  0.33822447  0.59200517  0.56252001 -0.14994836\n",
      "  1.62560121 -0.40365694  0.6193672 ]  energy_before :  40  energy_after :  50  reward :  -203.6890890793379\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "action : 1  next_temperatures :  [ 1.37572804 -0.24892988  0.33822447  0.59200517  0.56252001 -0.14994836\n",
      "  1.62560121 -0.40365694  0.6193672 ]  energy_before :  50  energy_after :  50  reward :  -193.6890890793379\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "action : 1  next_temperatures :  [ 1.37572804 -0.24892988  0.33822447  0.59200517  0.56252001 -0.14994836\n",
      "  1.62560121 -0.40365694  0.6193672 ]  energy_before :  50  energy_after :  50  reward :  -193.6890890793379\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "Episode 108/500, Total Reward: -997.4454453966895\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "action : 1  next_temperatures :  [-0.738825    0.41891039 -0.25136347 -0.10330477 -0.63189095  0.28294206\n",
      " -0.8103134   0.35314946 -0.3806328 ]  energy_before :  30  energy_after :  50  reward :  -219.86132847737136\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "action : 1  next_temperatures :  [-0.738825    0.41891039 -0.25136347 -0.10330477 -0.63189095  0.28294206\n",
      " -0.8103134   0.35314946 -0.3806328 ]  energy_before :  50  energy_after :  40  reward :  -189.86132847737136\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "action : 2  next_temperatures :  [0.261175   1.41891039 0.74863653 0.89669523 0.36810905 1.28294206\n",
      " 0.1896866  1.35314946 0.6193672 ]  energy_before :  40  energy_after :  50  reward :  -209.86132847737136\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "action : 1  next_temperatures :  [0.261175   1.41891039 0.74863653 0.89669523 0.36810905 1.28294206\n",
      " 0.1896866  1.35314946 0.6193672 ]  energy_before :  50  energy_after :  50  reward :  -190.86132847737136\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "action : 1  next_temperatures :  [0.261175   1.41891039 0.74863653 0.89669523 0.36810905 1.28294206\n",
      " 0.1896866  1.35314946 0.6193672 ]  energy_before :  50  energy_after :  50  reward :  -190.86132847737136\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "Episode 109/500, Total Reward: -1001.3066423868568\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "action : 1  next_temperatures :  [ 0.43799358 -0.29396358 -0.25136347  0.16452762  1.30723378 -0.62759374\n",
      "  0.7022921  -0.79169247  0.64941392]  energy_before :  30  energy_after :  50  reward :  -216.70315226581587\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "action : 1  next_temperatures :  [ 0.43799358 -0.29396358 -0.25136347  0.16452762  1.30723378 -0.62759374\n",
      "  0.7022921  -0.79169247  0.64941392]  energy_before :  50  energy_after :  40  reward :  -186.70315226581587\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "action : 1  next_temperatures :  [ 0.43799358 -0.29396358 -0.25136347  0.16452762  1.30723378 -0.62759374\n",
      "  0.7022921  -0.79169247  0.64941392]  energy_before :  40  energy_after :  50  reward :  -206.70315226581587\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "action : 1  next_temperatures :  [ 0.43799358 -0.29396358 -0.25136347  0.16452762  1.30723378 -0.62759374\n",
      "  0.7022921  -0.79169247  0.64941392]  energy_before :  50  energy_after :  50  reward :  -196.70315226581587\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "action : 1  next_temperatures :  [ 0.43799358 -0.29396358 -0.25136347  0.16452762  1.30723378 -0.62759374\n",
      "  0.7022921  -0.79169247  0.64941392]  energy_before :  50  energy_after :  50  reward :  -196.70315226581587\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "Episode 110/500, Total Reward: -1003.5157613290794\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "action : 1  next_temperatures :  [ 1.50273419 -2.14358252  1.71405433 -2.85780118  0.66418213 -1.58319543\n",
      "  0.94705027 -1.75071834  1.08853909]  energy_before :  30  energy_after :  50  reward :  -220.41873745084786\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "action : 1  next_temperatures :  [ 1.50273419 -2.14358252  1.71405433 -2.85780118  0.66418213 -1.58319543\n",
      "  0.94705027 -1.75071834  1.08853909]  energy_before :  50  energy_after :  40  reward :  -190.41873745084786\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "action : 1  next_temperatures :  [ 1.50273419 -2.14358252  1.71405433 -2.85780118  0.66418213 -1.58319543\n",
      "  0.94705027 -1.75071834  1.08853909]  energy_before :  40  energy_after :  50  reward :  -210.41873745084786\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "action : 1  next_temperatures :  [ 1.50273419 -2.14358252  1.71405433 -2.85780118  0.66418213 -1.58319543\n",
      "  0.94705027 -1.75071834  1.08853909]  energy_before :  50  energy_after :  50  reward :  -200.41873745084786\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "action : 1  next_temperatures :  [ 1.50273419 -2.14358252  1.71405433 -2.85780118  0.66418213 -1.58319543\n",
      "  0.94705027 -1.75071834  1.08853909]  energy_before :  50  energy_after :  50  reward :  -200.41873745084786\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "Episode 111/500, Total Reward: -1022.0936872542393\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "action : 1  next_temperatures :  [ 0.195158    1.29848461 -0.33800601  2.00167761  1.24243012  0.92922788\n",
      "  0.56033236  0.5297515   0.49219626]  energy_before :  30  energy_after :  50  reward :  -211.08874766449867\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "action : 1  next_temperatures :  [ 0.195158    1.29848461 -0.33800601  2.00167761  1.24243012  0.92922788\n",
      "  0.56033236  0.5297515   0.49219626]  energy_before :  50  energy_after :  40  reward :  -181.08874766449867\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "action : 1  next_temperatures :  [ 0.195158    1.29848461 -0.33800601  2.00167761  1.24243012  0.92922788\n",
      "  0.56033236  0.5297515   0.49219626]  energy_before :  40  energy_after :  50  reward :  -201.08874766449867\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "action : 1  next_temperatures :  [ 0.195158    1.29848461 -0.33800601  2.00167761  1.24243012  0.92922788\n",
      "  0.56033236  0.5297515   0.49219626]  energy_before :  50  energy_after :  50  reward :  -191.08874766449867\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "action : 1  next_temperatures :  [ 0.195158    1.29848461 -0.33800601  2.00167761  1.24243012  0.92922788\n",
      "  0.56033236  0.5297515   0.49219626]  energy_before :  50  energy_after :  50  reward :  -191.08874766449867\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "Episode 112/500, Total Reward: -975.4437383224933\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "action : 1  next_temperatures :  [-0.24692729 -0.59301881 -0.47937017 -0.5636161  -0.83128681 -0.1666926\n",
      "  0.3318914  -0.61355476 -0.48363747]  energy_before :  30  energy_after :  50  reward :  -221.64621261220933\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "action : 1  next_temperatures :  [-0.24692729 -0.59301881 -0.47937017 -0.5636161  -0.83128681 -0.1666926\n",
      "  0.3318914  -0.61355476 -0.48363747]  energy_before :  50  energy_after :  40  reward :  -191.64621261220933\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "action : 2  next_temperatures :  [0.75307271 0.40698119 0.52062983 0.4363839  0.16871319 0.8333074\n",
      " 1.3318914  0.38644524 0.51636253]  energy_before :  40  energy_after :  50  reward :  -211.64621261220933\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "action : 1  next_temperatures :  [0.75307271 0.40698119 0.52062983 0.4363839  0.16871319 0.8333074\n",
      " 1.3318914  0.38644524 0.51636253]  energy_before :  50  energy_after :  50  reward :  -192.64621261220933\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "action : 1  next_temperatures :  [0.75307271 0.40698119 0.52062983 0.4363839  0.16871319 0.8333074\n",
      " 1.3318914  0.38644524 0.51636253]  energy_before :  50  energy_after :  50  reward :  -192.64621261220933\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "Episode 113/500, Total Reward: -1010.2310630610466\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "action : 0  next_temperatures :  [ 0.50273419  0.89240664 -0.33933665  1.52587556  0.5564786   0.07159512\n",
      "  0.24076008  0.51181242  0.7878866 ]  energy_before :  30  energy_after :  50  reward :  -204.2497874380083\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "action : 0  next_temperatures :  [-0.49726581 -0.10759336 -1.33933665  0.52587556 -0.4435214  -0.92840488\n",
      " -0.75923992 -0.48818758 -0.2121134 ]  energy_before :  50  energy_after :  40  reward :  -183.2497874380083\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "action : 1  next_temperatures :  [-0.49726581 -0.10759336 -1.33933665  0.52587556 -0.4435214  -0.92840488\n",
      " -0.75923992 -0.48818758 -0.2121134 ]  energy_before :  40  energy_after :  50  reward :  -212.2497874380083\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "action : 1  next_temperatures :  [-0.49726581 -0.10759336 -1.33933665  0.52587556 -0.4435214  -0.92840488\n",
      " -0.75923992 -0.48818758 -0.2121134 ]  energy_before :  50  energy_after :  50  reward :  -202.2497874380083\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "action : 1  next_temperatures :  [-0.49726581 -0.10759336 -1.33933665  0.52587556 -0.4435214  -0.92840488\n",
      " -0.75923992 -0.48818758 -0.2121134 ]  energy_before :  50  energy_after :  50  reward :  -202.2497874380083\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step\n",
      "Episode 114/500, Total Reward: -1004.2489371900415\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "action : 2  next_temperatures :  [1.195158   0.84844368 0.94928243 1.10883158 0.81176483 0.48302253\n",
      " 0.80810891 0.57072563 0.95006641]  energy_before :  30  energy_after :  50  reward :  -219.2745959827467\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "action : 0  next_temperatures :  [ 0.195158   -0.15155632 -0.05071757  0.10883158 -0.18823517 -0.51697747\n",
      " -0.19189109 -0.42927437 -0.04993359]  energy_before :  50  energy_after :  40  reward :  -180.2745959827467\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "action : 1  next_temperatures :  [ 0.195158   -0.15155632 -0.05071757  0.10883158 -0.18823517 -0.51697747\n",
      " -0.19189109 -0.42927437 -0.04993359]  energy_before :  40  energy_after :  50  reward :  -209.2745959827467\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "action : 1  next_temperatures :  [ 0.195158   -0.15155632 -0.05071757  0.10883158 -0.18823517 -0.51697747\n",
      " -0.19189109 -0.42927437 -0.04993359]  energy_before :  50  energy_after :  50  reward :  -199.2745959827467\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "action : 1  next_temperatures :  [ 0.195158   -0.15155632 -0.05071757  0.10883158 -0.18823517 -0.51697747\n",
      " -0.19189109 -0.42927437 -0.04993359]  energy_before :  50  energy_after :  50  reward :  -199.2745959827467\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "Episode 115/500, Total Reward: -1007.3729799137334\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "action : 2  next_temperatures :  [-0.2992148  -0.08893114 -0.16339028  0.25782898 -0.1303806  -0.16121483\n",
      " -0.22313885  0.31657226  0.40793656]  energy_before :  30  energy_after :  50  reward :  -227.08393270464637\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "action : 1  next_temperatures :  [-0.2992148  -0.08893114 -0.16339028  0.25782898 -0.1303806  -0.16121483\n",
      " -0.22313885  0.31657226  0.40793656]  energy_before :  50  energy_after :  40  reward :  -188.08393270464637\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "action : 1  next_temperatures :  [-0.2992148  -0.08893114 -0.16339028  0.25782898 -0.1303806  -0.16121483\n",
      " -0.22313885  0.31657226  0.40793656]  energy_before :  40  energy_after :  50  reward :  -208.08393270464637\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "action : 1  next_temperatures :  [-0.2992148  -0.08893114 -0.16339028  0.25782898 -0.1303806  -0.16121483\n",
      " -0.22313885  0.31657226  0.40793656]  energy_before :  50  energy_after :  50  reward :  -198.08393270464637\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "action : 1  next_temperatures :  [-0.2992148  -0.08893114 -0.16339028  0.25782898 -0.1303806  -0.16121483\n",
      " -0.22313885  0.31657226  0.40793656]  energy_before :  50  energy_after :  50  reward :  -198.08393270464637\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "Episode 116/500, Total Reward: -1019.4196635232319\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "action : 1  next_temperatures :  [-0.05390414 -0.16831012 -1.02202613  1.10071239  0.7140311  -0.32032631\n",
      "  0.100187   -0.29321401  0.54640924]  energy_before :  30  energy_after :  50  reward :  -217.39644097548805\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "action : 1  next_temperatures :  [-0.05390414 -0.16831012 -1.02202613  1.10071239  0.7140311  -0.32032631\n",
      "  0.100187   -0.29321401  0.54640924]  energy_before :  50  energy_after :  40  reward :  -187.39644097548805\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "action : 1  next_temperatures :  [-0.05390414 -0.16831012 -1.02202613  1.10071239  0.7140311  -0.32032631\n",
      "  0.100187   -0.29321401  0.54640924]  energy_before :  40  energy_after :  50  reward :  -207.39644097548805\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "action : 1  next_temperatures :  [-0.05390414 -0.16831012 -1.02202613  1.10071239  0.7140311  -0.32032631\n",
      "  0.100187   -0.29321401  0.54640924]  energy_before :  50  energy_after :  50  reward :  -197.39644097548805\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "action : 1  next_temperatures :  [-0.05390414 -0.16831012 -1.02202613  1.10071239  0.7140311  -0.32032631\n",
      "  0.100187   -0.29321401  0.54640924]  energy_before :  50  energy_after :  50  reward :  -197.39644097548805\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "Episode 117/500, Total Reward: -1006.9822048774403\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "action : 1  next_temperatures :  [-1.2992148   1.44256725 -0.70737688  1.34643018 -1.21844711  1.83976368\n",
      " -1.15297484  1.95178186 -1.13419329]  energy_before :  30  energy_after :  50  reward :  -216.9316639450122\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "action : 1  next_temperatures :  [-1.2992148   1.44256725 -0.70737688  1.34643018 -1.21844711  1.83976368\n",
      " -1.15297484  1.95178186 -1.13419329]  energy_before :  50  energy_after :  40  reward :  -186.9316639450122\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "action : 1  next_temperatures :  [-1.2992148   1.44256725 -0.70737688  1.34643018 -1.21844711  1.83976368\n",
      " -1.15297484  1.95178186 -1.13419329]  energy_before :  40  energy_after :  50  reward :  -206.9316639450122\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "action : 1  next_temperatures :  [-1.2992148   1.44256725 -0.70737688  1.34643018 -1.21844711  1.83976368\n",
      " -1.15297484  1.95178186 -1.13419329]  energy_before :  50  energy_after :  50  reward :  -196.9316639450122\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "action : 1  next_temperatures :  [-1.2992148   1.44256725 -0.70737688  1.34643018 -1.21844711  1.83976368\n",
      " -1.15297484  1.95178186 -1.13419329]  energy_before :  50  energy_after :  50  reward :  -196.9316639450122\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "Episode 118/500, Total Reward: -1004.6583197250609\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "action : 1  next_temperatures :  [ 0.68705571 -0.5452705   1.24284047 -1.13777666  0.21554145 -0.22814609\n",
      "  0.56033236 -0.53600343  0.60759247]  energy_before :  30  energy_after :  50  reward :  -217.13383421685933\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "action : 1  next_temperatures :  [ 0.68705571 -0.5452705   1.24284047 -1.13777666  0.21554145 -0.22814609\n",
      "  0.56033236 -0.53600343  0.60759247]  energy_before :  50  energy_after :  40  reward :  -187.13383421685933\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "action : 1  next_temperatures :  [ 0.68705571 -0.5452705   1.24284047 -1.13777666  0.21554145 -0.22814609\n",
      "  0.56033236 -0.53600343  0.60759247]  energy_before :  40  energy_after :  50  reward :  -207.13383421685933\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "action : 1  next_temperatures :  [ 0.68705571 -0.5452705   1.24284047 -1.13777666  0.21554145 -0.22814609\n",
      "  0.56033236 -0.53600343  0.60759247]  energy_before :  50  energy_after :  50  reward :  -197.13383421685933\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "action : 1  next_temperatures :  [ 0.68705571 -0.5452705   1.24284047 -1.13777666  0.21554145 -0.22814609\n",
      "  0.56033236 -0.53600343  0.60759247]  energy_before :  50  energy_after :  50  reward :  -197.13383421685933\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "Episode 119/500, Total Reward: -1005.6691710842966\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "action : 1  next_temperatures :  [-0.24692729  0.45995719 -0.33800601  0.47740827 -0.58204199  0.62913003\n",
      "  0.50648556  0.11588846 -0.54559517]  energy_before :  30  energy_after :  50  reward :  -217.52370095812975\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "action : 1  next_temperatures :  [-0.24692729  0.45995719 -0.33800601  0.47740827 -0.58204199  0.62913003\n",
      "  0.50648556  0.11588846 -0.54559517]  energy_before :  50  energy_after :  40  reward :  -187.52370095812975\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "action : 1  next_temperatures :  [-0.24692729  0.45995719 -0.33800601  0.47740827 -0.58204199  0.62913003\n",
      "  0.50648556  0.11588846 -0.54559517]  energy_before :  40  energy_after :  50  reward :  -207.52370095812975\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "action : 1  next_temperatures :  [-0.24692729  0.45995719 -0.33800601  0.47740827 -0.58204199  0.62913003\n",
      "  0.50648556  0.11588846 -0.54559517]  energy_before :  50  energy_after :  50  reward :  -197.52370095812975\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "action : 1  next_temperatures :  [-0.24692729  0.45995719 -0.33800601  0.47740827 -0.58204199  0.62913003\n",
      "  0.50648556  0.11588846 -0.54559517]  energy_before :  50  energy_after :  50  reward :  -197.52370095812975\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "Episode 120/500, Total Reward: -1007.6185047906488\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "action : 1  next_temperatures :  [ 1.25367206  2.53072621  1.11667676 -0.25237357  0.82702208  0.15081707\n",
      "  0.31557419  0.00762373  0.3295573 ]  energy_before :  30  energy_after :  50  reward :  -211.72070415376405\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "action : 0  next_temperatures :  [ 0.25367206  1.53072621  0.11667676 -1.25237357 -0.17297792 -0.84918293\n",
      " -0.68442581 -0.99237627 -0.6704427 ]  energy_before :  50  energy_after :  40  reward :  -181.72070415376405\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "action : 1  next_temperatures :  [ 0.25367206  1.53072621  0.11667676 -1.25237357 -0.17297792 -0.84918293\n",
      " -0.68442581 -0.99237627 -0.6704427 ]  energy_before :  40  energy_after :  50  reward :  -210.72070415376405\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "action : 1  next_temperatures :  [ 0.25367206  1.53072621  0.11667676 -1.25237357 -0.17297792 -0.84918293\n",
      " -0.68442581 -0.99237627 -0.6704427 ]  energy_before :  50  energy_after :  50  reward :  -200.72070415376405\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "action : 1  next_temperatures :  [ 0.25367206  1.53072621  0.11667676 -1.25237357 -0.17297792 -0.84918293\n",
      " -0.68442581 -0.99237627 -0.6704427 ]  energy_before :  50  energy_after :  50  reward :  -200.72070415376405\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "Episode 121/500, Total Reward: -1005.6035207688202\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "action : 1  next_temperatures :  [-0.34447662 -0.5452705  -0.92018313  0.26527191  0.46478627 -0.84268094\n",
      " -0.56555523 -0.33099149 -0.04993359]  energy_before :  30  energy_after :  50  reward :  -220.86903331642827\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "action : 1  next_temperatures :  [-0.34447662 -0.5452705  -0.92018313  0.26527191  0.46478627 -0.84268094\n",
      " -0.56555523 -0.33099149 -0.04993359]  energy_before :  50  energy_after :  40  reward :  -190.86903331642827\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "action : 2  next_temperatures :  [0.65552338 0.4547295  0.07981687 1.26527191 1.46478627 0.15731906\n",
      " 0.43444477 0.66900851 0.95006641]  energy_before :  40  energy_after :  50  reward :  -210.86903331642827\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "action : 1  next_temperatures :  [0.65552338 0.4547295  0.07981687 1.26527191 1.46478627 0.15731906\n",
      " 0.43444477 0.66900851 0.95006641]  energy_before :  50  energy_after :  50  reward :  -191.86903331642827\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "action : 1  next_temperatures :  [0.65552338 0.4547295  0.07981687 1.26527191 1.46478627 0.15731906\n",
      " 0.43444477 0.66900851 0.95006641]  energy_before :  50  energy_after :  50  reward :  -191.86903331642827\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "Episode 122/500, Total Reward: -1006.3451665821414\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "action : 1  next_temperatures :  [ 0.06440038  0.62079362 -0.56601272  1.48567026  0.41493731  0.16822889\n",
      "  0.41347746  0.2617771   0.68329703]  energy_before :  30  energy_after :  50  reward :  -214.45343067955065\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "action : 1  next_temperatures :  [ 0.06440038  0.62079362 -0.56601272  1.48567026  0.41493731  0.16822889\n",
      "  0.41347746  0.2617771   0.68329703]  energy_before :  50  energy_after :  40  reward :  -184.45343067955065\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "action : 0  next_temperatures :  [-0.93559962 -0.37920638 -1.56601272  0.48567026 -0.58506269 -0.83177111\n",
      " -0.58652254 -0.7382229  -0.31670297]  energy_before :  40  energy_after :  50  reward :  -204.45343067955065\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "action : 2  next_temperatures :  [ 0.06440038  0.62079362 -0.56601272  1.48567026  0.41493731  0.16822889\n",
      "  0.41347746  0.2617771   0.68329703]  energy_before :  50  energy_after :  50  reward :  -203.45343067955065\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "action : 1  next_temperatures :  [ 0.06440038  0.62079362 -0.56601272  1.48567026  0.41493731  0.16822889\n",
      "  0.41347746  0.2617771   0.68329703]  energy_before :  50  energy_after :  50  reward :  -194.45343067955065\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "Episode 123/500, Total Reward: -1001.2671533977532\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "action : 2  next_temperatures :  [0.38570607 0.6834188  0.30782357 0.91880983 0.51267104 0.77185391\n",
      " 0.92396111 0.32348278 0.67900149]  energy_before :  30  energy_after :  50  reward :  -221.49327140246476\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "action : 1  next_temperatures :  [0.38570607 0.6834188  0.30782357 0.91880983 0.51267104 0.77185391\n",
      " 0.92396111 0.32348278 0.67900149]  energy_before :  50  energy_after :  40  reward :  -182.49327140246476\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "action : 1  next_temperatures :  [0.38570607 0.6834188  0.30782357 0.91880983 0.51267104 0.77185391\n",
      " 0.92396111 0.32348278 0.67900149]  energy_before :  40  energy_after :  50  reward :  -202.49327140246476\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "action : 1  next_temperatures :  [0.38570607 0.6834188  0.30782357 0.91880983 0.51267104 0.77185391\n",
      " 0.92396111 0.32348278 0.67900149]  energy_before :  50  energy_after :  50  reward :  -192.49327140246476\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "action : 1  next_temperatures :  [0.38570607 0.6834188  0.30782357 0.91880983 0.51267104 0.77185391\n",
      " 0.92396111 0.32348278 0.67900149]  energy_before :  50  energy_after :  50  reward :  -192.49327140246476\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "Episode 124/500, Total Reward: -991.4663570123238\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "action : 1  next_temperatures :  [-0.69731464  1.12256977 -0.12519976 -0.03204662 -0.01874869  2.09581987\n",
      " -0.96206346  0.72094241 -1.35104523]  energy_before :  30  energy_after :  50  reward :  -217.24708635012698\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "action : 1  next_temperatures :  [-0.69731464  1.12256977 -0.12519976 -0.03204662 -0.01874869  2.09581987\n",
      " -0.96206346  0.72094241 -1.35104523]  energy_before :  50  energy_after :  40  reward :  -187.24708635012698\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "action : 1  next_temperatures :  [-0.69731464  1.12256977 -0.12519976 -0.03204662 -0.01874869  2.09581987\n",
      " -0.96206346  0.72094241 -1.35104523]  energy_before :  40  energy_after :  50  reward :  -207.24708635012698\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "action : 1  next_temperatures :  [-0.69731464  1.12256977 -0.12519976 -0.03204662 -0.01874869  2.09581987\n",
      " -0.96206346  0.72094241 -1.35104523]  energy_before :  50  energy_after :  50  reward :  -197.24708635012698\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "action : 1  next_temperatures :  [-0.69731464  1.12256977 -0.12519976 -0.03204662 -0.01874869  2.09581987\n",
      " -0.96206346  0.72094241 -1.35104523]  energy_before :  50  energy_after :  50  reward :  -197.24708635012698\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "Episode 125/500, Total Reward: -1006.2354317506349\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "action : 1  next_temperatures :  [ 0.5687512  -0.30150278  0.5740208  -0.26056416  0.36508834 -0.18922555\n",
      " -0.17394215  0.41611193  0.3458212 ]  energy_before :  30  energy_after :  50  reward :  -216.65544117065917\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "action : 1  next_temperatures :  [ 0.5687512  -0.30150278  0.5740208  -0.26056416  0.36508834 -0.18922555\n",
      " -0.17394215  0.41611193  0.3458212 ]  energy_before :  50  energy_after :  40  reward :  -186.65544117065917\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step\n",
      "action : 1  next_temperatures :  [ 0.5687512  -0.30150278  0.5740208  -0.26056416  0.36508834 -0.18922555\n",
      " -0.17394215  0.41611193  0.3458212 ]  energy_before :  40  energy_after :  50  reward :  -206.65544117065917\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "action : 1  next_temperatures :  [ 0.5687512  -0.30150278  0.5740208  -0.26056416  0.36508834 -0.18922555\n",
      " -0.17394215  0.41611193  0.3458212 ]  energy_before :  50  energy_after :  50  reward :  -196.65544117065917\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "action : 1  next_temperatures :  [ 0.5687512  -0.30150278  0.5740208  -0.26056416  0.36508834 -0.18922555\n",
      " -0.17394215  0.41611193  0.3458212 ]  energy_before :  50  energy_after :  50  reward :  -196.65544117065917\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "Episode 126/500, Total Reward: -1003.2772058532959\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "action : 1  next_temperatures :  [ 0.68705571 -1.07050196 -0.20576213 -0.34902256  0.09756556 -1.22369254\n",
      " -0.12499052 -1.14259305  0.12716216]  energy_before :  30  energy_after :  50  reward :  -221.2047793252641\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "action : 1  next_temperatures :  [ 0.68705571 -1.07050196 -0.20576213 -0.34902256  0.09756556 -1.22369254\n",
      " -0.12499052 -1.14259305  0.12716216]  energy_before :  50  energy_after :  40  reward :  -191.2047793252641\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "action : 1  next_temperatures :  [ 0.68705571 -1.07050196 -0.20576213 -0.34902256  0.09756556 -1.22369254\n",
      " -0.12499052 -1.14259305  0.12716216]  energy_before :  40  energy_after :  50  reward :  -211.2047793252641\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "action : 1  next_temperatures :  [ 0.68705571 -1.07050196 -0.20576213 -0.34902256  0.09756556 -1.22369254\n",
      " -0.12499052 -1.14259305  0.12716216]  energy_before :  50  energy_after :  50  reward :  -201.2047793252641\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "action : 1  next_temperatures :  [ 0.68705571 -1.07050196 -0.20576213 -0.34902256  0.09756556 -1.22369254\n",
      " -0.12499052 -1.14259305  0.12716216]  energy_before :  50  energy_after :  50  reward :  -201.2047793252641\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "Episode 127/500, Total Reward: -1026.0238966263205\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "action : 1  next_temperatures :  [ 0.23666835  0.16844116 -0.70737688  1.43488858  0.91342696  0.00537716\n",
      " -0.03198241  0.36005998  0.60062223]  energy_before :  30  energy_after :  50  reward :  -215.01987487929665\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "action : 1  next_temperatures :  [ 0.23666835  0.16844116 -0.70737688  1.43488858  0.91342696  0.00537716\n",
      " -0.03198241  0.36005998  0.60062223]  energy_before :  50  energy_after :  40  reward :  -185.01987487929665\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "action : 1  next_temperatures :  [ 0.23666835  0.16844116 -0.70737688  1.43488858  0.91342696  0.00537716\n",
      " -0.03198241  0.36005998  0.60062223]  energy_before :  40  energy_after :  50  reward :  -205.01987487929665\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "action : 1  next_temperatures :  [ 0.23666835  0.16844116 -0.70737688  1.43488858  0.91342696  0.00537716\n",
      " -0.03198241  0.36005998  0.60062223]  energy_before :  50  energy_after :  50  reward :  -195.01987487929665\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "action : 1  next_temperatures :  [ 0.23666835  0.16844116 -0.70737688  1.43488858  0.91342696  0.00537716\n",
      " -0.03198241  0.36005998  0.60062223]  energy_before :  50  energy_after :  50  reward :  -195.01987487929665\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "Episode 128/500, Total Reward: -995.0993743964832\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "action : 2  next_temperatures :  [-0.23694927 -0.21374691  0.06461642 -0.07880439 -0.30129134  0.08094116\n",
      " -0.00611994  0.33883947 -0.11250809]  energy_before :  30  energy_after :  50  reward :  -227.46502287991876\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "action : 1  next_temperatures :  [-0.23694927 -0.21374691  0.06461642 -0.07880439 -0.30129134  0.08094116\n",
      " -0.00611994  0.33883947 -0.11250809]  energy_before :  50  energy_after :  40  reward :  -188.46502287991876\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "action : 1  next_temperatures :  [-0.23694927 -0.21374691  0.06461642 -0.07880439 -0.30129134  0.08094116\n",
      " -0.00611994  0.33883947 -0.11250809]  energy_before :  40  energy_after :  50  reward :  -208.46502287991876\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "action : 1  next_temperatures :  [-0.23694927 -0.21374691  0.06461642 -0.07880439 -0.30129134  0.08094116\n",
      " -0.00611994  0.33883947 -0.11250809]  energy_before :  50  energy_after :  50  reward :  -198.46502287991876\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "action : 2  next_temperatures :  [0.76305073 0.78625309 1.06461642 0.92119561 0.69870866 1.08094116\n",
      " 0.99388006 1.33883947 0.88749191]  energy_before :  50  energy_after :  50  reward :  -198.46502287991876\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "Episode 129/500, Total Reward: -1021.3251143995938\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "action : 1  next_temperatures :  [ 0.1723273  -0.29396358 -0.12519976  0.10883158 -0.18823517 -0.53541351\n",
      " -0.19189109 -0.42927437 -0.04993359]  energy_before :  30  energy_after :  50  reward :  -219.53275216904046\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step\n",
      "action : 1  next_temperatures :  [ 0.1723273  -0.29396358 -0.12519976  0.10883158 -0.18823517 -0.53541351\n",
      " -0.19189109 -0.42927437 -0.04993359]  energy_before :  50  energy_after :  40  reward :  -189.53275216904046\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "action : 1  next_temperatures :  [ 0.1723273  -0.29396358 -0.12519976  0.10883158 -0.18823517 -0.53541351\n",
      " -0.19189109 -0.42927437 -0.04993359]  energy_before :  40  energy_after :  50  reward :  -209.53275216904046\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "action : 1  next_temperatures :  [ 0.1723273  -0.29396358 -0.12519976  0.10883158 -0.18823517 -0.53541351\n",
      " -0.19189109 -0.42927437 -0.04993359]  energy_before :  50  energy_after :  50  reward :  -199.53275216904046\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "action : 1  next_temperatures :  [ 0.1723273  -0.29396358 -0.12519976  0.10883158 -0.18823517 -0.53541351\n",
      " -0.19189109 -0.42927437 -0.04993359]  energy_before :  50  energy_after :  50  reward :  -199.53275216904046\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "Episode 130/500, Total Reward: -1017.6637608452023\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "action : 2  next_temperatures :  [1.06440038 0.25368397 0.29262312 1.13422242 0.91644766 0.24642662\n",
      " 0.47850124 0.46399657 0.89043213]  energy_before :  30  energy_after :  50  reward :  -221.2592658904389\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "action : 1  next_temperatures :  [1.06440038 0.25368397 0.29262312 1.13422242 0.91644766 0.24642662\n",
      " 0.47850124 0.46399657 0.89043213]  energy_before :  50  energy_after :  40  reward :  -182.2592658904389\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "action : 1  next_temperatures :  [1.06440038 0.25368397 0.29262312 1.13422242 0.91644766 0.24642662\n",
      " 0.47850124 0.46399657 0.89043213]  energy_before :  40  energy_after :  50  reward :  -202.2592658904389\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "action : 0  next_temperatures :  [ 0.06440038 -0.74631603 -0.70737688  0.13422242 -0.08355234 -0.75357338\n",
      " -0.52149876 -0.53600343 -0.10956787]  energy_before :  50  energy_after :  50  reward :  -192.2592658904389\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "action : 2  next_temperatures :  [1.06440038 0.25368397 0.29262312 1.13422242 0.91644766 0.24642662\n",
      " 0.47850124 0.46399657 0.89043213]  energy_before :  50  energy_after :  50  reward :  -201.2592658904389\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "Episode 131/500, Total Reward: -999.2963294521945\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "action : 1  next_temperatures :  [-1.96338049 -0.33333499 -1.34579565 -0.44976686 -1.68370411  0.20202831\n",
      " -2.27886242 -0.18356718 -1.73595742]  energy_before :  30  energy_after :  50  reward :  -227.77234081244524\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "action : 1  next_temperatures :  [-1.96338049 -0.33333499 -1.34579565 -0.44976686 -1.68370411  0.20202831\n",
      " -2.27886242 -0.18356718 -1.73595742]  energy_before :  50  energy_after :  40  reward :  -197.77234081244524\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "action : 1  next_temperatures :  [-1.96338049 -0.33333499 -1.34579565 -0.44976686 -1.68370411  0.20202831\n",
      " -2.27886242 -0.18356718 -1.73595742]  energy_before :  40  energy_after :  50  reward :  -217.77234081244524\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "action : 1  next_temperatures :  [-1.96338049 -0.33333499 -1.34579565 -0.44976686 -1.68370411  0.20202831\n",
      " -2.27886242 -0.18356718 -1.73595742]  energy_before :  50  energy_after :  50  reward :  -207.77234081244524\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "action : 1  next_temperatures :  [-1.96338049 -0.33333499 -1.34579565 -0.44976686 -1.68370411  0.20202831\n",
      " -2.27886242 -0.18356718 -1.73595742]  energy_before :  50  energy_after :  50  reward :  -207.77234081244524\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "Episode 132/500, Total Reward: -1058.8617040622262\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "action : 1  next_temperatures :  [ 0.0083614  -0.13501195 -0.94906398  1.12528417  0.72898579 -0.25887283\n",
      "  0.11976765 -0.26465055  0.54640924]  energy_before :  30  energy_after :  50  reward :  -217.0787910623133\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "action : 1  next_temperatures :  [ 0.0083614  -0.13501195 -0.94906398  1.12528417  0.72898579 -0.25887283\n",
      "  0.11976765 -0.26465055  0.54640924]  energy_before :  50  energy_after :  40  reward :  -187.0787910623133\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "action : 1  next_temperatures :  [ 0.0083614  -0.13501195 -0.94906398  1.12528417  0.72898579 -0.25887283\n",
      "  0.11976765 -0.26465055  0.54640924]  energy_before :  40  energy_after :  50  reward :  -207.0787910623133\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "action : 1  next_temperatures :  [ 0.0083614  -0.13501195 -0.94906398  1.12528417  0.72898579 -0.25887283\n",
      "  0.11976765 -0.26465055  0.54640924]  energy_before :  50  energy_after :  50  reward :  -197.0787910623133\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "action : 1  next_temperatures :  [ 0.0083614  -0.13501195 -0.94906398  1.12528417  0.72898579 -0.25887283\n",
      "  0.11976765 -0.26465055  0.54640924]  energy_before :  50  energy_after :  50  reward :  -197.0787910623133\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "Episode 133/500, Total Reward: -1005.3939553115664\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "action : 1  next_temperatures :  [-2.67528308  0.56299302 -1.78508857  0.56750479 -2.2769068   0.47549632\n",
      " -2.67537066  0.66181912 -2.16424   ]  energy_before :  30  energy_after :  50  reward :  -227.30907585983286\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "action : 1  next_temperatures :  [-2.67528308  0.56299302 -1.78508857  0.56750479 -2.2769068   0.47549632\n",
      " -2.67537066  0.66181912 -2.16424   ]  energy_before :  50  energy_after :  40  reward :  -197.30907585983286\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "action : 1  next_temperatures :  [-2.67528308  0.56299302 -1.78508857  0.56750479 -2.2769068   0.47549632\n",
      " -2.67537066  0.66181912 -2.16424   ]  energy_before :  40  energy_after :  50  reward :  -217.30907585983286\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "action : 1  next_temperatures :  [-2.67528308  0.56299302 -1.78508857  0.56750479 -2.2769068   0.47549632\n",
      " -2.67537066  0.66181912 -2.16424   ]  energy_before :  50  energy_after :  50  reward :  -207.30907585983286\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "action : 1  next_temperatures :  [-2.67528308  0.56299302 -1.78508857  0.56750479 -2.2769068   0.47549632\n",
      " -2.67537066  0.66181912 -2.16424   ]  energy_before :  50  energy_after :  50  reward :  -207.30907585983286\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "Episode 134/500, Total Reward: -1056.5453792991643\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "action : 1  next_temperatures :  [-0.67655947  0.22707944 -0.25136347 -0.2114206  -0.63189095  0.2225128\n",
      " -0.76625693  0.32397173 -0.3806328 ]  energy_before :  30  energy_after :  50  reward :  -220.14456023877196\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "action : 1  next_temperatures :  [-0.67655947  0.22707944 -0.25136347 -0.2114206  -0.63189095  0.2225128\n",
      " -0.76625693  0.32397173 -0.3806328 ]  energy_before :  50  energy_after :  40  reward :  -190.14456023877196\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "action : 1  next_temperatures :  [-0.67655947  0.22707944 -0.25136347 -0.2114206  -0.63189095  0.2225128\n",
      " -0.76625693  0.32397173 -0.3806328 ]  energy_before :  40  energy_after :  50  reward :  -210.14456023877196\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "action : 1  next_temperatures :  [-0.67655947  0.22707944 -0.25136347 -0.2114206  -0.63189095  0.2225128\n",
      " -0.76625693  0.32397173 -0.3806328 ]  energy_before :  50  energy_after :  50  reward :  -200.14456023877196\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "action : 1  next_temperatures :  [-0.67655947  0.22707944 -0.25136347 -0.2114206  -0.63189095  0.2225128\n",
      " -0.76625693  0.32397173 -0.3806328 ]  energy_before :  50  energy_after :  50  reward :  -200.14456023877196\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "Episode 135/500, Total Reward: -1020.7228011938598\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step\n",
      "action : 1  next_temperatures :  [-0.28428661 -1.04788434 -0.73473768 -0.29414559 -1.047299   -0.87340768\n",
      " -0.52149876 -0.9967044  -0.41677479]  energy_before :  30  energy_after :  50  reward :  -224.2167388398993\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "action : 1  next_temperatures :  [-0.28428661 -1.04788434 -0.73473768 -0.29414559 -1.047299   -0.87340768\n",
      " -0.52149876 -0.9967044  -0.41677479]  energy_before :  50  energy_after :  40  reward :  -194.2167388398993\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "action : 1  next_temperatures :  [-0.28428661 -1.04788434 -0.73473768 -0.29414559 -1.047299   -0.87340768\n",
      " -0.52149876 -0.9967044  -0.41677479]  energy_before :  40  energy_after :  50  reward :  -214.2167388398993\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "action : 1  next_temperatures :  [-0.28428661 -1.04788434 -0.73473768 -0.29414559 -1.047299   -0.87340768\n",
      " -0.52149876 -0.9967044  -0.41677479]  energy_before :  50  energy_after :  50  reward :  -204.2167388398993\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "action : 1  next_temperatures :  [-0.28428661 -1.04788434 -0.73473768 -0.29414559 -1.047299   -0.87340768\n",
      " -0.52149876 -0.9967044  -0.41677479]  energy_before :  50  energy_after :  50  reward :  -204.2167388398993\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "Episode 136/500, Total Reward: -1041.0836941994964\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "action : 0  next_temperatures :  [ 0.30971104 -0.6883139   0.11667676 -1.01976073  0.11282282 -1.24043678\n",
      "  0.34355851 -0.93939566  0.03432611]  energy_before :  30  energy_after :  50  reward :  -211.97081183339984\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "action : 1  next_temperatures :  [ 0.30971104 -0.6883139   0.11667676 -1.01976073  0.11282282 -1.24043678\n",
      "  0.34355851 -0.93939566  0.03432611]  energy_before :  50  energy_after :  40  reward :  -190.97081183339984\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "action : 1  next_temperatures :  [ 0.30971104 -0.6883139   0.11667676 -1.01976073  0.11282282 -1.24043678\n",
      "  0.34355851 -0.93939566  0.03432611]  energy_before :  40  energy_after :  50  reward :  -210.97081183339984\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "action : 1  next_temperatures :  [ 0.30971104 -0.6883139   0.11667676 -1.01976073  0.11282282 -1.24043678\n",
      "  0.34355851 -0.93939566  0.03432611]  energy_before :  50  energy_after :  50  reward :  -200.97081183339984\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "action : 1  next_temperatures :  [ 0.30971104 -0.6883139   0.11667676 -1.01976073  0.11282282 -1.24043678\n",
      "  0.34355851 -0.93939566  0.03432611]  energy_before :  50  energy_after :  50  reward :  -200.97081183339984\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "Episode 137/500, Total Reward: -1015.8540591669991\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "action : 0  next_temperatures :  [ 1.37445166  0.66874348  1.68809897 -0.39072319  1.00511929  0.30819104\n",
      "  1.34357046  0.1225201   1.44386372]  energy_before :  30  energy_after :  50  reward :  -201.43616448783547\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "action : 0  next_temperatures :  [ 0.37445166 -0.33125652  0.68809897 -1.39072319  0.00511929 -0.69180896\n",
      "  0.34357046 -0.8774799   0.44386372]  energy_before :  50  energy_after :  40  reward :  -180.43616448783547\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "action : 1  next_temperatures :  [ 0.37445166 -0.33125652  0.68809897 -1.39072319  0.00511929 -0.69180896\n",
      "  0.34357046 -0.8774799   0.44386372]  energy_before :  40  energy_after :  50  reward :  -209.43616448783547\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "action : 1  next_temperatures :  [ 0.37445166 -0.33125652  0.68809897 -1.39072319  0.00511929 -0.69180896\n",
      "  0.34357046 -0.8774799   0.44386372]  energy_before :  50  energy_after :  50  reward :  -199.43616448783547\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "action : 1  next_temperatures :  [ 0.37445166 -0.33125652  0.68809897 -1.39072319  0.00511929 -0.69180896\n",
      "  0.34357046 -0.8774799   0.44386372]  energy_before :  50  energy_after :  50  reward :  -199.43616448783547\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "Episode 138/500, Total Reward: -990.1808224391773\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "action : 1  next_temperatures :  [-0.20541693  0.36027211  0.02680471  0.67316344  0.11584352 -0.25887283\n",
      " -0.12499052  0.06060434  0.77410378]  energy_before :  30  energy_after :  50  reward :  -216.57848838339385\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "action : 1  next_temperatures :  [-0.20541693  0.36027211  0.02680471  0.67316344  0.11584352 -0.25887283\n",
      " -0.12499052  0.06060434  0.77410378]  energy_before :  50  energy_after :  40  reward :  -186.57848838339385\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "action : 1  next_temperatures :  [-0.20541693  0.36027211  0.02680471  0.67316344  0.11584352 -0.25887283\n",
      " -0.12499052  0.06060434  0.77410378]  energy_before :  40  energy_after :  50  reward :  -206.57848838339385\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "action : 1  next_temperatures :  [-0.20541693  0.36027211  0.02680471  0.67316344  0.11584352 -0.25887283\n",
      " -0.12499052  0.06060434  0.77410378]  energy_before :  50  energy_after :  50  reward :  -196.57848838339385\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "action : 1  next_temperatures :  [-0.20541693  0.36027211  0.02680471  0.67316344  0.11584352 -0.25887283\n",
      " -0.12499052  0.06060434  0.77410378]  energy_before :  50  energy_after :  50  reward :  -196.57848838339385\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "Episode 139/500, Total Reward: -1002.8924419169692\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "action : 0  next_temperatures :  [ 0.19140653 -0.07009887  2.31010126 -2.41150628  0.49333658 -0.21416359\n",
      "  0.60463389 -0.20764894 -0.02530818]  energy_before :  30  energy_after :  50  reward :  -208.32924759438055\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "action : 1  next_temperatures :  [ 0.19140653 -0.07009887  2.31010126 -2.41150628  0.49333658 -0.21416359\n",
      "  0.60463389 -0.20764894 -0.02530818]  energy_before :  50  energy_after :  40  reward :  -187.32924759438055\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "action : 1  next_temperatures :  [ 0.19140653 -0.07009887  2.31010126 -2.41150628  0.49333658 -0.21416359\n",
      "  0.60463389 -0.20764894 -0.02530818]  energy_before :  40  energy_after :  50  reward :  -207.32924759438055\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "action : 0  next_temperatures :  [-0.80859347 -1.07009887  1.31010126 -3.41150628 -0.50666342 -1.21416359\n",
      " -0.39536611 -1.20764894 -1.02530818]  energy_before :  50  energy_after :  50  reward :  -197.32924759438055\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "action : 1  next_temperatures :  [-0.80859347 -1.07009887  1.31010126 -3.41150628 -0.50666342 -1.21416359\n",
      " -0.39536611 -1.20764894 -1.02530818]  energy_before :  50  energy_after :  50  reward :  -206.32924759438055\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "Episode 140/500, Total Reward: -1006.6462379719028\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "action : 1  next_temperatures :  [-2.54452546 -0.5452705  -1.54188141 -0.58736882 -2.23204273 -0.56921293\n",
      " -2.27886242 -0.57516301 -1.92630523]  energy_before :  30  energy_after :  50  reward :  -230.80063251389254\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "action : 1  next_temperatures :  [-2.54452546 -0.5452705  -1.54188141 -0.58736882 -2.23204273 -0.56921293\n",
      " -2.27886242 -0.57516301 -1.92630523]  energy_before :  50  energy_after :  40  reward :  -200.80063251389254\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "action : 1  next_temperatures :  [-2.54452546 -0.5452705  -1.54188141 -0.58736882 -2.23204273 -0.56921293\n",
      " -2.27886242 -0.57516301 -1.92630523]  energy_before :  40  energy_after :  50  reward :  -220.80063251389254\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "action : 1  next_temperatures :  [-2.54452546 -0.5452705  -1.54188141 -0.58736882 -2.23204273 -0.56921293\n",
      " -2.27886242 -0.57516301 -1.92630523]  energy_before :  50  energy_after :  50  reward :  -210.80063251389254\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "action : 1  next_temperatures :  [-2.54452546 -0.5452705  -1.54188141 -0.58736882 -2.23204273 -0.56921293\n",
      " -2.27886242 -0.57516301 -1.92630523]  energy_before :  50  energy_after :  50  reward :  -210.80063251389254\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "Episode 141/500, Total Reward: -1074.0031625694628\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step\n",
      "action : 1  next_temperatures :  [-1.56903211  0.55461613 -0.83962076  0.27264344 -1.45107561  1.28770654\n",
      " -0.76625693  0.73783478 -1.0799803 ]  energy_before :  30  energy_after :  50  reward :  -220.85316482551528\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "action : 1  next_temperatures :  [-1.56903211  0.55461613 -0.83962076  0.27264344 -1.45107561  1.28770654\n",
      " -0.76625693  0.73783478 -1.0799803 ]  energy_before :  50  energy_after :  40  reward :  -190.85316482551528\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "action : 1  next_temperatures :  [-1.56903211  0.55461613 -0.83962076  0.27264344 -1.45107561  1.28770654\n",
      " -0.76625693  0.73783478 -1.0799803 ]  energy_before :  40  energy_after :  50  reward :  -210.85316482551528\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "action : 1  next_temperatures :  [-1.56903211  0.55461613 -0.83962076  0.27264344 -1.45107561  1.28770654\n",
      " -0.76625693  0.73783478 -1.0799803 ]  energy_before :  50  energy_after :  50  reward :  -200.85316482551528\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "action : 1  next_temperatures :  [-1.56903211  0.55461613 -0.83962076  0.27264344 -1.45107561  1.28770654\n",
      " -0.76625693  0.73783478 -1.0799803 ]  energy_before :  50  energy_after :  50  reward :  -200.85316482551528\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "Episode 142/500, Total Reward: -1024.2658241275765\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step\n",
      "action : 1  next_temperatures :  [ 0.25742353  0.66351579  0.16360874  0.74851689  0.61433317 -0.23838833\n",
      "  0.16871929  0.61574902  0.43256198]  energy_before :  30  energy_after :  50  reward :  -214.5739599343618\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "action : 1  next_temperatures :  [ 0.25742353  0.66351579  0.16360874  0.74851689  0.61433317 -0.23838833\n",
      "  0.16871929  0.61574902  0.43256198]  energy_before :  50  energy_after :  40  reward :  -184.5739599343618\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "action : 0  next_temperatures :  [-0.74257647 -0.33648421 -0.83639126 -0.25148311 -0.38566683 -1.23838833\n",
      " -0.83128071 -0.38425098 -0.56743802]  energy_before :  40  energy_after :  50  reward :  -204.5739599343618\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "action : 1  next_temperatures :  [-0.74257647 -0.33648421 -0.83639126 -0.25148311 -0.38566683 -1.23838833\n",
      " -0.83128071 -0.38425098 -0.56743802]  energy_before :  50  energy_after :  50  reward :  -203.5739599343618\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "action : 1  next_temperatures :  [-0.74257647 -0.33648421 -0.83639126 -0.25148311 -0.38566683 -1.23838833\n",
      " -0.83128071 -0.38425098 -0.56743802]  energy_before :  50  energy_after :  50  reward :  -203.5739599343618\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "Episode 143/500, Total Reward: -1010.869799671809\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "action : 1  next_temperatures :  [0.195158   1.45010645 0.73970568 0.88693791 0.9931853  1.19552631\n",
      " 0.26172739 1.313711   0.58255123]  energy_before :  30  energy_after :  50  reward :  -210.3813907177099\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "action : 1  next_temperatures :  [0.195158   1.45010645 0.73970568 0.88693791 0.9931853  1.19552631\n",
      " 0.26172739 1.313711   0.58255123]  energy_before :  50  energy_after :  40  reward :  -180.3813907177099\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "action : 1  next_temperatures :  [0.195158   1.45010645 0.73970568 0.88693791 0.9931853  1.19552631\n",
      " 0.26172739 1.313711   0.58255123]  energy_before :  40  energy_after :  50  reward :  -200.3813907177099\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "action : 1  next_temperatures :  [0.195158   1.45010645 0.73970568 0.88693791 0.9931853  1.19552631\n",
      " 0.26172739 1.313711   0.58255123]  energy_before :  50  energy_after :  50  reward :  -190.3813907177099\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "action : 1  next_temperatures :  [0.195158   1.45010645 0.73970568 0.88693791 0.9931853  1.19552631\n",
      " 0.26172739 1.313711   0.58255123]  energy_before :  50  energy_after :  50  reward :  -190.3813907177099\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "Episode 144/500, Total Reward: -971.9069535885495\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "action : 1  next_temperatures :  [-0.3652318   0.06791839 -0.32280557  0.36355902 -0.23808413 -0.35412573\n",
      " -0.47254712  0.06060434 -0.10956787]  energy_before :  30  energy_after :  50  reward :  -219.37028047245363\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "action : 1  next_temperatures :  [-0.3652318   0.06791839 -0.32280557  0.36355902 -0.23808413 -0.35412573\n",
      " -0.47254712  0.06060434 -0.10956787]  energy_before :  50  energy_after :  40  reward :  -189.37028047245363\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "action : 1  next_temperatures :  [-0.3652318   0.06791839 -0.32280557  0.36355902 -0.23808413 -0.35412573\n",
      " -0.47254712  0.06060434 -0.10956787]  energy_before :  40  energy_after :  50  reward :  -209.37028047245363\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "action : 1  next_temperatures :  [-0.3652318   0.06791839 -0.32280557  0.36355902 -0.23808413 -0.35412573\n",
      " -0.47254712  0.06060434 -0.10956787]  energy_before :  50  energy_after :  50  reward :  -199.37028047245363\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "action : 1  next_temperatures :  [-0.3652318   0.06791839 -0.32280557  0.36355902 -0.23808413 -0.35412573\n",
      " -0.47254712  0.06060434 -0.10956787]  energy_before :  50  energy_after :  50  reward :  -199.37028047245363\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "Episode 145/500, Total Reward: -1016.8514023622681\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "action : 1  next_temperatures :  [ 1.75179633 -0.64495558  1.78701647 -1.44000954  1.46176557 -0.46965828\n",
      "  1.73027642 -0.14440759  0.64941392]  energy_before :  30  energy_after :  50  reward :  -213.3187622953799\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "action : 1  next_temperatures :  [ 1.75179633 -0.64495558  1.78701647 -1.44000954  1.46176557 -0.46965828\n",
      "  1.73027642 -0.14440759  0.64941392]  energy_before :  50  energy_after :  40  reward :  -183.3187622953799\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "action : 1  next_temperatures :  [ 1.75179633 -0.64495558  1.78701647 -1.44000954  1.46176557 -0.46965828\n",
      "  1.73027642 -0.14440759  0.64941392]  energy_before :  40  energy_after :  50  reward :  -203.3187622953799\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "action : 1  next_temperatures :  [ 1.75179633 -0.64495558  1.78701647 -1.44000954  1.46176557 -0.46965828\n",
      "  1.73027642 -0.14440759  0.64941392]  energy_before :  50  energy_after :  50  reward :  -193.3187622953799\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "action : 1  next_temperatures :  [ 1.75179633 -0.64495558  1.78701647 -1.44000954  1.46176557 -0.46965828\n",
      "  1.73027642 -0.14440759  0.64941392]  energy_before :  50  energy_after :  50  reward :  -193.3187622953799\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "Episode 146/500, Total Reward: -986.5938114768995\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "action : 1  next_temperatures :  [-1.05015267  1.0052932  -0.56601272  0.70510675 -1.18521446  1.73836543\n",
      " -0.56555523  1.00734485 -0.97697563]  energy_before :  30  energy_after :  50  reward :  -217.88780047196067\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "action : 1  next_temperatures :  [-1.05015267  1.0052932  -0.56601272  0.70510675 -1.18521446  1.73836543\n",
      " -0.56555523  1.00734485 -0.97697563]  energy_before :  50  energy_after :  40  reward :  -187.88780047196067\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "action : 1  next_temperatures :  [-1.05015267  1.0052932  -0.56601272  0.70510675 -1.18521446  1.73836543\n",
      " -0.56555523  1.00734485 -0.97697563]  energy_before :  40  energy_after :  50  reward :  -207.88780047196067\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "action : 1  next_temperatures :  [-1.05015267  1.0052932  -0.56601272  0.70510675 -1.18521446  1.73836543\n",
      " -0.56555523  1.00734485 -0.97697563]  energy_before :  50  energy_after :  50  reward :  -197.88780047196067\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "action : 1  next_temperatures :  [-1.05015267  1.0052932  -0.56601272  0.70510675 -1.18521446  1.73836543\n",
      " -0.56555523  1.00734485 -0.97697563]  energy_before :  50  energy_after :  50  reward :  -197.88780047196067\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "Episode 147/500, Total Reward: -1009.4390023598033\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "action : 1  next_temperatures :  [-1.18091029 -1.07050196 -1.06762747 -0.74217102 -0.66322459 -1.02265186\n",
      " -1.29982974 -0.58207352 -1.31851744]  energy_before :  30  energy_after :  50  reward :  -226.9475078870833\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "action : 1  next_temperatures :  [-1.18091029 -1.07050196 -1.06762747 -0.74217102 -0.66322459 -1.02265186\n",
      " -1.29982974 -0.58207352 -1.31851744]  energy_before :  50  energy_after :  40  reward :  -196.9475078870833\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step\n",
      "action : 1  next_temperatures :  [-1.18091029 -1.07050196 -1.06762747 -0.74217102 -0.66322459 -1.02265186\n",
      " -1.29982974 -0.58207352 -1.31851744]  energy_before :  40  energy_after :  50  reward :  -216.9475078870833\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "action : 1  next_temperatures :  [-1.18091029 -1.07050196 -1.06762747 -0.74217102 -0.66322459 -1.02265186\n",
      " -1.29982974 -0.58207352 -1.31851744]  energy_before :  50  energy_after :  50  reward :  -206.9475078870833\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "action : 1  next_temperatures :  [-1.18091029 -1.07050196 -1.06762747 -0.74217102 -0.66322459 -1.02265186\n",
      " -1.29982974 -0.58207352 -1.31851744]  energy_before :  50  energy_after :  50  reward :  -206.9475078870833\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "Episode 148/500, Total Reward: -1054.7375394354165\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "action : 1  next_temperatures :  [ 0.9423444   0.45241798  1.66845298 -0.41700448  0.9258892   0.08603486\n",
      "  1.24076008  0.24488473  0.81747417]  energy_before :  30  energy_after :  50  reward :  -212.0387460962583\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "action : 1  next_temperatures :  [ 0.9423444   0.45241798  1.66845298 -0.41700448  0.9258892   0.08603486\n",
      "  1.24076008  0.24488473  0.81747417]  energy_before :  50  energy_after :  40  reward :  -182.0387460962583\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "action : 1  next_temperatures :  [ 0.9423444   0.45241798  1.66845298 -0.41700448  0.9258892   0.08603486\n",
      "  1.24076008  0.24488473  0.81747417]  energy_before :  40  energy_after :  50  reward :  -202.0387460962583\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "action : 1  next_temperatures :  [ 0.9423444   0.45241798  1.66845298 -0.41700448  0.9258892   0.08603486\n",
      "  1.24076008  0.24488473  0.81747417]  energy_before :  50  energy_after :  50  reward :  -192.0387460962583\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "action : 1  next_temperatures :  [ 0.9423444   0.45241798  1.66845298 -0.41700448  0.9258892   0.08603486\n",
      "  1.24076008  0.24488473  0.81747417]  energy_before :  50  energy_after :  50  reward :  -192.0387460962583\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "Episode 149/500, Total Reward: -980.1937304812916\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "action : 1  next_temperatures :  [-0.3652318  -1.07887886 -0.47937017 -0.84864873 -0.33279717 -1.36810823\n",
      " -0.17516594 -0.62929537 -0.21257254]  energy_before :  30  energy_after :  50  reward :  -223.490068824574\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "action : 1  next_temperatures :  [-0.3652318  -1.07887886 -0.47937017 -0.84864873 -0.33279717 -1.36810823\n",
      " -0.17516594 -0.62929537 -0.21257254]  energy_before :  50  energy_after :  40  reward :  -193.490068824574\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "action : 1  next_temperatures :  [-0.3652318  -1.07887886 -0.47937017 -0.84864873 -0.33279717 -1.36810823\n",
      " -0.17516594 -0.62929537 -0.21257254]  energy_before :  40  energy_after :  50  reward :  -213.490068824574\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "action : 2  next_temperatures :  [ 0.6347682  -0.07887886  0.52062983  0.15135127  0.66720283 -0.36810823\n",
      "  0.82483406  0.37070463  0.78742746]  energy_before :  50  energy_after :  50  reward :  -203.490068824574\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "action : 1  next_temperatures :  [ 0.6347682  -0.07887886  0.52062983  0.15135127  0.66720283 -0.36810823\n",
      "  0.82483406  0.37070463  0.78742746]  energy_before :  50  energy_after :  50  reward :  -194.490068824574\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "Episode 150/500, Total Reward: -1028.4503441228699\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "action : 1  next_temperatures :  [-0.26560695  0.85534674 -0.29240467  0.93608147 -0.33279717  0.97019687\n",
      "  0.39716025  0.7293886  -0.16378086]  energy_before :  30  energy_after :  50  reward :  -215.16641572293736\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "action : 1  next_temperatures :  [-0.26560695  0.85534674 -0.29240467  0.93608147 -0.33279717  0.97019687\n",
      "  0.39716025  0.7293886  -0.16378086]  energy_before :  50  energy_after :  40  reward :  -185.16641572293736\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "action : 1  next_temperatures :  [-0.26560695  0.85534674 -0.29240467  0.93608147 -0.33279717  0.97019687\n",
      "  0.39716025  0.7293886  -0.16378086]  energy_before :  40  energy_after :  50  reward :  -205.16641572293736\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "action : 1  next_temperatures :  [-0.26560695  0.85534674 -0.29240467  0.93608147 -0.33279717  0.97019687\n",
      "  0.39716025  0.7293886  -0.16378086]  energy_before :  50  energy_after :  50  reward :  -195.16641572293736\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "action : 1  next_temperatures :  [-0.26560695  0.85534674 -0.29240467  0.93608147 -0.33279717  0.97019687\n",
      "  0.39716025  0.7293886  -0.16378086]  energy_before :  50  energy_after :  50  reward :  -195.16641572293736\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "Episode 151/500, Total Reward: -995.8320786146868\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "action : 1  next_temperatures :  [ 0.29893389 -1.15510863 -0.25136347 -0.76919998 -0.68672482 -0.89594062\n",
      " -0.07603889 -1.07425574 -0.65169772]  energy_before :  30  energy_after :  50  reward :  -223.2613959694264\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "action : 2  next_temperatures :  [ 1.29893389 -0.15510863  0.74863653  0.23080002  0.31327518  0.10405938\n",
      "  0.92396111 -0.07425574  0.34830228]  energy_before :  50  energy_after :  40  reward :  -193.2613959694264\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "action : 1  next_temperatures :  [ 1.29893389 -0.15510863  0.74863653  0.23080002  0.31327518  0.10405938\n",
      "  0.92396111 -0.07425574  0.34830228]  energy_before :  40  energy_after :  50  reward :  -204.2613959694264\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "action : 1  next_temperatures :  [ 1.29893389 -0.15510863  0.74863653  0.23080002  0.31327518  0.10405938\n",
      "  0.92396111 -0.07425574  0.34830228]  energy_before :  50  energy_after :  50  reward :  -194.2613959694264\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "action : 1  next_temperatures :  [ 1.29893389 -0.15510863  0.74863653  0.23080002  0.31327518  0.10405938\n",
      "  0.92396111 -0.07425574  0.34830228]  energy_before :  50  energy_after :  50  reward :  -194.2613959694264\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "Episode 152/500, Total Reward: -1009.306979847132\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "action : 1  next_temperatures :  [-1.31996998 -0.14988094 -1.05242702 -0.30888866 -0.71995746  0.2511911\n",
      " -1.3814158  -0.7594434  -1.0980513 ]  energy_before :  30  energy_after :  50  reward :  -224.53884345707135\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "action : 1  next_temperatures :  [-1.31996998 -0.14988094 -1.05242702 -0.30888866 -0.71995746  0.2511911\n",
      " -1.3814158  -0.7594434  -1.0980513 ]  energy_before :  50  energy_after :  40  reward :  -194.53884345707135\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "action : 1  next_temperatures :  [-1.31996998 -0.14988094 -1.05242702 -0.30888866 -0.71995746  0.2511911\n",
      " -1.3814158  -0.7594434  -1.0980513 ]  energy_before :  40  energy_after :  50  reward :  -214.53884345707135\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "action : 1  next_temperatures :  [-1.31996998 -0.14988094 -1.05242702 -0.30888866 -0.71995746  0.2511911\n",
      " -1.3814158  -0.7594434  -1.0980513 ]  energy_before :  50  energy_after :  50  reward :  -204.53884345707135\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "action : 1  next_temperatures :  [-1.31996998 -0.14988094 -1.05242702 -0.30888866 -0.71995746  0.2511911\n",
      " -1.3814158  -0.7594434  -1.0980513 ]  energy_before :  50  energy_after :  50  reward :  -204.53884345707135\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "Episode 153/500, Total Reward: -1042.6942172853567\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "action : 1  next_temperatures :  [ 1.50273419 -0.04265666  1.07563555  0.08344074  1.75587446 -0.07451237\n",
      "  1.55568226 -0.12981873  1.46260869]  energy_before :  30  energy_after :  50  reward :  -210.8110118608235\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "action : 1  next_temperatures :  [ 1.50273419 -0.04265666  1.07563555  0.08344074  1.75587446 -0.07451237\n",
      "  1.55568226 -0.12981873  1.46260869]  energy_before :  50  energy_after :  40  reward :  -180.8110118608235\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "action : 1  next_temperatures :  [ 1.50273419 -0.04265666  1.07563555  0.08344074  1.75587446 -0.07451237\n",
      "  1.55568226 -0.12981873  1.46260869]  energy_before :  40  energy_after :  50  reward :  -200.8110118608235\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "action : 1  next_temperatures :  [ 1.50273419 -0.04265666  1.07563555  0.08344074  1.75587446 -0.07451237\n",
      "  1.55568226 -0.12981873  1.46260869]  energy_before :  50  energy_after :  50  reward :  -190.8110118608235\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "action : 1  next_temperatures :  [ 1.50273419 -0.04265666  1.07563555  0.08344074  1.75587446 -0.07451237\n",
      "  1.55568226 -0.12981873  1.46260869]  energy_before :  50  energy_after :  50  reward :  -190.8110118608235\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "Episode 154/500, Total Reward: -974.0550593041175\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "action : 1  next_temperatures :  [-0.42749733 -0.29396358 -0.23616302 -0.76019033  0.61433317  0.70184999\n",
      "  0.7022921  -0.7748001  -0.92276265]  energy_before :  30  energy_after :  50  reward :  -219.39690175488482\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "action : 1  next_temperatures :  [-0.42749733 -0.29396358 -0.23616302 -0.76019033  0.61433317  0.70184999\n",
      "  0.7022921  -0.7748001  -0.92276265]  energy_before :  50  energy_after :  40  reward :  -189.39690175488482\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "action : 1  next_temperatures :  [-0.42749733 -0.29396358 -0.23616302 -0.76019033  0.61433317  0.70184999\n",
      "  0.7022921  -0.7748001  -0.92276265]  energy_before :  40  energy_after :  50  reward :  -209.39690175488482\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "action : 2  next_temperatures :  [0.57250267 0.70603642 0.76383698 0.23980967 1.61433317 1.70184999\n",
      " 1.7022921  0.2251999  0.07723735]  energy_before :  50  energy_after :  50  reward :  -199.39690175488482\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "action : 1  next_temperatures :  [0.57250267 0.70603642 0.76383698 0.23980967 1.61433317 1.70184999\n",
      " 1.7022921  0.2251999  0.07723735]  energy_before :  50  energy_after :  50  reward :  -190.39690175488482\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "Episode 155/500, Total Reward: -1007.9845087744241\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "action : 1  next_temperatures :  [-0.5167446   1.09911446 -0.06439797  0.42662659 -0.33279717  1.67691195\n",
      " -0.10296228  1.30680049 -0.21257254]  energy_before :  30  energy_after :  50  reward :  -214.72002108337318\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "action : 1  next_temperatures :  [-0.5167446   1.09911446 -0.06439797  0.42662659 -0.33279717  1.67691195\n",
      " -0.10296228  1.30680049 -0.21257254]  energy_before :  50  energy_after :  40  reward :  -184.72002108337318\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "action : 1  next_temperatures :  [-0.5167446   1.09911446 -0.06439797  0.42662659 -0.33279717  1.67691195\n",
      " -0.10296228  1.30680049 -0.21257254]  energy_before :  40  energy_after :  50  reward :  -204.72002108337318\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "action : 1  next_temperatures :  [-0.5167446   1.09911446 -0.06439797  0.42662659 -0.33279717  1.67691195\n",
      " -0.10296228  1.30680049 -0.21257254]  energy_before :  50  energy_after :  50  reward :  -194.72002108337318\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "action : 1  next_temperatures :  [-0.5167446   1.09911446 -0.06439797  0.42662659 -0.33279717  1.67691195\n",
      " -0.10296228  1.30680049 -0.21257254]  energy_before :  50  energy_after :  50  reward :  -194.72002108337318\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "Episode 156/500, Total Reward: -993.600105416866\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "action : 1  next_temperatures :  [ 0.37572804 -0.16831012  0.61962214 -0.48007205  0.16569248 -0.25887283\n",
      "  0.34820861 -0.19047769  0.37834899]  energy_before :  30  energy_after :  50  reward :  -217.21013241374413\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "action : 1  next_temperatures :  [ 0.37572804 -0.16831012  0.61962214 -0.48007205  0.16569248 -0.25887283\n",
      "  0.34820861 -0.19047769  0.37834899]  energy_before :  50  energy_after :  40  reward :  -187.21013241374413\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "action : 1  next_temperatures :  [ 0.37572804 -0.16831012  0.61962214 -0.48007205  0.16569248 -0.25887283\n",
      "  0.34820861 -0.19047769  0.37834899]  energy_before :  40  energy_after :  50  reward :  -207.21013241374413\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "action : 1  next_temperatures :  [ 0.37572804 -0.16831012  0.61962214 -0.48007205  0.16569248 -0.25887283\n",
      "  0.34820861 -0.19047769  0.37834899]  energy_before :  50  energy_after :  50  reward :  -197.21013241374413\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "action : 1  next_temperatures :  [ 0.37572804 -0.16831012  0.61962214 -0.48007205  0.16569248 -0.25887283\n",
      "  0.34820861 -0.19047769  0.37834899]  energy_before :  50  energy_after :  50  reward :  -197.21013241374413\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "Episode 157/500, Total Reward: -1006.0506620687206\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "action : 1  next_temperatures :  [ 0.14949661  1.30853689  0.51169897  0.87137579  0.06100966  1.32509074\n",
      " -0.26042337  1.42888625 -0.56495695]  energy_before :  30  energy_after :  50  reward :  -213.16928541851004\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "action : 1  next_temperatures :  [ 0.14949661  1.30853689  0.51169897  0.87137579  0.06100966  1.32509074\n",
      " -0.26042337  1.42888625 -0.56495695]  energy_before :  50  energy_after :  40  reward :  -183.16928541851004\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "action : 1  next_temperatures :  [ 0.14949661  1.30853689  0.51169897  0.87137579  0.06100966  1.32509074\n",
      " -0.26042337  1.42888625 -0.56495695]  energy_before :  40  energy_after :  50  reward :  -203.16928541851004\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "action : 1  next_temperatures :  [ 0.14949661  1.30853689  0.51169897  0.87137579  0.06100966  1.32509074\n",
      " -0.26042337  1.42888625 -0.56495695]  energy_before :  50  energy_after :  50  reward :  -193.16928541851004\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "action : 1  next_temperatures :  [ 0.14949661  1.30853689  0.51169897  0.87137579  0.06100966  1.32509074\n",
      " -0.26042337  1.42888625 -0.56495695]  energy_before :  50  energy_after :  50  reward :  -193.16928541851004\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "Episode 158/500, Total Reward: -985.8464270925502\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "action : 1  next_temperatures :  [-0.738825   -0.76893366 -1.19075109 -0.10330477 -0.63189095 -0.464742\n",
      " -1.0110151  -0.65117867 -0.59206344]  energy_before :  30  energy_after :  50  reward :  -224.15270468709952\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "action : 2  next_temperatures :  [ 0.261175    0.23106634 -0.19075109  0.89669523  0.36810905  0.535258\n",
      " -0.0110151   0.34882133  0.40793656]  energy_before :  50  energy_after :  40  reward :  -194.15270468709952\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "action : 1  next_temperatures :  [ 0.261175    0.23106634 -0.19075109  0.89669523  0.36810905  0.535258\n",
      " -0.0110151   0.34882133  0.40793656]  energy_before :  40  energy_after :  50  reward :  -205.15270468709952\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "action : 1  next_temperatures :  [ 0.261175    0.23106634 -0.19075109  0.89669523  0.36810905  0.535258\n",
      " -0.0110151   0.34882133  0.40793656]  energy_before :  50  energy_after :  50  reward :  -195.15270468709952\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "action : 1  next_temperatures :  [ 0.261175    0.23106634 -0.19075109  0.89669523  0.36810905  0.535258\n",
      " -0.0110151   0.34882133  0.40793656]  energy_before :  50  energy_after :  50  reward :  -195.15270468709952\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step\n",
      "Episode 159/500, Total Reward: -1013.7635234354975\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "action : 1  next_temperatures :  [ 0.99838337 -0.43469545  0.60659319 -0.59474035  1.00813999 -0.93486116\n",
      "  1.09880034 -0.90686771  1.32862517]  energy_before :  30  energy_after :  50  reward :  -215.8306226204345\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "action : 1  next_temperatures :  [ 0.99838337 -0.43469545  0.60659319 -0.59474035  1.00813999 -0.93486116\n",
      "  1.09880034 -0.90686771  1.32862517]  energy_before :  50  energy_after :  40  reward :  -185.8306226204345\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "action : 1  next_temperatures :  [ 0.99838337 -0.43469545  0.60659319 -0.59474035  1.00813999 -0.93486116\n",
      "  1.09880034 -0.90686771  1.32862517]  energy_before :  40  energy_after :  50  reward :  -205.8306226204345\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "action : 1  next_temperatures :  [ 0.99838337 -0.43469545  0.60659319 -0.59474035  1.00813999 -0.93486116\n",
      "  1.09880034 -0.90686771  1.32862517]  energy_before :  50  energy_after :  50  reward :  -195.8306226204345\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step\n",
      "action : 1  next_temperatures :  [ 0.99838337 -0.43469545  0.60659319 -0.59474035  1.00813999 -0.93486116\n",
      "  1.09880034 -0.90686771  1.32862517]  energy_before :  50  energy_after :  50  reward :  -195.8306226204345\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "Episode 160/500, Total Reward: -999.1531131021725\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "action : 1  next_temperatures :  [-0.84882744  0.3527329  -0.73625772  0.60927681 -0.48732896  0.02586165\n",
      " -1.15297484  0.02086888 -0.65169772]  energy_before :  30  energy_after :  50  reward :  -220.86834643871634\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "action : 1  next_temperatures :  [-0.84882744  0.3527329  -0.73625772  0.60927681 -0.48732896  0.02586165\n",
      " -1.15297484  0.02086888 -0.65169772]  energy_before :  50  energy_after :  40  reward :  -190.86834643871634\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "action : 1  next_temperatures :  [-0.84882744  0.3527329  -0.73625772  0.60927681 -0.48732896  0.02586165\n",
      " -1.15297484  0.02086888 -0.65169772]  energy_before :  40  energy_after :  50  reward :  -210.86834643871634\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "action : 1  next_temperatures :  [-0.84882744  0.3527329  -0.73625772  0.60927681 -0.48732896  0.02586165\n",
      " -1.15297484  0.02086888 -0.65169772]  energy_before :  50  energy_after :  50  reward :  -200.86834643871634\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "action : 1  next_temperatures :  [-0.84882744  0.3527329  -0.73625772  0.60927681 -0.48732896  0.02586165\n",
      " -1.15297484  0.02086888 -0.65169772]  energy_before :  50  energy_after :  50  reward :  -200.86834643871634\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "Episode 161/500, Total Reward: -1024.3417321935817\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "action : 1  next_temperatures :  [ 0.31968906 -0.39197328 -0.43376883  0.44464589  0.06100966 -0.3817798\n",
      "  0.01696922 -0.46689828  0.43256198]  energy_before :  30  energy_after :  50  reward :  -218.39954437396747\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "action : 1  next_temperatures :  [ 0.31968906 -0.39197328 -0.43376883  0.44464589  0.06100966 -0.3817798\n",
      "  0.01696922 -0.46689828  0.43256198]  energy_before :  50  energy_after :  40  reward :  -188.39954437396747\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "action : 1  next_temperatures :  [ 0.31968906 -0.39197328 -0.43376883  0.44464589  0.06100966 -0.3817798\n",
      "  0.01696922 -0.46689828  0.43256198]  energy_before :  40  energy_after :  50  reward :  -208.39954437396747\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "action : 2  next_temperatures :  [1.31968906 0.60802672 0.56623117 1.44464589 1.06100966 0.6182202\n",
      " 1.01696922 0.53310172 1.43256198]  energy_before :  50  energy_after :  50  reward :  -198.39954437396747\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "action : 1  next_temperatures :  [1.31968906 0.60802672 0.56623117 1.44464589 1.06100966 0.6182202\n",
      " 1.01696922 0.53310172 1.43256198]  energy_before :  50  energy_after :  50  reward :  -189.39954437396747\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "Episode 162/500, Total Reward: -1002.9977218698374\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "action : 1  next_temperatures :  [-0.42749733 -0.01501289 -0.46416972  0.31441547 -0.88113578 -0.20971004\n",
      " -0.64714128  0.10897794 -0.24871453]  energy_before :  30  energy_after :  50  reward :  -220.46998818197264\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "action : 1  next_temperatures :  [-0.42749733 -0.01501289 -0.46416972  0.31441547 -0.88113578 -0.20971004\n",
      " -0.64714128  0.10897794 -0.24871453]  energy_before :  50  energy_after :  40  reward :  -190.46998818197264\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "action : 1  next_temperatures :  [-0.42749733 -0.01501289 -0.46416972  0.31441547 -0.88113578 -0.20971004\n",
      " -0.64714128  0.10897794 -0.24871453]  energy_before :  40  energy_after :  50  reward :  -210.46998818197264\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "action : 1  next_temperatures :  [-0.42749733 -0.01501289 -0.46416972  0.31441547 -0.88113578 -0.20971004\n",
      " -0.64714128  0.10897794 -0.24871453]  energy_before :  50  energy_after :  50  reward :  -200.46998818197264\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "action : 1  next_temperatures :  [-0.42749733 -0.01501289 -0.46416972  0.31441547 -0.88113578 -0.20971004\n",
      " -0.64714128  0.10897794 -0.24871453]  energy_before :  50  energy_after :  50  reward :  -200.46998818197264\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "Episode 163/500, Total Reward: -1022.3499409098632\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "action : 1  next_temperatures :  [ 1.30971104  0.33430373  1.39028481 -0.10330477  0.9466596   1.05111062\n",
      "  0.36452582  1.03729042  0.69760324]  energy_before :  30  energy_after :  50  reward :  -210.97181550451128\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "action : 1  next_temperatures :  [ 1.30971104  0.33430373  1.39028481 -0.10330477  0.9466596   1.05111062\n",
      "  0.36452582  1.03729042  0.69760324]  energy_before :  50  energy_after :  40  reward :  -180.97181550451128\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "action : 1  next_temperatures :  [ 1.30971104  0.33430373  1.39028481 -0.10330477  0.9466596   1.05111062\n",
      "  0.36452582  1.03729042  0.69760324]  energy_before :  40  energy_after :  50  reward :  -200.97181550451128\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "action : 1  next_temperatures :  [ 1.30971104  0.33430373  1.39028481 -0.10330477  0.9466596   1.05111062\n",
      "  0.36452582  1.03729042  0.69760324]  energy_before :  50  energy_after :  50  reward :  -190.97181550451128\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "action : 1  next_temperatures :  [ 1.30971104  0.33430373  1.39028481 -0.10330477  0.9466596   1.05111062\n",
      "  0.36452582  1.03729042  0.69760324]  energy_before :  50  energy_after :  50  reward :  -190.97181550451128\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "Episode 164/500, Total Reward: -974.8590775225564\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "action : 1  next_temperatures :  [-0.55825495 -0.89458712 -0.52041138 -0.68197017 -0.83128681 -1.01679914\n",
      " -0.90821667 -0.45307725 -1.13419329]  energy_before :  30  energy_after :  50  reward :  -224.9987967771697\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "action : 1  next_temperatures :  [-0.55825495 -0.89458712 -0.52041138 -0.68197017 -0.83128681 -1.01679914\n",
      " -0.90821667 -0.45307725 -1.13419329]  energy_before :  50  energy_after :  40  reward :  -194.9987967771697\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step\n",
      "action : 1  next_temperatures :  [-0.55825495 -0.89458712 -0.52041138 -0.68197017 -0.83128681 -1.01679914\n",
      " -0.90821667 -0.45307725 -1.13419329]  energy_before :  40  energy_after :  50  reward :  -214.9987967771697\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "action : 1  next_temperatures :  [-0.55825495 -0.89458712 -0.52041138 -0.68197017 -0.83128681 -1.01679914\n",
      " -0.90821667 -0.45307725 -1.13419329]  energy_before :  50  energy_after :  50  reward :  -204.9987967771697\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "action : 2  next_temperatures :  [ 0.44174505  0.10541288  0.47958862  0.31802983  0.16871319 -0.01679914\n",
      "  0.09178333  0.54692275 -0.13419329]  energy_before :  50  energy_after :  50  reward :  -204.9987967771697\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n",
      "Episode 165/500, Total Reward: -1044.9939838858486\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "action : 1  next_temperatures :  [-0.42749733 -0.34171189 -0.47937017 -0.05416122 -0.2829482  -0.62759374\n",
      " -0.15762494 -0.48993333 -0.16378086]  energy_before :  30  energy_after :  50  reward :  -221.02462168116662\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "action : 2  next_temperatures :  [0.57250267 0.65828811 0.52062983 0.94583878 0.7170518  0.37240626\n",
      " 0.84237506 0.51006667 0.83621914]  energy_before :  50  energy_after :  40  reward :  -191.02462168116662\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "action : 1  next_temperatures :  [0.57250267 0.65828811 0.52062983 0.94583878 0.7170518  0.37240626\n",
      " 0.84237506 0.51006667 0.83621914]  energy_before :  40  energy_after :  50  reward :  -202.02462168116662\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "action : 1  next_temperatures :  [0.57250267 0.65828811 0.52062983 0.94583878 0.7170518  0.37240626\n",
      " 0.84237506 0.51006667 0.83621914]  energy_before :  50  energy_after :  50  reward :  -192.02462168116662\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step\n",
      "action : 1  next_temperatures :  [0.57250267 0.65828811 0.52062983 0.94583878 0.7170518  0.37240626\n",
      " 0.84237506 0.51006667 0.83621914]  energy_before :  50  energy_after :  50  reward :  -192.02462168116662\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "Episode 166/500, Total Reward: -998.1231084058331\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "action : 1  next_temperatures :  [ 0.31968906  0.97932482  0.5740208   0.5027991  -0.53219302  1.90121717\n",
      " -0.56555523  0.68485417 -0.17974357]  energy_before :  30  energy_after :  50  reward :  -214.31558669663207\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "action : 1  next_temperatures :  [ 0.31968906  0.97932482  0.5740208   0.5027991  -0.53219302  1.90121717\n",
      " -0.56555523  0.68485417 -0.17974357]  energy_before :  50  energy_after :  40  reward :  -184.31558669663207\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "action : 1  next_temperatures :  [ 0.31968906  0.97932482  0.5740208   0.5027991  -0.53219302  1.90121717\n",
      " -0.56555523  0.68485417 -0.17974357]  energy_before :  40  energy_after :  50  reward :  -204.31558669663207\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "action : 1  next_temperatures :  [ 0.31968906  0.97932482  0.5740208   0.5027991  -0.53219302  1.90121717\n",
      " -0.56555523  0.68485417 -0.17974357]  energy_before :  50  energy_after :  50  reward :  -194.31558669663207\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "action : 1  next_temperatures :  [ 0.31968906  0.97932482  0.5740208   0.5027991  -0.53219302  1.90121717\n",
      " -0.56555523  0.68485417 -0.17974357]  energy_before :  50  energy_after :  50  reward :  -194.31558669663207\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "Episode 167/500, Total Reward: -991.5779334831603\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "action : 1  next_temperatures :  [-0.94637678 -0.05857276 -0.93538358 -0.00501766 -1.03068267  0.00537716\n",
      " -1.05507157 -0.40547148 -0.97697563]  energy_before :  30  energy_after :  50  reward :  -223.40817497794822\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "action : 1  next_temperatures :  [-0.94637678 -0.05857276 -0.93538358 -0.00501766 -1.03068267  0.00537716\n",
      " -1.05507157 -0.40547148 -0.97697563]  energy_before :  50  energy_after :  40  reward :  -193.40817497794822\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "action : 2  next_temperatures :  [ 0.05362322  0.94142724  0.06461642  0.99498234 -0.03068267  1.00537716\n",
      " -0.05507157  0.59452852  0.02302437]  energy_before :  40  energy_after :  50  reward :  -213.40817497794822\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "action : 1  next_temperatures :  [ 0.05362322  0.94142724  0.06461642  0.99498234 -0.03068267  1.00537716\n",
      " -0.05507157  0.59452852  0.02302437]  energy_before :  50  energy_after :  50  reward :  -194.40817497794822\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "action : 1  next_temperatures :  [ 0.05362322  0.94142724  0.06461642  0.99498234 -0.03068267  1.00537716\n",
      " -0.05507157  0.59452852  0.02302437]  energy_before :  50  energy_after :  50  reward :  -194.40817497794822\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "Episode 168/500, Total Reward: -1019.0408748897411\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "action : 2  next_temperatures :  [ 1.06440038  0.4490751   0.44918773  0.91143829  0.41795801  0.55369404\n",
      "  1.01696922 -0.1809848   0.46214955]  energy_before :  30  energy_after :  50  reward :  -221.85611248249424\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "action : 1  next_temperatures :  [ 1.06440038  0.4490751   0.44918773  0.91143829  0.41795801  0.55369404\n",
      "  1.01696922 -0.1809848   0.46214955]  energy_before :  50  energy_after :  40  reward :  -182.85611248249424\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "action : 1  next_temperatures :  [ 1.06440038  0.4490751   0.44918773  0.91143829  0.41795801  0.55369404\n",
      "  1.01696922 -0.1809848   0.46214955]  energy_before :  40  energy_after :  50  reward :  -202.85611248249424\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "action : 1  next_temperatures :  [ 1.06440038  0.4490751   0.44918773  0.91143829  0.41795801  0.55369404\n",
      "  1.01696922 -0.1809848   0.46214955]  energy_before :  50  energy_after :  50  reward :  -192.85611248249424\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "action : 1  next_temperatures :  [ 1.06440038  0.4490751   0.44918773  0.91143829  0.41795801  0.55369404\n",
      "  1.01696922 -0.1809848   0.46214955]  energy_before :  50  energy_after :  50  reward :  -192.85611248249424\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "Episode 169/500, Total Reward: -993.2805624124712\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "action : 1  next_temperatures :  [-1.672808   -0.09040497 -1.16339028 -0.00501766 -1.62887025  0.16822889\n",
      " -1.31614695 -0.40009664 -1.67029947]  energy_before :  30  energy_after :  50  reward :  -225.77880533413474\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "action : 1  next_temperatures :  [-1.672808   -0.09040497 -1.16339028 -0.00501766 -1.62887025  0.16822889\n",
      " -1.31614695 -0.40009664 -1.67029947]  energy_before :  50  energy_after :  40  reward :  -195.77880533413474\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "action : 1  next_temperatures :  [-1.672808   -0.09040497 -1.16339028 -0.00501766 -1.62887025  0.16822889\n",
      " -1.31614695 -0.40009664 -1.67029947]  energy_before :  40  energy_after :  50  reward :  -215.77880533413474\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "action : 1  next_temperatures :  [-1.672808   -0.09040497 -1.16339028 -0.00501766 -1.62887025  0.16822889\n",
      " -1.31614695 -0.40009664 -1.67029947]  energy_before :  50  energy_after :  50  reward :  -205.77880533413474\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "action : 1  next_temperatures :  [-1.672808   -0.09040497 -1.16339028 -0.00501766 -1.62887025  0.16822889\n",
      " -1.31614695 -0.40009664 -1.67029947]  energy_before :  50  energy_after :  50  reward :  -205.77880533413474\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "Episode 170/500, Total Reward: -1048.8940266706736\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "action : 1  next_temperatures :  [-1.58978729 -0.29396358 -1.20443149 -0.20404907 -1.32977646  0.38638876\n",
      " -1.15297484 -0.19892388 -1.38357302]  energy_before :  30  energy_after :  50  reward :  -224.9710908557998\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "action : 1  next_temperatures :  [-1.58978729 -0.29396358 -1.20443149 -0.20404907 -1.32977646  0.38638876\n",
      " -1.15297484 -0.19892388 -1.38357302]  energy_before :  50  energy_after :  40  reward :  -194.9710908557998\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "action : 1  next_temperatures :  [-1.58978729 -0.29396358 -1.20443149 -0.20404907 -1.32977646  0.38638876\n",
      " -1.15297484 -0.19892388 -1.38357302]  energy_before :  40  energy_after :  50  reward :  -214.9710908557998\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "action : 2  next_temperatures :  [-0.58978729  0.70603642 -0.20443149  0.79595093 -0.32977646  1.38638876\n",
      " -0.15297484  0.80107612 -0.38357302]  energy_before :  50  energy_after :  50  reward :  -204.9710908557998\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "action : 1  next_temperatures :  [-0.58978729  0.70603642 -0.20443149  0.79595093 -0.32977646  1.38638876\n",
      " -0.15297484  0.80107612 -0.38357302]  energy_before :  50  energy_after :  50  reward :  -195.9710908557998\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "Episode 171/500, Total Reward: -1035.8554542789989\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "action : 2  next_temperatures :  [0.6347682  0.6834188  0.20598058 1.5511236  0.7170518  0.37240626\n",
      " 0.58129968 0.79262994 0.83621914]  energy_before :  30  energy_after :  50  reward :  -220.62510200490232\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "action : 1  next_temperatures :  [0.6347682  0.6834188  0.20598058 1.5511236  0.7170518  0.37240626\n",
      " 0.58129968 0.79262994 0.83621914]  energy_before :  50  energy_after :  40  reward :  -181.62510200490232\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "action : 1  next_temperatures :  [0.6347682  0.6834188  0.20598058 1.5511236  0.7170518  0.37240626\n",
      " 0.58129968 0.79262994 0.83621914]  energy_before :  40  energy_after :  50  reward :  -201.62510200490232\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "action : 1  next_temperatures :  [0.6347682  0.6834188  0.20598058 1.5511236  0.7170518  0.37240626\n",
      " 0.58129968 0.79262994 0.83621914]  energy_before :  50  energy_after :  50  reward :  -191.62510200490232\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "action : 1  next_temperatures :  [0.6347682  0.6834188  0.20598058 1.5511236  0.7170518  0.37240626\n",
      " 0.58129968 0.79262994 0.83621914]  energy_before :  50  energy_after :  50  reward :  -191.62510200490232\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "Episode 172/500, Total Reward: -987.1255100245116\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "action : 1  next_temperatures :  [ 1.59896274 -0.47033534  1.36934964 -0.8829003   1.30406157 -0.60664369\n",
      "  1.56117077 -0.11509026  0.95990647]  energy_before :  30  energy_after :  50  reward :  -213.28151839317047\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step\n",
      "action : 1  next_temperatures :  [ 1.59896274 -0.47033534  1.36934964 -0.8829003   1.30406157 -0.60664369\n",
      "  1.56117077 -0.11509026  0.95990647]  energy_before :  50  energy_after :  40  reward :  -183.28151839317047\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "action : 1  next_temperatures :  [ 1.59896274 -0.47033534  1.36934964 -0.8829003   1.30406157 -0.60664369\n",
      "  1.56117077 -0.11509026  0.95990647]  energy_before :  40  energy_after :  50  reward :  -203.28151839317047\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "action : 1  next_temperatures :  [ 1.59896274 -0.47033534  1.36934964 -0.8829003   1.30406157 -0.60664369\n",
      "  1.56117077 -0.11509026  0.95990647]  energy_before :  50  energy_after :  50  reward :  -193.28151839317047\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step\n",
      "action : 1  next_temperatures :  [ 1.59896274 -0.47033534  1.36934964 -0.8829003   1.30406157 -0.60664369\n",
      "  1.56117077 -0.11509026  0.95990647]  energy_before :  50  energy_after :  50  reward :  -193.28151839317047\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "Episode 173/500, Total Reward: -986.4075919658524\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "action : 1  next_temperatures :  [-1.25770444 -0.57626502 -1.47803954  0.14241301 -0.63189095 -0.50775944\n",
      " -0.87558224 -0.65962486 -0.82698637]  energy_before :  30  energy_after :  50  reward :  -224.6714398538291\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "action : 1  next_temperatures :  [-1.25770444 -0.57626502 -1.47803954  0.14241301 -0.63189095 -0.50775944\n",
      " -0.87558224 -0.65962486 -0.82698637]  energy_before :  50  energy_after :  40  reward :  -194.6714398538291\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "action : 1  next_temperatures :  [-1.25770444 -0.57626502 -1.47803954  0.14241301 -0.63189095 -0.50775944\n",
      " -0.87558224 -0.65962486 -0.82698637]  energy_before :  40  energy_after :  50  reward :  -214.6714398538291\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "action : 1  next_temperatures :  [-1.25770444 -0.57626502 -1.47803954  0.14241301 -0.63189095 -0.50775944\n",
      " -0.87558224 -0.65962486 -0.82698637]  energy_before :  50  energy_after :  50  reward :  -204.6714398538291\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "action : 1  next_temperatures :  [-1.25770444 -0.57626502 -1.47803954  0.14241301 -0.63189095 -0.50775944\n",
      " -0.87558224 -0.65962486 -0.82698637]  energy_before :  50  energy_after :  50  reward :  -204.6714398538291\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "Episode 174/500, Total Reward: -1043.3571992691454\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "action : 2  next_temperatures :  [ 0.50401058 -0.69876926  0.66199399 -0.58989739 -0.09299388 -0.43647523\n",
      "  0.96801759 -0.34223014  0.02302437]  energy_before :  30  energy_after :  50  reward :  -227.00331939191716\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "action : 1  next_temperatures :  [ 0.50401058 -0.69876926  0.66199399 -0.58989739 -0.09299388 -0.43647523\n",
      "  0.96801759 -0.34223014  0.02302437]  energy_before :  50  energy_after :  40  reward :  -188.00331939191716\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step\n",
      "action : 1  next_temperatures :  [ 0.50401058 -0.69876926  0.66199399 -0.58989739 -0.09299388 -0.43647523\n",
      "  0.96801759 -0.34223014  0.02302437]  energy_before :  40  energy_after :  50  reward :  -208.00331939191716\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "action : 2  next_temperatures :  [1.50401058 0.30123074 1.66199399 0.41010261 0.90700612 0.56352477\n",
      " 1.96801759 0.65776986 1.02302437]  energy_before :  50  energy_after :  50  reward :  -198.00331939191716\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "action : 1  next_temperatures :  [1.50401058 0.30123074 1.66199399 0.41010261 0.90700612 0.56352477\n",
      " 1.96801759 0.65776986 1.02302437]  energy_before :  50  energy_after :  50  reward :  -189.00331939191716\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "Episode 175/500, Total Reward: -1010.0165969595857\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step\n",
      "action : 1  next_temperatures :  [-0.11616967  1.40068276  0.02224458  1.07368343 -0.38264613  1.48947882\n",
      " -0.61450686  1.55788252 -0.10956787]  energy_before :  30  energy_after :  50  reward :  -213.67891842447315\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step\n",
      "action : 1  next_temperatures :  [-0.11616967  1.40068276  0.02224458  1.07368343 -0.38264613  1.48947882\n",
      " -0.61450686  1.55788252 -0.10956787]  energy_before :  50  energy_after :  40  reward :  -183.67891842447315\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "action : 1  next_temperatures :  [-0.11616967  1.40068276  0.02224458  1.07368343 -0.38264613  1.48947882\n",
      " -0.61450686  1.55788252 -0.10956787]  energy_before :  40  energy_after :  50  reward :  -203.67891842447315\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "action : 1  next_temperatures :  [-0.11616967  1.40068276  0.02224458  1.07368343 -0.38264613  1.48947882\n",
      " -0.61450686  1.55788252 -0.10956787]  energy_before :  50  energy_after :  50  reward :  -193.67891842447315\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "action : 1  next_temperatures :  [-0.11616967  1.40068276  0.02224458  1.07368343 -0.38264613  1.48947882\n",
      " -0.61450686  1.55788252 -0.10956787]  energy_before :  50  energy_after :  50  reward :  -193.67891842447315\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "Episode 176/500, Total Reward: -988.3945921223658\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "action : 1  next_temperatures :  [-1.672808   -0.29396358 -1.34579565  0.14241301 -0.83128681 -0.32032631\n",
      " -1.59353955  0.02298043 -1.40525821]  energy_before :  30  energy_after :  50  reward :  -225.29758466649696\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "action : 1  next_temperatures :  [-1.672808   -0.29396358 -1.34579565  0.14241301 -0.83128681 -0.32032631\n",
      " -1.59353955  0.02298043 -1.40525821]  energy_before :  50  energy_after :  40  reward :  -195.29758466649696\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step\n",
      "action : 1  next_temperatures :  [-1.672808   -0.29396358 -1.34579565  0.14241301 -0.83128681 -0.32032631\n",
      " -1.59353955  0.02298043 -1.40525821]  energy_before :  40  energy_after :  50  reward :  -215.29758466649696\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "action : 1  next_temperatures :  [-1.672808   -0.29396358 -1.34579565  0.14241301 -0.83128681 -0.32032631\n",
      " -1.59353955  0.02298043 -1.40525821]  energy_before :  50  energy_after :  50  reward :  -205.29758466649696\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "action : 1  next_temperatures :  [-1.672808   -0.29396358 -1.34579565  0.14241301 -0.83128681 -0.32032631\n",
      " -1.59353955  0.02298043 -1.40525821]  energy_before :  50  energy_after :  50  reward :  -205.29758466649696\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "Episode 177/500, Total Reward: -1046.4879233324848\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "action : 2  next_temperatures :  [ 0.69703373 -0.09563265 -0.00682568  0.49453711  1.11584352  0.07435686\n",
      "  0.77221105 -0.09114811  1.0042794 ]  energy_before :  30  energy_after :  50  reward :  -223.0353447743596\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "action : 1  next_temperatures :  [ 0.69703373 -0.09563265 -0.00682568  0.49453711  1.11584352  0.07435686\n",
      "  0.77221105 -0.09114811  1.0042794 ]  energy_before :  50  energy_after :  40  reward :  -184.0353447743596\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "action : 1  next_temperatures :  [ 0.69703373 -0.09563265 -0.00682568  0.49453711  1.11584352  0.07435686\n",
      "  0.77221105 -0.09114811  1.0042794 ]  energy_before :  40  energy_after :  50  reward :  -204.0353447743596\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step\n",
      "action : 1  next_temperatures :  [ 0.69703373 -0.09563265 -0.00682568  0.49453711  1.11584352  0.07435686\n",
      "  0.77221105 -0.09114811  1.0042794 ]  energy_before :  50  energy_after :  50  reward :  -194.0353447743596\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "action : 1  next_temperatures :  [ 0.69703373 -0.09563265 -0.00682568  0.49453711  1.11584352  0.07435686\n",
      "  0.77221105 -0.09114811  1.0042794 ]  energy_before :  50  energy_after :  50  reward :  -194.0353447743596\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "Episode 178/500, Total Reward: -999.176723871798\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "action : 1  next_temperatures :  [-0.18466176 -0.69354158 -0.33800601 -0.81834354 -0.73657378 -0.22814609\n",
      " -0.41870032 -0.65117867 -0.70591071]  energy_before :  30  energy_after :  50  reward :  -222.77506245893508\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "action : 1  next_temperatures :  [-0.18466176 -0.69354158 -0.33800601 -0.81834354 -0.73657378 -0.22814609\n",
      " -0.41870032 -0.65117867 -0.70591071]  energy_before :  50  energy_after :  40  reward :  -192.77506245893508\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "action : 1  next_temperatures :  [-0.18466176 -0.69354158 -0.33800601 -0.81834354 -0.73657378 -0.22814609\n",
      " -0.41870032 -0.65117867 -0.70591071]  energy_before :  40  energy_after :  50  reward :  -212.77506245893508\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step\n",
      "action : 1  next_temperatures :  [-0.18466176 -0.69354158 -0.33800601 -0.81834354 -0.73657378 -0.22814609\n",
      " -0.41870032 -0.65117867 -0.70591071]  energy_before :  50  energy_after :  50  reward :  -202.77506245893508\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "action : 1  next_temperatures :  [-0.18466176 -0.69354158 -0.33800601 -0.81834354 -0.73657378 -0.22814609\n",
      " -0.41870032 -0.65117867 -0.70591071]  energy_before :  50  energy_after :  50  reward :  -202.77506245893508\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "Episode 179/500, Total Reward: -1033.8753122946755\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step\n",
      "action : 1  next_temperatures :  [-0.18466176  1.19126033  0.16360874  0.92870994 -0.08355234  1.79674624\n",
      " -0.96206346  1.49108088 -0.32099851]  energy_before :  30  energy_after :  50  reward :  -213.97986995564742\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "action : 1  next_temperatures :  [-0.18466176  1.19126033  0.16360874  0.92870994 -0.08355234  1.79674624\n",
      " -0.96206346  1.49108088 -0.32099851]  energy_before :  50  energy_after :  40  reward :  -183.97986995564742\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "action : 1  next_temperatures :  [-0.18466176  1.19126033  0.16360874  0.92870994 -0.08355234  1.79674624\n",
      " -0.96206346  1.49108088 -0.32099851]  energy_before :  40  energy_after :  50  reward :  -203.97986995564742\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step\n",
      "action : 1  next_temperatures :  [-0.18466176  1.19126033  0.16360874  0.92870994 -0.08355234  1.79674624\n",
      " -0.96206346  1.49108088 -0.32099851]  energy_before :  50  energy_after :  50  reward :  -193.97986995564742\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "action : 1  next_temperatures :  [-0.18466176  1.19126033  0.16360874  0.92870994 -0.08355234  1.79674624\n",
      " -0.96206346  1.49108088 -0.32099851]  energy_before :  50  energy_after :  50  reward :  -193.97986995564742\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "Episode 180/500, Total Reward: -989.8993497782371\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "action : 1  next_temperatures :  [ 0.43799358 -0.62066257  0.70626469 -0.81834354 -0.53219302  0.10677541\n",
      " -0.30478202  0.44176331  0.34785419]  energy_before :  30  energy_after :  50  reward :  -218.2353299860647\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step\n",
      "action : 1  next_temperatures :  [ 0.43799358 -0.62066257  0.70626469 -0.81834354 -0.53219302  0.10677541\n",
      " -0.30478202  0.44176331  0.34785419]  energy_before :  50  energy_after :  40  reward :  -188.2353299860647\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "action : 1  next_temperatures :  [ 0.43799358 -0.62066257  0.70626469 -0.81834354 -0.53219302  0.10677541\n",
      " -0.30478202  0.44176331  0.34785419]  energy_before :  40  energy_after :  50  reward :  -208.2353299860647\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "action : 1  next_temperatures :  [ 0.43799358 -0.62066257  0.70626469 -0.81834354 -0.53219302  0.10677541\n",
      " -0.30478202  0.44176331  0.34785419]  energy_before :  50  energy_after :  50  reward :  -198.2353299860647\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step\n",
      "action : 1  next_temperatures :  [ 0.43799358 -0.62066257  0.70626469 -0.81834354 -0.53219302  0.10677541\n",
      " -0.30478202  0.44176331  0.34785419]  energy_before :  50  energy_after :  50  reward :  -198.2353299860647\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "Episode 181/500, Total Reward: -1011.1766499303235\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "action : 2  next_temperatures :  [ 0.50401058  0.25368397  0.59967215  0.38068787  0.7170518  -0.30358207\n",
      "  0.87500948 -0.07425574  0.89043213]  energy_before :  30  energy_after :  50  reward :  -223.15728983351855\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step\n",
      "action : 1  next_temperatures :  [ 0.50401058  0.25368397  0.59967215  0.38068787  0.7170518  -0.30358207\n",
      "  0.87500948 -0.07425574  0.89043213]  energy_before :  50  energy_after :  40  reward :  -184.15728983351855\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "action : 1  next_temperatures :  [ 0.50401058  0.25368397  0.59967215  0.38068787  0.7170518  -0.30358207\n",
      "  0.87500948 -0.07425574  0.89043213]  energy_before :  40  energy_after :  50  reward :  -204.15728983351855\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "action : 1  next_temperatures :  [ 0.50401058  0.25368397  0.59967215  0.38068787  0.7170518  -0.30358207\n",
      "  0.87500948 -0.07425574  0.89043213]  energy_before :  50  energy_after :  50  reward :  -194.15728983351855\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "action : 1  next_temperatures :  [ 0.50401058  0.25368397  0.59967215  0.38068787  0.7170518  -0.30358207\n",
      "  0.87500948 -0.07425574  0.89043213]  energy_before :  50  energy_after :  50  reward :  -194.15728983351855\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "Episode 182/500, Total Reward: -999.7864491675928\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step\n",
      "action : 1  next_temperatures :  [0.195158   0.78916925 0.30041276 0.76325996 0.46478627 0.10882386\n",
      " 0.36452582 0.82076096 0.54640924]  energy_before :  30  energy_after :  50  reward :  -213.64669388142033\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "action : 1  next_temperatures :  [0.195158   0.78916925 0.30041276 0.76325996 0.46478627 0.10882386\n",
      " 0.36452582 0.82076096 0.54640924]  energy_before :  50  energy_after :  40  reward :  -183.64669388142033\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "action : 1  next_temperatures :  [0.195158   0.78916925 0.30041276 0.76325996 0.46478627 0.10882386\n",
      " 0.36452582 0.82076096 0.54640924]  energy_before :  40  energy_after :  50  reward :  -203.64669388142033\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "action : 1  next_temperatures :  [0.195158   0.78916925 0.30041276 0.76325996 0.46478627 0.10882386\n",
      " 0.36452582 0.82076096 0.54640924]  energy_before :  50  energy_after :  50  reward :  -193.64669388142033\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "action : 1  next_temperatures :  [0.195158   0.78916925 0.30041276 0.76325996 0.46478627 0.10882386\n",
      " 0.36452582 0.82076096 0.54640924]  energy_before :  50  energy_after :  50  reward :  -193.64669388142033\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "Episode 183/500, Total Reward: -988.2334694071017\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "action : 2  next_temperatures :  [-0.63129764  0.70603642 -0.21963194  0.83772296 -0.77841715  0.81999248\n",
      " -0.50053144  0.64059862 -0.7901704 ]  energy_before :  30  energy_after :  50  reward :  -226.91569810112145\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "action : 1  next_temperatures :  [-0.63129764  0.70603642 -0.21963194  0.83772296 -0.77841715  0.81999248\n",
      " -0.50053144  0.64059862 -0.7901704 ]  energy_before :  50  energy_after :  40  reward :  -187.91569810112145\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "action : 1  next_temperatures :  [-0.63129764  0.70603642 -0.21963194  0.83772296 -0.77841715  0.81999248\n",
      " -0.50053144  0.64059862 -0.7901704 ]  energy_before :  40  energy_after :  50  reward :  -207.91569810112145\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "action : 1  next_temperatures :  [-0.63129764  0.70603642 -0.21963194  0.83772296 -0.77841715  0.81999248\n",
      " -0.50053144  0.64059862 -0.7901704 ]  energy_before :  50  energy_after :  50  reward :  -197.91569810112145\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "action : 1  next_temperatures :  [-0.63129764  0.70603642 -0.21963194  0.83772296 -0.77841715  0.81999248\n",
      " -0.50053144  0.64059862 -0.7901704 ]  energy_before :  50  energy_after :  50  reward :  -197.91569810112145\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "Episode 184/500, Total Reward: -1018.5784905056073\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "action : 1  next_temperatures :  [ 0.195158   -0.14988094  0.3460141  -0.49645324 -0.43747999  0.97019687\n",
      " -0.12499052  0.54664387 -0.59206344]  energy_before :  30  energy_after :  50  reward :  -217.7428552887552\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "action : 1  next_temperatures :  [ 0.195158   -0.14988094  0.3460141  -0.49645324 -0.43747999  0.97019687\n",
      " -0.12499052  0.54664387 -0.59206344]  energy_before :  50  energy_after :  40  reward :  -187.7428552887552\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "action : 1  next_temperatures :  [ 0.195158   -0.14988094  0.3460141  -0.49645324 -0.43747999  0.97019687\n",
      " -0.12499052  0.54664387 -0.59206344]  energy_before :  40  energy_after :  50  reward :  -207.7428552887552\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step\n",
      "action : 1  next_temperatures :  [ 0.195158   -0.14988094  0.3460141  -0.49645324 -0.43747999  0.97019687\n",
      " -0.12499052  0.54664387 -0.59206344]  energy_before :  50  energy_after :  50  reward :  -197.7428552887552\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "action : 1  next_temperatures :  [ 0.195158   -0.14988094  0.3460141  -0.49645324 -0.43747999  0.97019687\n",
      " -0.12499052  0.54664387 -0.59206344]  energy_before :  50  energy_after :  50  reward :  -197.7428552887552\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "Episode 185/500, Total Reward: -1008.714276443776\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "action : 1  next_temperatures :  [ 0.46082427  0.39545508  0.20464994 -0.25073545 -0.63189095  0.40687326\n",
      "  0.16871929 -0.36784757  0.46870397]  energy_before :  30  energy_after :  50  reward :  -217.1452481711345\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "action : 1  next_temperatures :  [ 0.46082427  0.39545508  0.20464994 -0.25073545 -0.63189095  0.40687326\n",
      "  0.16871929 -0.36784757  0.46870397]  energy_before :  50  energy_after :  40  reward :  -187.1452481711345\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "action : 1  next_temperatures :  [ 0.46082427  0.39545508  0.20464994 -0.25073545 -0.63189095  0.40687326\n",
      "  0.16871929 -0.36784757  0.46870397]  energy_before :  40  energy_after :  50  reward :  -207.1452481711345\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step\n",
      "action : 1  next_temperatures :  [ 0.46082427  0.39545508  0.20464994 -0.25073545 -0.63189095  0.40687326\n",
      "  0.16871929 -0.36784757  0.46870397]  energy_before :  50  energy_after :  50  reward :  -197.1452481711345\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step\n",
      "action : 1  next_temperatures :  [ 0.46082427  0.39545508  0.20464994 -0.25073545 -0.63189095  0.40687326\n",
      "  0.16871929 -0.36784757  0.46870397]  energy_before :  50  energy_after :  50  reward :  -197.1452481711345\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "Episode 186/500, Total Reward: -1005.7262408556726\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "action : 1  next_temperatures :  [ 1.25367206 -1.77416134  1.19571908 -2.31476487  0.55949931 -1.31382432\n",
      "  1.19180844 -1.55184908  0.92047884]  energy_before :  30  energy_after :  50  reward :  -219.83342188254835\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "action : 1  next_temperatures :  [ 1.25367206 -1.77416134  1.19571908 -2.31476487  0.55949931 -1.31382432\n",
      "  1.19180844 -1.55184908  0.92047884]  energy_before :  50  energy_after :  40  reward :  -189.83342188254835\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "action : 1  next_temperatures :  [ 1.25367206 -1.77416134  1.19571908 -2.31476487  0.55949931 -1.31382432\n",
      "  1.19180844 -1.55184908  0.92047884]  energy_before :  40  energy_after :  50  reward :  -209.83342188254835\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "action : 1  next_temperatures :  [ 1.25367206 -1.77416134  1.19571908 -2.31476487  0.55949931 -1.31382432\n",
      "  1.19180844 -1.55184908  0.92047884]  energy_before :  50  energy_after :  50  reward :  -199.83342188254835\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "action : 1  next_temperatures :  [ 1.25367206 -1.77416134  1.19571908 -2.31476487  0.55949931 -1.31382432\n",
      "  1.19180844 -1.55184908  0.92047884]  energy_before :  50  energy_after :  50  reward :  -199.83342188254835\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "Episode 187/500, Total Reward: -1019.1671094127418\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "action : 2  next_temperatures :  [ 0.44174505 -0.29919126  1.20464994 -0.72504218  0.61735387 -0.33430881\n",
      "  0.96801759 -0.0427745   0.51636253]  energy_before :  30  energy_after :  50  reward :  -224.6531877809146\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "action : 1  next_temperatures :  [ 0.44174505 -0.29919126  1.20464994 -0.72504218  0.61735387 -0.33430881\n",
      "  0.96801759 -0.0427745   0.51636253]  energy_before :  50  energy_after :  40  reward :  -185.6531877809146\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step\n",
      "action : 1  next_temperatures :  [ 0.44174505 -0.29919126  1.20464994 -0.72504218  0.61735387 -0.33430881\n",
      "  0.96801759 -0.0427745   0.51636253]  energy_before :  40  energy_after :  50  reward :  -205.6531877809146\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "action : 1  next_temperatures :  [ 0.44174505 -0.29919126  1.20464994 -0.72504218  0.61735387 -0.33430881\n",
      "  0.96801759 -0.0427745   0.51636253]  energy_before :  50  energy_after :  50  reward :  -195.6531877809146\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "action : 1  next_temperatures :  [ 0.44174505 -0.29919126  1.20464994 -0.72504218  0.61735387 -0.33430881\n",
      "  0.96801759 -0.0427745   0.51636253]  energy_before :  50  energy_after :  50  reward :  -195.6531877809146\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "Episode 188/500, Total Reward: -1007.265938904573\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "action : 1  next_temperatures :  [2.37445166 2.04570386 1.98766237 1.7251866  1.96025522 1.76909217\n",
      " 2.21979276 1.39795347 2.48000571]  energy_before :  30  energy_after :  50  reward :  -200.03989619233275\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "action : 1  next_temperatures :  [2.37445166 2.04570386 1.98766237 1.7251866  1.96025522 1.76909217\n",
      " 2.21979276 1.39795347 2.48000571]  energy_before :  50  energy_after :  40  reward :  -170.03989619233275\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "action : 1  next_temperatures :  [2.37445166 2.04570386 1.98766237 1.7251866  1.96025522 1.76909217\n",
      " 2.21979276 1.39795347 2.48000571]  energy_before :  40  energy_after :  50  reward :  -190.03989619233275\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "action : 1  next_temperatures :  [2.37445166 2.04570386 1.98766237 1.7251866  1.96025522 1.76909217\n",
      " 2.21979276 1.39795347 2.48000571]  energy_before :  50  energy_after :  50  reward :  -180.03989619233275\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "action : 1  next_temperatures :  [2.37445166 2.04570386 1.98766237 1.7251866  1.96025522 1.76909217\n",
      " 2.21979276 1.39795347 2.48000571]  energy_before :  50  energy_after :  50  reward :  -180.03989619233275\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "Episode 189/500, Total Reward: -920.1994809616638\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "action : 1  next_temperatures :  [ 0.74932124 -0.32579579  0.88867006 -0.51447254  0.22883451  0.00435293\n",
      "  0.23725157  0.20111814  0.27534432]  energy_before :  30  energy_after :  50  reward :  -216.25537555893243\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step\n",
      "action : 1  next_temperatures :  [ 0.74932124 -0.32579579  0.88867006 -0.51447254  0.22883451  0.00435293\n",
      "  0.23725157  0.20111814  0.27534432]  energy_before :  50  energy_after :  40  reward :  -186.25537555893243\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "action : 1  next_temperatures :  [ 0.74932124 -0.32579579  0.88867006 -0.51447254  0.22883451  0.00435293\n",
      "  0.23725157  0.20111814  0.27534432]  energy_before :  40  energy_after :  50  reward :  -206.25537555893243\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step\n",
      "action : 1  next_temperatures :  [ 0.74932124 -0.32579579  0.88867006 -0.51447254  0.22883451  0.00435293\n",
      "  0.23725157  0.20111814  0.27534432]  energy_before :  50  energy_after :  50  reward :  -196.25537555893243\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "action : 1  next_temperatures :  [ 0.74932124 -0.32579579  0.88867006 -0.51447254  0.22883451  0.00435293\n",
      "  0.23725157  0.20111814  0.27534432]  energy_before :  50  energy_after :  50  reward :  -196.25537555893243\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "Episode 190/500, Total Reward: -1001.2768777946621\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "action : 1  next_temperatures :  [1.97387673 2.36318827 1.1622781  2.4988466  1.80572343 1.66564547\n",
      " 1.53936504 1.87423053 1.84752088]  energy_before :  30  energy_after :  50  reward :  -201.26932494506528\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step\n",
      "action : 1  next_temperatures :  [1.97387673 2.36318827 1.1622781  2.4988466  1.80572343 1.66564547\n",
      " 1.53936504 1.87423053 1.84752088]  energy_before :  50  energy_after :  40  reward :  -171.26932494506528\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "action : 1  next_temperatures :  [1.97387673 2.36318827 1.1622781  2.4988466  1.80572343 1.66564547\n",
      " 1.53936504 1.87423053 1.84752088]  energy_before :  40  energy_after :  50  reward :  -191.26932494506528\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "action : 1  next_temperatures :  [1.97387673 2.36318827 1.1622781  2.4988466  1.80572343 1.66564547\n",
      " 1.53936504 1.87423053 1.84752088]  energy_before :  50  energy_after :  50  reward :  -181.26932494506528\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "action : 1  next_temperatures :  [1.97387673 2.36318827 1.1622781  2.4988466  1.80572343 1.66564547\n",
      " 1.53936504 1.87423053 1.84752088]  energy_before :  50  energy_after :  50  reward :  -181.26932494506528\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "Episode 191/500, Total Reward: -926.3466247253264\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "action : 1  next_temperatures :  [-0.30296627 -0.34171189 -1.02354617  0.93608147  0.02777701 -0.84268094\n",
      "  0.3938968  -0.61524399  0.3295573 ]  energy_before :  30  energy_after :  50  reward :  -219.43883666967432\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step\n",
      "action : 2  next_temperatures :  [ 0.69703373  0.65828811 -0.02354617  1.93608147  1.02777701  0.15731906\n",
      "  1.3938968   0.38475601  1.3295573 ]  energy_before :  50  energy_after :  40  reward :  -189.43883666967432\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "action : 1  next_temperatures :  [ 0.69703373  0.65828811 -0.02354617  1.93608147  1.02777701  0.15731906\n",
      "  1.3938968   0.38475601  1.3295573 ]  energy_before :  40  energy_after :  50  reward :  -200.43883666967432\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step\n",
      "action : 1  next_temperatures :  [ 0.69703373  0.65828811 -0.02354617  1.93608147  1.02777701  0.15731906\n",
      "  1.3938968   0.38475601  1.3295573 ]  energy_before :  50  energy_after :  50  reward :  -190.43883666967432\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step\n",
      "action : 1  next_temperatures :  [ 0.69703373  0.65828811 -0.02354617  1.93608147  1.02777701  0.15731906\n",
      "  1.3938968   0.38475601  1.3295573 ]  energy_before :  50  energy_after :  50  reward :  -190.43883666967432\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "Episode 192/500, Total Reward: -990.1941833483716\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "action : 1  next_temperatures :  [1.99463191 2.49805632 1.28844181 2.51686591 1.77249078 1.7783102\n",
      " 1.6209511  2.03547587 1.84752088]  energy_before :  30  energy_after :  50  reward :  -200.6472552268881\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "action : 1  next_temperatures :  [1.99463191 2.49805632 1.28844181 2.51686591 1.77249078 1.7783102\n",
      " 1.6209511  2.03547587 1.84752088]  energy_before :  50  energy_after :  40  reward :  -170.6472552268881\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "action : 1  next_temperatures :  [1.99463191 2.49805632 1.28844181 2.51686591 1.77249078 1.7783102\n",
      " 1.6209511  2.03547587 1.84752088]  energy_before :  40  energy_after :  50  reward :  -190.6472552268881\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "action : 1  next_temperatures :  [1.99463191 2.49805632 1.28844181 2.51686591 1.77249078 1.7783102\n",
      " 1.6209511  2.03547587 1.84752088]  energy_before :  50  energy_after :  50  reward :  -180.6472552268881\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "action : 1  next_temperatures :  [1.99463191 2.49805632 1.28844181 2.51686591 1.77249078 1.7783102\n",
      " 1.6209511  2.03547587 1.84752088]  energy_before :  50  energy_after :  50  reward :  -180.6472552268881\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "Episode 193/500, Total Reward: -923.2362761344405\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "action : 1  next_temperatures :  [-0.24692729 -0.59301881 -0.47937017 -0.5636161  -0.83128681 -0.1666926\n",
      "  0.3318914  -0.61355476 -0.48363747]  energy_before :  30  energy_after :  50  reward :  -221.64621261220933\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "action : 1  next_temperatures :  [-0.24692729 -0.59301881 -0.47937017 -0.5636161  -0.83128681 -0.1666926\n",
      "  0.3318914  -0.61355476 -0.48363747]  energy_before :  50  energy_after :  40  reward :  -191.64621261220933\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "action : 1  next_temperatures :  [-0.24692729 -0.59301881 -0.47937017 -0.5636161  -0.83128681 -0.1666926\n",
      "  0.3318914  -0.61355476 -0.48363747]  energy_before :  40  energy_after :  50  reward :  -211.64621261220933\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "action : 1  next_temperatures :  [-0.24692729 -0.59301881 -0.47937017 -0.5636161  -0.83128681 -0.1666926\n",
      "  0.3318914  -0.61355476 -0.48363747]  energy_before :  50  energy_after :  50  reward :  -201.64621261220933\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step\n",
      "action : 1  next_temperatures :  [-0.24692729 -0.59301881 -0.47937017 -0.5636161  -0.83128681 -0.1666926\n",
      "  0.3318914  -0.61355476 -0.48363747]  energy_before :  50  energy_after :  50  reward :  -201.64621261220933\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "Episode 194/500, Total Reward: -1028.2310630610466\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step\n",
      "action : 2  next_temperatures :  [ 0.36495089  0.12803051 -0.06762747  0.84509449 -0.1303806   0.47380451\n",
      "  1.11976765  0.20139702  0.2615615 ]  energy_before :  30  energy_after :  50  reward :  -223.80340150691825\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step\n",
      "action : 1  next_temperatures :  [ 0.36495089  0.12803051 -0.06762747  0.84509449 -0.1303806   0.47380451\n",
      "  1.11976765  0.20139702  0.2615615 ]  energy_before :  50  energy_after :  40  reward :  -184.80340150691825\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "action : 1  next_temperatures :  [ 0.36495089  0.12803051 -0.06762747  0.84509449 -0.1303806   0.47380451\n",
      "  1.11976765  0.20139702  0.2615615 ]  energy_before :  40  energy_after :  50  reward :  -204.80340150691825\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "action : 1  next_temperatures :  [ 0.36495089  0.12803051 -0.06762747  0.84509449 -0.1303806   0.47380451\n",
      "  1.11976765  0.20139702  0.2615615 ]  energy_before :  50  energy_after :  50  reward :  -194.80340150691825\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "action : 1  next_temperatures :  [ 0.36495089  0.12803051 -0.06762747  0.84509449 -0.1303806   0.47380451\n",
      "  1.11976765  0.20139702  0.2615615 ]  energy_before :  50  energy_after :  50  reward :  -194.80340150691825\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "Episode 195/500, Total Reward: -1003.0170075345912\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "action : 1  next_temperatures :  [ 0.5687512  -0.71867227 -0.30760512 -0.03204662  0.01116069 -0.78122745\n",
      " -0.36974869 -0.42082818  0.31148631]  energy_before :  30  energy_after :  50  reward :  -219.73873013371406\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "action : 1  next_temperatures :  [ 0.5687512  -0.71867227 -0.30760512 -0.03204662  0.01116069 -0.78122745\n",
      " -0.36974869 -0.42082818  0.31148631]  energy_before :  50  energy_after :  40  reward :  -189.73873013371406\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "action : 1  next_temperatures :  [ 0.5687512  -0.71867227 -0.30760512 -0.03204662  0.01116069 -0.78122745\n",
      " -0.36974869 -0.42082818  0.31148631]  energy_before :  40  energy_after :  50  reward :  -209.73873013371406\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "action : 1  next_temperatures :  [ 0.5687512  -0.71867227 -0.30760512 -0.03204662  0.01116069 -0.78122745\n",
      " -0.36974869 -0.42082818  0.31148631]  energy_before :  50  energy_after :  50  reward :  -199.73873013371406\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "action : 1  next_temperatures :  [ 0.5687512  -0.71867227 -0.30760512 -0.03204662  0.01116069 -0.78122745\n",
      " -0.36974869 -0.42082818  0.31148631]  energy_before :  50  energy_after :  50  reward :  -199.73873013371406\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "Episode 196/500, Total Reward: -1018.6936506685703\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "action : 1  next_temperatures :  [-0.16183106  1.45932104  0.30041276  1.09170274 -0.2829482   1.64157619\n",
      " -0.48886433  1.98940577 -0.53785045]  energy_before :  30  energy_after :  50  reward :  -212.98907554800425\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "action : 1  next_temperatures :  [-0.16183106  1.45932104  0.30041276  1.09170274 -0.2829482   1.64157619\n",
      " -0.48886433  1.98940577 -0.53785045]  energy_before :  50  energy_after :  40  reward :  -182.98907554800425\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "action : 1  next_temperatures :  [-0.16183106  1.45932104  0.30041276  1.09170274 -0.2829482   1.64157619\n",
      " -0.48886433  1.98940577 -0.53785045]  energy_before :  40  energy_after :  50  reward :  -202.98907554800425\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step\n",
      "action : 1  next_temperatures :  [-0.16183106  1.45932104  0.30041276  1.09170274 -0.2829482   1.64157619\n",
      " -0.48886433  1.98940577 -0.53785045]  energy_before :  50  energy_after :  50  reward :  -192.98907554800425\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "action : 1  next_temperatures :  [-0.16183106  1.45932104  0.30041276  1.09170274 -0.2829482   1.64157619\n",
      " -0.48886433  1.98940577 -0.53785045]  energy_before :  50  energy_after :  50  reward :  -192.98907554800425\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "Episode 197/500, Total Reward: -984.9453777400213\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step\n",
      "action : 2  next_temperatures :  [-1.36395542  0.46855138 -0.57380235  0.27421016 -1.02766197  0.86941132\n",
      " -0.99004778  0.39489143 -0.82540885]  energy_before :  30  energy_after :  50  reward :  -229.77381207520278\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "action : 1  next_temperatures :  [-1.36395542  0.46855138 -0.57380235  0.27421016 -1.02766197  0.86941132\n",
      " -0.99004778  0.39489143 -0.82540885]  energy_before :  50  energy_after :  40  reward :  -190.77381207520278\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "action : 1  next_temperatures :  [-1.36395542  0.46855138 -0.57380235  0.27421016 -1.02766197  0.86941132\n",
      " -0.99004778  0.39489143 -0.82540885]  energy_before :  40  energy_after :  50  reward :  -210.77381207520278\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "action : 1  next_temperatures :  [-1.36395542  0.46855138 -0.57380235  0.27421016 -1.02766197  0.86941132\n",
      " -0.99004778  0.39489143 -0.82540885]  energy_before :  50  energy_after :  50  reward :  -200.77381207520278\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "action : 1  next_temperatures :  [-1.36395542  0.46855138 -0.57380235  0.27421016 -1.02766197  0.86941132\n",
      " -0.99004778  0.39489143 -0.82540885]  energy_before :  50  energy_after :  50  reward :  -200.77381207520278\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "Episode 198/500, Total Reward: -1032.869060376014\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "action : 1  next_temperatures :  [ 1.30971104  0.34812561  1.44044628 -0.18766788  0.9931853   1.10334609\n",
      "  0.34820861  1.09718154  0.57351574]  energy_before :  30  energy_after :  50  reward :  -210.97394767646364\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "action : 1  next_temperatures :  [ 1.30971104  0.34812561  1.44044628 -0.18766788  0.9931853   1.10334609\n",
      "  0.34820861  1.09718154  0.57351574]  energy_before :  50  energy_after :  40  reward :  -180.97394767646364\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "action : 1  next_temperatures :  [ 1.30971104  0.34812561  1.44044628 -0.18766788  0.9931853   1.10334609\n",
      "  0.34820861  1.09718154  0.57351574]  energy_before :  40  energy_after :  50  reward :  -200.97394767646364\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "action : 1  next_temperatures :  [ 1.30971104  0.34812561  1.44044628 -0.18766788  0.9931853   1.10334609\n",
      "  0.34820861  1.09718154  0.57351574]  energy_before :  50  energy_after :  50  reward :  -190.97394767646364\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "action : 1  next_temperatures :  [ 1.30971104  0.34812561  1.44044628 -0.18766788  0.9931853   1.10334609\n",
      "  0.34820861  1.09718154  0.57351574]  energy_before :  50  energy_after :  50  reward :  -190.97394767646364\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step\n",
      "Episode 199/500, Total Reward: -974.8697383823182\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step\n",
      "action : 1  next_temperatures :  [-0.24692729 -0.24370219 -0.36840691 -0.2777644  -0.53219302 -0.37256178\n",
      "  0.26172739 -0.69724877 -0.21257254]  energy_before :  30  energy_after :  50  reward :  -220.68964951617886\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step\n",
      "action : 1  next_temperatures :  [-0.24692729 -0.24370219 -0.36840691 -0.2777644  -0.53219302 -0.37256178\n",
      "  0.26172739 -0.69724877 -0.21257254]  energy_before :  50  energy_after :  40  reward :  -190.68964951617886\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "action : 1  next_temperatures :  [-0.24692729 -0.24370219 -0.36840691 -0.2777644  -0.53219302 -0.37256178\n",
      "  0.26172739 -0.69724877 -0.21257254]  energy_before :  40  energy_after :  50  reward :  -210.68964951617886\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "action : 1  next_temperatures :  [-0.24692729 -0.24370219 -0.36840691 -0.2777644  -0.53219302 -0.37256178\n",
      "  0.26172739 -0.69724877 -0.21257254]  energy_before :  50  energy_after :  50  reward :  -200.68964951617886\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step\n",
      "action : 1  next_temperatures :  [-0.24692729 -0.24370219 -0.36840691 -0.2777644  -0.53219302 -0.37256178\n",
      "  0.26172739 -0.69724877 -0.21257254]  energy_before :  50  energy_after :  50  reward :  -200.68964951617886\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "Episode 200/500, Total Reward: -1023.4482475808943\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "action : 2  next_temperatures :  [-0.23694927 -0.18861622  0.17557968 -0.31715065 -0.08053164 -0.11102782\n",
      "  0.10810054 -0.31305241 -0.16997386]  energy_before :  30  energy_after :  50  reward :  -228.13362162837944\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "action : 1  next_temperatures :  [-0.23694927 -0.18861622  0.17557968 -0.31715065 -0.08053164 -0.11102782\n",
      "  0.10810054 -0.31305241 -0.16997386]  energy_before :  50  energy_after :  40  reward :  -189.13362162837944\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "action : 1  next_temperatures :  [-0.23694927 -0.18861622  0.17557968 -0.31715065 -0.08053164 -0.11102782\n",
      "  0.10810054 -0.31305241 -0.16997386]  energy_before :  40  energy_after :  50  reward :  -209.13362162837944\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "action : 1  next_temperatures :  [-0.23694927 -0.18861622  0.17557968 -0.31715065 -0.08053164 -0.11102782\n",
      "  0.10810054 -0.31305241 -0.16997386]  energy_before :  50  energy_after :  50  reward :  -199.13362162837944\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "action : 1  next_temperatures :  [-0.23694927 -0.18861622  0.17557968 -0.31715065 -0.08053164 -0.11102782\n",
      "  0.10810054 -0.31305241 -0.16997386]  energy_before :  50  energy_after :  50  reward :  -199.13362162837944\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step\n",
      "Episode 201/500, Total Reward: -1024.6681081418972\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "action : 1  next_temperatures :  [-0.11616967  0.72215407  0.20464994  0.25626226  1.25738481  1.31740906\n",
      "  0.31557419  0.76854818 -0.38364463]  energy_before :  30  energy_after :  50  reward :  -213.6578317868623\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "action : 1  next_temperatures :  [-0.11616967  0.72215407  0.20464994  0.25626226  1.25738481  1.31740906\n",
      "  0.31557419  0.76854818 -0.38364463]  energy_before :  50  energy_after :  40  reward :  -183.6578317868623\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "action : 1  next_temperatures :  [-0.11616967  0.72215407  0.20464994  0.25626226  1.25738481  1.31740906\n",
      "  0.31557419  0.76854818 -0.38364463]  energy_before :  40  energy_after :  50  reward :  -203.6578317868623\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "action : 1  next_temperatures :  [-0.11616967  0.72215407  0.20464994  0.25626226  1.25738481  1.31740906\n",
      "  0.31557419  0.76854818 -0.38364463]  energy_before :  50  energy_after :  50  reward :  -193.6578317868623\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step\n",
      "action : 1  next_temperatures :  [-0.11616967  0.72215407  0.20464994  0.25626226  1.25738481  1.31740906\n",
      "  0.31557419  0.76854818 -0.38364463]  energy_before :  50  energy_after :  50  reward :  -193.6578317868623\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "Episode 202/500, Total Reward: -988.2891589343114\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "action : 1  next_temperatures :  [ 0.1723273   1.0547169   0.11800739  0.53556148  1.07626691  0.50622306\n",
      "  0.11976765 -0.01464349  0.3295573 ]  energy_before :  30  energy_after :  50  reward :  -214.10221549156844\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "action : 1  next_temperatures :  [ 0.1723273   1.0547169   0.11800739  0.53556148  1.07626691  0.50622306\n",
      "  0.11976765 -0.01464349  0.3295573 ]  energy_before :  50  energy_after :  40  reward :  -184.10221549156844\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "action : 1  next_temperatures :  [ 0.1723273   1.0547169   0.11800739  0.53556148  1.07626691  0.50622306\n",
      "  0.11976765 -0.01464349  0.3295573 ]  energy_before :  40  energy_after :  50  reward :  -204.10221549156844\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "action : 1  next_temperatures :  [ 0.1723273   1.0547169   0.11800739  0.53556148  1.07626691  0.50622306\n",
      "  0.11976765 -0.01464349  0.3295573 ]  energy_before :  50  energy_after :  50  reward :  -194.10221549156844\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "action : 1  next_temperatures :  [ 0.1723273   1.0547169   0.11800739  0.53556148  1.07626691  0.50622306\n",
      "  0.11976765 -0.01464349  0.3295573 ]  energy_before :  50  energy_after :  50  reward :  -194.10221549156844\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step\n",
      "Episode 203/500, Total Reward: -990.5110774578422\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step\n",
      "action : 1  next_temperatures :  [-0.3652318   0.25137244 -0.88978224  1.15640842  0.43155363  0.20202831\n",
      " -0.17394215 -0.100641    0.37834899]  energy_before :  30  energy_after :  50  reward :  -217.1098854044597\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "action : 1  next_temperatures :  [-0.3652318   0.25137244 -0.88978224  1.15640842  0.43155363  0.20202831\n",
      " -0.17394215 -0.100641    0.37834899]  energy_before :  50  energy_after :  40  reward :  -187.1098854044597\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "action : 1  next_temperatures :  [-0.3652318   0.25137244 -0.88978224  1.15640842  0.43155363  0.20202831\n",
      " -0.17394215 -0.100641    0.37834899]  energy_before :  40  energy_after :  50  reward :  -207.1098854044597\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "action : 1  next_temperatures :  [-0.3652318   0.25137244 -0.88978224  1.15640842  0.43155363  0.20202831\n",
      " -0.17394215 -0.100641    0.37834899]  energy_before :  50  energy_after :  50  reward :  -197.1098854044597\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "action : 1  next_temperatures :  [-0.3652318   0.25137244 -0.88978224  1.15640842  0.43155363  0.20202831\n",
      " -0.17394215 -0.100641    0.37834899]  energy_before :  50  energy_after :  50  reward :  -197.1098854044597\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step\n",
      "Episode 204/500, Total Reward: -1005.5494270222985\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "action : 2  next_temperatures :  [-0.0190199   0.61933554  0.41878683  0.700121   -0.22509364  0.65939404\n",
      "  1.21277576  0.55536893  0.16939943]  energy_before :  30  energy_after :  50  reward :  -222.90893201623504\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "action : 1  next_temperatures :  [-0.0190199   0.61933554  0.41878683  0.700121   -0.22509364  0.65939404\n",
      "  1.21277576  0.55536893  0.16939943]  energy_before :  50  energy_after :  40  reward :  -183.90893201623504\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "action : 1  next_temperatures :  [-0.0190199   0.61933554  0.41878683  0.700121   -0.22509364  0.65939404\n",
      "  1.21277576  0.55536893  0.16939943]  energy_before :  40  energy_after :  50  reward :  -203.90893201623504\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "action : 1  next_temperatures :  [-0.0190199   0.61933554  0.41878683  0.700121   -0.22509364  0.65939404\n",
      "  1.21277576  0.55536893  0.16939943]  energy_before :  50  energy_after :  50  reward :  -193.90893201623504\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "action : 1  next_temperatures :  [-0.0190199   0.61933554  0.41878683  0.700121   -0.22509364  0.65939404\n",
      "  1.21277576  0.55536893  0.16939943]  energy_before :  50  energy_after :  50  reward :  -193.90893201623504\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "Episode 205/500, Total Reward: -998.5446600811752\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "action : 1  next_temperatures :  [-0.69434962  0.31814828 -0.51528123 -0.46911713 -0.8562113  -0.43363118\n",
      " -0.89423049 -0.66927764 -0.85538365]  energy_before :  30  energy_after :  50  reward :  -223.0693339452667\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "action : 2  next_temperatures :  [0.30565038 1.31814828 0.48471877 0.53088287 0.1437887  0.56636882\n",
      " 0.10576951 0.33072236 0.14461635]  energy_before :  50  energy_after :  40  reward :  -193.0693339452667\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "action : 1  next_temperatures :  [0.30565038 1.31814828 0.48471877 0.53088287 0.1437887  0.56636882\n",
      " 0.10576951 0.33072236 0.14461635]  energy_before :  40  energy_after :  50  reward :  -204.0693339452667\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "action : 1  next_temperatures :  [0.30565038 1.31814828 0.48471877 0.53088287 0.1437887  0.56636882\n",
      " 0.10576951 0.33072236 0.14461635]  energy_before :  50  energy_after :  50  reward :  -194.0693339452667\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "action : 1  next_temperatures :  [0.30565038 1.31814828 0.48471877 0.53088287 0.1437887  0.56636882\n",
      " 0.10576951 0.33072236 0.14461635]  energy_before :  50  energy_after :  50  reward :  -194.0693339452667\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step\n",
      "Episode 206/500, Total Reward: -1008.3466697263334\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step\n",
      "action : 1  next_temperatures :  [-0.38598698  0.997754    0.08266636  0.28247215 -0.33002778  1.59992439\n",
      "  0.3628941   1.18164339 -0.22461987]  energy_before :  30  energy_after :  50  reward :  -214.43328025018133\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step\n",
      "action : 1  next_temperatures :  [-0.38598698  0.997754    0.08266636  0.28247215 -0.33002778  1.59992439\n",
      "  0.3628941   1.18164339 -0.22461987]  energy_before :  50  energy_after :  40  reward :  -184.43328025018133\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "action : 1  next_temperatures :  [-0.38598698  0.997754    0.08266636  0.28247215 -0.33002778  1.59992439\n",
      "  0.3628941   1.18164339 -0.22461987]  energy_before :  40  energy_after :  50  reward :  -204.43328025018133\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "action : 1  next_temperatures :  [-0.38598698  0.997754    0.08266636  0.28247215 -0.33002778  1.59992439\n",
      "  0.3628941   1.18164339 -0.22461987]  energy_before :  50  energy_after :  50  reward :  -194.43328025018133\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "action : 1  next_temperatures :  [-0.38598698  0.997754    0.08266636  0.28247215 -0.33002778  1.59992439\n",
      "  0.3628941   1.18164339 -0.22461987]  energy_before :  50  energy_after :  50  reward :  -194.43328025018133\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "Episode 207/500, Total Reward: -992.1664012509066\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "action : 1  next_temperatures :  [1.99463191 1.54309002 2.1622621  0.52041257 2.05496825 0.66292944\n",
      " 1.63506328 1.38563846 1.92615413]  energy_before :  30  energy_after :  50  reward :  -204.11484983829436\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "action : 1  next_temperatures :  [1.99463191 1.54309002 2.1622621  0.52041257 2.05496825 0.66292944\n",
      " 1.63506328 1.38563846 1.92615413]  energy_before :  50  energy_after :  40  reward :  -174.11484983829436\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step\n",
      "action : 1  next_temperatures :  [1.99463191 1.54309002 2.1622621  0.52041257 2.05496825 0.66292944\n",
      " 1.63506328 1.38563846 1.92615413]  energy_before :  40  energy_after :  50  reward :  -194.11484983829436\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "action : 1  next_temperatures :  [1.99463191 1.54309002 2.1622621  0.52041257 2.05496825 0.66292944\n",
      " 1.63506328 1.38563846 1.92615413]  energy_before :  50  energy_after :  50  reward :  -184.11484983829436\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "action : 1  next_temperatures :  [1.99463191 1.54309002 2.1622621  0.52041257 2.05496825 0.66292944\n",
      " 1.63506328 1.38563846 1.92615413]  energy_before :  50  energy_after :  50  reward :  -184.11484983829436\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step\n",
      "Episode 208/500, Total Reward: -940.5742491914718\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "action : 1  next_temperatures :  [-2.05262775  0.51021857 -1.20443149  0.33653007 -1.96618158  1.30819104\n",
      " -2.47466896  1.76750147 -2.27808727]  energy_before :  30  energy_after :  50  reward :  -224.0535559132925\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "action : 1  next_temperatures :  [-2.05262775  0.51021857 -1.20443149  0.33653007 -1.96618158  1.30819104\n",
      " -2.47466896  1.76750147 -2.27808727]  energy_before :  50  energy_after :  40  reward :  -194.0535559132925\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "action : 1  next_temperatures :  [-2.05262775  0.51021857 -1.20443149  0.33653007 -1.96618158  1.30819104\n",
      " -2.47466896  1.76750147 -2.27808727]  energy_before :  40  energy_after :  50  reward :  -214.0535559132925\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "action : 1  next_temperatures :  [-2.05262775  0.51021857 -1.20443149  0.33653007 -1.96618158  1.30819104\n",
      " -2.47466896  1.76750147 -2.27808727]  energy_before :  50  energy_after :  50  reward :  -204.0535559132925\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "action : 1  next_temperatures :  [-2.05262775  0.51021857 -1.20443149  0.33653007 -1.96618158  1.30819104\n",
      " -2.47466896  1.76750147 -2.27808727]  energy_before :  50  energy_after :  50  reward :  -204.0535559132925\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "Episode 209/500, Total Reward: -1040.2677795664627\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "action : 1  next_temperatures :  [ 1.66773786 -0.46736535  1.11667676 -0.61931213  2.05496825 -0.29267225\n",
      "  1.8680403  -0.65117867  2.00473854]  energy_before :  30  energy_after :  50  reward :  -211.31836668940025\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "action : 1  next_temperatures :  [ 1.66773786 -0.46736535  1.11667676 -0.61931213  2.05496825 -0.29267225\n",
      "  1.8680403  -0.65117867  2.00473854]  energy_before :  50  energy_after :  40  reward :  -181.31836668940025\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "action : 1  next_temperatures :  [ 1.66773786 -0.46736535  1.11667676 -0.61931213  2.05496825 -0.29267225\n",
      "  1.8680403  -0.65117867  2.00473854]  energy_before :  40  energy_after :  50  reward :  -201.31836668940025\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "action : 1  next_temperatures :  [ 1.66773786 -0.46736535  1.11667676 -0.61931213  2.05496825 -0.29267225\n",
      "  1.8680403  -0.65117867  2.00473854]  energy_before :  50  energy_after :  50  reward :  -191.31836668940025\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "action : 1  next_temperatures :  [ 1.66773786 -0.46736535  1.11667676 -0.61931213  2.05496825 -0.29267225\n",
      "  1.8680403  -0.65117867  2.00473854]  energy_before :  50  energy_after :  50  reward :  -191.31836668940025\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "Episode 210/500, Total Reward: -976.5918334470012\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "action : 1  next_temperatures :  [-0.05390414  0.11064057  0.80202751 -0.38260399  0.01116069 -0.25887283\n",
      "  0.27967632 -0.04612472  0.43256198]  energy_before :  30  energy_after :  50  reward :  -217.1054386115076\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "action : 1  next_temperatures :  [-0.05390414  0.11064057  0.80202751 -0.38260399  0.01116069 -0.25887283\n",
      "  0.27967632 -0.04612472  0.43256198]  energy_before :  50  energy_after :  40  reward :  -187.1054386115076\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step\n",
      "action : 1  next_temperatures :  [-0.05390414  0.11064057  0.80202751 -0.38260399  0.01116069 -0.25887283\n",
      "  0.27967632 -0.04612472  0.43256198]  energy_before :  40  energy_after :  50  reward :  -207.1054386115076\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "action : 1  next_temperatures :  [-0.05390414  0.11064057  0.80202751 -0.38260399  0.01116069 -0.25887283\n",
      "  0.27967632 -0.04612472  0.43256198]  energy_before :  50  energy_after :  50  reward :  -197.1054386115076\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step\n",
      "action : 1  next_temperatures :  [-0.05390414  0.11064057  0.80202751 -0.38260399  0.01116069 -0.25887283\n",
      "  0.27967632 -0.04612472  0.43256198]  energy_before :  50  energy_after :  50  reward :  -197.1054386115076\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "Episode 211/500, Total Reward: -1005.5271930575379\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "action : 1  next_temperatures :  [-0.3652318  -0.09040497  0.02224458 -0.15490551 -0.23808413 -0.47396003\n",
      " -0.41870032 -0.0545709  -0.10956787]  energy_before :  30  energy_after :  50  reward :  -219.88318096267932\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "action : 1  next_temperatures :  [-0.3652318  -0.09040497  0.02224458 -0.15490551 -0.23808413 -0.47396003\n",
      " -0.41870032 -0.0545709  -0.10956787]  energy_before :  50  energy_after :  40  reward :  -189.88318096267932\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "action : 1  next_temperatures :  [-0.3652318  -0.09040497  0.02224458 -0.15490551 -0.23808413 -0.47396003\n",
      " -0.41870032 -0.0545709  -0.10956787]  energy_before :  40  energy_after :  50  reward :  -209.88318096267932\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "action : 1  next_temperatures :  [-0.3652318  -0.09040497  0.02224458 -0.15490551 -0.23808413 -0.47396003\n",
      " -0.41870032 -0.0545709  -0.10956787]  energy_before :  50  energy_after :  50  reward :  -199.88318096267932\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "action : 1  next_temperatures :  [-0.3652318  -0.09040497  0.02224458 -0.15490551 -0.23808413 -0.47396003\n",
      " -0.41870032 -0.0545709  -0.10956787]  energy_before :  50  energy_after :  50  reward :  -199.88318096267932\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "Episode 212/500, Total Reward: -1019.4159048133965\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "action : 1  next_temperatures :  [0.25742353 1.08822449 0.28369227 1.12528417 0.31025448 0.83704765\n",
      " 0.16871929 1.19162524 0.10728407]  energy_before :  30  energy_after :  50  reward :  -212.6304448176013\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step\n",
      "action : 1  next_temperatures :  [0.25742353 1.08822449 0.28369227 1.12528417 0.31025448 0.83704765\n",
      " 0.16871929 1.19162524 0.10728407]  energy_before :  50  energy_after :  40  reward :  -182.6304448176013\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "action : 1  next_temperatures :  [0.25742353 1.08822449 0.28369227 1.12528417 0.31025448 0.83704765\n",
      " 0.16871929 1.19162524 0.10728407]  energy_before :  40  energy_after :  50  reward :  -202.6304448176013\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step\n",
      "action : 1  next_temperatures :  [0.25742353 1.08822449 0.28369227 1.12528417 0.31025448 0.83704765\n",
      " 0.16871929 1.19162524 0.10728407]  energy_before :  50  energy_after :  50  reward :  -192.6304448176013\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "action : 1  next_temperatures :  [0.25742353 1.08822449 0.28369227 1.12528417 0.31025448 0.83704765\n",
      " 0.16871929 1.19162524 0.10728407]  energy_before :  50  energy_after :  50  reward :  -192.6304448176013\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "Episode 213/500, Total Reward: -983.1522240880065\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "action : 1  next_temperatures :  [-2.29546333 -0.01501289 -1.57380235  0.08344074 -2.02766197  0.16822889\n",
      " -2.47466896  0.20111814 -2.00702234]  energy_before :  30  energy_after :  50  reward :  -227.94084407830292\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "action : 1  next_temperatures :  [-2.29546333 -0.01501289 -1.57380235  0.08344074 -2.02766197  0.16822889\n",
      " -2.47466896  0.20111814 -2.00702234]  energy_before :  50  energy_after :  40  reward :  -197.94084407830292\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step\n",
      "action : 1  next_temperatures :  [-2.29546333 -0.01501289 -1.57380235  0.08344074 -2.02766197  0.16822889\n",
      " -2.47466896  0.20111814 -2.00702234]  energy_before :  40  energy_after :  50  reward :  -217.94084407830292\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step\n",
      "action : 1  next_temperatures :  [-2.29546333 -0.01501289 -1.57380235  0.08344074 -2.02766197  0.16822889\n",
      " -2.47466896  0.20111814 -2.00702234]  energy_before :  50  energy_after :  50  reward :  -207.94084407830292\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "action : 1  next_temperatures :  [-2.29546333 -0.01501289 -1.57380235  0.08344074 -2.02766197  0.16822889\n",
      " -2.47466896  0.20111814 -2.00702234]  energy_before :  50  energy_after :  50  reward :  -207.94084407830292\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "Episode 214/500, Total Reward: -1059.7042203915146\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "action : 1  next_temperatures :  [-0.11616967 -0.60977261 -0.47937017 -0.84045814  0.39832099 -1.34557529\n",
      " -0.53618425 -1.34376581 -1.29683224]  energy_before :  30  energy_after :  50  reward :  -224.1698071850529\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "action : 1  next_temperatures :  [-0.11616967 -0.60977261 -0.47937017 -0.84045814  0.39832099 -1.34557529\n",
      " -0.53618425 -1.34376581 -1.29683224]  energy_before :  50  energy_after :  40  reward :  -194.1698071850529\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "action : 1  next_temperatures :  [-0.11616967 -0.60977261 -0.47937017 -0.84045814  0.39832099 -1.34557529\n",
      " -0.53618425 -1.34376581 -1.29683224]  energy_before :  40  energy_after :  50  reward :  -214.1698071850529\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step\n",
      "action : 1  next_temperatures :  [-0.11616967 -0.60977261 -0.47937017 -0.84045814  0.39832099 -1.34557529\n",
      " -0.53618425 -1.34376581 -1.29683224]  energy_before :  50  energy_after :  50  reward :  -204.1698071850529\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "action : 1  next_temperatures :  [-0.11616967 -0.60977261 -0.47937017 -0.84045814  0.39832099 -1.34557529\n",
      " -0.53618425 -1.34376581 -1.29683224]  energy_before :  50  energy_after :  50  reward :  -204.1698071850529\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "Episode 215/500, Total Reward: -1040.8490359252644\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "action : 1  next_temperatures :  [ 0.50648566 -0.16831012  1.33100306 -0.98788881  0.43155363 -0.35412573\n",
      "  0.65823563 -0.16129996  0.72918445]  energy_before :  30  energy_after :  50  reward :  -216.0151621897088\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "action : 1  next_temperatures :  [ 0.50648566 -0.16831012  1.33100306 -0.98788881  0.43155363 -0.35412573\n",
      "  0.65823563 -0.16129996  0.72918445]  energy_before :  50  energy_after :  40  reward :  -186.0151621897088\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "action : 1  next_temperatures :  [ 0.50648566 -0.16831012  1.33100306 -0.98788881  0.43155363 -0.35412573\n",
      "  0.65823563 -0.16129996  0.72918445]  energy_before :  40  energy_after :  50  reward :  -206.0151621897088\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step\n",
      "action : 1  next_temperatures :  [ 0.50648566 -0.16831012  1.33100306 -0.98788881  0.43155363 -0.35412573\n",
      "  0.65823563 -0.16129996  0.72918445]  energy_before :  50  energy_after :  50  reward :  -196.0151621897088\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "action : 1  next_temperatures :  [ 0.50648566 -0.16831012  1.33100306 -0.98788881  0.43155363 -0.35412573\n",
      "  0.65823563 -0.16129996  0.72918445]  energy_before :  50  energy_after :  50  reward :  -196.0151621897088\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "Episode 216/500, Total Reward: -1000.075810948544\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "action : 1  next_temperatures :  [-1.80356562  1.59083833 -1.02202613  1.51597545 -1.32977646  1.76909217\n",
      " -1.46789702  1.92874681 -1.24804056]  energy_before :  30  energy_after :  50  reward :  -218.06665301827542\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "action : 1  next_temperatures :  [-1.80356562  1.59083833 -1.02202613  1.51597545 -1.32977646  1.76909217\n",
      " -1.46789702  1.92874681 -1.24804056]  energy_before :  50  energy_after :  40  reward :  -188.06665301827542\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "action : 1  next_temperatures :  [-1.80356562  1.59083833 -1.02202613  1.51597545 -1.32977646  1.76909217\n",
      " -1.46789702  1.92874681 -1.24804056]  energy_before :  40  energy_after :  50  reward :  -208.06665301827542\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "action : 1  next_temperatures :  [-1.80356562  1.59083833 -1.02202613  1.51597545 -1.32977646  1.76909217\n",
      " -1.46789702  1.92874681 -1.24804056]  energy_before :  50  energy_after :  50  reward :  -198.06665301827542\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "action : 1  next_temperatures :  [-1.80356562  1.59083833 -1.02202613  1.51597545 -1.32977646  1.76909217\n",
      " -1.46789702  1.92874681 -1.24804056]  energy_before :  50  energy_after :  50  reward :  -198.06665301827542\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "Episode 217/500, Total Reward: -1010.3332650913771\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "action : 1  next_temperatures :  [ 0.43799358  0.64508662  0.3460141   0.4102454  -0.13340131  1.64311253\n",
      "  0.45753393  0.46141419 -0.31196302]  energy_before :  30  energy_after :  50  reward :  -214.043963976734\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step\n",
      "action : 1  next_temperatures :  [ 0.43799358  0.64508662  0.3460141   0.4102454  -0.13340131  1.64311253\n",
      "  0.45753393  0.46141419 -0.31196302]  energy_before :  50  energy_after :  40  reward :  -184.043963976734\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step\n",
      "action : 1  next_temperatures :  [ 0.43799358  0.64508662  0.3460141   0.4102454  -0.13340131  1.64311253\n",
      "  0.45753393  0.46141419 -0.31196302]  energy_before :  40  energy_after :  50  reward :  -204.043963976734\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "action : 1  next_temperatures :  [ 0.43799358  0.64508662  0.3460141   0.4102454  -0.13340131  1.64311253\n",
      "  0.45753393  0.46141419 -0.31196302]  energy_before :  50  energy_after :  50  reward :  -194.043963976734\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "action : 1  next_temperatures :  [ 0.43799358  0.64508662  0.3460141   0.4102454  -0.13340131  1.64311253\n",
      "  0.45753393  0.46141419 -0.31196302]  energy_before :  50  energy_after :  50  reward :  -194.043963976734\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "Episode 218/500, Total Reward: -990.21981988367\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "action : 1  next_temperatures :  [ 0.5687512   1.22309254  0.37641499  0.98522503  0.31025448  0.06785487\n",
      "  0.26172739 -0.19892388  0.3295573 ]  energy_before :  30  energy_after :  50  reward :  -214.07604608039645\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "action : 1  next_temperatures :  [ 0.5687512   1.22309254  0.37641499  0.98522503  0.31025448  0.06785487\n",
      "  0.26172739 -0.19892388  0.3295573 ]  energy_before :  50  energy_after :  40  reward :  -184.07604608039645\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "action : 1  next_temperatures :  [ 0.5687512   1.22309254  0.37641499  0.98522503  0.31025448  0.06785487\n",
      "  0.26172739 -0.19892388  0.3295573 ]  energy_before :  40  energy_after :  50  reward :  -204.07604608039645\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "action : 1  next_temperatures :  [ 0.5687512   1.22309254  0.37641499  0.98522503  0.31025448  0.06785487\n",
      "  0.26172739 -0.19892388  0.3295573 ]  energy_before :  50  energy_after :  50  reward :  -194.07604608039645\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "action : 1  next_temperatures :  [ 0.5687512   1.22309254  0.37641499  0.98522503  0.31025448  0.06785487\n",
      "  0.26172739 -0.19892388  0.3295573 ]  energy_before :  50  energy_after :  50  reward :  -194.07604608039645\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "Episode 219/500, Total Reward: -990.3802304019823\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step\n",
      "action : 1  next_temperatures :  [ 0.74932124 -0.37689486  0.70626469 -0.55460645  0.36508834 -0.71977397\n",
      "  0.85404217 -0.14440759  0.27534432]  energy_before :  30  energy_after :  50  reward :  -216.84562210435246\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "action : 1  next_temperatures :  [ 0.74932124 -0.37689486  0.70626469 -0.55460645  0.36508834 -0.71977397\n",
      "  0.85404217 -0.14440759  0.27534432]  energy_before :  50  energy_after :  40  reward :  -186.84562210435246\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "action : 1  next_temperatures :  [ 0.74932124 -0.37689486  0.70626469 -0.55460645  0.36508834 -0.71977397\n",
      "  0.85404217 -0.14440759  0.27534432]  energy_before :  40  energy_after :  50  reward :  -206.84562210435246\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "action : 1  next_temperatures :  [ 0.74932124 -0.37689486  0.70626469 -0.55460645  0.36508834 -0.71977397\n",
      "  0.85404217 -0.14440759  0.27534432]  energy_before :  50  energy_after :  50  reward :  -196.84562210435246\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "action : 1  next_temperatures :  [ 0.74932124 -0.37689486  0.70626469 -0.55460645  0.36508834 -0.71977397\n",
      "  0.85404217 -0.14440759  0.27534432]  energy_before :  50  energy_after :  50  reward :  -196.84562210435246\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "Episode 220/500, Total Reward: -1004.2281105217623\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "action : 1  next_temperatures :  [-0.11616967 -0.09040497 -0.69217643  0.8369753  -0.08355234 -0.41250654\n",
      "  0.0691843  -0.35172303  0.22113133]  energy_before :  30  energy_after :  50  reward :  -218.61924205772294\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "action : 1  next_temperatures :  [-0.11616967 -0.09040497 -0.69217643  0.8369753  -0.08355234 -0.41250654\n",
      "  0.0691843  -0.35172303  0.22113133]  energy_before :  50  energy_after :  40  reward :  -188.61924205772294\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "action : 1  next_temperatures :  [-0.11616967 -0.09040497 -0.69217643  0.8369753  -0.08355234 -0.41250654\n",
      "  0.0691843  -0.35172303  0.22113133]  energy_before :  40  energy_after :  50  reward :  -208.61924205772294\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "action : 1  next_temperatures :  [-0.11616967 -0.09040497 -0.69217643  0.8369753  -0.08355234 -0.41250654\n",
      "  0.0691843  -0.35172303  0.22113133]  energy_before :  50  energy_after :  50  reward :  -198.61924205772294\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step\n",
      "action : 1  next_temperatures :  [-0.11616967 -0.09040497 -0.69217643  0.8369753  -0.08355234 -0.41250654\n",
      "  0.0691843  -0.35172303  0.22113133]  energy_before :  50  energy_after :  50  reward :  -198.61924205772294\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "Episode 221/500, Total Reward: -1013.0962102886147\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "action : 1  next_temperatures :  [-1.57110763 -0.85354032 -0.87306175 -1.20166329 -1.9827979  -0.44630596\n",
      " -1.17092377 -0.65271434 -1.17003409]  energy_before :  30  energy_after :  50  reward :  -227.92214904990064\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step\n",
      "action : 1  next_temperatures :  [-1.57110763 -0.85354032 -0.87306175 -1.20166329 -1.9827979  -0.44630596\n",
      " -1.17092377 -0.65271434 -1.17003409]  energy_before :  50  energy_after :  40  reward :  -197.92214904990064\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "action : 1  next_temperatures :  [-1.57110763 -0.85354032 -0.87306175 -1.20166329 -1.9827979  -0.44630596\n",
      " -1.17092377 -0.65271434 -1.17003409]  energy_before :  40  energy_after :  50  reward :  -217.92214904990064\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "action : 1  next_temperatures :  [-1.57110763 -0.85354032 -0.87306175 -1.20166329 -1.9827979  -0.44630596\n",
      " -1.17092377 -0.65271434 -1.17003409]  energy_before :  50  energy_after :  50  reward :  -207.92214904990064\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "action : 1  next_temperatures :  [-1.57110763 -0.85354032 -0.87306175 -1.20166329 -1.9827979  -0.44630596\n",
      " -1.17092377 -0.65271434 -1.17003409]  energy_before :  50  energy_after :  50  reward :  -207.92214904990064\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "Episode 222/500, Total Reward: -1059.6107452495032\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step\n",
      "action : 1  next_temperatures :  [-0.49598942  0.50435474 -0.10999931  0.28001498 -0.13063192  1.39081183\n",
      " -0.47254712  0.61574902 -0.44568838]  energy_before :  30  energy_after :  50  reward :  -216.86392558108085\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "action : 1  next_temperatures :  [-0.49598942  0.50435474 -0.10999931  0.28001498 -0.13063192  1.39081183\n",
      " -0.47254712  0.61574902 -0.44568838]  energy_before :  50  energy_after :  40  reward :  -186.86392558108085\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "action : 1  next_temperatures :  [-0.49598942  0.50435474 -0.10999931  0.28001498 -0.13063192  1.39081183\n",
      " -0.47254712  0.61574902 -0.44568838]  energy_before :  40  energy_after :  50  reward :  -206.86392558108085\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "action : 1  next_temperatures :  [-0.49598942  0.50435474 -0.10999931  0.28001498 -0.13063192  1.39081183\n",
      " -0.47254712  0.61574902 -0.44568838]  energy_before :  50  energy_after :  50  reward :  -196.86392558108085\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "action : 1  next_temperatures :  [-0.49598942  0.50435474 -0.10999931  0.28001498 -0.13063192  1.39081183\n",
      " -0.47254712  0.61574902 -0.44568838]  energy_before :  50  energy_after :  50  reward :  -196.86392558108085\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "Episode 223/500, Total Reward: -1004.3196279054042\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "action : 1  next_temperatures :  [-0.45032803 -0.31909427 -0.33800601 -0.57917822  0.43155363 -0.41250654\n",
      "  0.65823563 -0.8055135  -0.93825207]  energy_before :  30  energy_after :  50  reward :  -220.7530893906454\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "action : 1  next_temperatures :  [-0.45032803 -0.31909427 -0.33800601 -0.57917822  0.43155363 -0.41250654\n",
      "  0.65823563 -0.8055135  -0.93825207]  energy_before :  50  energy_after :  40  reward :  -190.7530893906454\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "action : 1  next_temperatures :  [-0.45032803 -0.31909427 -0.33800601 -0.57917822  0.43155363 -0.41250654\n",
      "  0.65823563 -0.8055135  -0.93825207]  energy_before :  40  energy_after :  50  reward :  -210.7530893906454\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "action : 1  next_temperatures :  [-0.45032803 -0.31909427 -0.33800601 -0.57917822  0.43155363 -0.41250654\n",
      "  0.65823563 -0.8055135  -0.93825207]  energy_before :  50  energy_after :  50  reward :  -200.7530893906454\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step\n",
      "action : 1  next_temperatures :  [-0.45032803 -0.31909427 -0.33800601 -0.57917822  0.43155363 -0.41250654\n",
      "  0.65823563 -0.8055135  -0.93825207]  energy_before :  50  energy_after :  50  reward :  -200.7530893906454\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "Episode 224/500, Total Reward: -1023.7654469532271\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "action : 1  next_temperatures :  [ 0.63101673 -1.60075957  1.34468346 -2.31476487  0.31025448 -1.12946386\n",
      "  1.0113867  -1.40146312  0.45244007]  energy_before :  30  energy_after :  50  reward :  -220.6966699730279\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "action : 1  next_temperatures :  [ 0.63101673 -1.60075957  1.34468346 -2.31476487  0.31025448 -1.12946386\n",
      "  1.0113867  -1.40146312  0.45244007]  energy_before :  50  energy_after :  40  reward :  -190.6966699730279\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "action : 1  next_temperatures :  [ 0.63101673 -1.60075957  1.34468346 -2.31476487  0.31025448 -1.12946386\n",
      "  1.0113867  -1.40146312  0.45244007]  energy_before :  40  energy_after :  50  reward :  -210.6966699730279\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "action : 1  next_temperatures :  [ 0.63101673 -1.60075957  1.34468346 -2.31476487  0.31025448 -1.12946386\n",
      "  1.0113867  -1.40146312  0.45244007]  energy_before :  50  energy_after :  50  reward :  -200.6966699730279\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "action : 1  next_temperatures :  [ 0.63101673 -1.60075957  1.34468346 -2.31476487  0.31025448 -1.12946386\n",
      "  1.0113867  -1.40146312  0.45244007]  energy_before :  50  energy_after :  50  reward :  -200.6966699730279\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "Episode 225/500, Total Reward: -1023.4833498651394\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "action : 1  next_temperatures :  [ 0.0083614  -0.46736535 -0.32280557  0.02692565 -0.03370338 -0.59993967\n",
      " -0.19189109 -0.25958284 -0.04993359]  energy_before :  30  energy_after :  50  reward :  -219.88993442937635\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "action : 1  next_temperatures :  [ 0.0083614  -0.46736535 -0.32280557  0.02692565 -0.03370338 -0.59993967\n",
      " -0.19189109 -0.25958284 -0.04993359]  energy_before :  50  energy_after :  40  reward :  -189.88993442937635\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "action : 1  next_temperatures :  [ 0.0083614  -0.46736535 -0.32280557  0.02692565 -0.03370338 -0.59993967\n",
      " -0.19189109 -0.25958284 -0.04993359]  energy_before :  40  energy_after :  50  reward :  -209.88993442937635\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step\n",
      "action : 1  next_temperatures :  [ 0.0083614  -0.46736535 -0.32280557  0.02692565 -0.03370338 -0.59993967\n",
      " -0.19189109 -0.25958284 -0.04993359]  energy_before :  50  energy_after :  50  reward :  -199.88993442937635\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step\n",
      "action : 1  next_temperatures :  [ 0.0083614  -0.46736535 -0.32280557  0.02692565 -0.03370338 -0.59993967\n",
      " -0.19189109 -0.25958284 -0.04993359]  energy_before :  50  energy_after :  50  reward :  -199.88993442937635\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "Episode 226/500, Total Reward: -1019.4496721468818\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step\n",
      "action : 1  next_temperatures :  [-1.05015267 -1.60829877 -0.88978224 -1.37366574 -1.20183079 -1.499209\n",
      " -0.33711427 -1.45203054 -0.97697563]  energy_before :  30  energy_after :  50  reward :  -228.38905964216474\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "action : 2  next_temperatures :  [-0.05015267 -0.60829877  0.11021776 -0.37366574 -0.20183079 -0.499209\n",
      "  0.66288573 -0.45203054  0.02302437]  energy_before :  50  energy_after :  40  reward :  -198.38905964216474\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "action : 1  next_temperatures :  [-0.05015267 -0.60829877  0.11021776 -0.37366574 -0.20183079 -0.499209\n",
      "  0.66288573 -0.45203054  0.02302437]  energy_before :  40  energy_after :  50  reward :  -209.38905964216474\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "action : 1  next_temperatures :  [-0.05015267 -0.60829877  0.11021776 -0.37366574 -0.20183079 -0.499209\n",
      "  0.66288573 -0.45203054  0.02302437]  energy_before :  50  energy_after :  50  reward :  -199.38905964216474\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "action : 1  next_temperatures :  [-0.05015267 -0.60829877  0.11021776 -0.37366574 -0.20183079 -0.499209\n",
      "  0.66288573 -0.45203054  0.02302437]  energy_before :  50  energy_after :  50  reward :  -199.38905964216474\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "Episode 227/500, Total Reward: -1034.9452982108237\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "action : 1  next_temperatures :  [-0.67655947 -0.62820178 -0.74841808 -0.32526984 -0.83128681 -0.45025654\n",
      " -0.76625693 -0.56134198 -0.70591071]  energy_before :  30  energy_after :  50  reward :  -223.69350214202058\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step\n",
      "action : 1  next_temperatures :  [-0.67655947 -0.62820178 -0.74841808 -0.32526984 -0.83128681 -0.45025654\n",
      " -0.76625693 -0.56134198 -0.70591071]  energy_before :  50  energy_after :  40  reward :  -193.69350214202058\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "action : 1  next_temperatures :  [-0.67655947 -0.62820178 -0.74841808 -0.32526984 -0.83128681 -0.45025654\n",
      " -0.76625693 -0.56134198 -0.70591071]  energy_before :  40  energy_after :  50  reward :  -213.69350214202058\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "action : 1  next_temperatures :  [-0.67655947 -0.62820178 -0.74841808 -0.32526984 -0.83128681 -0.45025654\n",
      " -0.76625693 -0.56134198 -0.70591071]  energy_before :  50  energy_after :  50  reward :  -203.69350214202058\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "action : 1  next_temperatures :  [-0.67655947 -0.62820178 -0.74841808 -0.32526984 -0.83128681 -0.45025654\n",
      " -0.76625693 -0.56134198 -0.70591071]  energy_before :  50  energy_after :  50  reward :  -203.69350214202058\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "Episode 228/500, Total Reward: -1038.467510710103\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "action : 2  next_temperatures :  [ 0.73439305 -0.31426968  0.56623117 -0.65132684  1.07928761 -0.14994836\n",
      "  0.43444477 -0.55184908 -0.35104523]  energy_before :  30  energy_after :  50  reward :  -226.20408258300114\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "action : 1  next_temperatures :  [ 0.73439305 -0.31426968  0.56623117 -0.65132684  1.07928761 -0.14994836\n",
      "  0.43444477 -0.55184908 -0.35104523]  energy_before :  50  energy_after :  40  reward :  -187.20408258300114\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "action : 1  next_temperatures :  [ 0.73439305 -0.31426968  0.56623117 -0.65132684  1.07928761 -0.14994836\n",
      "  0.43444477 -0.55184908 -0.35104523]  energy_before :  40  energy_after :  50  reward :  -207.20408258300114\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "action : 1  next_temperatures :  [ 0.73439305 -0.31426968  0.56623117 -0.65132684  1.07928761 -0.14994836\n",
      "  0.43444477 -0.55184908 -0.35104523]  energy_before :  50  energy_after :  50  reward :  -197.20408258300114\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "action : 1  next_temperatures :  [ 0.73439305 -0.31426968  0.56623117 -0.65132684  1.07928761 -0.14994836\n",
      "  0.43444477 -0.55184908 -0.35104523]  energy_before :  50  energy_after :  50  reward :  -197.20408258300114\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "Episode 229/500, Total Reward: -1015.0204129150056\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "action : 1  next_temperatures :  [ 0.68705571 -0.16831012 -0.06439797  0.4102454   1.25738481 -0.52751235\n",
      "  1.09880034 -0.44616674  1.73367361]  energy_before :  30  energy_after :  50  reward :  -214.01922729278584\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step\n",
      "action : 1  next_temperatures :  [ 0.68705571 -0.16831012 -0.06439797  0.4102454   1.25738481 -0.52751235\n",
      "  1.09880034 -0.44616674  1.73367361]  energy_before :  50  energy_after :  40  reward :  -184.01922729278584\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "action : 1  next_temperatures :  [ 0.68705571 -0.16831012 -0.06439797  0.4102454   1.25738481 -0.52751235\n",
      "  1.09880034 -0.44616674  1.73367361]  energy_before :  40  energy_after :  50  reward :  -204.01922729278584\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "action : 1  next_temperatures :  [ 0.68705571 -0.16831012 -0.06439797  0.4102454   1.25738481 -0.52751235\n",
      "  1.09880034 -0.44616674  1.73367361]  energy_before :  50  energy_after :  50  reward :  -194.01922729278584\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step\n",
      "action : 1  next_temperatures :  [ 0.68705571 -0.16831012 -0.06439797  0.4102454   1.25738481 -0.52751235\n",
      "  1.09880034 -0.44616674  1.73367361]  energy_before :  50  energy_after :  50  reward :  -194.01922729278584\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "Episode 230/500, Total Reward: -990.0961364639293\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "action : 1  next_temperatures :  [1.12914099 1.04047617 0.98443287 0.82796564 1.05798895 0.41404283\n",
      " 1.29460687 0.95282857 1.7878866 ]  energy_before :  30  energy_after :  50  reward :  -208.5106304901927\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step\n",
      "action : 1  next_temperatures :  [1.12914099 1.04047617 0.98443287 0.82796564 1.05798895 0.41404283\n",
      " 1.29460687 0.95282857 1.7878866 ]  energy_before :  50  energy_after :  40  reward :  -178.5106304901927\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step\n",
      "action : 1  next_temperatures :  [1.12914099 1.04047617 0.98443287 0.82796564 1.05798895 0.41404283\n",
      " 1.29460687 0.95282857 1.7878866 ]  energy_before :  40  energy_after :  50  reward :  -198.5106304901927\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "action : 1  next_temperatures :  [1.12914099 1.04047617 0.98443287 0.82796564 1.05798895 0.41404283\n",
      " 1.29460687 0.95282857 1.7878866 ]  energy_before :  50  energy_after :  50  reward :  -188.5106304901927\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "action : 1  next_temperatures :  [1.12914099 1.04047617 0.98443287 0.82796564 1.05798895 0.41404283\n",
      " 1.29460687 0.95282857 1.7878866 ]  energy_before :  50  energy_after :  50  reward :  -188.5106304901927\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "Episode 231/500, Total Reward: -962.5531524509636\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "action : 1  next_temperatures :  [-0.738825   -0.20672417 -0.55298376 -0.46240377 -0.88113578 -0.44630596\n",
      " -0.8898598  -0.66701527 -0.86312836]  energy_before :  30  energy_after :  50  reward :  -223.708381880539\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "action : 1  next_temperatures :  [-0.738825   -0.20672417 -0.55298376 -0.46240377 -0.88113578 -0.44630596\n",
      " -0.8898598  -0.66701527 -0.86312836]  energy_before :  50  energy_after :  40  reward :  -193.708381880539\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "action : 1  next_temperatures :  [-0.738825   -0.20672417 -0.55298376 -0.46240377 -0.88113578 -0.44630596\n",
      " -0.8898598  -0.66701527 -0.86312836]  energy_before :  40  energy_after :  50  reward :  -213.708381880539\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "action : 1  next_temperatures :  [-0.738825   -0.20672417 -0.55298376 -0.46240377 -0.88113578 -0.44630596\n",
      " -0.8898598  -0.66701527 -0.86312836]  energy_before :  50  energy_after :  50  reward :  -203.708381880539\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "action : 1  next_temperatures :  [-0.738825   -0.20672417 -0.55298376 -0.46240377 -0.88113578 -0.44630596\n",
      " -0.8898598  -0.66701527 -0.86312836]  energy_before :  50  energy_after :  50  reward :  -203.708381880539\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "Episode 232/500, Total Reward: -1038.541909402695\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step\n",
      "action : 1  next_temperatures :  [-0.71806982 -0.37605717 -0.52041138 -1.08617593 -0.78143785 -1.14994836\n",
      " -0.71730529 -1.01973945 -0.86312836]  energy_before :  30  energy_after :  50  reward :  -225.23227361876644\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "action : 1  next_temperatures :  [-0.71806982 -0.37605717 -0.52041138 -1.08617593 -0.78143785 -1.14994836\n",
      " -0.71730529 -1.01973945 -0.86312836]  energy_before :  50  energy_after :  40  reward :  -195.23227361876644\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step\n",
      "action : 1  next_temperatures :  [-0.71806982 -0.37605717 -0.52041138 -1.08617593 -0.78143785 -1.14994836\n",
      " -0.71730529 -1.01973945 -0.86312836]  energy_before :  40  energy_after :  50  reward :  -215.23227361876644\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "action : 1  next_temperatures :  [-0.71806982 -0.37605717 -0.52041138 -1.08617593 -0.78143785 -1.14994836\n",
      " -0.71730529 -1.01973945 -0.86312836]  energy_before :  50  energy_after :  50  reward :  -205.23227361876644\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "action : 1  next_temperatures :  [-0.71806982 -0.37605717 -0.52041138 -1.08617593 -0.78143785 -1.14994836\n",
      " -0.71730529 -1.01973945 -0.86312836]  energy_before :  50  energy_after :  50  reward :  -205.23227361876644\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "Episode 233/500, Total Reward: -1046.1613680938322\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step\n",
      "action : 1  next_temperatures :  [-0.86958262  0.83691757 -0.38360736  0.65596319 -1.00077329  1.57346525\n",
      " -1.34878137  1.35287059 -0.7384385 ]  energy_before :  30  energy_after :  50  reward :  -217.92196655134805\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "action : 1  next_temperatures :  [-0.86958262  0.83691757 -0.38360736  0.65596319 -1.00077329  1.57346525\n",
      " -1.34878137  1.35287059 -0.7384385 ]  energy_before :  50  energy_after :  40  reward :  -187.92196655134805\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "action : 1  next_temperatures :  [-0.86958262  0.83691757 -0.38360736  0.65596319 -1.00077329  1.57346525\n",
      " -1.34878137  1.35287059 -0.7384385 ]  energy_before :  40  energy_after :  50  reward :  -207.92196655134805\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "action : 1  next_temperatures :  [-0.86958262  0.83691757 -0.38360736  0.65596319 -1.00077329  1.57346525\n",
      " -1.34878137  1.35287059 -0.7384385 ]  energy_before :  50  energy_after :  50  reward :  -197.92196655134805\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "action : 1  next_temperatures :  [-0.86958262  0.83691757 -0.38360736  0.65596319 -1.00077329  1.57346525\n",
      " -1.34878137  1.35287059 -0.7384385 ]  energy_before :  50  energy_after :  50  reward :  -197.92196655134805\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "Episode 234/500, Total Reward: -1009.6098327567403\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "action : 1  next_temperatures :  [ 0.14623508 -0.86012217  0.09194949 -0.79131458 -0.53219302 -0.63725071\n",
      " -0.24002686 -0.9967044   0.36440851]  energy_before :  30  energy_after :  50  reward :  -221.45501868158485\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step\n",
      "action : 1  next_temperatures :  [ 0.14623508 -0.86012217  0.09194949 -0.79131458 -0.53219302 -0.63725071\n",
      " -0.24002686 -0.9967044   0.36440851]  energy_before :  50  energy_after :  40  reward :  -191.45501868158485\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "action : 1  next_temperatures :  [ 0.14623508 -0.86012217  0.09194949 -0.79131458 -0.53219302 -0.63725071\n",
      " -0.24002686 -0.9967044   0.36440851]  energy_before :  40  energy_after :  50  reward :  -211.45501868158485\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "action : 1  next_temperatures :  [ 0.14623508 -0.86012217  0.09194949 -0.79131458 -0.53219302 -0.63725071\n",
      " -0.24002686 -0.9967044   0.36440851]  energy_before :  50  energy_after :  50  reward :  -201.45501868158485\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "action : 1  next_temperatures :  [ 0.14623508 -0.86012217  0.09194949 -0.79131458 -0.53219302 -0.63725071\n",
      " -0.24002686 -0.9967044   0.36440851]  energy_before :  50  energy_after :  50  reward :  -201.45501868158485\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "Episode 235/500, Total Reward: -1027.2750934079243\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "action : 1  next_temperatures :  [-0.28428661  1.23063174  0.07240605  0.61746741 -0.33279717  1.39729859\n",
      " -1.0110151   1.1225201  -0.26678553]  energy_before :  30  energy_after :  50  reward :  -215.45456051328534\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "action : 1  next_temperatures :  [-0.28428661  1.23063174  0.07240605  0.61746741 -0.33279717  1.39729859\n",
      " -1.0110151   1.1225201  -0.26678553]  energy_before :  50  energy_after :  40  reward :  -185.45456051328534\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "action : 1  next_temperatures :  [-0.28428661  1.23063174  0.07240605  0.61746741 -0.33279717  1.39729859\n",
      " -1.0110151   1.1225201  -0.26678553]  energy_before :  40  energy_after :  50  reward :  -205.45456051328534\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "action : 1  next_temperatures :  [-0.28428661  1.23063174  0.07240605  0.61746741 -0.33279717  1.39729859\n",
      " -1.0110151   1.1225201  -0.26678553]  energy_before :  50  energy_after :  50  reward :  -195.45456051328534\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "action : 1  next_temperatures :  [-0.28428661  1.23063174  0.07240605  0.61746741 -0.33279717  1.39729859\n",
      " -1.0110151   1.1225201  -0.26678553]  energy_before :  50  energy_after :  50  reward :  -195.45456051328534\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "Episode 236/500, Total Reward: -997.2728025664267\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "action : 1  next_temperatures :  [2.06312399 1.93680419 1.21243958 2.21627115 2.15965108 1.48026079\n",
      " 2.07783302 1.36438811 2.44386372]  energy_before :  30  energy_after :  50  reward :  -201.04536437328676\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "action : 1  next_temperatures :  [2.06312399 1.93680419 1.21243958 2.21627115 2.15965108 1.48026079\n",
      " 2.07783302 1.36438811 2.44386372]  energy_before :  50  energy_after :  40  reward :  -171.04536437328676\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "action : 1  next_temperatures :  [2.06312399 1.93680419 1.21243958 2.21627115 2.15965108 1.48026079\n",
      " 2.07783302 1.36438811 2.44386372]  energy_before :  40  energy_after :  50  reward :  -191.04536437328676\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "action : 1  next_temperatures :  [2.06312399 1.93680419 1.21243958 2.21627115 2.15965108 1.48026079\n",
      " 2.07783302 1.36438811 2.44386372]  energy_before :  50  energy_after :  50  reward :  -181.04536437328676\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "action : 1  next_temperatures :  [2.06312399 1.93680419 1.21243958 2.21627115 2.15965108 1.48026079\n",
      " 2.07783302 1.36438811 2.44386372]  energy_before :  50  energy_after :  50  reward :  -181.04536437328676\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "Episode 237/500, Total Reward: -925.2268218664337\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "action : 1  next_temperatures :  [-1.2992148  -1.00516216 -1.29563417 -0.72578984 -1.23506343 -0.54770421\n",
      " -1.52990242 -0.98979389 -0.92276265]  energy_before :  30  energy_after :  50  reward :  -227.55102756879094\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "action : 1  next_temperatures :  [-1.2992148  -1.00516216 -1.29563417 -0.72578984 -1.23506343 -0.54770421\n",
      " -1.52990242 -0.98979389 -0.92276265]  energy_before :  50  energy_after :  40  reward :  -197.55102756879094\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "action : 1  next_temperatures :  [-1.2992148  -1.00516216 -1.29563417 -0.72578984 -1.23506343 -0.54770421\n",
      " -1.52990242 -0.98979389 -0.92276265]  energy_before :  40  energy_after :  50  reward :  -217.55102756879094\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "action : 1  next_temperatures :  [-1.2992148  -1.00516216 -1.29563417 -0.72578984 -1.23506343 -0.54770421\n",
      " -1.52990242 -0.98979389 -0.92276265]  energy_before :  50  energy_after :  50  reward :  -207.55102756879094\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step\n",
      "action : 1  next_temperatures :  [-1.2992148  -1.00516216 -1.29563417 -0.72578984 -1.23506343 -0.54770421\n",
      " -1.52990242 -0.98979389 -0.92276265]  energy_before :  50  energy_after :  50  reward :  -207.55102756879094\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "Episode 238/500, Total Reward: -1057.7551378439548\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "action : 1  next_temperatures :  [-1.19958995  0.62833282 -0.61161406  0.36028279 -1.2799275   1.48026079\n",
      " -0.76625693  0.85301002 -1.19382757]  energy_before :  30  energy_after :  50  reward :  -219.72932957448967\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "action : 1  next_temperatures :  [-1.19958995  0.62833282 -0.61161406  0.36028279 -1.2799275   1.48026079\n",
      " -0.76625693  0.85301002 -1.19382757]  energy_before :  50  energy_after :  40  reward :  -189.72932957448967\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "action : 1  next_temperatures :  [-1.19958995  0.62833282 -0.61161406  0.36028279 -1.2799275   1.48026079\n",
      " -0.76625693  0.85301002 -1.19382757]  energy_before :  40  energy_after :  50  reward :  -209.72932957448967\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "action : 1  next_temperatures :  [-1.19958995  0.62833282 -0.61161406  0.36028279 -1.2799275   1.48026079\n",
      " -0.76625693  0.85301002 -1.19382757]  energy_before :  50  energy_after :  50  reward :  -199.72932957448967\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step\n",
      "action : 1  next_temperatures :  [-1.19958995  0.62833282 -0.61161406  0.36028279 -1.2799275   1.48026079\n",
      " -0.76625693  0.85301002 -1.19382757]  energy_before :  50  energy_after :  50  reward :  -199.72932957448967\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "Episode 239/500, Total Reward: -1018.6466478724483\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "action : 1  next_temperatures :  [0.5687512  0.86456133 0.25025128 0.88693791 0.46478627 0.4253093\n",
      " 0.9029938  0.67717582 0.81747417]  energy_before :  30  energy_after :  50  reward :  -212.14175891788838\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step\n",
      "action : 1  next_temperatures :  [0.5687512  0.86456133 0.25025128 0.88693791 0.46478627 0.4253093\n",
      " 0.9029938  0.67717582 0.81747417]  energy_before :  50  energy_after :  40  reward :  -182.14175891788838\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "action : 1  next_temperatures :  [0.5687512  0.86456133 0.25025128 0.88693791 0.46478627 0.4253093\n",
      " 0.9029938  0.67717582 0.81747417]  energy_before :  40  energy_after :  50  reward :  -202.14175891788838\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "action : 1  next_temperatures :  [0.5687512  0.86456133 0.25025128 0.88693791 0.46478627 0.4253093\n",
      " 0.9029938  0.67717582 0.81747417]  energy_before :  50  energy_after :  50  reward :  -192.14175891788838\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "action : 1  next_temperatures :  [0.5687512  0.86456133 0.25025128 0.88693791 0.46478627 0.4253093\n",
      " 0.9029938  0.67717582 0.81747417]  energy_before :  50  energy_after :  50  reward :  -192.14175891788838\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step\n",
      "Episode 240/500, Total Reward: -980.7087945894419\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "action : 1  next_temperatures :  [1.89840335 2.14042372 1.89687051 1.39775051 2.22599552 1.24226821\n",
      " 1.56009231 1.71655458 1.83482234]  energy_before :  30  energy_after :  50  reward :  -202.08681893632496\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step\n",
      "action : 1  next_temperatures :  [1.89840335 2.14042372 1.89687051 1.39775051 2.22599552 1.24226821\n",
      " 1.56009231 1.71655458 1.83482234]  energy_before :  50  energy_after :  40  reward :  -172.08681893632496\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "action : 1  next_temperatures :  [1.89840335 2.14042372 1.89687051 1.39775051 2.22599552 1.24226821\n",
      " 1.56009231 1.71655458 1.83482234]  energy_before :  40  energy_after :  50  reward :  -192.08681893632496\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "action : 1  next_temperatures :  [1.89840335 2.14042372 1.89687051 1.39775051 2.22599552 1.24226821\n",
      " 1.56009231 1.71655458 1.83482234]  energy_before :  50  energy_after :  50  reward :  -182.08681893632496\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "action : 1  next_temperatures :  [1.89840335 2.14042372 1.89687051 1.39775051 2.22599552 1.24226821\n",
      " 1.56009231 1.71655458 1.83482234]  energy_before :  50  energy_after :  50  reward :  -182.08681893632496\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "Episode 241/500, Total Reward: -930.4340946816249\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "action : 1  next_temperatures :  [ 0.04572072 -1.35699185 -0.38360736 -1.22541601 -0.88113578 -0.66139315\n",
      " -0.47254712 -0.97597286 -0.06981168]  energy_before :  30  energy_after :  50  reward :  -223.98115509936625\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "action : 1  next_temperatures :  [ 0.04572072 -1.35699185 -0.38360736 -1.22541601 -0.88113578 -0.66139315\n",
      " -0.47254712 -0.97597286 -0.06981168]  energy_before :  50  energy_after :  40  reward :  -193.98115509936625\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "action : 1  next_temperatures :  [ 0.04572072 -1.35699185 -0.38360736 -1.22541601 -0.88113578 -0.66139315\n",
      " -0.47254712 -0.97597286 -0.06981168]  energy_before :  40  energy_after :  50  reward :  -213.98115509936625\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step\n",
      "action : 1  next_temperatures :  [ 0.04572072 -1.35699185 -0.38360736 -1.22541601 -0.88113578 -0.66139315\n",
      " -0.47254712 -0.97597286 -0.06981168]  energy_before :  50  energy_after :  50  reward :  -203.98115509936625\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "action : 1  next_temperatures :  [ 0.04572072 -1.35699185 -0.38360736 -1.22541601 -0.88113578 -0.66139315\n",
      " -0.47254712 -0.97597286 -0.06981168]  energy_before :  50  energy_after :  50  reward :  -203.98115509936625\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "Episode 242/500, Total Reward: -1039.9057754968312\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step\n",
      "action : 1  next_temperatures :  [-1.09581406  1.24152171 -0.47937017  1.07368343 -0.93596964  1.52327823\n",
      " -0.90821667  1.62698767 -1.0799803 ]  energy_before :  30  energy_after :  50  reward :  -217.03387979427578\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "action : 1  next_temperatures :  [-1.09581406  1.24152171 -0.47937017  1.07368343 -0.93596964  1.52327823\n",
      " -0.90821667  1.62698767 -1.0799803 ]  energy_before :  50  energy_after :  40  reward :  -187.03387979427578\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "action : 1  next_temperatures :  [-1.09581406  1.24152171 -0.47937017  1.07368343 -0.93596964  1.52327823\n",
      " -0.90821667  1.62698767 -1.0799803 ]  energy_before :  40  energy_after :  50  reward :  -207.03387979427578\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "action : 1  next_temperatures :  [-1.09581406  1.24152171 -0.47937017  1.07368343 -0.93596964  1.52327823\n",
      " -0.90821667  1.62698767 -1.0799803 ]  energy_before :  50  energy_after :  50  reward :  -197.03387979427578\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "action : 1  next_temperatures :  [-1.09581406  1.24152171 -0.47937017  1.07368343 -0.93596964  1.52327823\n",
      " -0.90821667  1.62698767 -1.0799803 ]  energy_before :  50  energy_after :  50  reward :  -197.03387979427578\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "Episode 243/500, Total Reward: -1005.1693989713789\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step\n",
      "action : 1  next_temperatures :  [-1.09581406 -1.14589404 -1.16339028 -0.68647499 -1.1303806  -0.4581577\n",
      " -1.39773301 -0.90686771 -0.70591071]  energy_before :  30  energy_after :  50  reward :  -226.69062310720497\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "action : 1  next_temperatures :  [-1.09581406 -1.14589404 -1.16339028 -0.68647499 -1.1303806  -0.4581577\n",
      " -1.39773301 -0.90686771 -0.70591071]  energy_before :  50  energy_after :  40  reward :  -196.69062310720497\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "action : 1  next_temperatures :  [-1.09581406 -1.14589404 -1.16339028 -0.68647499 -1.1303806  -0.4581577\n",
      " -1.39773301 -0.90686771 -0.70591071]  energy_before :  40  energy_after :  50  reward :  -216.69062310720497\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "action : 1  next_temperatures :  [-1.09581406 -1.14589404 -1.16339028 -0.68647499 -1.1303806  -0.4581577\n",
      " -1.39773301 -0.90686771 -0.70591071]  energy_before :  50  energy_after :  50  reward :  -206.69062310720497\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "action : 1  next_temperatures :  [-1.09581406 -1.14589404 -1.16339028 -0.68647499 -1.1303806  -0.4581577\n",
      " -1.39773301 -0.90686771 -0.70591071]  energy_before :  50  energy_after :  50  reward :  -206.69062310720497\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "Episode 244/500, Total Reward: -1053.4531155360248\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step\n",
      "action : 1  next_temperatures :  [ 0.74932124 -0.13312715  0.36121455 -0.4407572   0.29363816 -0.73104044\n",
      "  0.9029938  -0.46689828  0.76326118]  energy_before :  30  energy_after :  50  reward :  -216.70139413709433\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "action : 1  next_temperatures :  [ 0.74932124 -0.13312715  0.36121455 -0.4407572   0.29363816 -0.73104044\n",
      "  0.9029938  -0.46689828  0.76326118]  energy_before :  50  energy_after :  40  reward :  -186.70139413709433\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "action : 1  next_temperatures :  [ 0.74932124 -0.13312715  0.36121455 -0.4407572   0.29363816 -0.73104044\n",
      "  0.9029938  -0.46689828  0.76326118]  energy_before :  40  energy_after :  50  reward :  -206.70139413709433\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "action : 1  next_temperatures :  [ 0.74932124 -0.13312715  0.36121455 -0.4407572   0.29363816 -0.73104044\n",
      "  0.9029938  -0.46689828  0.76326118]  energy_before :  50  energy_after :  50  reward :  -196.70139413709433\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "action : 1  next_temperatures :  [ 0.74932124 -0.13312715  0.36121455 -0.4407572   0.29363816 -0.73104044\n",
      "  0.9029938  -0.46689828  0.76326118]  energy_before :  50  energy_after :  50  reward :  -196.70139413709433\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "Episode 245/500, Total Reward: -1003.5069706854716\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "action : 1  next_temperatures :  [ 0.06440038 -0.62066257  1.30364226 -1.49734369  0.21554145 -1.04957433\n",
      "  0.86383249 -0.84559448  0.22113133]  energy_before :  30  energy_after :  50  reward :  -219.34462717604237\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "action : 1  next_temperatures :  [ 0.06440038 -0.62066257  1.30364226 -1.49734369  0.21554145 -1.04957433\n",
      "  0.86383249 -0.84559448  0.22113133]  energy_before :  50  energy_after :  40  reward :  -189.34462717604237\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step\n",
      "action : 1  next_temperatures :  [ 0.06440038 -0.62066257  1.30364226 -1.49734369  0.21554145 -1.04957433\n",
      "  0.86383249 -0.84559448  0.22113133]  energy_before :  40  energy_after :  50  reward :  -209.34462717604237\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "action : 1  next_temperatures :  [ 0.06440038 -0.62066257  1.30364226 -1.49734369  0.21554145 -1.04957433\n",
      "  0.86383249 -0.84559448  0.22113133]  energy_before :  50  energy_after :  50  reward :  -199.34462717604237\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "action : 1  next_temperatures :  [ 0.06440038 -0.62066257  1.30364226 -1.49734369  0.21554145 -1.04957433\n",
      "  0.86383249 -0.84559448  0.22113133]  energy_before :  50  energy_after :  50  reward :  -199.34462717604237\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "Episode 246/500, Total Reward: -1016.7231358802119\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "action : 1  next_temperatures :  [ 0.50648566  1.19879953  0.5740208   1.00242527 -0.16995721  1.62467648\n",
      "  0.49016835  1.55097201 -0.48363747]  energy_before :  30  energy_after :  50  reward :  -211.70604656791627\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "action : 1  next_temperatures :  [ 0.50648566  1.19879953  0.5740208   1.00242527 -0.16995721  1.62467648\n",
      "  0.49016835  1.55097201 -0.48363747]  energy_before :  50  energy_after :  40  reward :  -181.70604656791627\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "action : 1  next_temperatures :  [ 0.50648566  1.19879953  0.5740208   1.00242527 -0.16995721  1.62467648\n",
      "  0.49016835  1.55097201 -0.48363747]  energy_before :  40  energy_after :  50  reward :  -201.70604656791627\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "action : 1  next_temperatures :  [ 0.50648566  1.19879953  0.5740208   1.00242527 -0.16995721  1.62467648\n",
      "  0.49016835  1.55097201 -0.48363747]  energy_before :  50  energy_after :  50  reward :  -191.70604656791627\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "action : 1  next_temperatures :  [ 0.50648566  1.19879953  0.5740208   1.00242527 -0.16995721  1.62467648\n",
      "  0.49016835  1.55097201 -0.48363747]  energy_before :  50  energy_after :  50  reward :  -191.70604656791627\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "Episode 247/500, Total Reward: -978.5302328395813\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "action : 1  next_temperatures :  [-0.11616967  0.10142598 -0.32280557  0.83042282  0.06100966 -0.37256178\n",
      " -0.07603889  0.0398728   0.22113133]  energy_before :  30  energy_after :  50  reward :  -217.63371330756036\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "action : 1  next_temperatures :  [-0.11616967  0.10142598 -0.32280557  0.83042282  0.06100966 -0.37256178\n",
      " -0.07603889  0.0398728   0.22113133]  energy_before :  50  energy_after :  40  reward :  -187.63371330756036\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "action : 1  next_temperatures :  [-0.11616967  0.10142598 -0.32280557  0.83042282  0.06100966 -0.37256178\n",
      " -0.07603889  0.0398728   0.22113133]  energy_before :  40  energy_after :  50  reward :  -207.63371330756036\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "action : 1  next_temperatures :  [-0.11616967  0.10142598 -0.32280557  0.83042282  0.06100966 -0.37256178\n",
      " -0.07603889  0.0398728   0.22113133]  energy_before :  50  energy_after :  50  reward :  -197.63371330756036\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "action : 1  next_temperatures :  [-0.11616967  0.10142598 -0.32280557  0.83042282  0.06100966 -0.37256178\n",
      " -0.07603889  0.0398728   0.22113133]  energy_before :  50  energy_after :  50  reward :  -197.63371330756036\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "Episode 248/500, Total Reward: -1008.1685665378018\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step\n",
      "action : 1  next_temperatures :  [-0.22617211  0.75398628 -0.15560065  0.8369753  -0.18823517  0.8472899\n",
      " -0.06135339  1.1378768  -0.75470239]  energy_before :  30  energy_after :  50  reward :  -215.80993544185844\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step\n",
      "action : 1  next_temperatures :  [-0.22617211  0.75398628 -0.15560065  0.8369753  -0.18823517  0.8472899\n",
      " -0.06135339  1.1378768  -0.75470239]  energy_before :  50  energy_after :  40  reward :  -185.80993544185844\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step\n",
      "action : 1  next_temperatures :  [-0.22617211  0.75398628 -0.15560065  0.8369753  -0.18823517  0.8472899\n",
      " -0.06135339  1.1378768  -0.75470239]  energy_before :  40  energy_after :  50  reward :  -205.80993544185844\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "action : 1  next_temperatures :  [-0.22617211  0.75398628 -0.15560065  0.8369753  -0.18823517  0.8472899\n",
      " -0.06135339  1.1378768  -0.75470239]  energy_before :  50  energy_after :  50  reward :  -195.80993544185844\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "action : 1  next_temperatures :  [-0.22617211  0.75398628 -0.15560065  0.8369753  -0.18823517  0.8472899\n",
      " -0.06135339  1.1378768  -0.75470239]  energy_before :  50  energy_after :  50  reward :  -195.80993544185844\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "Episode 249/500, Total Reward: -999.0496772092922\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "action : 1  next_temperatures :  [ 1.62103871 -1.54358724  0.5740208  -1.2336066   0.86357799 -1.42956172\n",
      "  1.57199947 -1.65166763  2.27580346]  energy_before :  30  energy_after :  50  reward :  -216.95198275670964\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step\n",
      "action : 1  next_temperatures :  [ 1.62103871 -1.54358724  0.5740208  -1.2336066   0.86357799 -1.42956172\n",
      "  1.57199947 -1.65166763  2.27580346]  energy_before :  50  energy_after :  40  reward :  -186.95198275670964\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "action : 1  next_temperatures :  [ 1.62103871 -1.54358724  0.5740208  -1.2336066   0.86357799 -1.42956172\n",
      "  1.57199947 -1.65166763  2.27580346]  energy_before :  40  energy_after :  50  reward :  -206.95198275670964\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "action : 1  next_temperatures :  [ 1.62103871 -1.54358724  0.5740208  -1.2336066   0.86357799 -1.42956172\n",
      "  1.57199947 -1.65166763  2.27580346]  energy_before :  50  energy_after :  50  reward :  -196.95198275670964\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "action : 1  next_temperatures :  [ 1.62103871 -1.54358724  0.5740208  -1.2336066   0.86357799 -1.42956172\n",
      "  1.57199947 -1.65166763  2.27580346]  energy_before :  50  energy_after :  50  reward :  -196.95198275670964\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step\n",
      "Episode 250/500, Total Reward: -1004.7599137835482\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step\n",
      "action : 1  next_temperatures :  [ 1.06064891 -0.82757194  0.08152632 -0.22174075  1.03804937 -0.78798733\n",
      "  1.31092408 -1.09114811  2.00473854]  energy_before :  30  energy_after :  50  reward :  -215.43256090543173\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "action : 1  next_temperatures :  [ 1.06064891 -0.82757194  0.08152632 -0.22174075  1.03804937 -0.78798733\n",
      "  1.31092408 -1.09114811  2.00473854]  energy_before :  50  energy_after :  40  reward :  -185.43256090543173\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "action : 1  next_temperatures :  [ 1.06064891 -0.82757194  0.08152632 -0.22174075  1.03804937 -0.78798733\n",
      "  1.31092408 -1.09114811  2.00473854]  energy_before :  40  energy_after :  50  reward :  -205.43256090543173\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "action : 1  next_temperatures :  [ 1.06064891 -0.82757194  0.08152632 -0.22174075  1.03804937 -0.78798733\n",
      "  1.31092408 -1.09114811  2.00473854]  energy_before :  50  energy_after :  50  reward :  -195.43256090543173\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "action : 1  next_temperatures :  [ 1.06064891 -0.82757194  0.08152632 -0.22174075  1.03804937 -0.78798733\n",
      "  1.31092408 -1.09114811  2.00473854]  energy_before :  50  energy_after :  50  reward :  -195.43256090543173\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "Episode 251/500, Total Reward: -997.1628045271586\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "action : 1  next_temperatures :  [ 0.9423444   0.38456511  2.44139571 -1.23483519  1.00813999 -0.1666926\n",
      "  1.24076008  0.22415319  0.90653836]  energy_before :  30  energy_after :  50  reward :  -212.25363096170656\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "action : 1  next_temperatures :  [ 0.9423444   0.38456511  2.44139571 -1.23483519  1.00813999 -0.1666926\n",
      "  1.24076008  0.22415319  0.90653836]  energy_before :  50  energy_after :  40  reward :  -182.25363096170656\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "action : 1  next_temperatures :  [ 0.9423444   0.38456511  2.44139571 -1.23483519  1.00813999 -0.1666926\n",
      "  1.24076008  0.22415319  0.90653836]  energy_before :  40  energy_after :  50  reward :  -202.25363096170656\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "action : 1  next_temperatures :  [ 0.9423444   0.38456511  2.44139571 -1.23483519  1.00813999 -0.1666926\n",
      "  1.24076008  0.22415319  0.90653836]  energy_before :  50  energy_after :  50  reward :  -192.25363096170656\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "action : 1  next_temperatures :  [ 0.9423444   0.38456511  2.44139571 -1.23483519  1.00813999 -0.1666926\n",
      "  1.24076008  0.22415319  0.90653836]  energy_before :  50  energy_after :  50  reward :  -192.25363096170656\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "Episode 252/500, Total Reward: -981.2681548085328\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "action : 1  next_temperatures :  [-0.82807226 -0.30066509 -1.02202613  0.10883158 -0.76648316 -0.90720709\n",
      " -1.25577327 -0.45998776 -0.86312836]  energy_before :  30  energy_after :  50  reward :  -224.29451155583953\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "action : 1  next_temperatures :  [-0.82807226 -0.30066509 -1.02202613  0.10883158 -0.76648316 -0.90720709\n",
      " -1.25577327 -0.45998776 -0.86312836]  energy_before :  50  energy_after :  40  reward :  -194.29451155583953\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "action : 1  next_temperatures :  [-0.82807226 -0.30066509 -1.02202613  0.10883158 -0.76648316 -0.90720709\n",
      " -1.25577327 -0.45998776 -0.86312836]  energy_before :  40  energy_after :  50  reward :  -214.29451155583953\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "action : 1  next_temperatures :  [-0.82807226 -0.30066509 -1.02202613  0.10883158 -0.76648316 -0.90720709\n",
      " -1.25577327 -0.45998776 -0.86312836]  energy_before :  50  energy_after :  50  reward :  -204.29451155583953\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "action : 1  next_temperatures :  [-0.82807226 -0.30066509 -1.02202613  0.10883158 -0.76648316 -0.90720709\n",
      " -1.25577327 -0.45998776 -0.86312836]  energy_before :  50  energy_after :  50  reward :  -204.29451155583953\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "Episode 253/500, Total Reward: -1041.4725577791976\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "action : 1  next_temperatures :  [1.12914099 2.20402722 0.88867006 1.79445561 2.09152416 0.41711551\n",
      " 0.50648556 1.84351713 0.87168715]  energy_before :  30  energy_after :  50  reward :  -206.2533766118436\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "action : 1  next_temperatures :  [1.12914099 2.20402722 0.88867006 1.79445561 2.09152416 0.41711551\n",
      " 0.50648556 1.84351713 0.87168715]  energy_before :  50  energy_after :  40  reward :  -176.2533766118436\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "action : 1  next_temperatures :  [1.12914099 2.20402722 0.88867006 1.79445561 2.09152416 0.41711551\n",
      " 0.50648556 1.84351713 0.87168715]  energy_before :  40  energy_after :  50  reward :  -196.2533766118436\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step\n",
      "action : 1  next_temperatures :  [1.12914099 2.20402722 0.88867006 1.79445561 2.09152416 0.41711551\n",
      " 0.50648556 1.84351713 0.87168715]  energy_before :  50  energy_after :  50  reward :  -186.2533766118436\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "action : 1  next_temperatures :  [1.12914099 2.20402722 0.88867006 1.79445561 2.09152416 0.41711551\n",
      " 0.50648556 1.84351713 0.87168715]  energy_before :  50  energy_after :  50  reward :  -186.2533766118436\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "Episode 254/500, Total Reward: -951.266883059218\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "action : 1  next_temperatures :  [-2.36395542  1.04047617 -1.47803954  1.05156883 -1.62887025  0.87494397\n",
      " -1.99004778  1.28990812 -1.61307465]  energy_before :  30  energy_after :  50  reward :  -222.8170905507681\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "action : 1  next_temperatures :  [-2.36395542  1.04047617 -1.47803954  1.05156883 -1.62887025  0.87494397\n",
      " -1.99004778  1.28990812 -1.61307465]  energy_before :  50  energy_after :  40  reward :  -192.8170905507681\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "action : 1  next_temperatures :  [-2.36395542  1.04047617 -1.47803954  1.05156883 -1.62887025  0.87494397\n",
      " -1.99004778  1.28990812 -1.61307465]  energy_before :  40  energy_after :  50  reward :  -212.8170905507681\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step\n",
      "action : 1  next_temperatures :  [-2.36395542  1.04047617 -1.47803954  1.05156883 -1.62887025  0.87494397\n",
      " -1.99004778  1.28990812 -1.61307465]  energy_before :  50  energy_after :  50  reward :  -202.8170905507681\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "action : 1  next_temperatures :  [-2.36395542  1.04047617 -1.47803954  1.05156883 -1.62887025  0.87494397\n",
      " -1.99004778  1.28990812 -1.61307465]  energy_before :  50  energy_after :  50  reward :  -202.8170905507681\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "Episode 255/500, Total Reward: -1034.0854527538406\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step\n",
      "action : 1  next_temperatures :  [ 0.0083614  -0.45982614 -0.15560065 -0.41700448 -0.68672482 -0.21892806\n",
      "  0.01696922 -0.29874242 -0.10956787]  energy_before :  30  energy_after :  50  reward :  -220.32106383704092\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "action : 1  next_temperatures :  [ 0.0083614  -0.45982614 -0.15560065 -0.41700448 -0.68672482 -0.21892806\n",
      "  0.01696922 -0.29874242 -0.10956787]  energy_before :  50  energy_after :  40  reward :  -190.32106383704092\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step\n",
      "action : 1  next_temperatures :  [ 0.0083614  -0.45982614 -0.15560065 -0.41700448 -0.68672482 -0.21892806\n",
      "  0.01696922 -0.29874242 -0.10956787]  energy_before :  40  energy_after :  50  reward :  -210.32106383704092\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "action : 1  next_temperatures :  [ 0.0083614  -0.45982614 -0.15560065 -0.41700448 -0.68672482 -0.21892806\n",
      "  0.01696922 -0.29874242 -0.10956787]  energy_before :  50  energy_after :  50  reward :  -200.32106383704092\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step\n",
      "action : 1  next_temperatures :  [ 0.0083614  -0.45982614 -0.15560065 -0.41700448 -0.68672482 -0.21892806\n",
      "  0.01696922 -0.29874242 -0.10956787]  energy_before :  50  energy_after :  50  reward :  -200.32106383704092\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "Episode 256/500, Total Reward: -1021.6053191852046\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "action : 1  next_temperatures :  [-0.57693461 -0.94568619 -0.52041138 -1.58744022 -1.09714796 -1.68254523\n",
      " -0.36974869 -1.40365694 -0.70591071]  energy_before :  30  energy_after :  50  reward :  -226.88948192250112\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "action : 1  next_temperatures :  [-0.57693461 -0.94568619 -0.52041138 -1.58744022 -1.09714796 -1.68254523\n",
      " -0.36974869 -1.40365694 -0.70591071]  energy_before :  50  energy_after :  40  reward :  -196.88948192250112\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "action : 1  next_temperatures :  [-0.57693461 -0.94568619 -0.52041138 -1.58744022 -1.09714796 -1.68254523\n",
      " -0.36974869 -1.40365694 -0.70591071]  energy_before :  40  energy_after :  50  reward :  -216.88948192250112\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step\n",
      "action : 1  next_temperatures :  [-0.57693461 -0.94568619 -0.52041138 -1.58744022 -1.09714796 -1.68254523\n",
      " -0.36974869 -1.40365694 -0.70591071]  energy_before :  50  energy_after :  50  reward :  -206.88948192250112\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "action : 1  next_temperatures :  [-0.57693461 -0.94568619 -0.52041138 -1.58744022 -1.09714796 -1.68254523\n",
      " -0.36974869 -1.40365694 -0.70591071]  energy_before :  50  energy_after :  50  reward :  -206.88948192250112\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "Episode 257/500, Total Reward: -1054.4474096125057\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "action : 1  next_temperatures :  [-0.13900036  0.50435474 -0.43376883  0.8771092  -0.63189095 -0.3817798\n",
      " -0.03198241 -0.67651722 -0.26678553]  energy_before :  30  energy_after :  50  reward :  -219.18026117241016\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "action : 1  next_temperatures :  [-0.13900036  0.50435474 -0.43376883  0.8771092  -0.63189095 -0.3817798\n",
      " -0.03198241 -0.67651722 -0.26678553]  energy_before :  50  energy_after :  40  reward :  -189.18026117241016\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "action : 1  next_temperatures :  [-0.13900036  0.50435474 -0.43376883  0.8771092  -0.63189095 -0.3817798\n",
      " -0.03198241 -0.67651722 -0.26678553]  energy_before :  40  energy_after :  50  reward :  -209.18026117241016\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step\n",
      "action : 1  next_temperatures :  [-0.13900036  0.50435474 -0.43376883  0.8771092  -0.63189095 -0.3817798\n",
      " -0.03198241 -0.67651722 -0.26678553]  energy_before :  50  energy_after :  50  reward :  -199.18026117241016\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "action : 1  next_temperatures :  [-0.13900036  0.50435474 -0.43376883  0.8771092  -0.63189095 -0.3817798\n",
      " -0.03198241 -0.67651722 -0.26678553]  energy_before :  50  energy_after :  50  reward :  -199.18026117241016\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "Episode 258/500, Total Reward: -1015.9013058620508\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step\n",
      "action : 1  next_temperatures :  [-0.18466176 -0.79657742 -0.66177553 -0.39161365  0.16569248 -0.87340768\n",
      "  0.60928399 -1.11187965  0.3295573 ]  energy_before :  30  energy_after :  50  reward :  -220.91538189987114\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step\n",
      "action : 1  next_temperatures :  [-0.18466176 -0.79657742 -0.66177553 -0.39161365  0.16569248 -0.87340768\n",
      "  0.60928399 -1.11187965  0.3295573 ]  energy_before :  50  energy_after :  40  reward :  -190.91538189987114\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step\n",
      "action : 1  next_temperatures :  [-0.18466176 -0.79657742 -0.66177553 -0.39161365  0.16569248 -0.87340768\n",
      "  0.60928399 -1.11187965  0.3295573 ]  energy_before :  40  energy_after :  50  reward :  -210.91538189987114\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "action : 1  next_temperatures :  [-0.18466176 -0.79657742 -0.66177553 -0.39161365  0.16569248 -0.87340768\n",
      "  0.60928399 -1.11187965  0.3295573 ]  energy_before :  50  energy_after :  50  reward :  -200.91538189987114\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "action : 1  next_temperatures :  [-0.18466176 -0.79657742 -0.66177553 -0.39161365  0.16569248 -0.87340768\n",
      "  0.60928399 -1.11187965  0.3295573 ]  energy_before :  50  energy_after :  50  reward :  -200.91538189987114\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "Episode 259/500, Total Reward: -1024.5769094993557\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step\n",
      "action : 1  next_temperatures :  [ 1.81406186 -0.24370219  3.3557026  -1.86592038  1.96025522 -0.61837572\n",
      "  1.92608295 -0.23654779  1.90173387]  energy_before :  30  energy_after :  50  reward :  -210.0067095773835\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "action : 1  next_temperatures :  [ 1.81406186 -0.24370219  3.3557026  -1.86592038  1.96025522 -0.61837572\n",
      "  1.92608295 -0.23654779  1.90173387]  energy_before :  50  energy_after :  40  reward :  -180.0067095773835\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "action : 1  next_temperatures :  [ 1.81406186 -0.24370219  3.3557026  -1.86592038  1.96025522 -0.61837572\n",
      "  1.92608295 -0.23654779  1.90173387]  energy_before :  40  energy_after :  50  reward :  -200.0067095773835\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "action : 1  next_temperatures :  [ 1.81406186 -0.24370219  3.3557026  -1.86592038  1.96025522 -0.61837572\n",
      "  1.92608295 -0.23654779  1.90173387]  energy_before :  50  energy_after :  50  reward :  -190.0067095773835\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "action : 1  next_temperatures :  [ 1.81406186 -0.24370219  3.3557026  -1.86592038  1.96025522 -0.61837572\n",
      "  1.92608295 -0.23654779  1.90173387]  energy_before :  50  energy_after :  50  reward :  -190.0067095773835\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "Episode 260/500, Total Reward: -970.0335478869175\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "action : 1  next_temperatures :  [-0.18466176  0.65430121  0.07240605  0.60927681 -0.36602981  1.34711158\n",
      " -0.22778895  0.88372342 -0.26678553]  energy_before :  30  energy_after :  50  reward :  -215.47844697425927\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "action : 1  next_temperatures :  [-0.18466176  0.65430121  0.07240605  0.60927681 -0.36602981  1.34711158\n",
      " -0.22778895  0.88372342 -0.26678553]  energy_before :  50  energy_after :  40  reward :  -185.47844697425927\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "action : 1  next_temperatures :  [-0.18466176  0.65430121  0.07240605  0.60927681 -0.36602981  1.34711158\n",
      " -0.22778895  0.88372342 -0.26678553]  energy_before :  40  energy_after :  50  reward :  -205.47844697425927\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "action : 1  next_temperatures :  [-0.18466176  0.65430121  0.07240605  0.60927681 -0.36602981  1.34711158\n",
      " -0.22778895  0.88372342 -0.26678553]  energy_before :  50  energy_after :  50  reward :  -195.47844697425927\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "action : 1  next_temperatures :  [-0.18466176  0.65430121  0.07240605  0.60927681 -0.36602981  1.34711158\n",
      " -0.22778895  0.88372342 -0.26678553]  energy_before :  50  energy_after :  50  reward :  -195.47844697425927\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "Episode 261/500, Total Reward: -997.3922348712963\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "action : 1  next_temperatures :  [-1.98413566 -0.39197328 -1.23483239 -0.46450992 -1.82826611  0.26040912\n",
      " -1.69633798 -0.23654779 -1.83896209]  energy_before :  30  energy_after :  50  reward :  -227.41515610035486\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "action : 1  next_temperatures :  [-1.98413566 -0.39197328 -1.23483239 -0.46450992 -1.82826611  0.26040912\n",
      " -1.69633798 -0.23654779 -1.83896209]  energy_before :  50  energy_after :  40  reward :  -197.41515610035486\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "action : 1  next_temperatures :  [-1.98413566 -0.39197328 -1.23483239 -0.46450992 -1.82826611  0.26040912\n",
      " -1.69633798 -0.23654779 -1.83896209]  energy_before :  40  energy_after :  50  reward :  -217.41515610035486\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "action : 1  next_temperatures :  [-1.98413566 -0.39197328 -1.23483239 -0.46450992 -1.82826611  0.26040912\n",
      " -1.69633798 -0.23654779 -1.83896209]  energy_before :  50  energy_after :  50  reward :  -207.41515610035486\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "action : 1  next_temperatures :  [-1.98413566 -0.39197328 -1.23483239 -0.46450992 -1.82826611  0.26040912\n",
      " -1.69633798 -0.23654779 -1.83896209]  energy_before :  50  energy_after :  50  reward :  -207.41515610035486\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "Episode 262/500, Total Reward: -1057.0757805017743\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "action : 1  next_temperatures :  [ 1.44046866 -0.18338853  1.75314119 -1.06722056  1.21252075 -0.30189027\n",
      "  1.39251014 -0.03767853  1.14275208]  energy_before :  30  energy_after :  50  reward :  -212.64878507475194\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "action : 1  next_temperatures :  [ 1.44046866 -0.18338853  1.75314119 -1.06722056  1.21252075 -0.30189027\n",
      "  1.39251014 -0.03767853  1.14275208]  energy_before :  50  energy_after :  40  reward :  -182.64878507475194\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "action : 1  next_temperatures :  [ 1.44046866 -0.18338853  1.75314119 -1.06722056  1.21252075 -0.30189027\n",
      "  1.39251014 -0.03767853  1.14275208]  energy_before :  40  energy_after :  50  reward :  -202.64878507475194\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "action : 1  next_temperatures :  [ 1.44046866 -0.18338853  1.75314119 -1.06722056  1.21252075 -0.30189027\n",
      "  1.39251014 -0.03767853  1.14275208]  energy_before :  50  energy_after :  50  reward :  -192.64878507475194\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "action : 1  next_temperatures :  [ 1.44046866 -0.18338853  1.75314119 -1.06722056  1.21252075 -0.30189027\n",
      "  1.39251014 -0.03767853  1.14275208]  energy_before :  50  energy_after :  50  reward :  -192.64878507475194\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "Episode 263/500, Total Reward: -983.2439253737597\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "action : 1  next_temperatures :  [-0.09541449 -0.58715498  0.16360874 -0.89943041  1.29227909 -0.12674784\n",
      " -0.41870032 -0.38320427  0.59881513]  energy_before :  30  energy_after :  50  reward :  -218.4559493587267\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "action : 1  next_temperatures :  [-0.09541449 -0.58715498  0.16360874 -0.89943041  1.29227909 -0.12674784\n",
      " -0.41870032 -0.38320427  0.59881513]  energy_before :  50  energy_after :  40  reward :  -188.4559493587267\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "action : 1  next_temperatures :  [-0.09541449 -0.58715498  0.16360874 -0.89943041  1.29227909 -0.12674784\n",
      " -0.41870032 -0.38320427  0.59881513]  energy_before :  40  energy_after :  50  reward :  -208.4559493587267\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "action : 1  next_temperatures :  [-0.09541449 -0.58715498  0.16360874 -0.89943041  1.29227909 -0.12674784\n",
      " -0.41870032 -0.38320427  0.59881513]  energy_before :  50  energy_after :  50  reward :  -198.4559493587267\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "action : 1  next_temperatures :  [-0.09541449 -0.58715498  0.16360874 -0.89943041  1.29227909 -0.12674784\n",
      " -0.41870032 -0.38320427  0.59881513]  energy_before :  50  energy_after :  50  reward :  -198.4559493587267\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "Episode 264/500, Total Reward: -1012.2797467936335\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "action : 1  next_temperatures :  [-0.67655947  1.47439946 -0.15560065  1.00242527 -1.03068267  1.89199914\n",
      " -0.05401065  1.58322108 -0.46737357]  energy_before :  30  energy_after :  50  reward :  -214.43218206632173\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "action : 1  next_temperatures :  [-0.67655947  1.47439946 -0.15560065  1.00242527 -1.03068267  1.89199914\n",
      " -0.05401065  1.58322108 -0.46737357]  energy_before :  50  energy_after :  40  reward :  -184.43218206632173\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "action : 1  next_temperatures :  [-0.67655947  1.47439946 -0.15560065  1.00242527 -1.03068267  1.89199914\n",
      " -0.05401065  1.58322108 -0.46737357]  energy_before :  40  energy_after :  50  reward :  -204.43218206632173\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "action : 1  next_temperatures :  [-0.67655947  1.47439946 -0.15560065  1.00242527 -1.03068267  1.89199914\n",
      " -0.05401065  1.58322108 -0.46737357]  energy_before :  50  energy_after :  50  reward :  -194.43218206632173\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "action : 1  next_temperatures :  [-0.67655947  1.47439946 -0.15560065  1.00242527 -1.03068267  1.89199914\n",
      " -0.05401065  1.58322108 -0.46737357]  energy_before :  50  energy_after :  50  reward :  -194.43218206632173\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "Episode 265/500, Total Reward: -992.1609103316086\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "action : 1  next_temperatures :  [ 0.81781333  1.39063048  0.95099189  0.19155657  0.16569248  1.48026079\n",
      " -0.71730529  0.72094241 -0.06318565]  energy_before :  30  energy_after :  50  reward :  -213.06260298639708\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "action : 1  next_temperatures :  [ 0.81781333  1.39063048  0.95099189  0.19155657  0.16569248  1.48026079\n",
      " -0.71730529  0.72094241 -0.06318565]  energy_before :  50  energy_after :  40  reward :  -183.06260298639708\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "action : 1  next_temperatures :  [ 0.81781333  1.39063048  0.95099189  0.19155657  0.16569248  1.48026079\n",
      " -0.71730529  0.72094241 -0.06318565]  energy_before :  40  energy_after :  50  reward :  -203.06260298639708\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "action : 1  next_temperatures :  [ 0.81781333  1.39063048  0.95099189  0.19155657  0.16569248  1.48026079\n",
      " -0.71730529  0.72094241 -0.06318565]  energy_before :  50  energy_after :  50  reward :  -193.06260298639708\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "action : 1  next_temperatures :  [ 0.81781333  1.39063048  0.95099189  0.19155657  0.16569248  1.48026079\n",
      " -0.71730529  0.72094241 -0.06318565]  energy_before :  50  energy_after :  50  reward :  -193.06260298639708\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "Episode 266/500, Total Reward: -985.3130149319854\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "action : 1  next_temperatures :  [1.06064891 1.17450653 0.80202751 1.04384627 1.11282282 0.61991201\n",
      " 1.25870901 0.96818527 1.71276289]  energy_before :  30  energy_after :  50  reward :  -208.2465787916785\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "action : 1  next_temperatures :  [1.06064891 1.17450653 0.80202751 1.04384627 1.11282282 0.61991201\n",
      " 1.25870901 0.96818527 1.71276289]  energy_before :  50  energy_after :  40  reward :  -178.2465787916785\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "action : 1  next_temperatures :  [1.06064891 1.17450653 0.80202751 1.04384627 1.11282282 0.61991201\n",
      " 1.25870901 0.96818527 1.71276289]  energy_before :  40  energy_after :  50  reward :  -198.2465787916785\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "action : 1  next_temperatures :  [1.06064891 1.17450653 0.80202751 1.04384627 1.11282282 0.61991201\n",
      " 1.25870901 0.96818527 1.71276289]  energy_before :  50  energy_after :  50  reward :  -188.2465787916785\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "action : 1  next_temperatures :  [1.06064891 1.17450653 0.80202751 1.04384627 1.11282282 0.61991201\n",
      " 1.25870901 0.96818527 1.71276289]  energy_before :  50  energy_after :  50  reward :  -188.2465787916785\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "Episode 267/500, Total Reward: -961.2328939583925\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "action : 1  next_temperatures :  [-0.11616967 -1.07050196 -0.74841808 -0.37359434 -1.08053164 -0.85292318\n",
      " -0.47254712 -0.86079762 -0.30292752]  energy_before :  30  energy_after :  50  reward :  -223.87841113420407\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "action : 2  next_temperatures :  [ 0.88383033 -0.07050196  0.25158192  0.62640566 -0.08053164  0.14707682\n",
      "  0.52745288  0.13920238  0.69707248]  energy_before :  50  energy_after :  40  reward :  -193.87841113420407\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "action : 1  next_temperatures :  [ 0.88383033 -0.07050196  0.25158192  0.62640566 -0.08053164  0.14707682\n",
      "  0.52745288  0.13920238  0.69707248]  energy_before :  40  energy_after :  50  reward :  -204.87841113420407\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "action : 1  next_temperatures :  [ 0.88383033 -0.07050196  0.25158192  0.62640566 -0.08053164  0.14707682\n",
      "  0.52745288  0.13920238  0.69707248]  energy_before :  50  energy_after :  50  reward :  -194.87841113420407\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "action : 1  next_temperatures :  [ 0.88383033 -0.07050196  0.25158192  0.62640566 -0.08053164  0.14707682\n",
      "  0.52745288  0.13920238  0.69707248]  energy_before :  50  energy_after :  50  reward :  -194.87841113420407\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "Episode 268/500, Total Reward: -1012.3920556710203\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "action : 1  next_temperatures :  [-0.30296627 -0.21605843 -1.06762747  0.91970028  0.11584352 -0.07451237\n",
      " -0.41870032 -0.33099149  0.10728407]  energy_before :  30  energy_after :  50  reward :  -219.2680284877463\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "action : 1  next_temperatures :  [-0.30296627 -0.21605843 -1.06762747  0.91970028  0.11584352 -0.07451237\n",
      " -0.41870032 -0.33099149  0.10728407]  energy_before :  50  energy_after :  40  reward :  -189.2680284877463\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "action : 1  next_temperatures :  [-0.30296627 -0.21605843 -1.06762747  0.91970028  0.11584352 -0.07451237\n",
      " -0.41870032 -0.33099149  0.10728407]  energy_before :  40  energy_after :  50  reward :  -209.2680284877463\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "action : 1  next_temperatures :  [-0.30296627 -0.21605843 -1.06762747  0.91970028  0.11584352 -0.07451237\n",
      " -0.41870032 -0.33099149  0.10728407]  energy_before :  50  energy_after :  50  reward :  -199.2680284877463\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "action : 1  next_temperatures :  [-0.30296627 -0.21605843 -1.06762747  0.91970028  0.11584352 -0.07451237\n",
      " -0.41870032 -0.33099149  0.10728407]  energy_before :  50  energy_after :  50  reward :  -199.2680284877463\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step\n",
      "Episode 269/500, Total Reward: -1016.3401424387315\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "action : 1  next_temperatures :  [1.44046866 1.81952763 0.61962214 2.32930133 1.96025522 1.58473172\n",
      " 1.29460687 1.44270728 1.7878866 ]  energy_before :  30  energy_after :  50  reward :  -203.72089255049642\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "action : 1  next_temperatures :  [1.44046866 1.81952763 0.61962214 2.32930133 1.96025522 1.58473172\n",
      " 1.29460687 1.44270728 1.7878866 ]  energy_before :  50  energy_after :  40  reward :  -173.72089255049642\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step\n",
      "action : 1  next_temperatures :  [1.44046866 1.81952763 0.61962214 2.32930133 1.96025522 1.58473172\n",
      " 1.29460687 1.44270728 1.7878866 ]  energy_before :  40  energy_after :  50  reward :  -193.72089255049642\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "action : 1  next_temperatures :  [1.44046866 1.81952763 0.61962214 2.32930133 1.96025522 1.58473172\n",
      " 1.29460687 1.44270728 1.7878866 ]  energy_before :  50  energy_after :  50  reward :  -183.72089255049642\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "action : 1  next_temperatures :  [1.44046866 1.81952763 0.61962214 2.32930133 1.96025522 1.58473172\n",
      " 1.29460687 1.44270728 1.7878866 ]  energy_before :  50  energy_after :  50  reward :  -183.72089255049642\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "Episode 270/500, Total Reward: -938.604462752482\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step\n",
      "action : 1  next_temperatures :  [-1.49223795  0.13325819 -0.74841808 -0.14589586 -1.48430825  0.87494397\n",
      " -0.96206346  0.25333092 -1.24804056]  energy_before :  30  energy_after :  50  reward :  -222.81943109258077\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "action : 1  next_temperatures :  [-1.49223795  0.13325819 -0.74841808 -0.14589586 -1.48430825  0.87494397\n",
      " -0.96206346  0.25333092 -1.24804056]  energy_before :  50  energy_after :  40  reward :  -192.81943109258077\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step\n",
      "action : 1  next_temperatures :  [-1.49223795  0.13325819 -0.74841808 -0.14589586 -1.48430825  0.87494397\n",
      " -0.96206346  0.25333092 -1.24804056]  energy_before :  40  energy_after :  50  reward :  -212.81943109258077\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "action : 1  next_temperatures :  [-1.49223795  0.13325819 -0.74841808 -0.14589586 -1.48430825  0.87494397\n",
      " -0.96206346  0.25333092 -1.24804056]  energy_before :  50  energy_after :  50  reward :  -202.81943109258077\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "action : 1  next_temperatures :  [-1.49223795  0.13325819 -0.74841808 -0.14589586 -1.48430825  0.87494397\n",
      " -0.96206346  0.25333092 -1.24804056]  energy_before :  50  energy_after :  50  reward :  -202.81943109258077\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "Episode 271/500, Total Reward: -1034.0971554629039\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "action : 1  next_temperatures :  [-0.11616967 -0.77683187 -0.47937017 -0.34902256 -0.33279717 -0.71977397\n",
      " -0.13198361 -0.46459477 -0.37056467]  energy_before :  30  energy_after :  50  reward :  -221.74110846461014\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "action : 1  next_temperatures :  [-0.11616967 -0.77683187 -0.47937017 -0.34902256 -0.33279717 -0.71977397\n",
      " -0.13198361 -0.46459477 -0.37056467]  energy_before :  50  energy_after :  40  reward :  -191.74110846461014\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "action : 1  next_temperatures :  [-0.11616967 -0.77683187 -0.47937017 -0.34902256 -0.33279717 -0.71977397\n",
      " -0.13198361 -0.46459477 -0.37056467]  energy_before :  40  energy_after :  50  reward :  -211.74110846461014\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "action : 1  next_temperatures :  [-0.11616967 -0.77683187 -0.47937017 -0.34902256 -0.33279717 -0.71977397\n",
      " -0.13198361 -0.46459477 -0.37056467]  energy_before :  50  energy_after :  50  reward :  -201.74110846461014\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step\n",
      "action : 1  next_temperatures :  [-0.11616967 -0.77683187 -0.47937017 -0.34902256 -0.33279717 -0.71977397\n",
      " -0.13198361 -0.46459477 -0.37056467]  energy_before :  50  energy_after :  50  reward :  -201.74110846461014\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "Episode 272/500, Total Reward: -1028.7055423230506\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "action : 1  next_temperatures :  [ 0.74932124 -0.1475773  -0.02335676  0.36355902  1.30723378 -0.47396003\n",
      "  1.14775197 -0.46689828  1.73367361]  energy_before :  30  energy_after :  50  reward :  -213.81025273402588\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "action : 1  next_temperatures :  [ 0.74932124 -0.1475773  -0.02335676  0.36355902  1.30723378 -0.47396003\n",
      "  1.14775197 -0.46689828  1.73367361]  energy_before :  50  energy_after :  40  reward :  -183.81025273402588\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step\n",
      "action : 1  next_temperatures :  [ 0.74932124 -0.1475773  -0.02335676  0.36355902  1.30723378 -0.47396003\n",
      "  1.14775197 -0.46689828  1.73367361]  energy_before :  40  energy_after :  50  reward :  -203.81025273402588\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "action : 1  next_temperatures :  [ 0.74932124 -0.1475773  -0.02335676  0.36355902  1.30723378 -0.47396003\n",
      "  1.14775197 -0.46689828  1.73367361]  energy_before :  50  energy_after :  50  reward :  -193.81025273402588\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "action : 1  next_temperatures :  [ 0.74932124 -0.1475773  -0.02335676  0.36355902  1.30723378 -0.47396003\n",
      "  1.14775197 -0.46689828  1.73367361]  energy_before :  50  energy_after :  50  reward :  -193.81025273402588\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "Episode 273/500, Total Reward: -989.0512636701294\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "action : 1  next_temperatures :  [-0.49598942 -0.71113307 -0.33800601 -1.12876701 -0.41920204 -0.65934471\n",
      " -0.17394215 -1.25239345 -0.86312836]  energy_before :  30  energy_after :  50  reward :  -224.04190622001582\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step\n",
      "action : 1  next_temperatures :  [-0.49598942 -0.71113307 -0.33800601 -1.12876701 -0.41920204 -0.65934471\n",
      " -0.17394215 -1.25239345 -0.86312836]  energy_before :  50  energy_after :  40  reward :  -194.04190622001582\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step\n",
      "action : 1  next_temperatures :  [-0.49598942 -0.71113307 -0.33800601 -1.12876701 -0.41920204 -0.65934471\n",
      " -0.17394215 -1.25239345 -0.86312836]  energy_before :  40  energy_after :  50  reward :  -214.04190622001582\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "action : 1  next_temperatures :  [-0.49598942 -0.71113307 -0.33800601 -1.12876701 -0.41920204 -0.65934471\n",
      " -0.17394215 -1.25239345 -0.86312836]  energy_before :  50  energy_after :  50  reward :  -204.04190622001582\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "action : 1  next_temperatures :  [-0.49598942 -0.71113307 -0.33800601 -1.12876701 -0.41920204 -0.65934471\n",
      " -0.17394215 -1.25239345 -0.86312836]  energy_before :  50  energy_after :  50  reward :  -204.04190622001582\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "Episode 274/500, Total Reward: -1040.2095311000792\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "action : 2  next_temperatures :  [-0.18091029 -0.00516216  0.37166545  0.00965401 -0.2799275  -0.12229429\n",
      "  0.77221105  0.07931126  0.13687164]  energy_before :  30  energy_after :  50  reward :  -226.21858083807757\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "action : 1  next_temperatures :  [-0.18091029 -0.00516216  0.37166545  0.00965401 -0.2799275  -0.12229429\n",
      "  0.77221105  0.07931126  0.13687164]  energy_before :  50  energy_after :  40  reward :  -187.21858083807757\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "action : 1  next_temperatures :  [-0.18091029 -0.00516216  0.37166545  0.00965401 -0.2799275  -0.12229429\n",
      "  0.77221105  0.07931126  0.13687164]  energy_before :  40  energy_after :  50  reward :  -207.21858083807757\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "action : 1  next_temperatures :  [-0.18091029 -0.00516216  0.37166545  0.00965401 -0.2799275  -0.12229429\n",
      "  0.77221105  0.07931126  0.13687164]  energy_before :  50  energy_after :  50  reward :  -197.21858083807757\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "action : 1  next_temperatures :  [-0.18091029 -0.00516216  0.37166545  0.00965401 -0.2799275  -0.12229429\n",
      "  0.77221105  0.07931126  0.13687164]  energy_before :  50  energy_after :  50  reward :  -197.21858083807757\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "Episode 275/500, Total Reward: -1015.0929041903878\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "action : 1  next_temperatures :  [-0.02721891 -0.58727465 -0.19949194 -0.59566179 -0.78143785 -0.43972166\n",
      " -0.03198241 -0.98115575 -0.91424346]  energy_before :  30  energy_after :  50  reward :  -222.5581884251959\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "action : 1  next_temperatures :  [-0.02721891 -0.58727465 -0.19949194 -0.59566179 -0.78143785 -0.43972166\n",
      " -0.03198241 -0.98115575 -0.91424346]  energy_before :  50  energy_after :  40  reward :  -192.5581884251959\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "action : 1  next_temperatures :  [-0.02721891 -0.58727465 -0.19949194 -0.59566179 -0.78143785 -0.43972166\n",
      " -0.03198241 -0.98115575 -0.91424346]  energy_before :  40  energy_after :  50  reward :  -212.5581884251959\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "action : 1  next_temperatures :  [-0.02721891 -0.58727465 -0.19949194 -0.59566179 -0.78143785 -0.43972166\n",
      " -0.03198241 -0.98115575 -0.91424346]  energy_before :  50  energy_after :  50  reward :  -202.5581884251959\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "action : 1  next_temperatures :  [-0.02721891 -0.58727465 -0.19949194 -0.59566179 -0.78143785 -0.43972166\n",
      " -0.03198241 -0.98115575 -0.91424346]  energy_before :  50  energy_after :  50  reward :  -202.5581884251959\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "Episode 276/500, Total Reward: -1032.7909421259797\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "action : 1  next_temperatures :  [ 1.87632739 -0.49500911  0.73636158 -0.03204662  1.05798895 -2.09223513\n",
      "  1.97503459 -0.25958284  2.27580346]  energy_before :  30  energy_after :  50  reward :  -212.95735772119403\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step\n",
      "action : 1  next_temperatures :  [ 1.87632739 -0.49500911  0.73636158 -0.03204662  1.05798895 -2.09223513\n",
      "  1.97503459 -0.25958284  2.27580346]  energy_before :  50  energy_after :  40  reward :  -182.95735772119403\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "action : 1  next_temperatures :  [ 1.87632739 -0.49500911  0.73636158 -0.03204662  1.05798895 -2.09223513\n",
      "  1.97503459 -0.25958284  2.27580346]  energy_before :  40  energy_after :  50  reward :  -202.95735772119403\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "action : 1  next_temperatures :  [ 1.87632739 -0.49500911  0.73636158 -0.03204662  1.05798895 -2.09223513\n",
      "  1.97503459 -0.25958284  2.27580346]  energy_before :  50  energy_after :  50  reward :  -192.95735772119403\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "action : 1  next_temperatures :  [ 1.87632739 -0.49500911  0.73636158 -0.03204662  1.05798895 -2.09223513\n",
      "  1.97503459 -0.25958284  2.27580346]  energy_before :  50  energy_after :  50  reward :  -192.95735772119403\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "Episode 277/500, Total Reward: -984.7867886059702\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "action : 1  next_temperatures :  [-0.24692729 -0.19092774 -0.74841808  0.63384859  0.06100966 -0.07451237\n",
      " -0.41870032 -0.12137255 -0.04993359]  energy_before :  30  energy_after :  50  reward :  -219.15593369572238\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "action : 1  next_temperatures :  [-0.24692729 -0.19092774 -0.74841808  0.63384859  0.06100966 -0.07451237\n",
      " -0.41870032 -0.12137255 -0.04993359]  energy_before :  50  energy_after :  40  reward :  -189.15593369572238\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "action : 1  next_temperatures :  [-0.24692729 -0.19092774 -0.74841808  0.63384859  0.06100966 -0.07451237\n",
      " -0.41870032 -0.12137255 -0.04993359]  energy_before :  40  energy_after :  50  reward :  -209.15593369572238\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "action : 1  next_temperatures :  [-0.24692729 -0.19092774 -0.74841808  0.63384859  0.06100966 -0.07451237\n",
      " -0.41870032 -0.12137255 -0.04993359]  energy_before :  50  energy_after :  50  reward :  -199.15593369572238\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "action : 1  next_temperatures :  [-0.24692729 -0.19092774 -0.74841808  0.63384859  0.06100966 -0.07451237\n",
      " -0.41870032 -0.12137255 -0.04993359]  energy_before :  50  energy_after :  50  reward :  -199.15593369572238\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "Episode 278/500, Total Reward: -1015.7796684786119\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "action : 1  next_temperatures :  [0.74932124 1.27335392 0.75642617 0.97785349 0.46478627 1.8489817\n",
      " 0.31557419 2.27427254 0.37834899]  energy_before :  30  energy_after :  50  reward :  -208.96108147706101\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "action : 1  next_temperatures :  [0.74932124 1.27335392 0.75642617 0.97785349 0.46478627 1.8489817\n",
      " 0.31557419 2.27427254 0.37834899]  energy_before :  50  energy_after :  40  reward :  -178.96108147706101\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "action : 1  next_temperatures :  [0.74932124 1.27335392 0.75642617 0.97785349 0.46478627 1.8489817\n",
      " 0.31557419 2.27427254 0.37834899]  energy_before :  40  energy_after :  50  reward :  -198.96108147706101\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "action : 1  next_temperatures :  [0.74932124 1.27335392 0.75642617 0.97785349 0.46478627 1.8489817\n",
      " 0.31557419 2.27427254 0.37834899]  energy_before :  50  energy_after :  50  reward :  -188.96108147706101\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "action : 1  next_temperatures :  [0.74932124 1.27335392 0.75642617 0.97785349 0.46478627 1.8489817\n",
      " 0.31557419 2.27427254 0.37834899]  energy_before :  50  energy_after :  50  reward :  -188.96108147706101\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "Episode 279/500, Total Reward: -964.8054073853051\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "action : 1  next_temperatures :  [-0.18466176 -0.39197328 -0.74841808  0.45938896  0.06100966 -0.01305889\n",
      " -0.07603889 -0.44616674 -0.10956787]  energy_before :  30  energy_after :  50  reward :  -219.44948687797856\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "action : 1  next_temperatures :  [-0.18466176 -0.39197328 -0.74841808  0.45938896  0.06100966 -0.01305889\n",
      " -0.07603889 -0.44616674 -0.10956787]  energy_before :  50  energy_after :  40  reward :  -189.44948687797856\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "action : 1  next_temperatures :  [-0.18466176 -0.39197328 -0.74841808  0.45938896  0.06100966 -0.01305889\n",
      " -0.07603889 -0.44616674 -0.10956787]  energy_before :  40  energy_after :  50  reward :  -209.44948687797856\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "action : 1  next_temperatures :  [-0.18466176 -0.39197328 -0.74841808  0.45938896  0.06100966 -0.01305889\n",
      " -0.07603889 -0.44616674 -0.10956787]  energy_before :  50  energy_after :  50  reward :  -199.44948687797856\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step\n",
      "action : 1  next_temperatures :  [-0.18466176 -0.39197328 -0.74841808  0.45938896  0.06100966 -0.01305889\n",
      " -0.07603889 -0.44616674 -0.10956787]  energy_before :  50  energy_after :  50  reward :  -199.44948687797856\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "Episode 280/500, Total Reward: -1017.2474343898928\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step\n",
      "action : 1  next_temperatures :  [-1.2992148  -0.42715624 -0.76361853 -0.69548464 -1.08053164 -0.93486116\n",
      " -0.90821667 -0.72028382 -1.13419329]  energy_before :  30  energy_after :  50  reward :  -225.96356079071614\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "action : 1  next_temperatures :  [-1.2992148  -0.42715624 -0.76361853 -0.69548464 -1.08053164 -0.93486116\n",
      " -0.90821667 -0.72028382 -1.13419329]  energy_before :  50  energy_after :  40  reward :  -195.96356079071614\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step\n",
      "action : 1  next_temperatures :  [-1.2992148  -0.42715624 -0.76361853 -0.69548464 -1.08053164 -0.93486116\n",
      " -0.90821667 -0.72028382 -1.13419329]  energy_before :  40  energy_after :  50  reward :  -215.96356079071614\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "action : 1  next_temperatures :  [-1.2992148  -0.42715624 -0.76361853 -0.69548464 -1.08053164 -0.93486116\n",
      " -0.90821667 -0.72028382 -1.13419329]  energy_before :  50  energy_after :  50  reward :  -205.96356079071614\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "action : 1  next_temperatures :  [-1.2992148  -0.42715624 -0.76361853 -0.69548464 -1.08053164 -0.93486116\n",
      " -0.90821667 -0.72028382 -1.13419329]  energy_before :  50  energy_after :  50  reward :  -205.96356079071614\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "Episode 281/500, Total Reward: -1049.8178039535808\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "action : 1  next_temperatures :  [-0.22617211  0.82100146  0.33081365  0.14978455 -0.32171962  1.59155988\n",
      "  0.88667659  0.80693993 -0.26678553]  energy_before :  30  energy_after :  50  reward :  -214.22790119788738\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "action : 1  next_temperatures :  [-0.22617211  0.82100146  0.33081365  0.14978455 -0.32171962  1.59155988\n",
      "  0.88667659  0.80693993 -0.26678553]  energy_before :  50  energy_after :  40  reward :  -184.22790119788738\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "action : 1  next_temperatures :  [-0.22617211  0.82100146  0.33081365  0.14978455 -0.32171962  1.59155988\n",
      "  0.88667659  0.80693993 -0.26678553]  energy_before :  40  energy_after :  50  reward :  -204.22790119788738\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "action : 1  next_temperatures :  [-0.22617211  0.82100146  0.33081365  0.14978455 -0.32171962  1.59155988\n",
      "  0.88667659  0.80693993 -0.26678553]  energy_before :  50  energy_after :  50  reward :  -194.22790119788738\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "action : 1  next_temperatures :  [-0.22617211  0.82100146  0.33081365  0.14978455 -0.32171962  1.59155988\n",
      "  0.88667659  0.80693993 -0.26678553]  energy_before :  50  energy_after :  50  reward :  -194.22790119788738\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "Episode 282/500, Total Reward: -991.1395059894369\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "action : 1  next_temperatures :  [-0.28428661  1.03126159  0.07240605  0.56750479  0.28533     1.49562416\n",
      " -0.22778895  1.08336051 -0.58001611]  energy_before :  30  energy_after :  50  reward :  -214.55660456228614\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "action : 1  next_temperatures :  [-0.28428661  1.03126159  0.07240605  0.56750479  0.28533     1.49562416\n",
      " -0.22778895  1.08336051 -0.58001611]  energy_before :  50  energy_after :  40  reward :  -184.55660456228614\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "action : 1  next_temperatures :  [-0.28428661  1.03126159  0.07240605  0.56750479  0.28533     1.49562416\n",
      " -0.22778895  1.08336051 -0.58001611]  energy_before :  40  energy_after :  50  reward :  -204.55660456228614\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "action : 1  next_temperatures :  [-0.28428661  1.03126159  0.07240605  0.56750479  0.28533     1.49562416\n",
      " -0.22778895  1.08336051 -0.58001611]  energy_before :  50  energy_after :  50  reward :  -194.55660456228614\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "action : 1  next_temperatures :  [-0.28428661  1.03126159  0.07240605  0.56750479  0.28533     1.49562416\n",
      " -0.22778895  1.08336051 -0.58001611]  energy_before :  50  energy_after :  50  reward :  -194.55660456228614\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "Episode 283/500, Total Reward: -992.7830228114307\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "action : 1  next_temperatures :  [-1.18091029 -0.85437801 -1.75164758  0.32915853 -0.98581861 -0.50775944\n",
      " -0.85926503 -0.97597286 -0.61194153]  energy_before :  30  energy_after :  50  reward :  -225.3985348194242\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "action : 1  next_temperatures :  [-1.18091029 -0.85437801 -1.75164758  0.32915853 -0.98581861 -0.50775944\n",
      " -0.85926503 -0.97597286 -0.61194153]  energy_before :  50  energy_after :  40  reward :  -195.3985348194242\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "action : 1  next_temperatures :  [-1.18091029 -0.85437801 -1.75164758  0.32915853 -0.98581861 -0.50775944\n",
      " -0.85926503 -0.97597286 -0.61194153]  energy_before :  40  energy_after :  50  reward :  -215.3985348194242\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "action : 1  next_temperatures :  [-1.18091029 -0.85437801 -1.75164758  0.32915853 -0.98581861 -0.50775944\n",
      " -0.85926503 -0.97597286 -0.61194153]  energy_before :  50  energy_after :  50  reward :  -205.3985348194242\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "action : 1  next_temperatures :  [-1.18091029 -0.85437801 -1.75164758  0.32915853 -0.98581861 -0.50775944\n",
      " -0.85926503 -0.97597286 -0.61194153]  energy_before :  50  energy_after :  50  reward :  -205.3985348194242\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "Episode 284/500, Total Reward: -1046.9926740971212\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "action : 1  next_temperatures :  [-0.40674216 -0.28474899 -0.33800601  0.09081228 -0.18823517 -0.53541351\n",
      " -0.03198241 -0.63044713 -0.16378086]  energy_before :  30  energy_after :  50  reward :  -220.4885439594703\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "action : 1  next_temperatures :  [-0.40674216 -0.28474899 -0.33800601  0.09081228 -0.18823517 -0.53541351\n",
      " -0.03198241 -0.63044713 -0.16378086]  energy_before :  50  energy_after :  40  reward :  -190.4885439594703\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "action : 1  next_temperatures :  [-0.40674216 -0.28474899 -0.33800601  0.09081228 -0.18823517 -0.53541351\n",
      " -0.03198241 -0.63044713 -0.16378086]  energy_before :  40  energy_after :  50  reward :  -210.4885439594703\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "action : 1  next_temperatures :  [-0.40674216 -0.28474899 -0.33800601  0.09081228 -0.18823517 -0.53541351\n",
      " -0.03198241 -0.63044713 -0.16378086]  energy_before :  50  energy_after :  50  reward :  -200.4885439594703\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "action : 1  next_temperatures :  [-0.40674216 -0.28474899 -0.33800601  0.09081228 -0.18823517 -0.53541351\n",
      " -0.03198241 -0.63044713 -0.16378086]  energy_before :  50  energy_after :  50  reward :  -200.4885439594703\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "Episode 285/500, Total Reward: -1022.4427197973514\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "action : 1  next_temperatures :  [-0.69731464  0.68864648 -0.70737688  0.91069063 -0.45409631  0.80529668\n",
      " -0.41870032  0.42302244 -0.46272675]  energy_before :  30  energy_after :  50  reward :  -217.91255865888795\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "action : 1  next_temperatures :  [-0.69731464  0.68864648 -0.70737688  0.91069063 -0.45409631  0.80529668\n",
      " -0.41870032  0.42302244 -0.46272675]  energy_before :  50  energy_after :  40  reward :  -187.91255865888795\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "action : 1  next_temperatures :  [-0.69731464  0.68864648 -0.70737688  0.91069063 -0.45409631  0.80529668\n",
      " -0.41870032  0.42302244 -0.46272675]  energy_before :  40  energy_after :  50  reward :  -207.91255865888795\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "action : 1  next_temperatures :  [-0.69731464  0.68864648 -0.70737688  0.91069063 -0.45409631  0.80529668\n",
      " -0.41870032  0.42302244 -0.46272675]  energy_before :  50  energy_after :  50  reward :  -197.91255865888795\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "action : 1  next_temperatures :  [-0.69731464  0.68864648 -0.70737688  0.91069063 -0.45409631  0.80529668\n",
      " -0.41870032  0.42302244 -0.46272675]  energy_before :  50  energy_after :  50  reward :  -197.91255865888795\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "Episode 286/500, Total Reward: -1009.5627932944398\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "action : 1  next_temperatures :  [ 0.195158    0.43733956  1.78701647 -0.63733143  0.41493731 -0.11650559\n",
      "  1.20404635  0.08536702  0.7036269 ]  energy_before :  30  energy_after :  50  reward :  -213.92634541520255\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "action : 1  next_temperatures :  [ 0.195158    0.43733956  1.78701647 -0.63733143  0.41493731 -0.11650559\n",
      "  1.20404635  0.08536702  0.7036269 ]  energy_before :  50  energy_after :  40  reward :  -183.92634541520255\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "action : 1  next_temperatures :  [ 0.195158    0.43733956  1.78701647 -0.63733143  0.41493731 -0.11650559\n",
      "  1.20404635  0.08536702  0.7036269 ]  energy_before :  40  energy_after :  50  reward :  -203.92634541520255\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "action : 1  next_temperatures :  [ 0.195158    0.43733956  1.78701647 -0.63733143  0.41493731 -0.11650559\n",
      "  1.20404635  0.08536702  0.7036269 ]  energy_before :  50  energy_after :  50  reward :  -193.92634541520255\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "action : 1  next_temperatures :  [ 0.195158    0.43733956  1.78701647 -0.63733143  0.41493731 -0.11650559\n",
      "  1.20404635  0.08536702  0.7036269 ]  energy_before :  50  energy_after :  50  reward :  -193.92634541520255\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "Episode 287/500, Total Reward: -989.6317270760128\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "action : 1  next_temperatures :  [-1.18091029 -0.71029538 -1.39139699  0.00317293 -0.88113578 -0.71977397\n",
      " -1.20682164 -0.47457663 -0.75470239]  energy_before :  30  energy_after :  50  reward :  -225.31644011908793\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "action : 1  next_temperatures :  [-1.18091029 -0.71029538 -1.39139699  0.00317293 -0.88113578 -0.71977397\n",
      " -1.20682164 -0.47457663 -0.75470239]  energy_before :  50  energy_after :  40  reward :  -195.31644011908793\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "action : 1  next_temperatures :  [-1.18091029 -0.71029538 -1.39139699  0.00317293 -0.88113578 -0.71977397\n",
      " -1.20682164 -0.47457663 -0.75470239]  energy_before :  40  energy_after :  50  reward :  -215.31644011908793\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "action : 1  next_temperatures :  [-1.18091029 -0.71029538 -1.39139699  0.00317293 -0.88113578 -0.71977397\n",
      " -1.20682164 -0.47457663 -0.75470239]  energy_before :  50  energy_after :  50  reward :  -205.31644011908793\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "action : 1  next_temperatures :  [-1.18091029 -0.71029538 -1.39139699  0.00317293 -0.88113578 -0.71977397\n",
      " -1.20682164 -0.47457663 -0.75470239]  energy_before :  50  energy_after :  50  reward :  -205.31644011908793\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "Episode 288/500, Total Reward: -1046.5822005954396\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "action : 1  next_temperatures :  [-0.9256216  -0.84432573 -1.03722657 -0.25073545  0.07928761 -1.60163147\n",
      " -0.6634585  -0.9967044  -0.53785045]  energy_before :  30  energy_after :  50  reward :  -224.77826657261522\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "action : 1  next_temperatures :  [-0.9256216  -0.84432573 -1.03722657 -0.25073545  0.07928761 -1.60163147\n",
      " -0.6634585  -0.9967044  -0.53785045]  energy_before :  50  energy_after :  40  reward :  -194.77826657261522\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "action : 1  next_temperatures :  [-0.9256216  -0.84432573 -1.03722657 -0.25073545  0.07928761 -1.60163147\n",
      " -0.6634585  -0.9967044  -0.53785045]  energy_before :  40  energy_after :  50  reward :  -214.77826657261522\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "action : 1  next_temperatures :  [-0.9256216  -0.84432573 -1.03722657 -0.25073545  0.07928761 -1.60163147\n",
      " -0.6634585  -0.9967044  -0.53785045]  energy_before :  50  energy_after :  50  reward :  -204.77826657261522\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "action : 1  next_temperatures :  [-0.9256216  -0.84432573 -1.03722657 -0.25073545  0.07928761 -1.60163147\n",
      " -0.6634585  -0.9967044  -0.53785045]  energy_before :  50  energy_after :  50  reward :  -204.77826657261522\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "Episode 289/500, Total Reward: -1043.891332863076\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step\n",
      "action : 1  next_temperatures :  [ 0.31968906 -0.77060904  0.02224458 -0.63569332 -0.10016866 -1.09976135\n",
      " -0.27674059 -1.41978147  0.0042794 ]  energy_before :  30  energy_after :  50  reward :  -221.95654138071114\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "action : 1  next_temperatures :  [ 0.31968906 -0.77060904  0.02224458 -0.63569332 -0.10016866 -1.09976135\n",
      " -0.27674059 -1.41978147  0.0042794 ]  energy_before :  50  energy_after :  40  reward :  -191.95654138071114\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "action : 1  next_temperatures :  [ 0.31968906 -0.77060904  0.02224458 -0.63569332 -0.10016866 -1.09976135\n",
      " -0.27674059 -1.41978147  0.0042794 ]  energy_before :  40  energy_after :  50  reward :  -211.95654138071114\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "action : 1  next_temperatures :  [ 0.31968906 -0.77060904  0.02224458 -0.63569332 -0.10016866 -1.09976135\n",
      " -0.27674059 -1.41978147  0.0042794 ]  energy_before :  50  energy_after :  50  reward :  -201.95654138071114\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "action : 1  next_temperatures :  [ 0.31968906 -0.77060904  0.02224458 -0.63569332 -0.10016866 -1.09976135\n",
      " -0.27674059 -1.41978147  0.0042794 ]  energy_before :  50  energy_after :  50  reward :  -201.95654138071114\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "Episode 290/500, Total Reward: -1029.7827069035557\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "action : 1  next_temperatures :  [-1.672808    1.71649179 -0.93538358  1.59214797 -1.2799275   1.85819973\n",
      " -1.39773301  2.0669571  -1.24804056]  energy_before :  30  energy_after :  50  reward :  -217.30009605545217\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "action : 1  next_temperatures :  [-1.672808    1.71649179 -0.93538358  1.59214797 -1.2799275   1.85819973\n",
      " -1.39773301  2.0669571  -1.24804056]  energy_before :  50  energy_after :  40  reward :  -187.30009605545217\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "action : 1  next_temperatures :  [-1.672808    1.71649179 -0.93538358  1.59214797 -1.2799275   1.85819973\n",
      " -1.39773301  2.0669571  -1.24804056]  energy_before :  40  energy_after :  50  reward :  -207.30009605545217\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "action : 1  next_temperatures :  [-1.672808    1.71649179 -0.93538358  1.59214797 -1.2799275   1.85819973\n",
      " -1.39773301  2.0669571  -1.24804056]  energy_before :  50  energy_after :  50  reward :  -197.30009605545217\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "action : 1  next_temperatures :  [-1.672808    1.71649179 -0.93538358  1.59214797 -1.2799275   1.85819973\n",
      " -1.39773301  2.0669571  -1.24804056]  energy_before :  50  energy_after :  50  reward :  -197.30009605545217\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "Episode 291/500, Total Reward: -1006.5004802772609\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "action : 1  next_temperatures :  [ 0.195158    0.24383323 -0.44516917  0.98399644  1.09454486  0.19076184\n",
      "  0.80509053 -0.23654779  0.7036269 ]  energy_before :  30  energy_after :  50  reward :  -214.46470515574077\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "action : 1  next_temperatures :  [ 0.195158    0.24383323 -0.44516917  0.98399644  1.09454486  0.19076184\n",
      "  0.80509053 -0.23654779  0.7036269 ]  energy_before :  50  energy_after :  40  reward :  -184.46470515574077\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "action : 1  next_temperatures :  [ 0.195158    0.24383323 -0.44516917  0.98399644  1.09454486  0.19076184\n",
      "  0.80509053 -0.23654779  0.7036269 ]  energy_before :  40  energy_after :  50  reward :  -204.46470515574077\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "action : 1  next_temperatures :  [ 0.195158    0.24383323 -0.44516917  0.98399644  1.09454486  0.19076184\n",
      "  0.80509053 -0.23654779  0.7036269 ]  energy_before :  50  energy_after :  50  reward :  -194.46470515574077\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "action : 1  next_temperatures :  [ 0.195158    0.24383323 -0.44516917  0.98399644  1.09454486  0.19076184\n",
      "  0.80509053 -0.23654779  0.7036269 ]  energy_before :  50  energy_after :  50  reward :  -194.46470515574077\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "Episode 292/500, Total Reward: -992.3235257787039\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "action : 1  next_temperatures :  [-0.24692729  0.72508599  0.02224458  0.65596319 -0.29541044  1.39038507\n",
      " -0.32079706  0.92902569 -0.28786836]  energy_before :  30  energy_after :  50  reward :  -215.42829862691227\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "action : 1  next_temperatures :  [-0.24692729  0.72508599  0.02224458  0.65596319 -0.29541044  1.39038507\n",
      " -0.32079706  0.92902569 -0.28786836]  energy_before :  50  energy_after :  40  reward :  -185.42829862691227\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "action : 1  next_temperatures :  [-0.24692729  0.72508599  0.02224458  0.65596319 -0.29541044  1.39038507\n",
      " -0.32079706  0.92902569 -0.28786836]  energy_before :  40  energy_after :  50  reward :  -205.42829862691227\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "action : 1  next_temperatures :  [-0.24692729  0.72508599  0.02224458  0.65596319 -0.29541044  1.39038507\n",
      " -0.32079706  0.92902569 -0.28786836]  energy_before :  50  energy_after :  50  reward :  -195.42829862691227\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "action : 1  next_temperatures :  [-0.24692729  0.72508599  0.02224458  0.65596319 -0.29541044  1.39038507\n",
      " -0.32079706  0.92902569 -0.28786836]  energy_before :  50  energy_after :  50  reward :  -195.42829862691227\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "Episode 293/500, Total Reward: -997.1414931345613\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "action : 1  next_temperatures :  [-0.11616967 -1.53374439  0.02224458 -1.5858021  -0.73657378 -1.54017799\n",
      "  0.15240207 -1.53495671 -0.04993359]  energy_before :  30  energy_after :  50  reward :  -224.9227115743131\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "action : 1  next_temperatures :  [-0.11616967 -1.53374439  0.02224458 -1.5858021  -0.73657378 -1.54017799\n",
      "  0.15240207 -1.53495671 -0.04993359]  energy_before :  50  energy_after :  40  reward :  -194.9227115743131\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "action : 1  next_temperatures :  [-0.11616967 -1.53374439  0.02224458 -1.5858021  -0.73657378 -1.54017799\n",
      "  0.15240207 -1.53495671 -0.04993359]  energy_before :  40  energy_after :  50  reward :  -214.9227115743131\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "action : 1  next_temperatures :  [-0.11616967 -1.53374439  0.02224458 -1.5858021  -0.73657378 -1.54017799\n",
      "  0.15240207 -1.53495671 -0.04993359]  energy_before :  50  energy_after :  50  reward :  -204.9227115743131\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "action : 1  next_temperatures :  [-0.11616967 -1.53374439  0.02224458 -1.5858021  -0.73657378 -1.54017799\n",
      "  0.15240207 -1.53495671 -0.04993359]  energy_before :  50  energy_after :  50  reward :  -204.9227115743131\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "Episode 294/500, Total Reward: -1044.6135578715655\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "action : 1  next_temperatures :  [-1.34072515 -0.89458712 -1.76836807  0.09081228 -0.98581861 -0.53541351\n",
      " -0.56555523 -0.87461865 -1.0799803 ]  energy_before :  30  energy_after :  50  reward :  -225.95425435884977\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "action : 1  next_temperatures :  [-1.34072515 -0.89458712 -1.76836807  0.09081228 -0.98581861 -0.53541351\n",
      " -0.56555523 -0.87461865 -1.0799803 ]  energy_before :  50  energy_after :  40  reward :  -195.95425435884977\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "action : 1  next_temperatures :  [-1.34072515 -0.89458712 -1.76836807  0.09081228 -0.98581861 -0.53541351\n",
      " -0.56555523 -0.87461865 -1.0799803 ]  energy_before :  40  energy_after :  50  reward :  -215.95425435884977\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "action : 1  next_temperatures :  [-1.34072515 -0.89458712 -1.76836807  0.09081228 -0.98581861 -0.53541351\n",
      " -0.56555523 -0.87461865 -1.0799803 ]  energy_before :  50  energy_after :  50  reward :  -205.95425435884977\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "action : 1  next_temperatures :  [-1.34072515 -0.89458712 -1.76836807  0.09081228 -0.98581861 -0.53541351\n",
      " -0.56555523 -0.87461865 -1.0799803 ]  energy_before :  50  energy_after :  50  reward :  -205.95425435884977\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "Episode 295/500, Total Reward: -1049.7712717942488\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "action : 1  next_temperatures :  [ 0.43799358 -0.29396358  0.39161544 -0.4227379   0.21554145 -0.29267225\n",
      "  0.26172739 -0.34481252  0.39641999]  energy_before :  30  energy_after :  50  reward :  -217.65088840001602\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "action : 1  next_temperatures :  [ 0.43799358 -0.29396358  0.39161544 -0.4227379   0.21554145 -0.29267225\n",
      "  0.26172739 -0.34481252  0.39641999]  energy_before :  50  energy_after :  40  reward :  -187.65088840001602\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "action : 1  next_temperatures :  [ 0.43799358 -0.29396358  0.39161544 -0.4227379   0.21554145 -0.29267225\n",
      "  0.26172739 -0.34481252  0.39641999]  energy_before :  40  energy_after :  50  reward :  -207.65088840001602\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "action : 1  next_temperatures :  [ 0.43799358 -0.29396358  0.39161544 -0.4227379   0.21554145 -0.29267225\n",
      "  0.26172739 -0.34481252  0.39641999]  energy_before :  50  energy_after :  50  reward :  -197.65088840001602\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "action : 1  next_temperatures :  [ 0.43799358 -0.29396358  0.39161544 -0.4227379   0.21554145 -0.29267225\n",
      "  0.26172739 -0.34481252  0.39641999]  energy_before :  50  energy_after :  50  reward :  -197.65088840001602\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "Episode 296/500, Total Reward: -1008.2544420000801\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "action : 1  next_temperatures :  [-0.80731709 -0.87196949 -0.79401942 -0.61931213 -0.33279717 -0.96866058\n",
      " -1.05507157 -0.65117867 -1.28289176]  energy_before :  30  energy_after :  50  reward :  -225.383217880547\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "action : 1  next_temperatures :  [-0.80731709 -0.87196949 -0.79401942 -0.61931213 -0.33279717 -0.96866058\n",
      " -1.05507157 -0.65117867 -1.28289176]  energy_before :  50  energy_after :  40  reward :  -195.383217880547\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "action : 1  next_temperatures :  [-0.80731709 -0.87196949 -0.79401942 -0.61931213 -0.33279717 -0.96866058\n",
      " -1.05507157 -0.65117867 -1.28289176]  energy_before :  40  energy_after :  50  reward :  -215.383217880547\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "action : 1  next_temperatures :  [-0.80731709 -0.87196949 -0.79401942 -0.61931213 -0.33279717 -0.96866058\n",
      " -1.05507157 -0.65117867 -1.28289176]  energy_before :  50  energy_after :  50  reward :  -205.383217880547\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "action : 1  next_temperatures :  [-0.80731709 -0.87196949 -0.79401942 -0.61931213 -0.33279717 -0.96866058\n",
      " -1.05507157 -0.65117867 -1.28289176]  energy_before :  50  energy_after :  50  reward :  -205.383217880547\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "Episode 297/500, Total Reward: -1046.916089402735\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "action : 1  next_temperatures :  [ 0.68705571 -0.91301629  0.25025128 -0.57999728 -0.0503197  -0.91437667\n",
      "  0.56033236 -0.52909291  0.0042794 ]  energy_before :  30  energy_after :  50  reward :  -219.4848841057136\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "action : 1  next_temperatures :  [ 0.68705571 -0.91301629  0.25025128 -0.57999728 -0.0503197  -0.91437667\n",
      "  0.56033236 -0.52909291  0.0042794 ]  energy_before :  50  energy_after :  40  reward :  -189.4848841057136\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "action : 1  next_temperatures :  [ 0.68705571 -0.91301629  0.25025128 -0.57999728 -0.0503197  -0.91437667\n",
      "  0.56033236 -0.52909291  0.0042794 ]  energy_before :  40  energy_after :  50  reward :  -209.4848841057136\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "action : 1  next_temperatures :  [ 0.68705571 -0.91301629  0.25025128 -0.57999728 -0.0503197  -0.91437667\n",
      "  0.56033236 -0.52909291  0.0042794 ]  energy_before :  50  energy_after :  50  reward :  -199.4848841057136\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "action : 1  next_temperatures :  [ 0.68705571 -0.91301629  0.25025128 -0.57999728 -0.0503197  -0.91437667\n",
      "  0.56033236 -0.52909291  0.0042794 ]  energy_before :  50  energy_after :  50  reward :  -199.4848841057136\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "Episode 298/500, Total Reward: -1017.424420528568\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "action : 1  next_temperatures :  [ 0.04572072  1.36717517  0.36121455  0.8549946   0.11584352  1.85819973\n",
      " -0.52149876  1.90340826 -0.48363747]  energy_before :  30  energy_after :  50  reward :  -212.49857969073315\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "action : 1  next_temperatures :  [ 0.04572072  1.36717517  0.36121455  0.8549946   0.11584352  1.85819973\n",
      " -0.52149876  1.90340826 -0.48363747]  energy_before :  50  energy_after :  40  reward :  -182.49857969073315\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "action : 1  next_temperatures :  [ 0.04572072  1.36717517  0.36121455  0.8549946   0.11584352  1.85819973\n",
      " -0.52149876  1.90340826 -0.48363747]  energy_before :  40  energy_after :  50  reward :  -202.49857969073315\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step\n",
      "action : 1  next_temperatures :  [ 0.04572072  1.36717517  0.36121455  0.8549946   0.11584352  1.85819973\n",
      " -0.52149876  1.90340826 -0.48363747]  energy_before :  50  energy_after :  50  reward :  -192.49857969073315\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step\n",
      "action : 1  next_temperatures :  [ 0.04572072  1.36717517  0.36121455  0.8549946   0.11584352  1.85819973\n",
      " -0.52149876  1.90340826 -0.48363747]  energy_before :  50  energy_after :  50  reward :  -192.49857969073315\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "Episode 299/500, Total Reward: -982.4928984536657\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "action : 1  next_temperatures :  [-0.16183106 -0.45061156  0.25025128 -0.98788881 -0.20318986 -0.2619455\n",
      "  0.07081602 -1.12877202 -0.80891538]  energy_before :  30  energy_after :  50  reward :  -221.68208688575533\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step\n",
      "action : 1  next_temperatures :  [-0.16183106 -0.45061156  0.25025128 -0.98788881 -0.20318986 -0.2619455\n",
      "  0.07081602 -1.12877202 -0.80891538]  energy_before :  50  energy_after :  40  reward :  -191.68208688575533\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "action : 1  next_temperatures :  [-0.16183106 -0.45061156  0.25025128 -0.98788881 -0.20318986 -0.2619455\n",
      "  0.07081602 -1.12877202 -0.80891538]  energy_before :  40  energy_after :  50  reward :  -211.68208688575533\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step\n",
      "action : 1  next_temperatures :  [-0.16183106 -0.45061156  0.25025128 -0.98788881 -0.20318986 -0.2619455\n",
      "  0.07081602 -1.12877202 -0.80891538]  energy_before :  50  energy_after :  50  reward :  -201.68208688575533\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "action : 1  next_temperatures :  [-0.16183106 -0.45061156  0.25025128 -0.98788881 -0.20318986 -0.2619455\n",
      "  0.07081602 -1.12877202 -0.80891538]  energy_before :  50  energy_after :  50  reward :  -201.68208688575533\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "Episode 300/500, Total Reward: -1028.4104344287766\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "action : 1  next_temperatures :  [-0.3652318   0.05786611  1.54532936 -1.62921224  0.06100966 -1.30358207\n",
      " -0.03198241 -0.68342774 -0.16378086]  energy_before :  30  energy_after :  50  reward :  -220.51301199116705\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "action : 1  next_temperatures :  [-0.3652318   0.05786611  1.54532936 -1.62921224  0.06100966 -1.30358207\n",
      " -0.03198241 -0.68342774 -0.16378086]  energy_before :  50  energy_after :  40  reward :  -190.51301199116705\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "action : 1  next_temperatures :  [-0.3652318   0.05786611  1.54532936 -1.62921224  0.06100966 -1.30358207\n",
      " -0.03198241 -0.68342774 -0.16378086]  energy_before :  40  energy_after :  50  reward :  -210.51301199116705\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "action : 1  next_temperatures :  [-0.3652318   0.05786611  1.54532936 -1.62921224  0.06100966 -1.30358207\n",
      " -0.03198241 -0.68342774 -0.16378086]  energy_before :  50  energy_after :  50  reward :  -200.51301199116705\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "action : 1  next_temperatures :  [-0.3652318   0.05786611  1.54532936 -1.62921224  0.06100966 -1.30358207\n",
      " -0.03198241 -0.68342774 -0.16378086]  energy_before :  50  energy_after :  50  reward :  -200.51301199116705\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "Episode 301/500, Total Reward: -1022.5650599558353\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step\n",
      "action : 1  next_temperatures :  [-0.49598942  0.13325819 -1.06762747  1.17442773  0.41493731  0.16822889\n",
      " -0.27674059 -0.15285378  0.3295573 ]  energy_before :  30  energy_after :  50  reward :  -217.77280183609864\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step\n",
      "action : 1  next_temperatures :  [-0.49598942  0.13325819 -1.06762747  1.17442773  0.41493731  0.16822889\n",
      " -0.27674059 -0.15285378  0.3295573 ]  energy_before :  50  energy_after :  40  reward :  -187.77280183609864\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "action : 1  next_temperatures :  [-0.49598942  0.13325819 -1.06762747  1.17442773  0.41493731  0.16822889\n",
      " -0.27674059 -0.15285378  0.3295573 ]  energy_before :  40  energy_after :  50  reward :  -207.77280183609864\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "action : 1  next_temperatures :  [-0.49598942  0.13325819 -1.06762747  1.17442773  0.41493731  0.16822889\n",
      " -0.27674059 -0.15285378  0.3295573 ]  energy_before :  50  energy_after :  50  reward :  -197.77280183609864\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "action : 1  next_temperatures :  [-0.49598942  0.13325819 -1.06762747  1.17442773  0.41493731  0.16822889\n",
      " -0.27674059 -0.15285378  0.3295573 ]  energy_before :  50  energy_after :  50  reward :  -197.77280183609864\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "Episode 302/500, Total Reward: -1008.8640091804932\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "action : 1  next_temperatures :  [ 0.06440038 -0.39197328 -0.66177553  0.51836123  0.06100966 -0.32032631\n",
      " -0.12499052 -0.51527188  0.3295573 ]  energy_before :  30  energy_after :  50  reward :  -219.04100895625075\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "action : 1  next_temperatures :  [ 0.06440038 -0.39197328 -0.66177553  0.51836123  0.06100966 -0.32032631\n",
      " -0.12499052 -0.51527188  0.3295573 ]  energy_before :  50  energy_after :  40  reward :  -189.04100895625075\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "action : 1  next_temperatures :  [ 0.06440038 -0.39197328 -0.66177553  0.51836123  0.06100966 -0.32032631\n",
      " -0.12499052 -0.51527188  0.3295573 ]  energy_before :  40  energy_after :  50  reward :  -209.04100895625075\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "action : 1  next_temperatures :  [ 0.06440038 -0.39197328 -0.66177553  0.51836123  0.06100966 -0.32032631\n",
      " -0.12499052 -0.51527188  0.3295573 ]  energy_before :  50  energy_after :  50  reward :  -199.04100895625075\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "action : 1  next_temperatures :  [ 0.06440038 -0.39197328 -0.66177553  0.51836123  0.06100966 -0.32032631\n",
      " -0.12499052 -0.51527188  0.3295573 ]  energy_before :  50  energy_after :  50  reward :  -199.04100895625075\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "Episode 303/500, Total Reward: -1015.2050447812537\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "action : 1  next_temperatures :  [-1.18091029 -0.81165583 -0.56601272 -0.93219278 -1.82826611 -0.30189027\n",
      " -1.29982974 -0.59743022 -0.8480692 ]  energy_before :  30  energy_after :  50  reward :  -226.3662571637153\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "action : 1  next_temperatures :  [-1.18091029 -0.81165583 -0.56601272 -0.93219278 -1.82826611 -0.30189027\n",
      " -1.29982974 -0.59743022 -0.8480692 ]  energy_before :  50  energy_after :  40  reward :  -196.3662571637153\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "action : 1  next_temperatures :  [-1.18091029 -0.81165583 -0.56601272 -0.93219278 -1.82826611 -0.30189027\n",
      " -1.29982974 -0.59743022 -0.8480692 ]  energy_before :  40  energy_after :  50  reward :  -216.3662571637153\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "action : 1  next_temperatures :  [-1.18091029 -0.81165583 -0.56601272 -0.93219278 -1.82826611 -0.30189027\n",
      " -1.29982974 -0.59743022 -0.8480692 ]  energy_before :  50  energy_after :  50  reward :  -206.3662571637153\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "action : 1  next_temperatures :  [-1.18091029 -0.81165583 -0.56601272 -0.93219278 -1.82826611 -0.30189027\n",
      " -1.29982974 -0.59743022 -0.8480692 ]  energy_before :  50  energy_after :  50  reward :  -206.3662571637153\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "Episode 304/500, Total Reward: -1051.8312858185764\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "action : 1  next_temperatures :  [-1.38431103  0.33430373 -0.61161406 -0.00501766 -1.52917232  0.90874338\n",
      " -1.1040232   0.33165008 -1.02576732]  energy_before :  30  energy_after :  50  reward :  -222.08520839680307\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "action : 1  next_temperatures :  [-1.38431103  0.33430373 -0.61161406 -0.00501766 -1.52917232  0.90874338\n",
      " -1.1040232   0.33165008 -1.02576732]  energy_before :  50  energy_after :  40  reward :  -192.08520839680307\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "action : 1  next_temperatures :  [-1.38431103  0.33430373 -0.61161406 -0.00501766 -1.52917232  0.90874338\n",
      " -1.1040232   0.33165008 -1.02576732]  energy_before :  40  energy_after :  50  reward :  -212.08520839680307\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "action : 1  next_temperatures :  [-1.38431103  0.33430373 -0.61161406 -0.00501766 -1.52917232  0.90874338\n",
      " -1.1040232   0.33165008 -1.02576732]  energy_before :  50  energy_after :  50  reward :  -202.08520839680307\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "action : 1  next_temperatures :  [-1.38431103  0.33430373 -0.61161406 -0.00501766 -1.52917232  0.90874338\n",
      " -1.1040232   0.33165008 -1.02576732]  energy_before :  50  energy_after :  50  reward :  -202.08520839680307\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "Episode 305/500, Total Reward: -1030.4260419840152\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "action : 1  next_temperatures :  [ 1.17065135 -0.8962625   1.07563555 -1.88377587  0.86357799 -1.49408788\n",
      "  1.31092408 -1.27619633  1.67713721]  energy_before :  30  energy_after :  50  reward :  -217.45239637923038\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "action : 1  next_temperatures :  [ 1.17065135 -0.8962625   1.07563555 -1.88377587  0.86357799 -1.49408788\n",
      "  1.31092408 -1.27619633  1.67713721]  energy_before :  50  energy_after :  40  reward :  -187.45239637923038\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "action : 1  next_temperatures :  [ 1.17065135 -0.8962625   1.07563555 -1.88377587  0.86357799 -1.49408788\n",
      "  1.31092408 -1.27619633  1.67713721]  energy_before :  40  energy_after :  50  reward :  -207.45239637923038\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "action : 1  next_temperatures :  [ 1.17065135 -0.8962625   1.07563555 -1.88377587  0.86357799 -1.49408788\n",
      "  1.31092408 -1.27619633  1.67713721]  energy_before :  50  energy_after :  50  reward :  -197.45239637923038\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "action : 1  next_temperatures :  [ 1.17065135 -0.8962625   1.07563555 -1.88377587  0.86357799 -1.49408788\n",
      "  1.31092408 -1.27619633  1.67713721]  energy_before :  50  energy_after :  50  reward :  -197.45239637923038\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "Episode 306/500, Total Reward: -1007.2619818961518\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "action : 1  next_temperatures :  [-0.67655947  0.671055   -0.61161406  0.78005068 -0.50228365  0.62913003\n",
      "  0.16708756  0.54434037 -0.48363747]  energy_before :  30  energy_after :  50  reward :  -217.4824310055988\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "action : 1  next_temperatures :  [-0.67655947  0.671055   -0.61161406  0.78005068 -0.50228365  0.62913003\n",
      "  0.16708756  0.54434037 -0.48363747]  energy_before :  50  energy_after :  40  reward :  -187.4824310055988\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "action : 1  next_temperatures :  [-0.67655947  0.671055   -0.61161406  0.78005068 -0.50228365  0.62913003\n",
      "  0.16708756  0.54434037 -0.48363747]  energy_before :  40  energy_after :  50  reward :  -207.4824310055988\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "action : 1  next_temperatures :  [-0.67655947  0.671055   -0.61161406  0.78005068 -0.50228365  0.62913003\n",
      "  0.16708756  0.54434037 -0.48363747]  energy_before :  50  energy_after :  50  reward :  -197.4824310055988\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "action : 1  next_temperatures :  [-0.67655947  0.671055   -0.61161406  0.78005068 -0.50228365  0.62913003\n",
      "  0.16708756  0.54434037 -0.48363747]  energy_before :  50  energy_after :  50  reward :  -197.4824310055988\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "Episode 307/500, Total Reward: -1007.412155027994\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "action : 1  next_temperatures :  [-0.05390414 -0.73710145  0.95251193 -1.12794795  0.26040552 -1.14994836\n",
      "  0.73026446 -0.97597286  0.22113133]  energy_before :  30  energy_after :  50  reward :  -219.88056150977076\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "action : 1  next_temperatures :  [-0.05390414 -0.73710145  0.95251193 -1.12794795  0.26040552 -1.14994836\n",
      "  0.73026446 -0.97597286  0.22113133]  energy_before :  50  energy_after :  40  reward :  -189.88056150977076\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "action : 1  next_temperatures :  [-0.05390414 -0.73710145  0.95251193 -1.12794795  0.26040552 -1.14994836\n",
      "  0.73026446 -0.97597286  0.22113133]  energy_before :  40  energy_after :  50  reward :  -209.88056150977076\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "action : 1  next_temperatures :  [-0.05390414 -0.73710145  0.95251193 -1.12794795  0.26040552 -1.14994836\n",
      "  0.73026446 -0.97597286  0.22113133]  energy_before :  50  energy_after :  50  reward :  -199.88056150977076\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step\n",
      "action : 1  next_temperatures :  [-0.05390414 -0.73710145  0.95251193 -1.12794795  0.26040552 -1.14994836\n",
      "  0.73026446 -0.97597286  0.22113133]  energy_before :  50  energy_after :  50  reward :  -199.88056150977076\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "Episode 308/500, Total Reward: -1019.4028075488538\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "action : 1  next_temperatures :  [-0.42749733  0.46917177 -0.02335676  0.13422242 -0.18823517  0.48676279\n",
      " -1.1040232   0.47523522 -0.32099851]  energy_before :  30  energy_after :  50  reward :  -218.49871877769576\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "action : 1  next_temperatures :  [-0.42749733  0.46917177 -0.02335676  0.13422242 -0.18823517  0.48676279\n",
      " -1.1040232   0.47523522 -0.32099851]  energy_before :  50  energy_after :  40  reward :  -188.49871877769576\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "action : 1  next_temperatures :  [-0.42749733  0.46917177 -0.02335676  0.13422242 -0.18823517  0.48676279\n",
      " -1.1040232   0.47523522 -0.32099851]  energy_before :  40  energy_after :  50  reward :  -208.49871877769576\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "action : 1  next_temperatures :  [-0.42749733  0.46917177 -0.02335676  0.13422242 -0.18823517  0.48676279\n",
      " -1.1040232   0.47523522 -0.32099851]  energy_before :  50  energy_after :  50  reward :  -198.49871877769576\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step\n",
      "action : 1  next_temperatures :  [-0.42749733  0.46917177 -0.02335676  0.13422242 -0.18823517  0.48676279\n",
      " -1.1040232   0.47523522 -0.32099851]  energy_before :  50  energy_after :  50  reward :  -198.49871877769576\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step\n",
      "Episode 309/500, Total Reward: -1012.4935938884788\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "action : 1  next_temperatures :  [-0.18466176  0.59482523 -0.25136347 -0.56197798  0.18230881 -0.40226429\n",
      " -1.20682164 -0.92145658 -1.19382757]  energy_before :  30  energy_after :  50  reward :  -221.9452392408404\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step\n",
      "action : 1  next_temperatures :  [-0.18466176  0.59482523 -0.25136347 -0.56197798  0.18230881 -0.40226429\n",
      " -1.20682164 -0.92145658 -1.19382757]  energy_before :  50  energy_after :  40  reward :  -191.9452392408404\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "action : 1  next_temperatures :  [-0.18466176  0.59482523 -0.25136347 -0.56197798  0.18230881 -0.40226429\n",
      " -1.20682164 -0.92145658 -1.19382757]  energy_before :  40  energy_after :  50  reward :  -211.9452392408404\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step\n",
      "action : 1  next_temperatures :  [-0.18466176  0.59482523 -0.25136347 -0.56197798  0.18230881 -0.40226429\n",
      " -1.20682164 -0.92145658 -1.19382757]  energy_before :  50  energy_after :  50  reward :  -201.9452392408404\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "action : 1  next_temperatures :  [-0.18466176  0.59482523 -0.25136347 -0.56197798  0.18230881 -0.40226429\n",
      " -1.20682164 -0.92145658 -1.19382757]  energy_before :  50  energy_after :  50  reward :  -201.9452392408404\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "Episode 310/500, Total Reward: -1029.726196204202\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "action : 1  next_temperatures :  [ 0.66837605 -0.04852048  0.02224458 -0.68565593 -0.26799351 -1.48794253\n",
      "  0.68760661 -1.48044043 -0.43484578]  energy_before :  30  energy_after :  50  reward :  -221.02717143287845\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "action : 1  next_temperatures :  [ 0.66837605 -0.04852048  0.02224458 -0.68565593 -0.26799351 -1.48794253\n",
      "  0.68760661 -1.48044043 -0.43484578]  energy_before :  50  energy_after :  40  reward :  -191.02717143287845\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step\n",
      "action : 1  next_temperatures :  [ 0.66837605 -0.04852048  0.02224458 -0.68565593 -0.26799351 -1.48794253\n",
      "  0.68760661 -1.48044043 -0.43484578]  energy_before :  40  energy_after :  50  reward :  -211.02717143287845\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "action : 1  next_temperatures :  [ 0.66837605 -0.04852048  0.02224458 -0.68565593 -0.26799351 -1.48794253\n",
      "  0.68760661 -1.48044043 -0.43484578]  energy_before :  50  energy_after :  50  reward :  -201.02717143287845\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step\n",
      "action : 1  next_temperatures :  [ 0.66837605 -0.04852048  0.02224458 -0.68565593 -0.26799351 -1.48794253\n",
      "  0.68760661 -1.48044043 -0.43484578]  energy_before :  50  energy_after :  50  reward :  -201.02717143287845\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "Episode 311/500, Total Reward: -1025.1358571643923\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "action : 1  next_temperatures :  [ 0.0083614   2.11188135  0.30041276  1.42751705 -0.01874869  2.27813187\n",
      " -0.27674059  1.65232622  0.05849238]  energy_before :  30  energy_after :  50  reward :  -210.4583662473966\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "action : 1  next_temperatures :  [ 0.0083614   2.11188135  0.30041276  1.42751705 -0.01874869  2.27813187\n",
      " -0.27674059  1.65232622  0.05849238]  energy_before :  50  energy_after :  40  reward :  -180.4583662473966\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "action : 1  next_temperatures :  [ 0.0083614   2.11188135  0.30041276  1.42751705 -0.01874869  2.27813187\n",
      " -0.27674059  1.65232622  0.05849238]  energy_before :  40  energy_after :  50  reward :  -200.4583662473966\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "action : 1  next_temperatures :  [ 0.0083614   2.11188135  0.30041276  1.42751705 -0.01874869  2.27813187\n",
      " -0.27674059  1.65232622  0.05849238]  energy_before :  50  energy_after :  50  reward :  -190.4583662473966\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "action : 1  next_temperatures :  [ 0.0083614   2.11188135  0.30041276  1.42751705 -0.01874869  2.27813187\n",
      " -0.27674059  1.65232622  0.05849238]  energy_before :  50  energy_after :  50  reward :  -190.4583662473966\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "Episode 312/500, Total Reward: -972.2918312369831\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "action : 1  next_temperatures :  [1.96323229 1.58663791 2.17006773 0.52222251 2.06762039 0.70126471\n",
      " 1.62546233 1.40300569 1.90811186]  energy_before :  30  energy_after :  50  reward :  -204.05237455836243\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "action : 1  next_temperatures :  [1.96323229 1.58663791 2.17006773 0.52222251 2.06762039 0.70126471\n",
      " 1.62546233 1.40300569 1.90811186]  energy_before :  50  energy_after :  40  reward :  -174.05237455836243\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "action : 1  next_temperatures :  [1.96323229 1.58663791 2.17006773 0.52222251 2.06762039 0.70126471\n",
      " 1.62546233 1.40300569 1.90811186]  energy_before :  40  energy_after :  50  reward :  -194.05237455836243\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "action : 1  next_temperatures :  [1.96323229 1.58663791 2.17006773 0.52222251 2.06762039 0.70126471\n",
      " 1.62546233 1.40300569 1.90811186]  energy_before :  50  energy_after :  50  reward :  -184.05237455836243\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "action : 1  next_temperatures :  [1.96323229 1.58663791 2.17006773 0.52222251 2.06762039 0.70126471\n",
      " 1.62546233 1.40300569 1.90811186]  energy_before :  50  energy_after :  50  reward :  -184.05237455836243\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "Episode 313/500, Total Reward: -940.2618727918122\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "action : 1  next_temperatures :  [2.30595957 0.646762   1.84629821 0.42089317 2.21847286 0.12705506\n",
      " 2.56734936 0.74474529 2.1547278 ]  energy_before :  30  energy_after :  50  reward :  -204.96773667613056\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "action : 1  next_temperatures :  [2.30595957 0.646762   1.84629821 0.42089317 2.21847286 0.12705506\n",
      " 2.56734936 0.74474529 2.1547278 ]  energy_before :  50  energy_after :  40  reward :  -174.96773667613056\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "action : 1  next_temperatures :  [2.30595957 0.646762   1.84629821 0.42089317 2.21847286 0.12705506\n",
      " 2.56734936 0.74474529 2.1547278 ]  energy_before :  40  energy_after :  50  reward :  -194.96773667613056\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "action : 1  next_temperatures :  [2.30595957 0.646762   1.84629821 0.42089317 2.21847286 0.12705506\n",
      " 2.56734936 0.74474529 2.1547278 ]  energy_before :  50  energy_after :  50  reward :  -184.96773667613056\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "action : 1  next_temperatures :  [2.30595957 0.646762   1.84629821 0.42089317 2.21847286 0.12705506\n",
      " 2.56734936 0.74474529 2.1547278 ]  energy_before :  50  energy_after :  50  reward :  -184.96773667613056\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "Episode 314/500, Total Reward: -944.8386833806528\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "action : 1  next_temperatures :  [-0.49598942 -0.87196949 -0.29240467 -0.82571507 -0.2829482  -1.275928\n",
      " -0.07603889 -0.9967044  -0.16378086]  energy_before :  30  energy_after :  50  reward :  -223.28147901389596\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "action : 1  next_temperatures :  [-0.49598942 -0.87196949 -0.29240467 -0.82571507 -0.2829482  -1.275928\n",
      " -0.07603889 -0.9967044  -0.16378086]  energy_before :  50  energy_after :  40  reward :  -193.28147901389596\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "action : 1  next_temperatures :  [-0.49598942 -0.87196949 -0.29240467 -0.82571507 -0.2829482  -1.275928\n",
      " -0.07603889 -0.9967044  -0.16378086]  energy_before :  40  energy_after :  50  reward :  -213.28147901389596\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "action : 1  next_temperatures :  [-0.49598942 -0.87196949 -0.29240467 -0.82571507 -0.2829482  -1.275928\n",
      " -0.07603889 -0.9967044  -0.16378086]  energy_before :  50  energy_after :  50  reward :  -203.28147901389596\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "action : 1  next_temperatures :  [-0.49598942 -0.87196949 -0.29240467 -0.82571507 -0.2829482  -1.275928\n",
      " -0.07603889 -0.9967044  -0.16378086]  energy_before :  50  energy_after :  50  reward :  -203.28147901389596\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "Episode 315/500, Total Reward: -1036.40739506948\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "action : 1  next_temperatures :  [-0.11616967 -1.22128612 -0.97642479 -0.2777644   0.55949931 -1.09976135\n",
      "  0.36452582 -1.48274394  0.54640924]  energy_before :  30  energy_after :  50  reward :  -221.70371588607486\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "action : 1  next_temperatures :  [-0.11616967 -1.22128612 -0.97642479 -0.2777644   0.55949931 -1.09976135\n",
      "  0.36452582 -1.48274394  0.54640924]  energy_before :  50  energy_after :  40  reward :  -191.70371588607486\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "action : 1  next_temperatures :  [-0.11616967 -1.22128612 -0.97642479 -0.2777644   0.55949931 -1.09976135\n",
      "  0.36452582 -1.48274394  0.54640924]  energy_before :  40  energy_after :  50  reward :  -211.70371588607486\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "action : 1  next_temperatures :  [-0.11616967 -1.22128612 -0.97642479 -0.2777644   0.55949931 -1.09976135\n",
      "  0.36452582 -1.48274394  0.54640924]  energy_before :  50  energy_after :  50  reward :  -201.70371588607486\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "action : 1  next_temperatures :  [-0.11616967 -1.22128612 -0.97642479 -0.2777644   0.55949931 -1.09976135\n",
      "  0.36452582 -1.48274394  0.54640924]  energy_before :  50  energy_after :  50  reward :  -201.70371588607486\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "Episode 316/500, Total Reward: -1028.5185794303743\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "action : 1  next_temperatures :  [-0.5167446  -1.07050196 -0.36840691 -0.99689846 -1.1303806  -0.87340768\n",
      " -0.24410616 -0.67421372 -1.26895128]  energy_before :  30  energy_after :  50  reward :  -225.14361137664687\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "action : 1  next_temperatures :  [-0.5167446  -1.07050196 -0.36840691 -0.99689846 -1.1303806  -0.87340768\n",
      " -0.24410616 -0.67421372 -1.26895128]  energy_before :  50  energy_after :  40  reward :  -195.14361137664687\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "action : 1  next_temperatures :  [-0.5167446  -1.07050196 -0.36840691 -0.99689846 -1.1303806  -0.87340768\n",
      " -0.24410616 -0.67421372 -1.26895128]  energy_before :  40  energy_after :  50  reward :  -215.14361137664687\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "action : 1  next_temperatures :  [-0.5167446  -1.07050196 -0.36840691 -0.99689846 -1.1303806  -0.87340768\n",
      " -0.24410616 -0.67421372 -1.26895128]  energy_before :  50  energy_after :  50  reward :  -205.14361137664687\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "action : 1  next_temperatures :  [-0.5167446  -1.07050196 -0.36840691 -0.99689846 -1.1303806  -0.87340768\n",
      " -0.24410616 -0.67421372 -1.26895128]  energy_before :  50  energy_after :  50  reward :  -205.14361137664687\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "Episode 317/500, Total Reward: -1045.7180568832343\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "action : 1  next_temperatures :  [ 0.50648566 -0.21605843  1.39028481 -1.07143286  0.43155363 -0.35412573\n",
      "  0.7022921  -0.19892388  0.71555376]  energy_before :  30  energy_after :  50  reward :  -216.09437094539334\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "action : 1  next_temperatures :  [ 0.50648566 -0.21605843  1.39028481 -1.07143286  0.43155363 -0.35412573\n",
      "  0.7022921  -0.19892388  0.71555376]  energy_before :  50  energy_after :  40  reward :  -186.09437094539334\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "action : 1  next_temperatures :  [ 0.50648566 -0.21605843  1.39028481 -1.07143286  0.43155363 -0.35412573\n",
      "  0.7022921  -0.19892388  0.71555376]  energy_before :  40  energy_after :  50  reward :  -206.09437094539334\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "action : 1  next_temperatures :  [ 0.50648566 -0.21605843  1.39028481 -1.07143286  0.43155363 -0.35412573\n",
      "  0.7022921  -0.19892388  0.71555376]  energy_before :  50  energy_after :  50  reward :  -196.09437094539334\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "action : 1  next_temperatures :  [ 0.50648566 -0.21605843  1.39028481 -1.07143286  0.43155363 -0.35412573\n",
      "  0.7022921  -0.19892388  0.71555376]  energy_before :  50  energy_after :  50  reward :  -196.09437094539334\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "Episode 318/500, Total Reward: -1000.4718547269667\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "action : 1  next_temperatures :  [-1.2992148   0.23629403 -0.96274438  0.27264344 -1.23506343  0.44784225\n",
      " -0.85926503 -0.23654779 -0.97697563]  energy_before :  30  energy_after :  50  reward :  -222.61303135131257\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "action : 1  next_temperatures :  [-1.2992148   0.23629403 -0.96274438  0.27264344 -1.23506343  0.44784225\n",
      " -0.85926503 -0.23654779 -0.97697563]  energy_before :  50  energy_after :  40  reward :  -192.61303135131257\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "action : 1  next_temperatures :  [-1.2992148   0.23629403 -0.96274438  0.27264344 -1.23506343  0.44784225\n",
      " -0.85926503 -0.23654779 -0.97697563]  energy_before :  40  energy_after :  50  reward :  -212.61303135131257\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "action : 1  next_temperatures :  [-1.2992148   0.23629403 -0.96274438  0.27264344 -1.23506343  0.44784225\n",
      " -0.85926503 -0.23654779 -0.97697563]  energy_before :  50  energy_after :  50  reward :  -202.61303135131257\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "action : 1  next_temperatures :  [-1.2992148   0.23629403 -0.96274438  0.27264344 -1.23506343  0.44784225\n",
      " -0.85926503 -0.23654779 -0.97697563]  energy_before :  50  energy_after :  50  reward :  -202.61303135131257\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "Episode 319/500, Total Reward: -1033.0651567565628\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "action : 1  next_temperatures :  [-1.07298336  0.65430121 -0.61161406  0.5027991  -0.78143785  1.63389451\n",
      " -1.52990242  1.13019845 -1.13419329]  energy_before :  30  energy_after :  50  reward :  -219.2089377185083\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "action : 1  next_temperatures :  [-1.07298336  0.65430121 -0.61161406  0.5027991  -0.78143785  1.63389451\n",
      " -1.52990242  1.13019845 -1.13419329]  energy_before :  50  energy_after :  40  reward :  -189.2089377185083\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "action : 1  next_temperatures :  [-1.07298336  0.65430121 -0.61161406  0.5027991  -0.78143785  1.63389451\n",
      " -1.52990242  1.13019845 -1.13419329]  energy_before :  40  energy_after :  50  reward :  -209.2089377185083\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "action : 1  next_temperatures :  [-1.07298336  0.65430121 -0.61161406  0.5027991  -0.78143785  1.63389451\n",
      " -1.52990242  1.13019845 -1.13419329]  energy_before :  50  energy_after :  50  reward :  -199.2089377185083\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "action : 1  next_temperatures :  [-1.07298336  0.65430121 -0.61161406  0.5027991  -0.78143785  1.63389451\n",
      " -1.52990242  1.13019845 -1.13419329]  energy_before :  50  energy_after :  50  reward :  -199.2089377185083\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "Episode 320/500, Total Reward: -1016.0446885925415\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "action : 1  next_temperatures :  [-1.74130008  1.14937584 -0.97756482  0.87895208 -1.52917232  1.40037126\n",
      " -1.0730205   1.3444244  -2.10219625]  energy_before :  30  energy_after :  50  reward :  -220.65013039145248\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "action : 1  next_temperatures :  [-1.74130008  1.14937584 -0.97756482  0.87895208 -1.52917232  1.40037126\n",
      " -1.0730205   1.3444244  -2.10219625]  energy_before :  50  energy_after :  40  reward :  -190.65013039145248\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "action : 1  next_temperatures :  [-1.74130008  1.14937584 -0.97756482  0.87895208 -1.52917232  1.40037126\n",
      " -1.0730205   1.3444244  -2.10219625]  energy_before :  40  energy_after :  50  reward :  -210.65013039145248\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "action : 1  next_temperatures :  [-1.74130008  1.14937584 -0.97756482  0.87895208 -1.52917232  1.40037126\n",
      " -1.0730205   1.3444244  -2.10219625]  energy_before :  50  energy_after :  50  reward :  -200.65013039145248\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "action : 1  next_temperatures :  [-1.74130008  1.14937584 -0.97756482  0.87895208 -1.52917232  1.40037126\n",
      " -1.0730205   1.3444244  -2.10219625]  energy_before :  50  energy_after :  50  reward :  -200.65013039145248\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "Episode 321/500, Total Reward: -1023.2506519572623\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step\n",
      "action : 1  next_temperatures :  [-0.98788713 -0.09040497 -0.83962076  0.20814252 -0.73657378 -0.07451237\n",
      " -1.0110151  -0.02923235 -0.53785045]  energy_before :  30  energy_after :  50  reward :  -222.09895440264398\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step\n",
      "action : 1  next_temperatures :  [-0.98788713 -0.09040497 -0.83962076  0.20814252 -0.73657378 -0.07451237\n",
      " -1.0110151  -0.02923235 -0.53785045]  energy_before :  50  energy_after :  40  reward :  -192.09895440264398\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "action : 1  next_temperatures :  [-0.98788713 -0.09040497 -0.83962076  0.20814252 -0.73657378 -0.07451237\n",
      " -1.0110151  -0.02923235 -0.53785045]  energy_before :  40  energy_after :  50  reward :  -212.09895440264398\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "action : 1  next_temperatures :  [-0.98788713 -0.09040497 -0.83962076  0.20814252 -0.73657378 -0.07451237\n",
      " -1.0110151  -0.02923235 -0.53785045]  energy_before :  50  energy_after :  50  reward :  -202.09895440264398\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "action : 1  next_temperatures :  [-0.98788713 -0.09040497 -0.83962076  0.20814252 -0.73657378 -0.07451237\n",
      " -1.0110151  -0.02923235 -0.53785045]  energy_before :  50  energy_after :  50  reward :  -202.09895440264398\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "Episode 322/500, Total Reward: -1030.49477201322\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "action : 1  next_temperatures :  [-2.09413811  1.2993223  -1.06762747  0.91232875 -2.34337208  1.4515825\n",
      " -2.65742173  2.17368616 -2.27808727]  energy_before :  30  energy_after :  50  reward :  -222.60372693787926\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "action : 1  next_temperatures :  [-2.09413811  1.2993223  -1.06762747  0.91232875 -2.34337208  1.4515825\n",
      " -2.65742173  2.17368616 -2.27808727]  energy_before :  50  energy_after :  40  reward :  -192.60372693787926\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step\n",
      "action : 1  next_temperatures :  [-2.09413811  1.2993223  -1.06762747  0.91232875 -2.34337208  1.4515825\n",
      " -2.65742173  2.17368616 -2.27808727]  energy_before :  40  energy_after :  50  reward :  -212.60372693787926\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "action : 1  next_temperatures :  [-2.09413811  1.2993223  -1.06762747  0.91232875 -2.34337208  1.4515825\n",
      " -2.65742173  2.17368616 -2.27808727]  energy_before :  50  energy_after :  50  reward :  -202.60372693787926\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "action : 1  next_temperatures :  [-2.09413811  1.2993223  -1.06762747  0.91232875 -2.34337208  1.4515825\n",
      " -2.65742173  2.17368616 -2.27808727]  energy_before :  50  energy_after :  50  reward :  -202.60372693787926\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "Episode 323/500, Total Reward: -1033.0186346893963\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "action : 1  next_temperatures :  [0.81781333 1.28927003 0.43265665 1.53235664 1.41191661 0.58457625\n",
      " 0.31557419 0.55432222 0.7036269 ]  energy_before :  30  energy_after :  50  reward :  -210.35788719311685\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "action : 1  next_temperatures :  [0.81781333 1.28927003 0.43265665 1.53235664 1.41191661 0.58457625\n",
      " 0.31557419 0.55432222 0.7036269 ]  energy_before :  50  energy_after :  40  reward :  -180.35788719311685\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step\n",
      "action : 1  next_temperatures :  [0.81781333 1.28927003 0.43265665 1.53235664 1.41191661 0.58457625\n",
      " 0.31557419 0.55432222 0.7036269 ]  energy_before :  40  energy_after :  50  reward :  -200.35788719311685\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "action : 1  next_temperatures :  [0.81781333 1.28927003 0.43265665 1.53235664 1.41191661 0.58457625\n",
      " 0.31557419 0.55432222 0.7036269 ]  energy_before :  50  energy_after :  50  reward :  -190.35788719311685\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "action : 1  next_temperatures :  [0.81781333 1.28927003 0.43265665 1.53235664 1.41191661 0.58457625\n",
      " 0.31557419 0.55432222 0.7036269 ]  energy_before :  50  energy_after :  50  reward :  -190.35788719311685\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "Episode 324/500, Total Reward: -971.7894359655843\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "action : 1  next_temperatures :  [-0.55825495  0.99607862  0.07240605  0.64859166 -1.03068267  1.70456601\n",
      " -0.85926503  1.50490191 -1.02576732]  energy_before :  30  energy_after :  50  reward :  -216.54742572633614\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "action : 1  next_temperatures :  [-0.55825495  0.99607862  0.07240605  0.64859166 -1.03068267  1.70456601\n",
      " -0.85926503  1.50490191 -1.02576732]  energy_before :  50  energy_after :  40  reward :  -186.54742572633614\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step\n",
      "action : 1  next_temperatures :  [-0.55825495  0.99607862  0.07240605  0.64859166 -1.03068267  1.70456601\n",
      " -0.85926503  1.50490191 -1.02576732]  energy_before :  40  energy_after :  50  reward :  -206.54742572633614\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "action : 1  next_temperatures :  [-0.55825495  0.99607862  0.07240605  0.64859166 -1.03068267  1.70456601\n",
      " -0.85926503  1.50490191 -1.02576732]  energy_before :  50  energy_after :  50  reward :  -196.54742572633614\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step\n",
      "action : 1  next_temperatures :  [-0.55825495  0.99607862  0.07240605  0.64859166 -1.03068267  1.70456601\n",
      " -0.85926503  1.50490191 -1.02576732]  energy_before :  50  energy_after :  50  reward :  -196.54742572633614\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "Episode 325/500, Total Reward: -1002.7371286316807\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step\n",
      "action : 1  next_temperatures :  [-0.9256216  -0.92223088 -0.88978224 -0.76919998 -0.93596964 -0.62759374\n",
      " -0.76625693 -0.88997534 -0.48363747]  energy_before :  30  energy_after :  50  reward :  -225.2102678188516\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "action : 1  next_temperatures :  [-0.9256216  -0.92223088 -0.88978224 -0.76919998 -0.93596964 -0.62759374\n",
      " -0.76625693 -0.88997534 -0.48363747]  energy_before :  50  energy_after :  40  reward :  -195.2102678188516\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "action : 1  next_temperatures :  [-0.9256216  -0.92223088 -0.88978224 -0.76919998 -0.93596964 -0.62759374\n",
      " -0.76625693 -0.88997534 -0.48363747]  energy_before :  40  energy_after :  50  reward :  -215.2102678188516\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step\n",
      "action : 1  next_temperatures :  [-0.9256216  -0.92223088 -0.88978224 -0.76919998 -0.93596964 -0.62759374\n",
      " -0.76625693 -0.88997534 -0.48363747]  energy_before :  50  energy_after :  50  reward :  -205.2102678188516\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "action : 1  next_temperatures :  [-0.9256216  -0.92223088 -0.88978224 -0.76919998 -0.93596964 -0.62759374\n",
      " -0.76625693 -0.88997534 -0.48363747]  energy_before :  50  energy_after :  50  reward :  -205.2102678188516\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "Episode 326/500, Total Reward: -1046.051339094258\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "action : 1  next_temperatures :  [-0.55825495 -0.95406309 -0.43376883 -1.00590812 -0.58204199 -0.88467415\n",
      " -0.50518155 -1.00668626 -0.79342595]  energy_before :  30  energy_after :  50  reward :  -224.72400488880672\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "action : 1  next_temperatures :  [-0.55825495 -0.95406309 -0.43376883 -1.00590812 -0.58204199 -0.88467415\n",
      " -0.50518155 -1.00668626 -0.79342595]  energy_before :  50  energy_after :  40  reward :  -194.72400488880672\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "action : 1  next_temperatures :  [-0.55825495 -0.95406309 -0.43376883 -1.00590812 -0.58204199 -0.88467415\n",
      " -0.50518155 -1.00668626 -0.79342595]  energy_before :  40  energy_after :  50  reward :  -214.72400488880672\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "action : 1  next_temperatures :  [-0.55825495 -0.95406309 -0.43376883 -1.00590812 -0.58204199 -0.88467415\n",
      " -0.50518155 -1.00668626 -0.79342595]  energy_before :  50  energy_after :  50  reward :  -204.72400488880672\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "action : 1  next_temperatures :  [-0.55825495 -0.95406309 -0.43376883 -1.00590812 -0.58204199 -0.88467415\n",
      " -0.50518155 -1.00668626 -0.79342595]  energy_before :  50  energy_after :  50  reward :  -204.72400488880672\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "Episode 327/500, Total Reward: -1043.6200244440336\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step\n",
      "action : 1  next_temperatures :  [-0.20541693  0.66351579 -0.66177553  1.60033856  0.46478627  0.45501182\n",
      " -0.56555523  0.18422577 -0.19630865]  energy_before :  30  energy_after :  50  reward :  -216.2611781292647\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "action : 1  next_temperatures :  [-0.20541693  0.66351579 -0.66177553  1.60033856  0.46478627  0.45501182\n",
      " -0.56555523  0.18422577 -0.19630865]  energy_before :  50  energy_after :  40  reward :  -186.2611781292647\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step\n",
      "action : 1  next_temperatures :  [-0.20541693  0.66351579 -0.66177553  1.60033856  0.46478627  0.45501182\n",
      " -0.56555523  0.18422577 -0.19630865]  energy_before :  40  energy_after :  50  reward :  -206.2611781292647\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "action : 1  next_temperatures :  [-0.20541693  0.66351579 -0.66177553  1.60033856  0.46478627  0.45501182\n",
      " -0.56555523  0.18422577 -0.19630865]  energy_before :  50  energy_after :  50  reward :  -196.2611781292647\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "action : 1  next_temperatures :  [-0.20541693  0.66351579 -0.66177553  1.60033856  0.46478627  0.45501182\n",
      " -0.56555523  0.18422577 -0.19630865]  energy_before :  50  energy_after :  50  reward :  -196.2611781292647\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "Episode 328/500, Total Reward: -1001.3058906463234\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "action : 1  next_temperatures :  [-1.74130008  0.99021479 -0.97642479  0.87956638 -1.14865856  1.79674624\n",
      " -1.15297484  1.19162524 -1.31490324]  energy_before :  30  energy_after :  50  reward :  -219.47610885034803\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "action : 1  next_temperatures :  [-1.74130008  0.99021479 -0.97642479  0.87956638 -1.14865856  1.79674624\n",
      " -1.15297484  1.19162524 -1.31490324]  energy_before :  50  energy_after :  40  reward :  -189.47610885034803\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step\n",
      "action : 1  next_temperatures :  [-1.74130008  0.99021479 -0.97642479  0.87956638 -1.14865856  1.79674624\n",
      " -1.15297484  1.19162524 -1.31490324]  energy_before :  40  energy_after :  50  reward :  -209.47610885034803\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step\n",
      "action : 1  next_temperatures :  [-1.74130008  0.99021479 -0.97642479  0.87956638 -1.14865856  1.79674624\n",
      " -1.15297484  1.19162524 -1.31490324]  energy_before :  50  energy_after :  50  reward :  -199.47610885034803\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "action : 1  next_temperatures :  [-1.74130008  0.99021479 -0.97642479  0.87956638 -1.14865856  1.79674624\n",
      " -1.15297484  1.19162524 -1.31490324]  energy_before :  50  energy_after :  50  reward :  -199.47610885034803\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "Episode 329/500, Total Reward: -1017.3805442517402\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "action : 1  next_temperatures :  [ 0.31968906 -0.84432573 -0.33800601 -0.2114206   0.36508834 -0.71977397\n",
      " -0.61450686 -0.21581625 -0.26678553]  energy_before :  30  energy_after :  50  reward :  -220.52585754524833\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "action : 1  next_temperatures :  [ 0.31968906 -0.84432573 -0.33800601 -0.2114206   0.36508834 -0.71977397\n",
      " -0.61450686 -0.21581625 -0.26678553]  energy_before :  50  energy_after :  40  reward :  -190.52585754524833\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "action : 1  next_temperatures :  [ 0.31968906 -0.84432573 -0.33800601 -0.2114206   0.36508834 -0.71977397\n",
      " -0.61450686 -0.21581625 -0.26678553]  energy_before :  40  energy_after :  50  reward :  -210.52585754524833\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "action : 1  next_temperatures :  [ 0.31968906 -0.84432573 -0.33800601 -0.2114206   0.36508834 -0.71977397\n",
      " -0.61450686 -0.21581625 -0.26678553]  energy_before :  50  energy_after :  50  reward :  -200.52585754524833\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "action : 1  next_temperatures :  [ 0.31968906 -0.84432573 -0.33800601 -0.2114206   0.36508834 -0.71977397\n",
      " -0.61450686 -0.21581625 -0.26678553]  energy_before :  50  energy_after :  50  reward :  -200.52585754524833\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step\n",
      "Episode 330/500, Total Reward: -1022.6292877262416\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step\n",
      "action : 1  next_temperatures :  [0.31968906 1.19126033 0.49497848 1.08269308 0.21554145 0.86572594\n",
      " 0.16871929 1.3444244  0.10728407]  energy_before :  30  energy_after :  50  reward :  -212.20968389979882\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "action : 1  next_temperatures :  [0.31968906 1.19126033 0.49497848 1.08269308 0.21554145 0.86572594\n",
      " 0.16871929 1.3444244  0.10728407]  energy_before :  50  energy_after :  40  reward :  -182.20968389979882\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "action : 1  next_temperatures :  [0.31968906 1.19126033 0.49497848 1.08269308 0.21554145 0.86572594\n",
      " 0.16871929 1.3444244  0.10728407]  energy_before :  40  energy_after :  50  reward :  -202.20968389979882\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "action : 1  next_temperatures :  [0.31968906 1.19126033 0.49497848 1.08269308 0.21554145 0.86572594\n",
      " 0.16871929 1.3444244  0.10728407]  energy_before :  50  energy_after :  50  reward :  -192.20968389979882\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "action : 1  next_temperatures :  [0.31968906 1.19126033 0.49497848 1.08269308 0.21554145 0.86572594\n",
      " 0.16871929 1.3444244  0.10728407]  energy_before :  50  energy_after :  50  reward :  -192.20968389979882\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "Episode 331/500, Total Reward: -981.0484194989941\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step\n",
      "action : 1  next_temperatures :  [-0.03314896  0.38456511 -0.40032785  1.24814306  0.54288298  0.2511911\n",
      " -0.52149876  0.16886907 -0.16378086]  energy_before :  30  energy_after :  50  reward :  -216.52310509620267\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "action : 1  next_temperatures :  [-0.03314896  0.38456511 -0.40032785  1.24814306  0.54288298  0.2511911\n",
      " -0.52149876  0.16886907 -0.16378086]  energy_before :  50  energy_after :  40  reward :  -186.52310509620267\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "action : 1  next_temperatures :  [-0.03314896  0.38456511 -0.40032785  1.24814306  0.54288298  0.2511911\n",
      " -0.52149876  0.16886907 -0.16378086]  energy_before :  40  energy_after :  50  reward :  -206.52310509620267\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "action : 1  next_temperatures :  [-0.03314896  0.38456511 -0.40032785  1.24814306  0.54288298  0.2511911\n",
      " -0.52149876  0.16886907 -0.16378086]  energy_before :  50  energy_after :  50  reward :  -196.52310509620267\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step\n",
      "action : 1  next_temperatures :  [-0.03314896  0.38456511 -0.40032785  1.24814306  0.54288298  0.2511911\n",
      " -0.52149876  0.16886907 -0.16378086]  energy_before :  50  energy_after :  50  reward :  -196.52310509620267\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "Episode 332/500, Total Reward: -1002.6155254810134\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "action : 1  next_temperatures :  [-0.30296627 -1.78253824 -0.36840691 -1.93144512  0.19726349 -1.42751327\n",
      "  0.44284844 -1.80293112 -0.48363747]  energy_before :  30  energy_after :  50  reward :  -225.45932645579754\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "action : 1  next_temperatures :  [-0.30296627 -1.78253824 -0.36840691 -1.93144512  0.19726349 -1.42751327\n",
      "  0.44284844 -1.80293112 -0.48363747]  energy_before :  50  energy_after :  40  reward :  -195.45932645579754\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "action : 1  next_temperatures :  [-0.30296627 -1.78253824 -0.36840691 -1.93144512  0.19726349 -1.42751327\n",
      "  0.44284844 -1.80293112 -0.48363747]  energy_before :  40  energy_after :  50  reward :  -215.45932645579754\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "action : 1  next_temperatures :  [-0.30296627 -1.78253824 -0.36840691 -1.93144512  0.19726349 -1.42751327\n",
      "  0.44284844 -1.80293112 -0.48363747]  energy_before :  50  energy_after :  50  reward :  -205.45932645579754\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "action : 1  next_temperatures :  [-0.30296627 -1.78253824 -0.36840691 -1.93144512  0.19726349 -1.42751327\n",
      "  0.44284844 -1.80293112 -0.48363747]  energy_before :  50  energy_after :  50  reward :  -205.45932645579754\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "Episode 333/500, Total Reward: -1047.2966322789878\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step\n",
      "action : 1  next_temperatures :  [ 0.23666835 -1.28076209 -0.74841808 -0.4006233   0.47974096 -1.40907722\n",
      "  0.45753393 -1.58271605  0.68555591]  energy_before :  30  energy_after :  50  reward :  -221.56209758976902\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step\n",
      "action : 1  next_temperatures :  [ 0.23666835 -1.28076209 -0.74841808 -0.4006233   0.47974096 -1.40907722\n",
      "  0.45753393 -1.58271605  0.68555591]  energy_before :  50  energy_after :  40  reward :  -191.56209758976902\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step\n",
      "action : 1  next_temperatures :  [ 0.23666835 -1.28076209 -0.74841808 -0.4006233   0.47974096 -1.40907722\n",
      "  0.45753393 -1.58271605  0.68555591]  energy_before :  40  energy_after :  50  reward :  -211.56209758976902\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step\n",
      "action : 1  next_temperatures :  [ 0.23666835 -1.28076209 -0.74841808 -0.4006233   0.47974096 -1.40907722\n",
      "  0.45753393 -1.58271605  0.68555591]  energy_before :  50  energy_after :  50  reward :  -201.56209758976902\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "action : 1  next_temperatures :  [ 0.23666835 -1.28076209 -0.74841808 -0.4006233   0.47974096 -1.40907722\n",
      "  0.45753393 -1.58271605  0.68555591]  energy_before :  50  energy_after :  50  reward :  -201.56209758976902\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "Episode 334/500, Total Reward: -1027.810487948845\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "action : 1  next_temperatures :  [ 0.43799358  0.76152549  0.61962214  0.63384859 -0.2829482   1.70456601\n",
      " -0.85926503  1.26764091 -0.1881767 ]  energy_before :  30  energy_after :  50  reward :  -213.90519321270096\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "action : 1  next_temperatures :  [ 0.43799358  0.76152549  0.61962214  0.63384859 -0.2829482   1.70456601\n",
      " -0.85926503  1.26764091 -0.1881767 ]  energy_before :  50  energy_after :  40  reward :  -183.90519321270096\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "action : 1  next_temperatures :  [ 0.43799358  0.76152549  0.61962214  0.63384859 -0.2829482   1.70456601\n",
      " -0.85926503  1.26764091 -0.1881767 ]  energy_before :  40  energy_after :  50  reward :  -203.90519321270096\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "action : 1  next_temperatures :  [ 0.43799358  0.76152549  0.61962214  0.63384859 -0.2829482   1.70456601\n",
      " -0.85926503  1.26764091 -0.1881767 ]  energy_before :  50  energy_after :  50  reward :  -193.90519321270096\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step\n",
      "action : 1  next_temperatures :  [ 0.43799358  0.76152549  0.61962214  0.63384859 -0.2829482   1.70456601\n",
      " -0.85926503  1.26764091 -0.1881767 ]  energy_before :  50  energy_after :  50  reward :  -193.90519321270096\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "Episode 335/500, Total Reward: -989.5259660635048\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "action : 1  next_temperatures :  [ 0.06440038 -0.62820178  1.25804092 -1.45475261  0.26040552 -1.06084081\n",
      "  0.84005598 -0.91279101  0.22113133]  energy_before :  30  energy_after :  50  reward :  -219.41255208157395\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "action : 1  next_temperatures :  [ 0.06440038 -0.62820178  1.25804092 -1.45475261  0.26040552 -1.06084081\n",
      "  0.84005598 -0.91279101  0.22113133]  energy_before :  50  energy_after :  40  reward :  -189.41255208157395\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "action : 1  next_temperatures :  [ 0.06440038 -0.62820178  1.25804092 -1.45475261  0.26040552 -1.06084081\n",
      "  0.84005598 -0.91279101  0.22113133]  energy_before :  40  energy_after :  50  reward :  -209.41255208157395\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "action : 1  next_temperatures :  [ 0.06440038 -0.62820178  1.25804092 -1.45475261  0.26040552 -1.06084081\n",
      "  0.84005598 -0.91279101  0.22113133]  energy_before :  50  energy_after :  50  reward :  -199.41255208157395\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "action : 1  next_temperatures :  [ 0.06440038 -0.62820178  1.25804092 -1.45475261  0.26040552 -1.06084081\n",
      "  0.84005598 -0.91279101  0.22113133]  energy_before :  50  energy_after :  50  reward :  -199.41255208157395\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "Episode 336/500, Total Reward: -1017.0627604078697\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "action : 1  next_temperatures :  [ 0.06440038  2.57093532  0.3460141   1.647844    0.06100966  2.29042257\n",
      " -0.17394215  1.81357156  0.05849238]  energy_before :  30  energy_after :  50  reward :  -209.32125218561129\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "action : 1  next_temperatures :  [ 0.06440038  2.57093532  0.3460141   1.647844    0.06100966  2.29042257\n",
      " -0.17394215  1.81357156  0.05849238]  energy_before :  50  energy_after :  40  reward :  -179.32125218561129\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "action : 1  next_temperatures :  [ 0.06440038  2.57093532  0.3460141   1.647844    0.06100966  2.29042257\n",
      " -0.17394215  1.81357156  0.05849238]  energy_before :  40  energy_after :  50  reward :  -199.32125218561129\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step\n",
      "action : 1  next_temperatures :  [ 0.06440038  2.57093532  0.3460141   1.647844    0.06100966  2.29042257\n",
      " -0.17394215  1.81357156  0.05849238]  energy_before :  50  energy_after :  50  reward :  -189.32125218561129\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "action : 1  next_temperatures :  [ 0.06440038  2.57093532  0.3460141   1.647844    0.06100966  2.29042257\n",
      " -0.17394215  1.81357156  0.05849238]  energy_before :  50  energy_after :  50  reward :  -189.32125218561129\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "Episode 337/500, Total Reward: -966.6062609280564\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "action : 1  next_temperatures :  [-0.30296627  0.88717895  0.11800739  0.45938896 -0.23808413  1.95037995\n",
      " -0.03198241  1.49108088  0.0042794 ]  energy_before :  30  energy_after :  50  reward :  -213.66271727914227\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "action : 1  next_temperatures :  [-0.30296627  0.88717895  0.11800739  0.45938896 -0.23808413  1.95037995\n",
      " -0.03198241  1.49108088  0.0042794 ]  energy_before :  50  energy_after :  40  reward :  -183.66271727914227\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "action : 1  next_temperatures :  [-0.30296627  0.88717895  0.11800739  0.45938896 -0.23808413  1.95037995\n",
      " -0.03198241  1.49108088  0.0042794 ]  energy_before :  40  energy_after :  50  reward :  -203.66271727914227\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "action : 1  next_temperatures :  [-0.30296627  0.88717895  0.11800739  0.45938896 -0.23808413  1.95037995\n",
      " -0.03198241  1.49108088  0.0042794 ]  energy_before :  50  energy_after :  50  reward :  -193.66271727914227\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "action : 1  next_temperatures :  [-0.30296627  0.88717895  0.11800739  0.45938896 -0.23808413  1.95037995\n",
      " -0.03198241  1.49108088  0.0042794 ]  energy_before :  50  energy_after :  50  reward :  -193.66271727914227\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "Episode 338/500, Total Reward: -988.3135863957114\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "action : 1  next_temperatures :  [ 0.68705571 -0.10799646  0.6758638  -0.46450992  0.36508834 -0.41250654\n",
      "  0.60928399 -0.60096226  0.64941392]  energy_before :  30  energy_after :  50  reward :  -216.5992694242123\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step\n",
      "action : 1  next_temperatures :  [ 0.68705571 -0.10799646  0.6758638  -0.46450992  0.36508834 -0.41250654\n",
      "  0.60928399 -0.60096226  0.64941392]  energy_before :  50  energy_after :  40  reward :  -186.5992694242123\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "action : 1  next_temperatures :  [ 0.68705571 -0.10799646  0.6758638  -0.46450992  0.36508834 -0.41250654\n",
      "  0.60928399 -0.60096226  0.64941392]  energy_before :  40  energy_after :  50  reward :  -206.5992694242123\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "action : 1  next_temperatures :  [ 0.68705571 -0.10799646  0.6758638  -0.46450992  0.36508834 -0.41250654\n",
      "  0.60928399 -0.60096226  0.64941392]  energy_before :  50  energy_after :  50  reward :  -196.5992694242123\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "action : 1  next_temperatures :  [ 0.68705571 -0.10799646  0.6758638  -0.46450992  0.36508834 -0.41250654\n",
      "  0.60928399 -0.60096226  0.64941392]  energy_before :  50  energy_after :  50  reward :  -196.5992694242123\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "Episode 339/500, Total Reward: -1002.9963471210615\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "action : 1  next_temperatures :  [-0.86958262 -1.28076209 -1.6604449  -0.10330477 -1.03068267 -0.68904722\n",
      " -0.74178111 -1.09114811 -0.80891538]  energy_before :  30  energy_after :  50  reward :  -226.27566887181655\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "action : 1  next_temperatures :  [-0.86958262 -1.28076209 -1.6604449  -0.10330477 -1.03068267 -0.68904722\n",
      " -0.74178111 -1.09114811 -0.80891538]  energy_before :  50  energy_after :  40  reward :  -196.27566887181655\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "action : 1  next_temperatures :  [-0.86958262 -1.28076209 -1.6604449  -0.10330477 -1.03068267 -0.68904722\n",
      " -0.74178111 -1.09114811 -0.80891538]  energy_before :  40  energy_after :  50  reward :  -216.27566887181655\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "action : 1  next_temperatures :  [-0.86958262 -1.28076209 -1.6604449  -0.10330477 -1.03068267 -0.68904722\n",
      " -0.74178111 -1.09114811 -0.80891538]  energy_before :  50  energy_after :  50  reward :  -206.27566887181655\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "action : 1  next_temperatures :  [-0.86958262 -1.28076209 -1.6604449  -0.10330477 -1.03068267 -0.68904722\n",
      " -0.74178111 -1.09114811 -0.80891538]  energy_before :  50  energy_after :  50  reward :  -206.27566887181655\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "Episode 340/500, Total Reward: -1051.3783443590828\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step\n",
      "action : 1  next_temperatures :  [ 0.31968906 -0.74631603  0.98443287 -1.20903482 -0.08355234 -0.84268094\n",
      "  0.59296678 -0.84390525 -0.30744527]  energy_before :  30  energy_after :  50  reward :  -220.13584593036833\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "action : 1  next_temperatures :  [ 0.31968906 -0.74631603  0.98443287 -1.20903482 -0.08355234 -0.84268094\n",
      "  0.59296678 -0.84390525 -0.30744527]  energy_before :  50  energy_after :  40  reward :  -190.13584593036833\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step\n",
      "action : 1  next_temperatures :  [ 0.31968906 -0.74631603  0.98443287 -1.20903482 -0.08355234 -0.84268094\n",
      "  0.59296678 -0.84390525 -0.30744527]  energy_before :  40  energy_after :  50  reward :  -210.13584593036833\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "action : 1  next_temperatures :  [ 0.31968906 -0.74631603  0.98443287 -1.20903482 -0.08355234 -0.84268094\n",
      "  0.59296678 -0.84390525 -0.30744527]  energy_before :  50  energy_after :  50  reward :  -200.13584593036833\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step\n",
      "action : 1  next_temperatures :  [ 0.31968906 -0.74631603  0.98443287 -1.20903482 -0.08355234 -0.84268094\n",
      "  0.59296678 -0.84390525 -0.30744527]  energy_before :  50  energy_after :  50  reward :  -200.13584593036833\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step\n",
      "Episode 341/500, Total Reward: -1020.6792296518416\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "action : 1  next_temperatures :  [-1.38431103 -0.65249478 -1.40507739 -0.11149537 -1.08053164 -0.56614025\n",
      " -1.50053144 -0.44616674 -0.65169772]  energy_before :  30  energy_after :  50  reward :  -225.79844636005956\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "action : 1  next_temperatures :  [-1.38431103 -0.65249478 -1.40507739 -0.11149537 -1.08053164 -0.56614025\n",
      " -1.50053144 -0.44616674 -0.65169772]  energy_before :  50  energy_after :  40  reward :  -195.79844636005956\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step\n",
      "action : 1  next_temperatures :  [-1.38431103 -0.65249478 -1.40507739 -0.11149537 -1.08053164 -0.56614025\n",
      " -1.50053144 -0.44616674 -0.65169772]  energy_before :  40  energy_after :  50  reward :  -215.79844636005956\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "action : 1  next_temperatures :  [-1.38431103 -0.65249478 -1.40507739 -0.11149537 -1.08053164 -0.56614025\n",
      " -1.50053144 -0.44616674 -0.65169772]  energy_before :  50  energy_after :  50  reward :  -205.79844636005956\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step\n",
      "action : 1  next_temperatures :  [-1.38431103 -0.65249478 -1.40507739 -0.11149537 -1.08053164 -0.56614025\n",
      " -1.50053144 -0.44616674 -0.65169772]  energy_before :  50  energy_after :  50  reward :  -205.79844636005956\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step\n",
      "Episode 342/500, Total Reward: -1048.9922318002978\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step\n",
      "action : 1  next_temperatures :  [ 0.68705571 -1.32180888  0.04732532 -1.02597507  0.32853244 -0.93486116\n",
      "  0.80509053 -1.22705489  0.87168715]  energy_before :  30  energy_after :  50  reward :  -219.77000886506968\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "action : 1  next_temperatures :  [ 0.68705571 -1.32180888  0.04732532 -1.02597507  0.32853244 -0.93486116\n",
      "  0.80509053 -1.22705489  0.87168715]  energy_before :  50  energy_after :  40  reward :  -189.77000886506968\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "action : 1  next_temperatures :  [ 0.68705571 -1.32180888  0.04732532 -1.02597507  0.32853244 -0.93486116\n",
      "  0.80509053 -1.22705489  0.87168715]  energy_before :  40  energy_after :  50  reward :  -209.77000886506968\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "action : 1  next_temperatures :  [ 0.68705571 -1.32180888  0.04732532 -1.02597507  0.32853244 -0.93486116\n",
      "  0.80509053 -1.22705489  0.87168715]  energy_before :  50  energy_after :  50  reward :  -199.77000886506968\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "action : 1  next_temperatures :  [ 0.68705571 -1.32180888  0.04732532 -1.02597507  0.32853244 -0.93486116\n",
      "  0.80509053 -1.22705489  0.87168715]  energy_before :  50  energy_after :  50  reward :  -199.77000886506968\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step\n",
      "Episode 343/500, Total Reward: -1018.8500443253484\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step\n",
      "action : 1  next_temperatures :  [-0.22617211 -1.06296275 -0.70737688 -0.71022771 -0.66844686 -1.23291056\n",
      "  0.22909297 -1.09805862 -0.43484578]  energy_before :  30  energy_after :  50  reward :  -223.91190831382968\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "action : 1  next_temperatures :  [-0.22617211 -1.06296275 -0.70737688 -0.71022771 -0.66844686 -1.23291056\n",
      "  0.22909297 -1.09805862 -0.43484578]  energy_before :  50  energy_after :  40  reward :  -193.91190831382968\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step\n",
      "action : 1  next_temperatures :  [-0.22617211 -1.06296275 -0.70737688 -0.71022771 -0.66844686 -1.23291056\n",
      "  0.22909297 -1.09805862 -0.43484578]  energy_before :  40  energy_after :  50  reward :  -213.91190831382968\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "action : 1  next_temperatures :  [-0.22617211 -1.06296275 -0.70737688 -0.71022771 -0.66844686 -1.23291056\n",
      "  0.22909297 -1.09805862 -0.43484578]  energy_before :  50  energy_after :  50  reward :  -203.91190831382968\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step\n",
      "action : 1  next_temperatures :  [-0.22617211 -1.06296275 -0.70737688 -0.71022771 -0.66844686 -1.23291056\n",
      "  0.22909297 -1.09805862 -0.43484578]  energy_before :  50  energy_after :  50  reward :  -203.91190831382968\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "Episode 344/500, Total Reward: -1039.5595415691485\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "action : 1  next_temperatures :  [ 0.31968906 -1.48180762 -0.10999931 -1.12876701  0.29363816 -0.93486116\n",
      "  0.85404217 -1.3981724   0.45244007]  energy_before :  30  energy_after :  50  reward :  -221.1337980486912\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "action : 1  next_temperatures :  [ 0.31968906 -1.48180762 -0.10999931 -1.12876701  0.29363816 -0.93486116\n",
      "  0.85404217 -1.3981724   0.45244007]  energy_before :  50  energy_after :  40  reward :  -191.1337980486912\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "action : 1  next_temperatures :  [ 0.31968906 -1.48180762 -0.10999931 -1.12876701  0.29363816 -0.93486116\n",
      "  0.85404217 -1.3981724   0.45244007]  energy_before :  40  energy_after :  50  reward :  -211.1337980486912\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "action : 1  next_temperatures :  [ 0.31968906 -1.48180762 -0.10999931 -1.12876701  0.29363816 -0.93486116\n",
      "  0.85404217 -1.3981724   0.45244007]  energy_before :  50  energy_after :  50  reward :  -201.1337980486912\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "action : 1  next_temperatures :  [ 0.31968906 -1.48180762 -0.10999931 -1.12876701  0.29363816 -0.93486116\n",
      "  0.85404217 -1.3981724   0.45244007]  energy_before :  50  energy_after :  50  reward :  -201.1337980486912\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "Episode 345/500, Total Reward: -1025.668990243456\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "action : 1  next_temperatures :  [ 0.12666591 -0.13312715  0.20464994 -0.07218052  0.21554145 -0.53541351\n",
      " -0.17394215 -0.07530245  0.43256198]  energy_before :  30  energy_after :  50  reward :  -218.01054650339648\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "action : 1  next_temperatures :  [ 0.12666591 -0.13312715  0.20464994 -0.07218052  0.21554145 -0.53541351\n",
      " -0.17394215 -0.07530245  0.43256198]  energy_before :  50  energy_after :  40  reward :  -188.01054650339648\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step\n",
      "action : 1  next_temperatures :  [ 0.12666591 -0.13312715  0.20464994 -0.07218052  0.21554145 -0.53541351\n",
      " -0.17394215 -0.07530245  0.43256198]  energy_before :  40  energy_after :  50  reward :  -208.01054650339648\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "action : 1  next_temperatures :  [ 0.12666591 -0.13312715  0.20464994 -0.07218052  0.21554145 -0.53541351\n",
      " -0.17394215 -0.07530245  0.43256198]  energy_before :  50  energy_after :  50  reward :  -198.01054650339648\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "action : 1  next_temperatures :  [ 0.12666591 -0.13312715  0.20464994 -0.07218052  0.21554145 -0.53541351\n",
      " -0.17394215 -0.07530245  0.43256198]  energy_before :  50  energy_after :  50  reward :  -198.01054650339648\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step\n",
      "Episode 346/500, Total Reward: -1010.0527325169824\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "action : 1  next_temperatures :  [-0.55825495 -1.10254359  0.77162661 -2.00352234 -0.43747999 -1.36810823\n",
      "  0.16871929 -0.66807104 -0.48363747]  energy_before :  30  energy_after :  50  reward :  -223.68127171889122\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "action : 1  next_temperatures :  [-0.55825495 -1.10254359  0.77162661 -2.00352234 -0.43747999 -1.36810823\n",
      "  0.16871929 -0.66807104 -0.48363747]  energy_before :  50  energy_after :  40  reward :  -193.68127171889122\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "action : 1  next_temperatures :  [-0.55825495 -1.10254359  0.77162661 -2.00352234 -0.43747999 -1.36810823\n",
      "  0.16871929 -0.66807104 -0.48363747]  energy_before :  40  energy_after :  50  reward :  -213.68127171889122\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "action : 1  next_temperatures :  [-0.55825495 -1.10254359  0.77162661 -2.00352234 -0.43747999 -1.36810823\n",
      "  0.16871929 -0.66807104 -0.48363747]  energy_before :  50  energy_after :  50  reward :  -203.68127171889122\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step\n",
      "action : 1  next_temperatures :  [-0.55825495 -1.10254359  0.77162661 -2.00352234 -0.43747999 -1.36810823\n",
      "  0.16871929 -0.66807104 -0.48363747]  energy_before :  50  energy_after :  50  reward :  -203.68127171889122\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "Episode 347/500, Total Reward: -1038.4063585944562\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step\n",
      "action : 1  next_temperatures :  [ 0.195158   -0.82757194  0.16360874 -0.85683933 -0.68672482 -0.21995229\n",
      " -0.07603889 -0.88997534 -0.45110968]  energy_before :  30  energy_after :  50  reward :  -221.64944554405554\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "action : 1  next_temperatures :  [ 0.195158   -0.82757194  0.16360874 -0.85683933 -0.68672482 -0.21995229\n",
      " -0.07603889 -0.88997534 -0.45110968]  energy_before :  50  energy_after :  40  reward :  -191.64944554405554\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step\n",
      "action : 1  next_temperatures :  [ 0.195158   -0.82757194  0.16360874 -0.85683933 -0.68672482 -0.21995229\n",
      " -0.07603889 -0.88997534 -0.45110968]  energy_before :  40  energy_after :  50  reward :  -211.64944554405554\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "action : 1  next_temperatures :  [ 0.195158   -0.82757194  0.16360874 -0.85683933 -0.68672482 -0.21995229\n",
      " -0.07603889 -0.88997534 -0.45110968]  energy_before :  50  energy_after :  50  reward :  -201.64944554405554\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "action : 1  next_temperatures :  [ 0.195158   -0.82757194  0.16360874 -0.85683933 -0.68672482 -0.21995229\n",
      " -0.07603889 -0.88997534 -0.45110968]  energy_before :  50  energy_after :  50  reward :  -201.64944554405554\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "Episode 348/500, Total Reward: -1028.2472277202778\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "action : 1  next_temperatures :  [-0.5167446   0.21032564 -0.79401942  0.9917775   0.01116069 -0.28140577\n",
      " -0.34527287 -0.14440759  0.27534432]  energy_before :  30  energy_after :  50  reward :  -218.59324210365702\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "action : 1  next_temperatures :  [-0.5167446   0.21032564 -0.79401942  0.9917775   0.01116069 -0.28140577\n",
      " -0.34527287 -0.14440759  0.27534432]  energy_before :  50  energy_after :  40  reward :  -188.59324210365702\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "action : 1  next_temperatures :  [-0.5167446   0.21032564 -0.79401942  0.9917775   0.01116069 -0.28140577\n",
      " -0.34527287 -0.14440759  0.27534432]  energy_before :  40  energy_after :  50  reward :  -208.59324210365702\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "action : 1  next_temperatures :  [-0.5167446   0.21032564 -0.79401942  0.9917775   0.01116069 -0.28140577\n",
      " -0.34527287 -0.14440759  0.27534432]  energy_before :  50  energy_after :  50  reward :  -198.59324210365702\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step\n",
      "action : 1  next_temperatures :  [-0.5167446   0.21032564 -0.79401942  0.9917775   0.01116069 -0.28140577\n",
      " -0.34527287 -0.14440759  0.27534432]  energy_before :  50  energy_after :  50  reward :  -198.59324210365702\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "Episode 349/500, Total Reward: -1012.9662105182852\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "action : 1  next_temperatures :  [-0.30296627 -0.01501289  0.02224458 -0.30888866 -0.48732896  1.09003116\n",
      " -0.47254712  0.67717582 -0.70591071]  energy_before :  30  energy_after :  50  reward :  -218.5032030449277\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "action : 1  next_temperatures :  [-0.30296627 -0.01501289  0.02224458 -0.30888866 -0.48732896  1.09003116\n",
      " -0.47254712  0.67717582 -0.70591071]  energy_before :  50  energy_after :  40  reward :  -188.5032030449277\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "action : 1  next_temperatures :  [-0.30296627 -0.01501289  0.02224458 -0.30888866 -0.48732896  1.09003116\n",
      " -0.47254712  0.67717582 -0.70591071]  energy_before :  40  energy_after :  50  reward :  -208.5032030449277\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "action : 1  next_temperatures :  [-0.30296627 -0.01501289  0.02224458 -0.30888866 -0.48732896  1.09003116\n",
      " -0.47254712  0.67717582 -0.70591071]  energy_before :  50  energy_after :  50  reward :  -198.5032030449277\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "action : 1  next_temperatures :  [-0.30296627 -0.01501289  0.02224458 -0.30888866 -0.48732896  1.09003116\n",
      " -0.47254712  0.67717582 -0.70591071]  energy_before :  50  energy_after :  50  reward :  -198.5032030449277\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "Episode 350/500, Total Reward: -1012.5160152246384\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "action : 1  next_temperatures :  [-0.55825495 -0.6432802  -0.52041138 -0.24254485 -0.13340131 -1.36810823\n",
      "  0.16871929 -0.66730321  0.16149705]  energy_before :  30  energy_after :  50  reward :  -221.8030877881522\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "action : 1  next_temperatures :  [-0.55825495 -0.6432802  -0.52041138 -0.24254485 -0.13340131 -1.36810823\n",
      "  0.16871929 -0.66730321  0.16149705]  energy_before :  50  energy_after :  40  reward :  -191.8030877881522\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "action : 1  next_temperatures :  [-0.55825495 -0.6432802  -0.52041138 -0.24254485 -0.13340131 -1.36810823\n",
      "  0.16871929 -0.66730321  0.16149705]  energy_before :  40  energy_after :  50  reward :  -211.8030877881522\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "action : 1  next_temperatures :  [-0.55825495 -0.6432802  -0.52041138 -0.24254485 -0.13340131 -1.36810823\n",
      "  0.16871929 -0.66730321  0.16149705]  energy_before :  50  energy_after :  50  reward :  -201.8030877881522\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "action : 1  next_temperatures :  [-0.55825495 -0.6432802  -0.52041138 -0.24254485 -0.13340131 -1.36810823\n",
      "  0.16871929 -0.66730321  0.16149705]  energy_before :  50  energy_after :  50  reward :  -201.8030877881522\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "Episode 351/500, Total Reward: -1029.015438940761\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "action : 1  next_temperatures :  [-0.11616967 -0.92223088  1.95726148 -2.17552479  0.11584352 -1.36810823\n",
      "  0.52443449 -0.82010236 -0.04993359]  energy_before :  30  energy_after :  50  reward :  -220.8545300313125\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "action : 1  next_temperatures :  [-0.11616967 -0.92223088  1.95726148 -2.17552479  0.11584352 -1.36810823\n",
      "  0.52443449 -0.82010236 -0.04993359]  energy_before :  50  energy_after :  40  reward :  -190.8545300313125\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "action : 1  next_temperatures :  [-0.11616967 -0.92223088  1.95726148 -2.17552479  0.11584352 -1.36810823\n",
      "  0.52443449 -0.82010236 -0.04993359]  energy_before :  40  energy_after :  50  reward :  -210.8545300313125\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "action : 1  next_temperatures :  [-0.11616967 -0.92223088  1.95726148 -2.17552479  0.11584352 -1.36810823\n",
      "  0.52443449 -0.82010236 -0.04993359]  energy_before :  50  energy_after :  50  reward :  -200.8545300313125\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "action : 1  next_temperatures :  [-0.11616967 -0.92223088  1.95726148 -2.17552479  0.11584352 -1.36810823\n",
      "  0.52443449 -0.82010236 -0.04993359]  energy_before :  50  energy_after :  50  reward :  -200.8545300313125\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "Episode 352/500, Total Reward: -1024.2726501565626\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "action : 1  next_temperatures :  [-0.24692729  0.23629403  0.07240605  0.01955412 -0.43747999  1.00092361\n",
      " -0.52149876  0.62265954 -0.38364463]  energy_before :  30  energy_after :  50  reward :  -217.63771331999178\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step\n",
      "action : 1  next_temperatures :  [-0.24692729  0.23629403  0.07240605  0.01955412 -0.43747999  1.00092361\n",
      " -0.52149876  0.62265954 -0.38364463]  energy_before :  50  energy_after :  40  reward :  -187.63771331999178\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "action : 1  next_temperatures :  [-0.24692729  0.23629403  0.07240605  0.01955412 -0.43747999  1.00092361\n",
      " -0.52149876  0.62265954 -0.38364463]  energy_before :  40  energy_after :  50  reward :  -207.63771331999178\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "action : 1  next_temperatures :  [-0.24692729  0.23629403  0.07240605  0.01955412 -0.43747999  1.00092361\n",
      " -0.52149876  0.62265954 -0.38364463]  energy_before :  50  energy_after :  50  reward :  -197.63771331999178\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "action : 1  next_temperatures :  [-0.24692729  0.23629403  0.07240605  0.01955412 -0.43747999  1.00092361\n",
      " -0.52149876  0.62265954 -0.38364463]  energy_before :  50  energy_after :  50  reward :  -197.63771331999178\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step\n",
      "Episode 353/500, Total Reward: -1008.1885665999589\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "action : 1  next_temperatures :  [-1.05015267 -0.09291804 -0.61161406 -0.57262575 -0.93596964 -0.6798292\n",
      " -0.8103134  -0.93527761 -0.94083364]  energy_before :  30  energy_after :  50  reward :  -224.6295340043267\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "action : 1  next_temperatures :  [-1.05015267 -0.09291804 -0.61161406 -0.57262575 -0.93596964 -0.6798292\n",
      " -0.8103134  -0.93527761 -0.94083364]  energy_before :  50  energy_after :  40  reward :  -194.6295340043267\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step\n",
      "action : 1  next_temperatures :  [-1.05015267 -0.09291804 -0.61161406 -0.57262575 -0.93596964 -0.6798292\n",
      " -0.8103134  -0.93527761 -0.94083364]  energy_before :  40  energy_after :  50  reward :  -214.6295340043267\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step\n",
      "action : 1  next_temperatures :  [-1.05015267 -0.09291804 -0.61161406 -0.57262575 -0.93596964 -0.6798292\n",
      " -0.8103134  -0.93527761 -0.94083364]  energy_before :  50  energy_after :  50  reward :  -204.6295340043267\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "action : 1  next_temperatures :  [-1.05015267 -0.09291804 -0.61161406 -0.57262575 -0.93596964 -0.6798292\n",
      " -0.8103134  -0.93527761 -0.94083364]  energy_before :  50  energy_after :  50  reward :  -204.6295340043267\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step\n",
      "Episode 354/500, Total Reward: -1043.1476700216335\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "action : 1  next_temperatures :  [ 0.27817871  0.20194875  0.04732532  0.19155657 -0.13340131 -0.27935732\n",
      " -0.22778895 -0.44616674 -0.04993359]  energy_before :  30  energy_after :  50  reward :  -218.41763856270887\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step\n",
      "action : 1  next_temperatures :  [ 0.27817871  0.20194875  0.04732532  0.19155657 -0.13340131 -0.27935732\n",
      " -0.22778895 -0.44616674 -0.04993359]  energy_before :  50  energy_after :  40  reward :  -188.41763856270887\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "action : 1  next_temperatures :  [ 0.27817871  0.20194875  0.04732532  0.19155657 -0.13340131 -0.27935732\n",
      " -0.22778895 -0.44616674 -0.04993359]  energy_before :  40  energy_after :  50  reward :  -208.41763856270887\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step\n",
      "action : 1  next_temperatures :  [ 0.27817871  0.20194875  0.04732532  0.19155657 -0.13340131 -0.27935732\n",
      " -0.22778895 -0.44616674 -0.04993359]  energy_before :  50  energy_after :  50  reward :  -198.41763856270887\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "action : 1  next_temperatures :  [ 0.27817871  0.20194875  0.04732532  0.19155657 -0.13340131 -0.27935732\n",
      " -0.22778895 -0.44616674 -0.04993359]  energy_before :  50  energy_after :  50  reward :  -198.41763856270887\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "Episode 355/500, Total Reward: -1012.0881928135443\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "action : 1  next_temperatures :  [-0.55825495  0.79754615 -0.56601272  1.44226011 -0.33279717  0.26040912\n",
      " -0.61450686  0.89216961 -0.18004475]  energy_before :  30  energy_after :  50  reward :  -216.85923146258682\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step\n",
      "action : 1  next_temperatures :  [-0.55825495  0.79754615 -0.56601272  1.44226011 -0.33279717  0.26040912\n",
      " -0.61450686  0.89216961 -0.18004475]  energy_before :  50  energy_after :  40  reward :  -186.85923146258682\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step\n",
      "action : 1  next_temperatures :  [-0.55825495  0.79754615 -0.56601272  1.44226011 -0.33279717  0.26040912\n",
      " -0.61450686  0.89216961 -0.18004475]  energy_before :  40  energy_after :  50  reward :  -206.85923146258682\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step\n",
      "action : 1  next_temperatures :  [-0.55825495  0.79754615 -0.56601272  1.44226011 -0.33279717  0.26040912\n",
      " -0.61450686  0.89216961 -0.18004475]  energy_before :  50  energy_after :  50  reward :  -196.85923146258682\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "action : 1  next_temperatures :  [-0.55825495  0.79754615 -0.56601272  1.44226011 -0.33279717  0.26040912\n",
      " -0.61450686  0.89216961 -0.18004475]  energy_before :  50  energy_after :  50  reward :  -196.85923146258682\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "Episode 356/500, Total Reward: -1004.2961573129342\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "action : 1  next_temperatures :  [-0.738825   -0.16831012 -0.95590418  0.14241301 -0.53219302  0.41404283\n",
      " -0.47254712 -0.14440759 -0.59206344]  energy_before :  30  energy_after :  50  reward :  -221.04779463537994\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "action : 1  next_temperatures :  [-0.738825   -0.16831012 -0.95590418  0.14241301 -0.53219302  0.41404283\n",
      " -0.47254712 -0.14440759 -0.59206344]  energy_before :  50  energy_after :  40  reward :  -191.04779463537994\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "action : 1  next_temperatures :  [-0.738825   -0.16831012 -0.95590418  0.14241301 -0.53219302  0.41404283\n",
      " -0.47254712 -0.14440759 -0.59206344]  energy_before :  40  energy_after :  50  reward :  -211.04779463537994\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "action : 1  next_temperatures :  [-0.738825   -0.16831012 -0.95590418  0.14241301 -0.53219302  0.41404283\n",
      " -0.47254712 -0.14440759 -0.59206344]  energy_before :  50  energy_after :  50  reward :  -201.04779463537994\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "action : 1  next_temperatures :  [-0.738825   -0.16831012 -0.95590418  0.14241301 -0.53219302  0.41404283\n",
      " -0.47254712 -0.14440759 -0.59206344]  energy_before :  50  energy_after :  50  reward :  -201.04779463537994\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "Episode 357/500, Total Reward: -1025.2389731768997\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step\n",
      "action : 1  next_temperatures :  [-0.55825495  0.82937836 -0.38360736  1.02453987 -0.23808413  0.90874338\n",
      " -0.56555523  1.30680049 -0.84144317]  energy_before :  30  energy_after :  50  reward :  -216.51748273117425\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step\n",
      "action : 1  next_temperatures :  [-0.55825495  0.82937836 -0.38360736  1.02453987 -0.23808413  0.90874338\n",
      " -0.56555523  1.30680049 -0.84144317]  energy_before :  50  energy_after :  40  reward :  -186.51748273117425\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step\n",
      "action : 1  next_temperatures :  [-0.55825495  0.82937836 -0.38360736  1.02453987 -0.23808413  0.90874338\n",
      " -0.56555523  1.30680049 -0.84144317]  energy_before :  40  energy_after :  50  reward :  -206.51748273117425\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "action : 1  next_temperatures :  [-0.55825495  0.82937836 -0.38360736  1.02453987 -0.23808413  0.90874338\n",
      " -0.56555523  1.30680049 -0.84144317]  energy_before :  50  energy_after :  50  reward :  -196.51748273117425\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step\n",
      "action : 1  next_temperatures :  [-0.55825495  0.82937836 -0.38360736  1.02453987 -0.23808413  0.90874338\n",
      " -0.56555523  1.30680049 -0.84144317]  energy_before :  50  energy_after :  50  reward :  -196.51748273117425\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step\n",
      "Episode 358/500, Total Reward: -1002.5874136558713\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "action : 1  next_temperatures :  [ 0.12666591  0.38456511 -0.33800601  1.17442773  0.93004328  0.20202831\n",
      "  0.41347746  0.29095483  0.64941392]  energy_before :  30  energy_after :  50  reward :  -214.16642947939258\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "action : 1  next_temperatures :  [ 0.12666591  0.38456511 -0.33800601  1.17442773  0.93004328  0.20202831\n",
      "  0.41347746  0.29095483  0.64941392]  energy_before :  50  energy_after :  40  reward :  -184.16642947939258\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step\n",
      "action : 1  next_temperatures :  [ 0.12666591  0.38456511 -0.33800601  1.17442773  0.93004328  0.20202831\n",
      "  0.41347746  0.29095483  0.64941392]  energy_before :  40  energy_after :  50  reward :  -204.16642947939258\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "action : 1  next_temperatures :  [ 0.12666591  0.38456511 -0.33800601  1.17442773  0.93004328  0.20202831\n",
      "  0.41347746  0.29095483  0.64941392]  energy_before :  50  energy_after :  50  reward :  -194.16642947939258\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "action : 1  next_temperatures :  [ 0.12666591  0.38456511 -0.33800601  1.17442773  0.93004328  0.20202831\n",
      "  0.41347746  0.29095483  0.64941392]  energy_before :  50  energy_after :  50  reward :  -194.16642947939258\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "Episode 359/500, Total Reward: -990.8321473969629\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step\n",
      "action : 1  next_temperatures :  [ 0.9423444   0.38456511  0.39161544  0.90168098  1.05798895 -0.22814609\n",
      "  1.08248312  0.12970949  1.08853909]  energy_before :  30  energy_after :  50  reward :  -212.24921950081202\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "action : 1  next_temperatures :  [ 0.9423444   0.38456511  0.39161544  0.90168098  1.05798895 -0.22814609\n",
      "  1.08248312  0.12970949  1.08853909]  energy_before :  50  energy_after :  40  reward :  -182.24921950081202\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "action : 1  next_temperatures :  [ 0.9423444   0.38456511  0.39161544  0.90168098  1.05798895 -0.22814609\n",
      "  1.08248312  0.12970949  1.08853909]  energy_before :  40  energy_after :  50  reward :  -202.24921950081202\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "action : 1  next_temperatures :  [ 0.9423444   0.38456511  0.39161544  0.90168098  1.05798895 -0.22814609\n",
      "  1.08248312  0.12970949  1.08853909]  energy_before :  50  energy_after :  50  reward :  -192.24921950081202\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "action : 1  next_temperatures :  [ 0.9423444   0.38456511  0.39161544  0.90168098  1.05798895 -0.22814609\n",
      "  1.08248312  0.12970949  1.08853909]  energy_before :  50  energy_after :  50  reward :  -192.24921950081202\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "Episode 360/500, Total Reward: -981.2460975040601\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "action : 1  next_temperatures :  [-0.42749733 -1.2715475  -0.83962076 -0.91417348 -0.83128681 -0.42377301\n",
      " -0.79562791 -0.94295596 -0.43484578]  energy_before :  30  energy_after :  50  reward :  -224.88132854938277\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "action : 1  next_temperatures :  [-0.42749733 -1.2715475  -0.83962076 -0.91417348 -0.83128681 -0.42377301\n",
      " -0.79562791 -0.94295596 -0.43484578]  energy_before :  50  energy_after :  40  reward :  -194.88132854938277\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "action : 1  next_temperatures :  [-0.42749733 -1.2715475  -0.83962076 -0.91417348 -0.83128681 -0.42377301\n",
      " -0.79562791 -0.94295596 -0.43484578]  energy_before :  40  energy_after :  50  reward :  -214.88132854938277\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "action : 1  next_temperatures :  [-0.42749733 -1.2715475  -0.83962076 -0.91417348 -0.83128681 -0.42377301\n",
      " -0.79562791 -0.94295596 -0.43484578]  energy_before :  50  energy_after :  50  reward :  -204.88132854938277\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "action : 1  next_temperatures :  [-0.42749733 -1.2715475  -0.83962076 -0.91417348 -0.83128681 -0.42377301\n",
      " -0.79562791 -0.94295596 -0.43484578]  energy_before :  50  energy_after :  50  reward :  -204.88132854938277\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "Episode 361/500, Total Reward: -1044.4066427469138\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "action : 2  next_temperatures :  [-0.18091029 -0.39720096  0.46438818 -0.57105903 -0.43445929 -0.63133399\n",
      "  0.9076439  -0.25930396 -0.02576732]  energy_before :  30  energy_after :  50  reward :  -228.12800275854548\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "action : 1  next_temperatures :  [-0.18091029 -0.39720096  0.46438818 -0.57105903 -0.43445929 -0.63133399\n",
      "  0.9076439  -0.25930396 -0.02576732]  energy_before :  50  energy_after :  40  reward :  -189.12800275854548\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "action : 1  next_temperatures :  [-0.18091029 -0.39720096  0.46438818 -0.57105903 -0.43445929 -0.63133399\n",
      "  0.9076439  -0.25930396 -0.02576732]  energy_before :  40  energy_after :  50  reward :  -209.12800275854548\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "action : 1  next_temperatures :  [-0.18091029 -0.39720096  0.46438818 -0.57105903 -0.43445929 -0.63133399\n",
      "  0.9076439  -0.25930396 -0.02576732]  energy_before :  50  energy_after :  50  reward :  -199.12800275854548\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "action : 1  next_temperatures :  [-0.18091029 -0.39720096  0.46438818 -0.57105903 -0.43445929 -0.63133399\n",
      "  0.9076439  -0.25930396 -0.02576732]  energy_before :  50  energy_after :  50  reward :  -199.12800275854548\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "Episode 362/500, Total Reward: -1024.6400137927274\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "action : 1  next_temperatures :  [-0.3652318  -0.36014107 -0.70737688 -0.16964858 -0.63189095  0.17949536\n",
      "  0.15240207 -0.25958284 -0.43484578]  energy_before :  30  energy_after :  50  reward :  -220.59682045822458\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step\n",
      "action : 1  next_temperatures :  [-0.3652318  -0.36014107 -0.70737688 -0.16964858 -0.63189095  0.17949536\n",
      "  0.15240207 -0.25958284 -0.43484578]  energy_before :  50  energy_after :  40  reward :  -190.59682045822458\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "action : 1  next_temperatures :  [-0.3652318  -0.36014107 -0.70737688 -0.16964858 -0.63189095  0.17949536\n",
      "  0.15240207 -0.25958284 -0.43484578]  energy_before :  40  energy_after :  50  reward :  -210.59682045822458\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "action : 1  next_temperatures :  [-0.3652318  -0.36014107 -0.70737688 -0.16964858 -0.63189095  0.17949536\n",
      "  0.15240207 -0.25958284 -0.43484578]  energy_before :  50  energy_after :  50  reward :  -200.59682045822458\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "action : 1  next_temperatures :  [-0.3652318  -0.36014107 -0.70737688 -0.16964858 -0.63189095  0.17949536\n",
      "  0.15240207 -0.25958284 -0.43484578]  energy_before :  50  energy_after :  50  reward :  -200.59682045822458\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "Episode 363/500, Total Reward: -1022.9841022911229\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "action : 1  next_temperatures :  [-0.30296627 -0.21605843 -0.38360736  0.26527191 -0.11678498 -0.49649297\n",
      " -0.12499052  0.23970185  0.37834899]  energy_before :  30  energy_after :  50  reward :  -218.757577782879\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "action : 1  next_temperatures :  [-0.30296627 -0.21605843 -0.38360736  0.26527191 -0.11678498 -0.49649297\n",
      " -0.12499052  0.23970185  0.37834899]  energy_before :  50  energy_after :  40  reward :  -188.757577782879\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step\n",
      "action : 1  next_temperatures :  [-0.30296627 -0.21605843 -0.38360736  0.26527191 -0.11678498 -0.49649297\n",
      " -0.12499052  0.23970185  0.37834899]  energy_before :  40  energy_after :  50  reward :  -208.757577782879\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "action : 1  next_temperatures :  [-0.30296627 -0.21605843 -0.38360736  0.26527191 -0.11678498 -0.49649297\n",
      " -0.12499052  0.23970185  0.37834899]  energy_before :  50  energy_after :  50  reward :  -198.757577782879\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "action : 1  next_temperatures :  [-0.30296627 -0.21605843 -0.38360736  0.26527191 -0.11678498 -0.49649297\n",
      " -0.12499052  0.23970185  0.37834899]  energy_before :  50  energy_after :  50  reward :  -198.757577782879\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "Episode 364/500, Total Reward: -1013.787888914395\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "action : 1  next_temperatures :  [-0.24692729 -0.50254832 -0.49989077 -0.4116806  -0.66844686  0.07912134\n",
      " -0.63898268  0.12970949  0.07204563]  energy_before :  30  energy_after :  50  reward :  -220.68760007135\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "action : 1  next_temperatures :  [-0.24692729 -0.50254832 -0.49989077 -0.4116806  -0.66844686  0.07912134\n",
      " -0.63898268  0.12970949  0.07204563]  energy_before :  50  energy_after :  40  reward :  -190.68760007135\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "action : 1  next_temperatures :  [-0.24692729 -0.50254832 -0.49989077 -0.4116806  -0.66844686  0.07912134\n",
      " -0.63898268  0.12970949  0.07204563]  energy_before :  40  energy_after :  50  reward :  -210.68760007135\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "action : 1  next_temperatures :  [-0.24692729 -0.50254832 -0.49989077 -0.4116806  -0.66844686  0.07912134\n",
      " -0.63898268  0.12970949  0.07204563]  energy_before :  50  energy_after :  50  reward :  -200.68760007135\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "action : 1  next_temperatures :  [-0.24692729 -0.50254832 -0.49989077 -0.4116806  -0.66844686  0.07912134\n",
      " -0.63898268  0.12970949  0.07204563]  energy_before :  50  energy_after :  50  reward :  -200.68760007135\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "Episode 365/500, Total Reward: -1023.4380003567501\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "action : 1  next_temperatures :  [ 0.79498263 -0.71113307  1.21243958 -1.47993868  0.36508834 -1.0065569\n",
      "  0.80509053 -0.58207352  0.3295573 ]  energy_before :  30  energy_after :  50  reward :  -218.27254378103478\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "action : 1  next_temperatures :  [ 0.79498263 -0.71113307  1.21243958 -1.47993868  0.36508834 -1.0065569\n",
      "  0.80509053 -0.58207352  0.3295573 ]  energy_before :  50  energy_after :  40  reward :  -188.27254378103478\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "action : 1  next_temperatures :  [ 0.79498263 -0.71113307  1.21243958 -1.47993868  0.36508834 -1.0065569\n",
      "  0.80509053 -0.58207352  0.3295573 ]  energy_before :  40  energy_after :  50  reward :  -208.27254378103478\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "action : 1  next_temperatures :  [ 0.79498263 -0.71113307  1.21243958 -1.47993868  0.36508834 -1.0065569\n",
      "  0.80509053 -0.58207352  0.3295573 ]  energy_before :  50  energy_after :  50  reward :  -198.27254378103478\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "action : 1  next_temperatures :  [ 0.79498263 -0.71113307  1.21243958 -1.47993868  0.36508834 -1.0065569\n",
      "  0.80509053 -0.58207352  0.3295573 ]  energy_before :  50  energy_after :  50  reward :  -198.27254378103478\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "Episode 366/500, Total Reward: -1011.3627189051739\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step\n",
      "action : 1  next_temperatures :  [-1.11864475  1.31691379 -0.52041138  1.1326557  -0.88113578  1.58473172\n",
      " -0.87558224  1.7813225  -1.12515779]  energy_before :  30  energy_after :  50  reward :  -216.7053082415685\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "action : 1  next_temperatures :  [-1.11864475  1.31691379 -0.52041138  1.1326557  -0.88113578  1.58473172\n",
      " -0.87558224  1.7813225  -1.12515779]  energy_before :  50  energy_after :  40  reward :  -186.7053082415685\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "action : 1  next_temperatures :  [-1.11864475  1.31691379 -0.52041138  1.1326557  -0.88113578  1.58473172\n",
      " -0.87558224  1.7813225  -1.12515779]  energy_before :  40  energy_after :  50  reward :  -206.7053082415685\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "action : 1  next_temperatures :  [-1.11864475  1.31691379 -0.52041138  1.1326557  -0.88113578  1.58473172\n",
      " -0.87558224  1.7813225  -1.12515779]  energy_before :  50  energy_after :  50  reward :  -196.7053082415685\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "action : 1  next_temperatures :  [-1.11864475  1.31691379 -0.52041138  1.1326557  -0.88113578  1.58473172\n",
      " -0.87558224  1.7813225  -1.12515779]  energy_before :  50  energy_after :  50  reward :  -196.7053082415685\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "Episode 367/500, Total Reward: -1003.5265412078425\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "action : 1  next_temperatures :  [-0.55825495  1.0052932  -0.1404002   0.54948548 -0.43747999  1.30819104\n",
      "  0.07081602  0.63648056 -0.3806328 ]  energy_before :  30  energy_after :  50  reward :  -215.94650164112153\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "action : 1  next_temperatures :  [-0.55825495  1.0052932  -0.1404002   0.54948548 -0.43747999  1.30819104\n",
      "  0.07081602  0.63648056 -0.3806328 ]  energy_before :  50  energy_after :  40  reward :  -185.94650164112153\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step\n",
      "action : 1  next_temperatures :  [-0.55825495  1.0052932  -0.1404002   0.54948548 -0.43747999  1.30819104\n",
      "  0.07081602  0.63648056 -0.3806328 ]  energy_before :  40  energy_after :  50  reward :  -205.94650164112153\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "action : 1  next_temperatures :  [-0.55825495  1.0052932  -0.1404002   0.54948548 -0.43747999  1.30819104\n",
      "  0.07081602  0.63648056 -0.3806328 ]  energy_before :  50  energy_after :  50  reward :  -195.94650164112153\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "action : 1  next_temperatures :  [-0.55825495  1.0052932  -0.1404002   0.54948548 -0.43747999  1.30819104\n",
      "  0.07081602  0.63648056 -0.3806328 ]  energy_before :  50  energy_after :  50  reward :  -195.94650164112153\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "Episode 368/500, Total Reward: -999.7325082056077\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "action : 1  next_temperatures :  [ 0.4172384   0.35105752  0.70626469 -0.08119017  0.06100966  0.73257673\n",
      " -0.71730529  0.40613008 -0.0047561 ]  energy_before :  30  energy_after :  50  reward :  -216.1289744981609\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "action : 1  next_temperatures :  [ 0.4172384   0.35105752  0.70626469 -0.08119017  0.06100966  0.73257673\n",
      " -0.71730529  0.40613008 -0.0047561 ]  energy_before :  50  energy_after :  40  reward :  -186.1289744981609\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "action : 1  next_temperatures :  [ 0.4172384   0.35105752  0.70626469 -0.08119017  0.06100966  0.73257673\n",
      " -0.71730529  0.40613008 -0.0047561 ]  energy_before :  40  energy_after :  50  reward :  -206.1289744981609\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "action : 1  next_temperatures :  [ 0.4172384   0.35105752  0.70626469 -0.08119017  0.06100966  0.73257673\n",
      " -0.71730529  0.40613008 -0.0047561 ]  energy_before :  50  energy_after :  50  reward :  -196.1289744981609\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "action : 1  next_temperatures :  [ 0.4172384   0.35105752  0.70626469 -0.08119017  0.06100966  0.73257673\n",
      " -0.71730529  0.40613008 -0.0047561 ]  energy_before :  50  energy_after :  50  reward :  -196.1289744981609\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "Episode 369/500, Total Reward: -1000.6448724908045\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "action : 1  next_temperatures :  [0.68705571 1.09743908 0.0876065  1.61671974 1.11282282 0.35566202\n",
      " 0.39716025 1.0610933  1.03432611]  energy_before :  30  energy_after :  50  reward :  -210.55011448031357\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step\n",
      "action : 1  next_temperatures :  [0.68705571 1.09743908 0.0876065  1.61671974 1.11282282 0.35566202\n",
      " 0.39716025 1.0610933  1.03432611]  energy_before :  50  energy_after :  40  reward :  -180.55011448031357\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "action : 1  next_temperatures :  [0.68705571 1.09743908 0.0876065  1.61671974 1.11282282 0.35566202\n",
      " 0.39716025 1.0610933  1.03432611]  energy_before :  40  energy_after :  50  reward :  -200.55011448031357\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "action : 1  next_temperatures :  [0.68705571 1.09743908 0.0876065  1.61671974 1.11282282 0.35566202\n",
      " 0.39716025 1.0610933  1.03432611]  energy_before :  50  energy_after :  50  reward :  -190.55011448031357\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "action : 1  next_temperatures :  [0.68705571 1.09743908 0.0876065  1.61671974 1.11282282 0.35566202\n",
      " 0.39716025 1.0610933  1.03432611]  energy_before :  50  energy_after :  50  reward :  -190.55011448031357\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "Episode 370/500, Total Reward: -972.7505724015679\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "action : 1  next_temperatures :  [0.50648566 1.38225359 0.61962214 0.7403263  1.64454511 0.68238971\n",
      " 0.60928399 0.14056887 0.7036269 ]  energy_before :  30  energy_after :  50  reward :  -210.97089772199215\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "action : 1  next_temperatures :  [0.50648566 1.38225359 0.61962214 0.7403263  1.64454511 0.68238971\n",
      " 0.60928399 0.14056887 0.7036269 ]  energy_before :  50  energy_after :  40  reward :  -180.97089772199215\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "action : 1  next_temperatures :  [0.50648566 1.38225359 0.61962214 0.7403263  1.64454511 0.68238971\n",
      " 0.60928399 0.14056887 0.7036269 ]  energy_before :  40  energy_after :  50  reward :  -200.97089772199215\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "action : 1  next_temperatures :  [0.50648566 1.38225359 0.61962214 0.7403263  1.64454511 0.68238971\n",
      " 0.60928399 0.14056887 0.7036269 ]  energy_before :  50  energy_after :  50  reward :  -190.97089772199215\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "action : 1  next_temperatures :  [0.50648566 1.38225359 0.61962214 0.7403263  1.64454511 0.68238971\n",
      " 0.60928399 0.14056887 0.7036269 ]  energy_before :  50  energy_after :  50  reward :  -190.97089772199215\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "Episode 371/500, Total Reward: -974.8544886099608\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "action : 1  next_temperatures :  [ 0.06440038  1.11586825  0.27533202  0.90168098 -0.03370338  1.70456601\n",
      " -0.22778895  1.58322108 -0.3806328 ]  energy_before :  30  energy_after :  50  reward :  -212.99705640769864\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "action : 1  next_temperatures :  [ 0.06440038  1.11586825  0.27533202  0.90168098 -0.03370338  1.70456601\n",
      " -0.22778895  1.58322108 -0.3806328 ]  energy_before :  50  energy_after :  40  reward :  -182.99705640769864\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "action : 1  next_temperatures :  [ 0.06440038  1.11586825  0.27533202  0.90168098 -0.03370338  1.70456601\n",
      " -0.22778895  1.58322108 -0.3806328 ]  energy_before :  40  energy_after :  50  reward :  -202.99705640769864\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "action : 1  next_temperatures :  [ 0.06440038  1.11586825  0.27533202  0.90168098 -0.03370338  1.70456601\n",
      " -0.22778895  1.58322108 -0.3806328 ]  energy_before :  50  energy_after :  50  reward :  -192.99705640769864\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "action : 1  next_temperatures :  [ 0.06440038  1.11586825  0.27533202  0.90168098 -0.03370338  1.70456601\n",
      " -0.22778895  1.58322108 -0.3806328 ]  energy_before :  50  energy_after :  50  reward :  -192.99705640769864\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "Episode 372/500, Total Reward: -984.9852820384932\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step\n",
      "action : 1  next_temperatures :  [1.99463191 1.81952763 1.10026028 2.19563085 2.15965108 1.39729859\n",
      " 2.02888139 1.23769534 2.38965073]  energy_before :  30  energy_after :  50  reward :  -201.67677220853489\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "action : 1  next_temperatures :  [1.99463191 1.81952763 1.10026028 2.19563085 2.15965108 1.39729859\n",
      " 2.02888139 1.23769534 2.38965073]  energy_before :  50  energy_after :  40  reward :  -171.67677220853489\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "action : 1  next_temperatures :  [1.99463191 1.81952763 1.10026028 2.19563085 2.15965108 1.39729859\n",
      " 2.02888139 1.23769534 2.38965073]  energy_before :  40  energy_after :  50  reward :  -191.67677220853489\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "action : 1  next_temperatures :  [1.99463191 1.81952763 1.10026028 2.19563085 2.15965108 1.39729859\n",
      " 2.02888139 1.23769534 2.38965073]  energy_before :  50  energy_after :  50  reward :  -181.67677220853489\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "action : 1  next_temperatures :  [1.99463191 1.81952763 1.10026028 2.19563085 2.15965108 1.39729859\n",
      " 2.02888139 1.23769534 2.38965073]  energy_before :  50  energy_after :  50  reward :  -181.67677220853489\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "Episode 373/500, Total Reward: -928.3838610426744\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "action : 1  next_temperatures :  [ 0.81781333  1.84382063  0.70626469  0.25708132  0.06100966  1.07389962\n",
      " -1.0110151   2.28962924 -0.97697563]  energy_before :  30  energy_after :  50  reward :  -212.93847223852126\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "action : 1  next_temperatures :  [ 0.81781333  1.84382063  0.70626469  0.25708132  0.06100966  1.07389962\n",
      " -1.0110151   2.28962924 -0.97697563]  energy_before :  50  energy_after :  40  reward :  -182.93847223852126\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "action : 1  next_temperatures :  [ 0.81781333  1.84382063  0.70626469  0.25708132  0.06100966  1.07389962\n",
      " -1.0110151   2.28962924 -0.97697563]  energy_before :  40  energy_after :  50  reward :  -202.93847223852126\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "action : 1  next_temperatures :  [ 0.81781333  1.84382063  0.70626469  0.25708132  0.06100966  1.07389962\n",
      " -1.0110151   2.28962924 -0.97697563]  energy_before :  50  energy_after :  50  reward :  -192.93847223852126\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "action : 1  next_temperatures :  [ 0.81781333  1.84382063  0.70626469  0.25708132  0.06100966  1.07389962\n",
      " -1.0110151   2.28962924 -0.97697563]  energy_before :  50  energy_after :  50  reward :  -192.93847223852126\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "Episode 374/500, Total Reward: -984.6923611926063\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "action : 1  next_temperatures :  [ 0.195158    0.51943316  0.44785709  0.19155657  0.41493731  1.10129764\n",
      " -0.12499052  0.91520466  0.43256198]  energy_before :  30  energy_after :  50  reward :  -213.90698412238388\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step\n",
      "action : 1  next_temperatures :  [ 0.195158    0.51943316  0.44785709  0.19155657  0.41493731  1.10129764\n",
      " -0.12499052  0.91520466  0.43256198]  energy_before :  50  energy_after :  40  reward :  -183.90698412238388\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step\n",
      "action : 1  next_temperatures :  [ 0.195158    0.51943316  0.44785709  0.19155657  0.41493731  1.10129764\n",
      " -0.12499052  0.91520466  0.43256198]  energy_before :  40  energy_after :  50  reward :  -203.90698412238388\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "action : 1  next_temperatures :  [ 0.195158    0.51943316  0.44785709  0.19155657  0.41493731  1.10129764\n",
      " -0.12499052  0.91520466  0.43256198]  energy_before :  50  energy_after :  50  reward :  -193.90698412238388\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "action : 1  next_temperatures :  [ 0.195158    0.51943316  0.44785709  0.19155657  0.41493731  1.10129764\n",
      " -0.12499052  0.91520466  0.43256198]  energy_before :  50  energy_after :  50  reward :  -193.90698412238388\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "Episode 375/500, Total Reward: -989.5349206119193\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "action : 1  next_temperatures :  [-0.98788713 -1.02024058 -0.94906398 -0.74217102 -1.03068267 -0.32032631\n",
      " -1.34878137 -0.57516301 -1.40525821]  energy_before :  30  energy_after :  50  reward :  -226.37957430146946\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "action : 1  next_temperatures :  [-0.98788713 -1.02024058 -0.94906398 -0.74217102 -1.03068267 -0.32032631\n",
      " -1.34878137 -0.57516301 -1.40525821]  energy_before :  50  energy_after :  40  reward :  -196.37957430146946\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "action : 1  next_temperatures :  [-0.98788713 -1.02024058 -0.94906398 -0.74217102 -1.03068267 -0.32032631\n",
      " -1.34878137 -0.57516301 -1.40525821]  energy_before :  40  energy_after :  50  reward :  -216.37957430146946\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step\n",
      "action : 1  next_temperatures :  [-0.98788713 -1.02024058 -0.94906398 -0.74217102 -1.03068267 -0.32032631\n",
      " -1.34878137 -0.57516301 -1.40525821]  energy_before :  50  energy_after :  50  reward :  -206.37957430146946\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step\n",
      "action : 1  next_temperatures :  [-0.98788713 -1.02024058 -0.94906398 -0.74217102 -1.03068267 -0.32032631\n",
      " -1.34878137 -0.57516301 -1.40525821]  energy_before :  50  energy_after :  50  reward :  -206.37957430146946\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "Episode 376/500, Total Reward: -1051.8978715073472\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step\n",
      "action : 2  next_temperatures :  [-0.42997242  0.24782014 -0.83220995  1.33079665 -0.1303806   0.29046828\n",
      "  0.28269471  0.18757599  0.07723735]  energy_before :  30  energy_after :  50  reward :  -225.97596985486805\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "action : 1  next_temperatures :  [-0.42997242  0.24782014 -0.83220995  1.33079665 -0.1303806   0.29046828\n",
      "  0.28269471  0.18757599  0.07723735]  energy_before :  50  energy_after :  40  reward :  -186.97596985486805\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step\n",
      "action : 1  next_temperatures :  [-0.42997242  0.24782014 -0.83220995  1.33079665 -0.1303806   0.29046828\n",
      "  0.28269471  0.18757599  0.07723735]  energy_before :  40  energy_after :  50  reward :  -206.97596985486805\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step\n",
      "action : 1  next_temperatures :  [-0.42997242  0.24782014 -0.83220995  1.33079665 -0.1303806   0.29046828\n",
      "  0.28269471  0.18757599  0.07723735]  energy_before :  50  energy_after :  50  reward :  -196.97596985486805\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "action : 1  next_temperatures :  [-0.42997242  0.24782014 -0.83220995  1.33079665 -0.1303806   0.29046828\n",
      "  0.28269471  0.18757599  0.07723735]  energy_before :  50  energy_after :  50  reward :  -196.97596985486805\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "Episode 377/500, Total Reward: -1013.8798492743402\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "action : 2  next_temperatures :  [ 0.96685104 -0.07301503  1.52841946 -0.75944267  0.56252001 -0.54939601\n",
      "  1.49016835 -0.37447921  0.38805847]  energy_before :  30  energy_after :  50  reward :  -223.82031558814526\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "action : 1  next_temperatures :  [ 0.96685104 -0.07301503  1.52841946 -0.75944267  0.56252001 -0.54939601\n",
      "  1.49016835 -0.37447921  0.38805847]  energy_before :  50  energy_after :  40  reward :  -184.82031558814526\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "action : 1  next_temperatures :  [ 0.96685104 -0.07301503  1.52841946 -0.75944267  0.56252001 -0.54939601\n",
      "  1.49016835 -0.37447921  0.38805847]  energy_before :  40  energy_after :  50  reward :  -204.82031558814526\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "action : 1  next_temperatures :  [ 0.96685104 -0.07301503  1.52841946 -0.75944267  0.56252001 -0.54939601\n",
      "  1.49016835 -0.37447921  0.38805847]  energy_before :  50  energy_after :  50  reward :  -194.82031558814526\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step\n",
      "action : 1  next_temperatures :  [ 0.96685104 -0.07301503  1.52841946 -0.75944267  0.56252001 -0.54939601\n",
      "  1.49016835 -0.37447921  0.38805847]  energy_before :  50  energy_after :  50  reward :  -194.82031558814526\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "Episode 378/500, Total Reward: -1003.1015779407263\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "action : 1  next_temperatures :  [ 0.43799358 -0.75385524 -0.00815632 -0.32690796  0.61433317 -0.44630596\n",
      "  0.9029938  -0.92759926  0.43256198]  energy_before :  30  energy_after :  50  reward :  -218.07494221596906\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "action : 1  next_temperatures :  [ 0.43799358 -0.75385524 -0.00815632 -0.32690796  0.61433317 -0.44630596\n",
      "  0.9029938  -0.92759926  0.43256198]  energy_before :  50  energy_after :  40  reward :  -188.07494221596906\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step\n",
      "action : 1  next_temperatures :  [ 0.43799358 -0.75385524 -0.00815632 -0.32690796  0.61433317 -0.44630596\n",
      "  0.9029938  -0.92759926  0.43256198]  energy_before :  40  energy_after :  50  reward :  -208.07494221596906\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "action : 1  next_temperatures :  [ 0.43799358 -0.75385524 -0.00815632 -0.32690796  0.61433317 -0.44630596\n",
      "  0.9029938  -0.92759926  0.43256198]  energy_before :  50  energy_after :  50  reward :  -198.07494221596906\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step\n",
      "action : 1  next_temperatures :  [ 0.43799358 -0.75385524 -0.00815632 -0.32690796  0.61433317 -0.44630596\n",
      "  0.9029938  -0.92759926  0.43256198]  energy_before :  50  energy_after :  50  reward :  -198.07494221596906\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "Episode 379/500, Total Reward: -1010.3747110798453\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step\n",
      "action : 2  next_temperatures :  [1.09553314 0.46855138 0.99184368 0.61739601 0.56252001 0.58749346\n",
      " 1.50648556 0.41792648 0.95006641]  energy_before :  30  energy_after :  50  reward :  -219.8021838664558\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "action : 1  next_temperatures :  [1.09553314 0.46855138 0.99184368 0.61739601 0.56252001 0.58749346\n",
      " 1.50648556 0.41792648 0.95006641]  energy_before :  50  energy_after :  40  reward :  -180.8021838664558\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "action : 1  next_temperatures :  [1.09553314 0.46855138 0.99184368 0.61739601 0.56252001 0.58749346\n",
      " 1.50648556 0.41792648 0.95006641]  energy_before :  40  energy_after :  50  reward :  -200.8021838664558\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "action : 1  next_temperatures :  [1.09553314 0.46855138 0.99184368 0.61739601 0.56252001 0.58749346\n",
      " 1.50648556 0.41792648 0.95006641]  energy_before :  50  energy_after :  50  reward :  -190.8021838664558\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "action : 1  next_temperatures :  [1.09553314 0.46855138 0.99184368 0.61739601 0.56252001 0.58749346\n",
      " 1.50648556 0.41792648 0.95006641]  energy_before :  50  energy_after :  50  reward :  -190.8021838664558\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step\n",
      "Episode 380/500, Total Reward: -983.0109193322791\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "action : 1  next_temperatures :  [-0.57693461  0.0829968  -1.29563417  1.56511901 -0.68672482 -0.29267225\n",
      " -0.19189109 -0.7748001  -0.57399244]  energy_before :  30  energy_after :  50  reward :  -220.7445336649836\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "action : 1  next_temperatures :  [-0.57693461  0.0829968  -1.29563417  1.56511901 -0.68672482 -0.29267225\n",
      " -0.19189109 -0.7748001  -0.57399244]  energy_before :  50  energy_after :  40  reward :  -190.7445336649836\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "action : 1  next_temperatures :  [-0.57693461  0.0829968  -1.29563417  1.56511901 -0.68672482 -0.29267225\n",
      " -0.19189109 -0.7748001  -0.57399244]  energy_before :  40  energy_after :  50  reward :  -210.7445336649836\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "action : 1  next_temperatures :  [-0.57693461  0.0829968  -1.29563417  1.56511901 -0.68672482 -0.29267225\n",
      " -0.19189109 -0.7748001  -0.57399244]  energy_before :  50  energy_after :  50  reward :  -200.7445336649836\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "action : 1  next_temperatures :  [-0.57693461  0.0829968  -1.29563417  1.56511901 -0.68672482 -0.29267225\n",
      " -0.19189109 -0.7748001  -0.57399244]  energy_before :  50  energy_after :  50  reward :  -200.7445336649836\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "Episode 381/500, Total Reward: -1023.722668324918\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "action : 1  next_temperatures :  [-0.30296627 -0.10883414 -0.55081227  0.5027991  -0.15167926 -0.41250654\n",
      "  0.16871929 -0.35940138 -0.16378086]  energy_before :  30  energy_after :  50  reward :  -219.37846233838522\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "action : 1  next_temperatures :  [-0.30296627 -0.10883414 -0.55081227  0.5027991  -0.15167926 -0.41250654\n",
      "  0.16871929 -0.35940138 -0.16378086]  energy_before :  50  energy_after :  40  reward :  -189.37846233838522\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "action : 0  next_temperatures :  [-1.30296627 -1.10883414 -1.55081227 -0.4972009  -1.15167926 -1.41250654\n",
      " -0.83128071 -1.35940138 -1.16378086]  energy_before :  40  energy_after :  50  reward :  -209.37846233838522\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "action : 2  next_temperatures :  [-0.30296627 -0.10883414 -0.55081227  0.5027991  -0.15167926 -0.41250654\n",
      "  0.16871929 -0.35940138 -0.16378086]  energy_before :  50  energy_after :  50  reward :  -208.37846233838522\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step\n",
      "action : 1  next_temperatures :  [-0.30296627 -0.10883414 -0.55081227  0.5027991  -0.15167926 -0.41250654\n",
      "  0.16871929 -0.35940138 -0.16378086]  energy_before :  50  energy_after :  50  reward :  -199.37846233838522\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "Episode 382/500, Total Reward: -1025.8923116919261\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "action : 1  next_temperatures :  [ 0.12666591 -0.29396358 -0.52041138  0.28001498  0.06100966 -0.10523912\n",
      " -0.32079706  0.10897794  0.10728407]  energy_before :  30  energy_after :  50  reward :  -218.5564585737122\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "action : 1  next_temperatures :  [ 0.12666591 -0.29396358 -0.52041138  0.28001498  0.06100966 -0.10523912\n",
      " -0.32079706  0.10897794  0.10728407]  energy_before :  50  energy_after :  40  reward :  -188.5564585737122\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "action : 1  next_temperatures :  [ 0.12666591 -0.29396358 -0.52041138  0.28001498  0.06100966 -0.10523912\n",
      " -0.32079706  0.10897794  0.10728407]  energy_before :  40  energy_after :  50  reward :  -208.5564585737122\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "action : 1  next_temperatures :  [ 0.12666591 -0.29396358 -0.52041138  0.28001498  0.06100966 -0.10523912\n",
      " -0.32079706  0.10897794  0.10728407]  energy_before :  50  energy_after :  50  reward :  -198.5564585737122\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "action : 1  next_temperatures :  [ 0.12666591 -0.29396358 -0.52041138  0.28001498  0.06100966 -0.10523912\n",
      " -0.32079706  0.10897794  0.10728407]  energy_before :  50  energy_after :  50  reward :  -198.5564585737122\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "Episode 383/500, Total Reward: -1012.7822928685611\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "action : 1  next_temperatures :  [ 0.29893389 -0.3165812   1.57269017 -1.26063556  0.41493731 -0.47396003\n",
      "  0.65823563 -0.32254531  0.78494638]  energy_before :  30  energy_after :  50  reward :  -216.6439787210516\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "action : 1  next_temperatures :  [ 0.29893389 -0.3165812   1.57269017 -1.26063556  0.41493731 -0.47396003\n",
      "  0.65823563 -0.32254531  0.78494638]  energy_before :  50  energy_after :  40  reward :  -186.6439787210516\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "action : 1  next_temperatures :  [ 0.29893389 -0.3165812   1.57269017 -1.26063556  0.41493731 -0.47396003\n",
      "  0.65823563 -0.32254531  0.78494638]  energy_before :  40  energy_after :  50  reward :  -206.6439787210516\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "action : 1  next_temperatures :  [ 0.29893389 -0.3165812   1.57269017 -1.26063556  0.41493731 -0.47396003\n",
      "  0.65823563 -0.32254531  0.78494638]  energy_before :  50  energy_after :  50  reward :  -196.6439787210516\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "action : 1  next_temperatures :  [ 0.29893389 -0.3165812   1.57269017 -1.26063556  0.41493731 -0.47396003\n",
      "  0.65823563 -0.32254531  0.78494638]  energy_before :  50  energy_after :  50  reward :  -196.6439787210516\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "Episode 384/500, Total Reward: -1003.219893605258\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "action : 1  next_temperatures :  [ 0.66837605 -1.43322162  1.35988391 -2.23531612  0.34681039 -1.04752589\n",
      "  1.02830998 -1.37586131  0.40545548]  energy_before :  30  energy_after :  50  reward :  -220.2830891159617\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "action : 1  next_temperatures :  [ 0.66837605 -1.43322162  1.35988391 -2.23531612  0.34681039 -1.04752589\n",
      "  1.02830998 -1.37586131  0.40545548]  energy_before :  50  energy_after :  40  reward :  -190.2830891159617\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step\n",
      "action : 1  next_temperatures :  [ 0.66837605 -1.43322162  1.35988391 -2.23531612  0.34681039 -1.04752589\n",
      "  1.02830998 -1.37586131  0.40545548]  energy_before :  40  energy_after :  50  reward :  -210.2830891159617\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step\n",
      "action : 1  next_temperatures :  [ 0.66837605 -1.43322162  1.35988391 -2.23531612  0.34681039 -1.04752589\n",
      "  1.02830998 -1.37586131  0.40545548]  energy_before :  50  energy_after :  50  reward :  -200.2830891159617\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "action : 1  next_temperatures :  [ 0.66837605 -1.43322162  1.35988391 -2.23531612  0.34681039 -1.04752589\n",
      "  1.02830998 -1.37586131  0.40545548]  energy_before :  50  energy_after :  50  reward :  -200.2830891159617\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "Episode 385/500, Total Reward: -1021.4154455798085\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "action : 1  next_temperatures :  [ 0.92158922  0.38456511  2.59568025 -1.16152938  1.00813999 -0.1666926\n",
      "  1.22444286  0.25333092  0.90096217]  energy_before :  30  energy_after :  50  reward :  -212.03951147136647\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "action : 1  next_temperatures :  [ 0.92158922  0.38456511  2.59568025 -1.16152938  1.00813999 -0.1666926\n",
      "  1.22444286  0.25333092  0.90096217]  energy_before :  50  energy_after :  40  reward :  -182.03951147136647\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "action : 1  next_temperatures :  [ 0.92158922  0.38456511  2.59568025 -1.16152938  1.00813999 -0.1666926\n",
      "  1.22444286  0.25333092  0.90096217]  energy_before :  40  energy_after :  50  reward :  -202.03951147136647\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step\n",
      "action : 1  next_temperatures :  [ 0.92158922  0.38456511  2.59568025 -1.16152938  1.00813999 -0.1666926\n",
      "  1.22444286  0.25333092  0.90096217]  energy_before :  50  energy_after :  50  reward :  -192.03951147136647\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "action : 1  next_temperatures :  [ 0.92158922  0.38456511  2.59568025 -1.16152938  1.00813999 -0.1666926\n",
      "  1.22444286  0.25333092  0.90096217]  energy_before :  50  energy_after :  50  reward :  -192.03951147136647\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "Episode 386/500, Total Reward: -980.1975573568324\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step\n",
      "action : 1  next_temperatures :  [-0.3652318  -0.51762674 -0.40336794  0.14159395 -0.2829482  -0.81502687\n",
      "  0.03491815 -0.67651722 -0.32099851]  energy_before :  30  energy_after :  50  reward :  -221.2052051733088\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "action : 1  next_temperatures :  [-0.3652318  -0.51762674 -0.40336794  0.14159395 -0.2829482  -0.81502687\n",
      "  0.03491815 -0.67651722 -0.32099851]  energy_before :  50  energy_after :  40  reward :  -191.2052051733088\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "action : 1  next_temperatures :  [-0.3652318  -0.51762674 -0.40336794  0.14159395 -0.2829482  -0.81502687\n",
      "  0.03491815 -0.67651722 -0.32099851]  energy_before :  40  energy_after :  50  reward :  -211.2052051733088\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "action : 1  next_temperatures :  [-0.3652318  -0.51762674 -0.40336794  0.14159395 -0.2829482  -0.81502687\n",
      "  0.03491815 -0.67651722 -0.32099851]  energy_before :  50  energy_after :  50  reward :  -201.2052051733088\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "action : 1  next_temperatures :  [-0.3652318  -0.51762674 -0.40336794  0.14159395 -0.2829482  -0.81502687\n",
      "  0.03491815 -0.67651722 -0.32099851]  energy_before :  50  energy_after :  50  reward :  -201.2052051733088\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step\n",
      "Episode 387/500, Total Reward: -1026.026025866544\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "action : 1  next_temperatures :  [-0.67655947 -0.01501289 -0.70737688  0.26527191 -0.43747999  0.47549632\n",
      " -1.04038608  0.47523522 -0.86975439]  energy_before :  30  energy_after :  50  reward :  -220.53056625687972\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step\n",
      "action : 1  next_temperatures :  [-0.67655947 -0.01501289 -0.70737688  0.26527191 -0.43747999  0.47549632\n",
      " -1.04038608  0.47523522 -0.86975439]  energy_before :  50  energy_after :  40  reward :  -190.53056625687972\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "action : 1  next_temperatures :  [-0.67655947 -0.01501289 -0.70737688  0.26527191 -0.43747999  0.47549632\n",
      " -1.04038608  0.47523522 -0.86975439]  energy_before :  40  energy_after :  50  reward :  -210.53056625687972\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "action : 1  next_temperatures :  [-0.67655947 -0.01501289 -0.70737688  0.26527191 -0.43747999  0.47549632\n",
      " -1.04038608  0.47523522 -0.86975439]  energy_before :  50  energy_after :  50  reward :  -200.53056625687972\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "action : 1  next_temperatures :  [-0.67655947 -0.01501289 -0.70737688  0.26527191 -0.43747999  0.47549632\n",
      " -1.04038608  0.47523522 -0.86975439]  energy_before :  50  energy_after :  50  reward :  -200.53056625687972\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step\n",
      "Episode 388/500, Total Reward: -1022.6528312843986\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step\n",
      "action : 1  next_temperatures :  [-0.9256216  -1.28997667 -0.93538358 -1.09436652 -0.83128681 -0.84268094\n",
      " -0.96206346 -1.27312499 -1.0799803 ]  energy_before :  30  energy_after :  50  reward :  -227.23448488288932\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "action : 1  next_temperatures :  [-0.9256216  -1.28997667 -0.93538358 -1.09436652 -0.83128681 -0.84268094\n",
      " -0.96206346 -1.27312499 -1.0799803 ]  energy_before :  50  energy_after :  40  reward :  -197.23448488288932\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "action : 1  next_temperatures :  [-0.9256216  -1.28997667 -0.93538358 -1.09436652 -0.83128681 -0.84268094\n",
      " -0.96206346 -1.27312499 -1.0799803 ]  energy_before :  40  energy_after :  50  reward :  -217.23448488288932\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "action : 1  next_temperatures :  [-0.9256216  -1.28997667 -0.93538358 -1.09436652 -0.83128681 -0.84268094\n",
      " -0.96206346 -1.27312499 -1.0799803 ]  energy_before :  50  energy_after :  50  reward :  -207.23448488288932\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "action : 1  next_temperatures :  [-0.9256216  -1.28997667 -0.93538358 -1.09436652 -0.83128681 -0.84268094\n",
      " -0.96206346 -1.27312499 -1.0799803 ]  energy_before :  50  energy_after :  50  reward :  -207.23448488288932\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "Episode 389/500, Total Reward: -1056.1724244144466\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "action : 1  next_temperatures :  [-1.56903211  1.10665366 -0.83962076  0.80585104 -1.48430825  1.62365226\n",
      " -0.8103134   1.26764091 -1.32755293]  energy_before :  30  energy_after :  50  reward :  -219.22702959055474\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "action : 1  next_temperatures :  [-1.56903211  1.10665366 -0.83962076  0.80585104 -1.48430825  1.62365226\n",
      " -0.8103134   1.26764091 -1.32755293]  energy_before :  50  energy_after :  40  reward :  -189.22702959055474\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "action : 1  next_temperatures :  [-1.56903211  1.10665366 -0.83962076  0.80585104 -1.48430825  1.62365226\n",
      " -0.8103134   1.26764091 -1.32755293]  energy_before :  40  energy_after :  50  reward :  -209.22702959055474\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "action : 1  next_temperatures :  [-1.56903211  1.10665366 -0.83962076  0.80585104 -1.48430825  1.62365226\n",
      " -0.8103134   1.26764091 -1.32755293]  energy_before :  50  energy_after :  50  reward :  -199.22702959055474\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "action : 1  next_temperatures :  [-1.56903211  1.10665366 -0.83962076  0.80585104 -1.48430825  1.62365226\n",
      " -0.8103134   1.26764091 -1.32755293]  energy_before :  50  energy_after :  50  reward :  -199.22702959055474\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "Episode 390/500, Total Reward: -1016.1351479527737\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step\n",
      "action : 1  next_temperatures :  [-0.67655947  0.91482271 -0.25136347  0.75670749 -0.83128681  1.58473172\n",
      " -0.56555523  1.51181242 -1.02576732]  energy_before :  30  energy_after :  50  reward :  -216.58245795324524\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step\n",
      "action : 1  next_temperatures :  [-0.67655947  0.91482271 -0.25136347  0.75670749 -0.83128681  1.58473172\n",
      " -0.56555523  1.51181242 -1.02576732]  energy_before :  50  energy_after :  40  reward :  -186.58245795324524\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "action : 1  next_temperatures :  [-0.67655947  0.91482271 -0.25136347  0.75670749 -0.83128681  1.58473172\n",
      " -0.56555523  1.51181242 -1.02576732]  energy_before :  40  energy_after :  50  reward :  -206.58245795324524\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "action : 1  next_temperatures :  [-0.67655947  0.91482271 -0.25136347  0.75670749 -0.83128681  1.58473172\n",
      " -0.56555523  1.51181242 -1.02576732]  energy_before :  50  energy_after :  50  reward :  -196.58245795324524\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "action : 1  next_temperatures :  [-0.67655947  0.91482271 -0.25136347  0.75670749 -0.83128681  1.58473172\n",
      " -0.56555523  1.51181242 -1.02576732]  energy_before :  50  energy_after :  50  reward :  -196.58245795324524\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step\n",
      "Episode 391/500, Total Reward: -1002.9122897662262\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step\n",
      "action : 1  next_temperatures :  [-0.96713196 -1.1735378  -1.25003283 -0.62832178 -0.7116493  -0.95176087\n",
      " -0.71730529 -1.20632335 -0.75470239]  energy_before :  30  energy_after :  50  reward :  -226.36076557603107\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "action : 1  next_temperatures :  [-0.96713196 -1.1735378  -1.25003283 -0.62832178 -0.7116493  -0.95176087\n",
      " -0.71730529 -1.20632335 -0.75470239]  energy_before :  50  energy_after :  40  reward :  -196.36076557603107\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step\n",
      "action : 1  next_temperatures :  [-0.96713196 -1.1735378  -1.25003283 -0.62832178 -0.7116493  -0.95176087\n",
      " -0.71730529 -1.20632335 -0.75470239]  energy_before :  40  energy_after :  50  reward :  -216.36076557603107\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "action : 1  next_temperatures :  [-0.96713196 -1.1735378  -1.25003283 -0.62832178 -0.7116493  -0.95176087\n",
      " -0.71730529 -1.20632335 -0.75470239]  energy_before :  50  energy_after :  50  reward :  -206.36076557603107\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "action : 1  next_temperatures :  [-0.96713196 -1.1735378  -1.25003283 -0.62832178 -0.7116493  -0.95176087\n",
      " -0.71730529 -1.20632335 -0.75470239]  energy_before :  50  energy_after :  50  reward :  -206.36076557603107\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "Episode 392/500, Total Reward: -1051.8038278801553\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "action : 1  next_temperatures :  [ 0.81781333  1.84382063  0.70626469  0.25708132  0.06100966  1.07389962\n",
      " -1.0110151   2.28962924 -0.97697563]  energy_before :  30  energy_after :  50  reward :  -212.93847223852126\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "action : 1  next_temperatures :  [ 0.81781333  1.84382063  0.70626469  0.25708132  0.06100966  1.07389962\n",
      " -1.0110151   2.28962924 -0.97697563]  energy_before :  50  energy_after :  40  reward :  -182.93847223852126\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "action : 1  next_temperatures :  [ 0.81781333  1.84382063  0.70626469  0.25708132  0.06100966  1.07389962\n",
      " -1.0110151   2.28962924 -0.97697563]  energy_before :  40  energy_after :  50  reward :  -202.93847223852126\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "action : 1  next_temperatures :  [ 0.81781333  1.84382063  0.70626469  0.25708132  0.06100966  1.07389962\n",
      " -1.0110151   2.28962924 -0.97697563]  energy_before :  50  energy_after :  50  reward :  -192.93847223852126\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step\n",
      "action : 1  next_temperatures :  [ 0.81781333  1.84382063  0.70626469  0.25708132  0.06100966  1.07389962\n",
      " -1.0110151   2.28962924 -0.97697563]  energy_before :  50  energy_after :  50  reward :  -192.93847223852126\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "Episode 393/500, Total Reward: -984.6923611926063\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "action : 1  next_temperatures :  [-0.42749733 -1.28076209 -0.07959842 -1.75944267 -0.40092408 -1.37732625\n",
      " -0.07603889 -1.21323386 -0.43484578]  energy_before :  30  energy_after :  50  reward :  -225.04966937535553\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step\n",
      "action : 1  next_temperatures :  [-0.42749733 -1.28076209 -0.07959842 -1.75944267 -0.40092408 -1.37732625\n",
      " -0.07603889 -1.21323386 -0.43484578]  energy_before :  50  energy_after :  40  reward :  -195.04966937535553\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step\n",
      "action : 1  next_temperatures :  [-0.42749733 -1.28076209 -0.07959842 -1.75944267 -0.40092408 -1.37732625\n",
      " -0.07603889 -1.21323386 -0.43484578]  energy_before :  40  energy_after :  50  reward :  -215.04966937535553\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "action : 1  next_temperatures :  [-0.42749733 -1.28076209 -0.07959842 -1.75944267 -0.40092408 -1.37732625\n",
      " -0.07603889 -1.21323386 -0.43484578]  energy_before :  50  energy_after :  50  reward :  -205.04966937535553\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "action : 1  next_temperatures :  [-0.42749733 -1.28076209 -0.07959842 -1.75944267 -0.40092408 -1.37732625\n",
      " -0.07603889 -1.21323386 -0.43484578]  energy_before :  50  energy_after :  50  reward :  -205.04966937535553\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "Episode 394/500, Total Reward: -1045.2483468767778\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "action : 1  next_temperatures :  [-0.98788713 -0.14234173 -0.46416972 -0.14425774 -0.88113578 -0.22814609\n",
      "  0.21277576 -0.40009664 -0.57399244]  energy_before :  30  energy_after :  50  reward :  -221.60925152051226\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "action : 1  next_temperatures :  [-0.98788713 -0.14234173 -0.46416972 -0.14425774 -0.88113578 -0.22814609\n",
      "  0.21277576 -0.40009664 -0.57399244]  energy_before :  50  energy_after :  40  reward :  -191.60925152051226\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "action : 1  next_temperatures :  [-0.98788713 -0.14234173 -0.46416972 -0.14425774 -0.88113578 -0.22814609\n",
      "  0.21277576 -0.40009664 -0.57399244]  energy_before :  40  energy_after :  50  reward :  -211.60925152051226\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "action : 1  next_temperatures :  [-0.98788713 -0.14234173 -0.46416972 -0.14425774 -0.88113578 -0.22814609\n",
      "  0.21277576 -0.40009664 -0.57399244]  energy_before :  50  energy_after :  50  reward :  -201.60925152051226\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step\n",
      "action : 1  next_temperatures :  [-0.98788713 -0.14234173 -0.46416972 -0.14425774 -0.88113578 -0.22814609\n",
      "  0.21277576 -0.40009664 -0.57399244]  energy_before :  50  energy_after :  50  reward :  -201.60925152051226\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "Episode 395/500, Total Reward: -1028.0462576025614\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "action : 1  next_temperatures :  [-0.3652318  -1.19615542 -0.38360736 -1.05505167 -1.1509433  -0.59993967\n",
      " -1.0110151  -0.59934981 -1.32936003]  energy_before :  30  energy_after :  50  reward :  -225.6906541685325\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "action : 1  next_temperatures :  [-0.3652318  -1.19615542 -0.38360736 -1.05505167 -1.1509433  -0.59993967\n",
      " -1.0110151  -0.59934981 -1.32936003]  energy_before :  50  energy_after :  40  reward :  -195.6906541685325\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step\n",
      "action : 1  next_temperatures :  [-0.3652318  -1.19615542 -0.38360736 -1.05505167 -1.1509433  -0.59993967\n",
      " -1.0110151  -0.59934981 -1.32936003]  energy_before :  40  energy_after :  50  reward :  -215.6906541685325\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "action : 1  next_temperatures :  [-0.3652318  -1.19615542 -0.38360736 -1.05505167 -1.1509433  -0.59993967\n",
      " -1.0110151  -0.59934981 -1.32936003]  energy_before :  50  energy_after :  50  reward :  -205.6906541685325\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "action : 1  next_temperatures :  [-0.3652318  -1.19615542 -0.38360736 -1.05505167 -1.1509433  -0.59993967\n",
      " -1.0110151  -0.59934981 -1.32936003]  energy_before :  50  energy_after :  50  reward :  -205.6906541685325\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "Episode 396/500, Total Reward: -1048.4532708426625\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "action : 1  next_temperatures :  [-0.24692729 -0.56034891  0.25025128 -1.10337617 -0.33279717 -0.52619549\n",
      "  0.21277576 -1.0581312  -0.53785045]  energy_before :  30  energy_after :  50  reward :  -221.90259964375974\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "action : 1  next_temperatures :  [-0.24692729 -0.56034891  0.25025128 -1.10337617 -0.33279717 -0.52619549\n",
      "  0.21277576 -1.0581312  -0.53785045]  energy_before :  50  energy_after :  40  reward :  -191.90259964375974\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "action : 1  next_temperatures :  [-0.24692729 -0.56034891  0.25025128 -1.10337617 -0.33279717 -0.52619549\n",
      "  0.21277576 -1.0581312  -0.53785045]  energy_before :  40  energy_after :  50  reward :  -211.90259964375974\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step\n",
      "action : 1  next_temperatures :  [-0.24692729 -0.56034891  0.25025128 -1.10337617 -0.33279717 -0.52619549\n",
      "  0.21277576 -1.0581312  -0.53785045]  energy_before :  50  energy_after :  50  reward :  -201.90259964375974\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "action : 1  next_temperatures :  [-0.24692729 -0.56034891  0.25025128 -1.10337617 -0.33279717 -0.52619549\n",
      "  0.21277576 -1.0581312  -0.53785045]  energy_before :  50  energy_after :  50  reward :  -201.90259964375974\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "Episode 397/500, Total Reward: -1029.5129982187987\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "action : 1  next_temperatures :  [ 1.26418442  0.29383352  1.01383685  0.42355246  1.35170941 -0.05595661\n",
      "  1.29797627  0.2014173   0.92751949]  energy_before :  30  energy_after :  50  reward :  -211.281926890941\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "action : 1  next_temperatures :  [ 1.26418442  0.29383352  1.01383685  0.42355246  1.35170941 -0.05595661\n",
      "  1.29797627  0.2014173   0.92751949]  energy_before :  50  energy_after :  40  reward :  -181.281926890941\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "action : 1  next_temperatures :  [ 1.26418442  0.29383352  1.01383685  0.42355246  1.35170941 -0.05595661\n",
      "  1.29797627  0.2014173   0.92751949]  energy_before :  40  energy_after :  50  reward :  -201.281926890941\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "action : 1  next_temperatures :  [ 1.26418442  0.29383352  1.01383685  0.42355246  1.35170941 -0.05595661\n",
      "  1.29797627  0.2014173   0.92751949]  energy_before :  50  energy_after :  50  reward :  -191.281926890941\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step\n",
      "action : 1  next_temperatures :  [ 1.26418442  0.29383352  1.01383685  0.42355246  1.35170941 -0.05595661\n",
      "  1.29797627  0.2014173   0.92751949]  energy_before :  50  energy_after :  50  reward :  -191.281926890941\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "Episode 398/500, Total Reward: -976.409634454705\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "action : 1  next_temperatures :  [ 1.51830058 -0.56788812  0.9342714  -0.4407572   1.16267178 -0.44630596\n",
      "  1.43656661 -0.51527188  0.87168715]  energy_before :  30  energy_after :  50  reward :  -214.04672564414975\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "action : 1  next_temperatures :  [ 1.51830058 -0.56788812  0.9342714  -0.4407572   1.16267178 -0.44630596\n",
      "  1.43656661 -0.51527188  0.87168715]  energy_before :  50  energy_after :  40  reward :  -184.04672564414975\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "action : 1  next_temperatures :  [ 1.51830058 -0.56788812  0.9342714  -0.4407572   1.16267178 -0.44630596\n",
      "  1.43656661 -0.51527188  0.87168715]  energy_before :  40  energy_after :  50  reward :  -204.04672564414975\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "action : 1  next_temperatures :  [ 1.51830058 -0.56788812  0.9342714  -0.4407572   1.16267178 -0.44630596\n",
      "  1.43656661 -0.51527188  0.87168715]  energy_before :  50  energy_after :  50  reward :  -194.04672564414975\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "action : 1  next_temperatures :  [ 1.51830058 -0.56788812  0.9342714  -0.4407572   1.16267178 -0.44630596\n",
      "  1.43656661 -0.51527188  0.87168715]  energy_before :  50  energy_after :  50  reward :  -194.04672564414975\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "Episode 399/500, Total Reward: -990.2336282207488\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "action : 1  next_temperatures :  [-1.42997242 -0.89458712 -1.57380235 -0.12787655 -1.23506343 -0.80376039\n",
      " -0.24247444 -0.72873    -1.19382757]  energy_before :  30  energy_after :  50  reward :  -226.23009428127483\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step\n",
      "action : 1  next_temperatures :  [-1.42997242 -0.89458712 -1.57380235 -0.12787655 -1.23506343 -0.80376039\n",
      " -0.24247444 -0.72873    -1.19382757]  energy_before :  50  energy_after :  40  reward :  -196.23009428127483\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "action : 1  next_temperatures :  [-1.42997242 -0.89458712 -1.57380235 -0.12787655 -1.23506343 -0.80376039\n",
      " -0.24247444 -0.72873    -1.19382757]  energy_before :  40  energy_after :  50  reward :  -216.23009428127483\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "action : 1  next_temperatures :  [-1.42997242 -0.89458712 -1.57380235 -0.12787655 -1.23506343 -0.80376039\n",
      " -0.24247444 -0.72873    -1.19382757]  energy_before :  50  energy_after :  50  reward :  -206.23009428127483\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "action : 1  next_temperatures :  [-1.42997242 -0.89458712 -1.57380235 -0.12787655 -1.23506343 -0.80376039\n",
      " -0.24247444 -0.72873    -1.19382757]  energy_before :  50  energy_after :  50  reward :  -206.23009428127483\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "Episode 400/500, Total Reward: -1051.1504714063742\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step\n",
      "action : 1  next_temperatures :  [-1.05015267  1.373039   -0.54321205  0.93976724 -1.18521446  1.67691195\n",
      " -0.36974869  1.15246566 -0.80891538]  energy_before :  30  energy_after :  50  reward :  -216.81505940583645\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "action : 1  next_temperatures :  [-1.05015267  1.373039   -0.54321205  0.93976724 -1.18521446  1.67691195\n",
      " -0.36974869  1.15246566 -0.80891538]  energy_before :  50  energy_after :  40  reward :  -186.81505940583645\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step\n",
      "action : 1  next_temperatures :  [-1.05015267  1.373039   -0.54321205  0.93976724 -1.18521446  1.67691195\n",
      " -0.36974869  1.15246566 -0.80891538]  energy_before :  40  energy_after :  50  reward :  -206.81505940583645\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "action : 1  next_temperatures :  [-1.05015267  1.373039   -0.54321205  0.93976724 -1.18521446  1.67691195\n",
      " -0.36974869  1.15246566 -0.80891538]  energy_before :  50  energy_after :  50  reward :  -196.81505940583645\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "action : 1  next_temperatures :  [-1.05015267  1.373039   -0.54321205  0.93976724 -1.18521446  1.67691195\n",
      " -0.36974869  1.15246566 -0.80891538]  energy_before :  50  energy_after :  50  reward :  -196.81505940583645\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "Episode 401/500, Total Reward: -1004.0752970291823\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step\n",
      "action : 1  next_temperatures :  [ 1.66254906  0.60487751  1.98766237 -0.82080072  2.75285376 -0.21892806\n",
      "  1.83307485  0.2617771   1.46260869]  energy_before :  30  energy_after :  50  reward :  -208.4743254357025\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step\n",
      "action : 1  next_temperatures :  [ 1.66254906  0.60487751  1.98766237 -0.82080072  2.75285376 -0.21892806\n",
      "  1.83307485  0.2617771   1.46260869]  energy_before :  50  energy_after :  40  reward :  -178.4743254357025\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "action : 1  next_temperatures :  [ 1.66254906  0.60487751  1.98766237 -0.82080072  2.75285376 -0.21892806\n",
      "  1.83307485  0.2617771   1.46260869]  energy_before :  40  energy_after :  50  reward :  -198.4743254357025\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "action : 1  next_temperatures :  [ 1.66254906  0.60487751  1.98766237 -0.82080072  2.75285376 -0.21892806\n",
      "  1.83307485  0.2617771   1.46260869]  energy_before :  50  energy_after :  50  reward :  -188.4743254357025\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "action : 1  next_temperatures :  [ 1.66254906  0.60487751  1.98766237 -0.82080072  2.75285376 -0.21892806\n",
      "  1.83307485  0.2617771   1.46260869]  energy_before :  50  energy_after :  50  reward :  -188.4743254357025\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "Episode 402/500, Total Reward: -962.3716271785124\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "action : 1  next_temperatures :  [ 2.12538953 -0.19930464  3.3830634  -2.11245722  1.91040625 -0.25887283\n",
      "  2.07783302 -0.31409912  1.95594685]  energy_before :  30  energy_after :  50  reward :  -209.43209475737396\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "action : 1  next_temperatures :  [ 2.12538953 -0.19930464  3.3830634  -2.11245722  1.91040625 -0.25887283\n",
      "  2.07783302 -0.31409912  1.95594685]  energy_before :  50  energy_after :  40  reward :  -179.43209475737396\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step\n",
      "action : 1  next_temperatures :  [ 2.12538953 -0.19930464  3.3830634  -2.11245722  1.91040625 -0.25887283\n",
      "  2.07783302 -0.31409912  1.95594685]  energy_before :  40  energy_after :  50  reward :  -199.43209475737396\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step\n",
      "action : 1  next_temperatures :  [ 2.12538953 -0.19930464  3.3830634  -2.11245722  1.91040625 -0.25887283\n",
      "  2.07783302 -0.31409912  1.95594685]  energy_before :  50  energy_after :  50  reward :  -189.43209475737396\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "action : 1  next_temperatures :  [ 2.12538953 -0.19930464  3.3830634  -2.11245722  1.91040625 -0.25887283\n",
      "  2.07783302 -0.31409912  1.95594685]  energy_before :  50  energy_after :  50  reward :  -189.43209475737396\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "Episode 403/500, Total Reward: -967.1604737868698\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "action : 1  next_temperatures :  [-0.23136091 -1.25458428 -0.17232114 -1.25162591 -0.68672482 -1.20320805\n",
      " -0.56555523 -1.40519261 -0.67338292]  energy_before :  30  energy_after :  50  reward :  -225.4439558469957\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "action : 1  next_temperatures :  [-0.23136091 -1.25458428 -0.17232114 -1.25162591 -0.68672482 -1.20320805\n",
      " -0.56555523 -1.40519261 -0.67338292]  energy_before :  50  energy_after :  40  reward :  -195.4439558469957\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step\n",
      "action : 1  next_temperatures :  [-0.23136091 -1.25458428 -0.17232114 -1.25162591 -0.68672482 -1.20320805\n",
      " -0.56555523 -1.40519261 -0.67338292]  energy_before :  40  energy_after :  50  reward :  -215.4439558469957\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step\n",
      "action : 1  next_temperatures :  [-0.23136091 -1.25458428 -0.17232114 -1.25162591 -0.68672482 -1.20320805\n",
      " -0.56555523 -1.40519261 -0.67338292]  energy_before :  50  energy_after :  50  reward :  -205.4439558469957\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step\n",
      "action : 1  next_temperatures :  [-0.23136091 -1.25458428 -0.17232114 -1.25162591 -0.68672482 -1.20320805\n",
      " -0.56555523 -1.40519261 -0.67338292]  energy_before :  50  energy_after :  50  reward :  -205.4439558469957\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "Episode 404/500, Total Reward: -1047.2197792349784\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "action : 1  next_temperatures :  [ 0.58950637  0.74644708  0.49497848  0.78783174  0.01116069  1.00092361\n",
      "  0.18177306  1.9264433  -0.21257254]  energy_before :  30  energy_after :  50  reward :  -212.47350821366564\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "action : 1  next_temperatures :  [ 0.58950637  0.74644708  0.49497848  0.78783174  0.01116069  1.00092361\n",
      "  0.18177306  1.9264433  -0.21257254]  energy_before :  50  energy_after :  40  reward :  -182.47350821366564\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "action : 1  next_temperatures :  [ 0.58950637  0.74644708  0.49497848  0.78783174  0.01116069  1.00092361\n",
      "  0.18177306  1.9264433  -0.21257254]  energy_before :  40  energy_after :  50  reward :  -202.47350821366564\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "action : 1  next_temperatures :  [ 0.58950637  0.74644708  0.49497848  0.78783174  0.01116069  1.00092361\n",
      "  0.18177306  1.9264433  -0.21257254]  energy_before :  50  energy_after :  50  reward :  -192.47350821366564\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "action : 1  next_temperatures :  [ 0.58950637  0.74644708  0.49497848  0.78783174  0.01116069  1.00092361\n",
      "  0.18177306  1.9264433  -0.21257254]  energy_before :  50  energy_after :  50  reward :  -192.47350821366564\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "Episode 405/500, Total Reward: -982.3675410683281\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step\n",
      "action : 1  next_temperatures :  [ 0.0083614   2.11188135  0.30041276  1.42751705 -0.01874869  2.27813187\n",
      " -0.27674059  1.65232622  0.05849238]  energy_before :  30  energy_after :  50  reward :  -210.4583662473966\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "action : 1  next_temperatures :  [ 0.0083614   2.11188135  0.30041276  1.42751705 -0.01874869  2.27813187\n",
      " -0.27674059  1.65232622  0.05849238]  energy_before :  50  energy_after :  40  reward :  -180.4583662473966\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "action : 1  next_temperatures :  [ 0.0083614   2.11188135  0.30041276  1.42751705 -0.01874869  2.27813187\n",
      " -0.27674059  1.65232622  0.05849238]  energy_before :  40  energy_after :  50  reward :  -200.4583662473966\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step\n",
      "action : 1  next_temperatures :  [ 0.0083614   2.11188135  0.30041276  1.42751705 -0.01874869  2.27813187\n",
      " -0.27674059  1.65232622  0.05849238]  energy_before :  50  energy_after :  50  reward :  -190.4583662473966\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "action : 1  next_temperatures :  [ 0.0083614   2.11188135  0.30041276  1.42751705 -0.01874869  2.27813187\n",
      " -0.27674059  1.65232622  0.05849238]  energy_before :  50  energy_after :  50  reward :  -190.4583662473966\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "Episode 406/500, Total Reward: -972.2918312369831\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "action : 1  next_temperatures :  [-0.09541449  0.20865027 -0.56601272  1.15640842 -0.58204199  0.02586165\n",
      " -0.07603889 -0.47534446 -0.3806328 ]  energy_before :  30  energy_after :  50  reward :  -218.78456500902118\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "action : 1  next_temperatures :  [-0.09541449  0.20865027 -0.56601272  1.15640842 -0.58204199  0.02586165\n",
      " -0.07603889 -0.47534446 -0.3806328 ]  energy_before :  50  energy_after :  40  reward :  -188.78456500902118\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step\n",
      "action : 1  next_temperatures :  [-0.09541449  0.20865027 -0.56601272  1.15640842 -0.58204199  0.02586165\n",
      " -0.07603889 -0.47534446 -0.3806328 ]  energy_before :  40  energy_after :  50  reward :  -208.78456500902118\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "action : 1  next_temperatures :  [-0.09541449  0.20865027 -0.56601272  1.15640842 -0.58204199  0.02586165\n",
      " -0.07603889 -0.47534446 -0.3806328 ]  energy_before :  50  energy_after :  50  reward :  -198.78456500902118\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "action : 1  next_temperatures :  [-0.09541449  0.20865027 -0.56601272  1.15640842 -0.58204199  0.02586165\n",
      " -0.07603889 -0.47534446 -0.3806328 ]  energy_before :  50  energy_after :  50  reward :  -198.78456500902118\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "Episode 407/500, Total Reward: -1013.9228250451059\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "action : 1  next_temperatures :  [ 0.195158    1.69387417  0.3460141   1.50123238 -0.29956452  2.24842935\n",
      " -0.82663061  2.41248284  0.16149705]  energy_before :  30  energy_after :  50  reward :  -210.56750724061826\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step\n",
      "action : 1  next_temperatures :  [ 0.195158    1.69387417  0.3460141   1.50123238 -0.29956452  2.24842935\n",
      " -0.82663061  2.41248284  0.16149705]  energy_before :  50  energy_after :  40  reward :  -180.56750724061826\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "action : 1  next_temperatures :  [ 0.195158    1.69387417  0.3460141   1.50123238 -0.29956452  2.24842935\n",
      " -0.82663061  2.41248284  0.16149705]  energy_before :  40  energy_after :  50  reward :  -200.56750724061826\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step\n",
      "action : 1  next_temperatures :  [ 0.195158    1.69387417  0.3460141   1.50123238 -0.29956452  2.24842935\n",
      " -0.82663061  2.41248284  0.16149705]  energy_before :  50  energy_after :  50  reward :  -190.56750724061826\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step\n",
      "action : 1  next_temperatures :  [ 0.195158    1.69387417  0.3460141   1.50123238 -0.29956452  2.24842935\n",
      " -0.82663061  2.41248284  0.16149705]  energy_before :  50  energy_after :  50  reward :  -190.56750724061826\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "Episode 408/500, Total Reward: -972.8375362030913\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "action : 1  next_temperatures :  [ 0.81781333  1.39063048  0.95099189  0.19155657  0.16569248  1.48026079\n",
      " -0.71730529  0.72094241 -0.06318565]  energy_before :  30  energy_after :  50  reward :  -213.06260298639708\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "action : 1  next_temperatures :  [ 0.81781333  1.39063048  0.95099189  0.19155657  0.16569248  1.48026079\n",
      " -0.71730529  0.72094241 -0.06318565]  energy_before :  50  energy_after :  40  reward :  -183.06260298639708\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "action : 1  next_temperatures :  [ 0.81781333  1.39063048  0.95099189  0.19155657  0.16569248  1.48026079\n",
      " -0.71730529  0.72094241 -0.06318565]  energy_before :  40  energy_after :  50  reward :  -203.06260298639708\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "action : 1  next_temperatures :  [ 0.81781333  1.39063048  0.95099189  0.19155657  0.16569248  1.48026079\n",
      " -0.71730529  0.72094241 -0.06318565]  energy_before :  50  energy_after :  50  reward :  -193.06260298639708\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "action : 1  next_temperatures :  [ 0.81781333  1.39063048  0.95099189  0.19155657  0.16569248  1.48026079\n",
      " -0.71730529  0.72094241 -0.06318565]  energy_before :  50  energy_after :  50  reward :  -193.06260298639708\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "Episode 409/500, Total Reward: -985.3130149319854\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "action : 1  next_temperatures :  [ 1.06064891 -0.3249581   0.16360874  0.43727436  1.21252075 -0.51697747\n",
      "  1.19180844 -0.14440759 -0.18329753]  energy_before :  30  energy_after :  50  reward :  -215.10377949858787\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "action : 1  next_temperatures :  [ 1.06064891 -0.3249581   0.16360874  0.43727436  1.21252075 -0.51697747\n",
      "  1.19180844 -0.14440759 -0.18329753]  energy_before :  50  energy_after :  40  reward :  -185.10377949858787\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "action : 1  next_temperatures :  [ 1.06064891 -0.3249581   0.16360874  0.43727436  1.21252075 -0.51697747\n",
      "  1.19180844 -0.14440759 -0.18329753]  energy_before :  40  energy_after :  50  reward :  -205.10377949858787\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "action : 1  next_temperatures :  [ 1.06064891 -0.3249581   0.16360874  0.43727436  1.21252075 -0.51697747\n",
      "  1.19180844 -0.14440759 -0.18329753]  energy_before :  50  energy_after :  50  reward :  -195.10377949858787\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "action : 1  next_temperatures :  [ 1.06064891 -0.3249581   0.16360874  0.43727436  1.21252075 -0.51697747\n",
      "  1.19180844 -0.14440759 -0.18329753]  energy_before :  50  energy_after :  50  reward :  -195.10377949858787\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "Episode 410/500, Total Reward: -995.5188974929393\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step\n",
      "action : 1  next_temperatures :  [0.88007886 1.73492097 1.17660995 1.27166176 1.16267178 0.79121359\n",
      " 1.43656661 1.30680049 1.28835267]  energy_before :  30  energy_after :  50  reward :  -206.95112331567393\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step\n",
      "action : 1  next_temperatures :  [0.88007886 1.73492097 1.17660995 1.27166176 1.16267178 0.79121359\n",
      " 1.43656661 1.30680049 1.28835267]  energy_before :  50  energy_after :  40  reward :  -176.95112331567393\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "action : 1  next_temperatures :  [0.88007886 1.73492097 1.17660995 1.27166176 1.16267178 0.79121359\n",
      " 1.43656661 1.30680049 1.28835267]  energy_before :  40  energy_after :  50  reward :  -196.95112331567393\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "action : 1  next_temperatures :  [0.88007886 1.73492097 1.17660995 1.27166176 1.16267178 0.79121359\n",
      " 1.43656661 1.30680049 1.28835267]  energy_before :  50  energy_after :  50  reward :  -186.95112331567393\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "action : 1  next_temperatures :  [0.88007886 1.73492097 1.17660995 1.27166176 1.16267178 0.79121359\n",
      " 1.43656661 1.30680049 1.28835267]  energy_before :  50  energy_after :  50  reward :  -186.95112331567393\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "Episode 411/500, Total Reward: -954.7556165783697\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step\n",
      "action : 1  next_temperatures :  [2.12538953 0.83691757 1.48604762 0.99423468 2.25436411 0.31080098\n",
      " 2.27363956 0.80002941 2.11858581]  energy_before :  30  energy_after :  50  reward :  -204.79999074211153\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "action : 1  next_temperatures :  [2.12538953 0.83691757 1.48604762 0.99423468 2.25436411 0.31080098\n",
      " 2.27363956 0.80002941 2.11858581]  energy_before :  50  energy_after :  40  reward :  -174.79999074211153\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "action : 1  next_temperatures :  [2.12538953 0.83691757 1.48604762 0.99423468 2.25436411 0.31080098\n",
      " 2.27363956 0.80002941 2.11858581]  energy_before :  40  energy_after :  50  reward :  -194.79999074211153\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "action : 1  next_temperatures :  [2.12538953 0.83691757 1.48604762 0.99423468 2.25436411 0.31080098\n",
      " 2.27363956 0.80002941 2.11858581]  energy_before :  50  energy_after :  50  reward :  -184.79999074211153\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "action : 1  next_temperatures :  [2.12538953 0.83691757 1.48604762 0.99423468 2.25436411 0.31080098\n",
      " 2.27363956 0.80002941 2.11858581]  energy_before :  50  energy_after :  50  reward :  -184.79999074211153\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "Episode 412/500, Total Reward: -943.9999537105576\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "action : 1  next_temperatures :  [-0.24692729  1.53387543  0.13320784  1.14739877 -0.33279717  1.58473172\n",
      " -0.52149876  1.90340826 -0.53785045]  energy_before :  30  energy_after :  50  reward :  -213.3364516518946\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "action : 1  next_temperatures :  [-0.24692729  1.53387543  0.13320784  1.14739877 -0.33279717  1.58473172\n",
      " -0.52149876  1.90340826 -0.53785045]  energy_before :  50  energy_after :  40  reward :  -183.3364516518946\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step\n",
      "action : 1  next_temperatures :  [-0.24692729  1.53387543  0.13320784  1.14739877 -0.33279717  1.58473172\n",
      " -0.52149876  1.90340826 -0.53785045]  energy_before :  40  energy_after :  50  reward :  -203.3364516518946\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "action : 1  next_temperatures :  [-0.24692729  1.53387543  0.13320784  1.14739877 -0.33279717  1.58473172\n",
      " -0.52149876  1.90340826 -0.53785045]  energy_before :  50  energy_after :  50  reward :  -193.3364516518946\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "action : 1  next_temperatures :  [-0.24692729  1.53387543  0.13320784  1.14739877 -0.33279717  1.58473172\n",
      " -0.52149876  1.90340826 -0.53785045]  energy_before :  50  energy_after :  50  reward :  -193.3364516518946\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "Episode 413/500, Total Reward: -986.682258259473\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step\n",
      "action : 1  next_temperatures :  [ 0.37572804 -0.36935565 -0.38360736  0.4102454   0.01116069 -0.41250654\n",
      "  0.03491815 -0.44616674  0.43256198]  energy_before :  30  energy_after :  50  reward :  -218.34702201737977\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "action : 1  next_temperatures :  [ 0.37572804 -0.36935565 -0.38360736  0.4102454   0.01116069 -0.41250654\n",
      "  0.03491815 -0.44616674  0.43256198]  energy_before :  50  energy_after :  40  reward :  -188.34702201737977\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step\n",
      "action : 1  next_temperatures :  [ 0.37572804 -0.36935565 -0.38360736  0.4102454   0.01116069 -0.41250654\n",
      "  0.03491815 -0.44616674  0.43256198]  energy_before :  40  energy_after :  50  reward :  -208.34702201737977\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step\n",
      "action : 1  next_temperatures :  [ 0.37572804 -0.36935565 -0.38360736  0.4102454   0.01116069 -0.41250654\n",
      "  0.03491815 -0.44616674  0.43256198]  energy_before :  50  energy_after :  50  reward :  -198.34702201737977\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step\n",
      "action : 1  next_temperatures :  [ 0.37572804 -0.36935565 -0.38360736  0.4102454   0.01116069 -0.41250654\n",
      "  0.03491815 -0.44616674  0.43256198]  energy_before :  50  energy_after :  50  reward :  -198.34702201737977\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "Episode 414/500, Total Reward: -1011.7351100868989\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "action : 1  next_temperatures :  [-2.11489328 -0.3165812  -1.40507739 -0.2777644  -1.93294894  0.0483946\n",
      " -2.32781406 -0.0545709  -1.89317508]  energy_before :  30  energy_after :  50  reward :  -228.27443065940807\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "action : 1  next_temperatures :  [-2.11489328 -0.3165812  -1.40507739 -0.2777644  -1.93294894  0.0483946\n",
      " -2.32781406 -0.0545709  -1.89317508]  energy_before :  50  energy_after :  40  reward :  -198.27443065940807\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step\n",
      "action : 1  next_temperatures :  [-2.11489328 -0.3165812  -1.40507739 -0.2777644  -1.93294894  0.0483946\n",
      " -2.32781406 -0.0545709  -1.89317508]  energy_before :  40  energy_after :  50  reward :  -218.27443065940807\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "action : 1  next_temperatures :  [-2.11489328 -0.3165812  -1.40507739 -0.2777644  -1.93294894  0.0483946\n",
      " -2.32781406 -0.0545709  -1.89317508]  energy_before :  50  energy_after :  50  reward :  -208.27443065940807\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "action : 1  next_temperatures :  [-2.11489328 -0.3165812  -1.40507739 -0.2777644  -1.93294894  0.0483946\n",
      " -2.32781406 -0.0545709  -1.89317508]  energy_before :  50  energy_after :  50  reward :  -208.27443065940807\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "Episode 415/500, Total Reward: -1061.3721532970403\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "action : 1  next_temperatures :  [ 0.21591317 -0.83678653 -0.15560065 -0.53986338 -0.03370338 -1.21447452\n",
      "  0.34820861 -1.41133529 -0.53785045]  energy_before :  30  energy_after :  50  reward :  -222.16549240330474\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "action : 1  next_temperatures :  [ 0.21591317 -0.83678653 -0.15560065 -0.53986338 -0.03370338 -1.21447452\n",
      "  0.34820861 -1.41133529 -0.53785045]  energy_before :  50  energy_after :  40  reward :  -192.16549240330474\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "action : 1  next_temperatures :  [ 0.21591317 -0.83678653 -0.15560065 -0.53986338 -0.03370338 -1.21447452\n",
      "  0.34820861 -1.41133529 -0.53785045]  energy_before :  40  energy_after :  50  reward :  -212.16549240330474\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step\n",
      "action : 1  next_temperatures :  [ 0.21591317 -0.83678653 -0.15560065 -0.53986338 -0.03370338 -1.21447452\n",
      "  0.34820861 -1.41133529 -0.53785045]  energy_before :  50  energy_after :  50  reward :  -202.16549240330474\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "action : 1  next_temperatures :  [ 0.21591317 -0.83678653 -0.15560065 -0.53986338 -0.03370338 -1.21447452\n",
      "  0.34820861 -1.41133529 -0.53785045]  energy_before :  50  energy_after :  50  reward :  -202.16549240330474\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "Episode 416/500, Total Reward: -1030.8274620165237\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "action : 1  next_temperatures :  [2.24369404 2.17135732 1.61829151 2.10274953 2.05496825 1.70456601\n",
      " 2.17084113 1.58322108 2.44386372]  energy_before :  30  energy_after :  50  reward :  -199.90644742173967\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step\n",
      "action : 1  next_temperatures :  [2.24369404 2.17135732 1.61829151 2.10274953 2.05496825 1.70456601\n",
      " 2.17084113 1.58322108 2.44386372]  energy_before :  50  energy_after :  40  reward :  -169.90644742173967\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "action : 1  next_temperatures :  [2.24369404 2.17135732 1.61829151 2.10274953 2.05496825 1.70456601\n",
      " 2.17084113 1.58322108 2.44386372]  energy_before :  40  energy_after :  50  reward :  -189.90644742173967\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "action : 1  next_temperatures :  [2.24369404 2.17135732 1.61829151 2.10274953 2.05496825 1.70456601\n",
      " 2.17084113 1.58322108 2.44386372]  energy_before :  50  energy_after :  50  reward :  -179.90644742173967\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step\n",
      "action : 1  next_temperatures :  [2.24369404 2.17135732 1.61829151 2.10274953 2.05496825 1.70456601\n",
      " 2.17084113 1.58322108 2.44386372]  energy_before :  50  energy_after :  50  reward :  -179.90644742173967\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "Episode 417/500, Total Reward: -919.5322371086984\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "action : 1  next_temperatures :  [-0.55825495 -1.13081562  0.16360874 -1.5776115  -1.03068267 -0.93486116\n",
      "  0.11976765 -1.08270192 -0.90288455]  energy_before :  30  energy_after :  50  reward :  -224.93443600454515\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "action : 1  next_temperatures :  [-0.55825495 -1.13081562  0.16360874 -1.5776115  -1.03068267 -0.93486116\n",
      "  0.11976765 -1.08270192 -0.90288455]  energy_before :  50  energy_after :  40  reward :  -194.93443600454515\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step\n",
      "action : 1  next_temperatures :  [-0.55825495 -1.13081562  0.16360874 -1.5776115  -1.03068267 -0.93486116\n",
      "  0.11976765 -1.08270192 -0.90288455]  energy_before :  40  energy_after :  50  reward :  -214.93443600454515\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "action : 1  next_temperatures :  [-0.55825495 -1.13081562  0.16360874 -1.5776115  -1.03068267 -0.93486116\n",
      "  0.11976765 -1.08270192 -0.90288455]  energy_before :  50  energy_after :  50  reward :  -204.93443600454515\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step\n",
      "action : 1  next_temperatures :  [-0.55825495 -1.13081562  0.16360874 -1.5776115  -1.03068267 -0.93486116\n",
      "  0.11976765 -1.08270192 -0.90288455]  energy_before :  50  energy_after :  50  reward :  -204.93443600454515\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "Episode 418/500, Total Reward: -1044.6721800227258\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "action : 1  next_temperatures :  [-0.67655947 -0.5285167  -0.26504387 -0.61112154 -0.43747999 -0.81502687\n",
      " -0.07603889 -0.51232851 -0.32099851]  energy_before :  30  energy_after :  50  reward :  -222.24311434895537\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "action : 1  next_temperatures :  [-0.67655947 -0.5285167  -0.26504387 -0.61112154 -0.43747999 -0.81502687\n",
      " -0.07603889 -0.51232851 -0.32099851]  energy_before :  50  energy_after :  40  reward :  -192.24311434895537\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "action : 1  next_temperatures :  [-0.67655947 -0.5285167  -0.26504387 -0.61112154 -0.43747999 -0.81502687\n",
      " -0.07603889 -0.51232851 -0.32099851]  energy_before :  40  energy_after :  50  reward :  -212.24311434895537\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "action : 1  next_temperatures :  [-0.67655947 -0.5285167  -0.26504387 -0.61112154 -0.43747999 -0.81502687\n",
      " -0.07603889 -0.51232851 -0.32099851]  energy_before :  50  energy_after :  50  reward :  -202.24311434895537\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "action : 1  next_temperatures :  [-0.67655947 -0.5285167  -0.26504387 -0.61112154 -0.43747999 -0.81502687\n",
      " -0.07603889 -0.51232851 -0.32099851]  energy_before :  50  energy_after :  50  reward :  -202.24311434895537\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "Episode 419/500, Total Reward: -1031.2155717447768\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "action : 1  next_temperatures :  [0.81781333 0.13325819 0.07240605 0.80585104 1.16267178 0.01459518\n",
      " 1.01395084 0.27022329 0.81747417]  energy_before :  30  energy_after :  50  reward :  -212.89175613412903\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step\n",
      "action : 1  next_temperatures :  [0.81781333 0.13325819 0.07240605 0.80585104 1.16267178 0.01459518\n",
      " 1.01395084 0.27022329 0.81747417]  energy_before :  50  energy_after :  40  reward :  -182.89175613412903\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "action : 1  next_temperatures :  [0.81781333 0.13325819 0.07240605 0.80585104 1.16267178 0.01459518\n",
      " 1.01395084 0.27022329 0.81747417]  energy_before :  40  energy_after :  50  reward :  -202.89175613412903\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "action : 1  next_temperatures :  [0.81781333 0.13325819 0.07240605 0.80585104 1.16267178 0.01459518\n",
      " 1.01395084 0.27022329 0.81747417]  energy_before :  50  energy_after :  50  reward :  -192.89175613412903\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "action : 1  next_temperatures :  [0.81781333 0.13325819 0.07240605 0.80585104 1.16267178 0.01459518\n",
      " 1.01395084 0.27022329 0.81747417]  energy_before :  50  energy_after :  50  reward :  -192.89175613412903\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "Episode 420/500, Total Reward: -984.4587806706452\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "action : 1  next_temperatures :  [ 0.06440038 -0.04098128  0.21985039 -0.34247009 -0.56542567  0.94971237\n",
      " -1.34878137  0.75165581 -0.86312836]  energy_before :  30  energy_after :  50  reward :  -219.1751678209809\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "action : 1  next_temperatures :  [ 0.06440038 -0.04098128  0.21985039 -0.34247009 -0.56542567  0.94971237\n",
      " -1.34878137  0.75165581 -0.86312836]  energy_before :  50  energy_after :  40  reward :  -189.1751678209809\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "action : 1  next_temperatures :  [ 0.06440038 -0.04098128  0.21985039 -0.34247009 -0.56542567  0.94971237\n",
      " -1.34878137  0.75165581 -0.86312836]  energy_before :  40  energy_after :  50  reward :  -209.1751678209809\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "action : 1  next_temperatures :  [ 0.06440038 -0.04098128  0.21985039 -0.34247009 -0.56542567  0.94971237\n",
      " -1.34878137  0.75165581 -0.86312836]  energy_before :  50  energy_after :  50  reward :  -199.1751678209809\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "action : 1  next_temperatures :  [ 0.06440038 -0.04098128  0.21985039 -0.34247009 -0.56542567  0.94971237\n",
      " -1.34878137  0.75165581 -0.86312836]  energy_before :  50  energy_after :  50  reward :  -199.1751678209809\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "Episode 421/500, Total Reward: -1015.8758391049046\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "action : 1  next_temperatures :  [ 1.87632739 -0.42715624  0.75642617  0.05180458  1.11282282 -1.97137661\n",
      "  2.02888139 -0.21581625  2.29387446]  energy_before :  30  energy_after :  50  reward :  -212.49421230001175\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "action : 1  next_temperatures :  [ 1.87632739 -0.42715624  0.75642617  0.05180458  1.11282282 -1.97137661\n",
      "  2.02888139 -0.21581625  2.29387446]  energy_before :  50  energy_after :  40  reward :  -182.49421230001175\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "action : 1  next_temperatures :  [ 1.87632739 -0.42715624  0.75642617  0.05180458  1.11282282 -1.97137661\n",
      "  2.02888139 -0.21581625  2.29387446]  energy_before :  40  energy_after :  50  reward :  -202.49421230001175\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "action : 1  next_temperatures :  [ 1.87632739 -0.42715624  0.75642617  0.05180458  1.11282282 -1.97137661\n",
      "  2.02888139 -0.21581625  2.29387446]  energy_before :  50  energy_after :  50  reward :  -192.49421230001175\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "action : 1  next_temperatures :  [ 1.87632739 -0.42715624  0.75642617  0.05180458  1.11282282 -1.97137661\n",
      "  2.02888139 -0.21581625  2.29387446]  energy_before :  50  energy_after :  50  reward :  -192.49421230001175\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "Episode 422/500, Total Reward: -982.4710615000588\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "action : 1  next_temperatures :  [-0.11616967 -1.07050196 -0.70737688 -0.4006233  -1.047299   -0.87340768\n",
      " -0.44562372 -0.85446298 -0.26678553]  energy_before :  30  energy_after :  50  reward :  -223.78225070863112\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "action : 1  next_temperatures :  [-0.11616967 -1.07050196 -0.70737688 -0.4006233  -1.047299   -0.87340768\n",
      " -0.44562372 -0.85446298 -0.26678553]  energy_before :  50  energy_after :  40  reward :  -193.78225070863112\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "action : 1  next_temperatures :  [-0.11616967 -1.07050196 -0.70737688 -0.4006233  -1.047299   -0.87340768\n",
      " -0.44562372 -0.85446298 -0.26678553]  energy_before :  40  energy_after :  50  reward :  -213.78225070863112\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "action : 1  next_temperatures :  [-0.11616967 -1.07050196 -0.70737688 -0.4006233  -1.047299   -0.87340768\n",
      " -0.44562372 -0.85446298 -0.26678553]  energy_before :  50  energy_after :  50  reward :  -203.78225070863112\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "action : 1  next_temperatures :  [-0.11616967 -1.07050196 -0.70737688 -0.4006233  -1.047299   -0.87340768\n",
      " -0.44562372 -0.85446298 -0.26678553]  energy_before :  50  energy_after :  50  reward :  -203.78225070863112\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "Episode 423/500, Total Reward: -1038.9112535431557\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "action : 1  next_temperatures :  [ 0.46082427  0.11901746  0.36121455  0.10064099  0.77551149 -0.82219644\n",
      "  0.26172739  0.23029587  0.60062223]  energy_before :  30  energy_after :  50  reward :  -215.91234219364904\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step\n",
      "action : 1  next_temperatures :  [ 0.46082427  0.11901746  0.36121455  0.10064099  0.77551149 -0.82219644\n",
      "  0.26172739  0.23029587  0.60062223]  energy_before :  50  energy_after :  40  reward :  -185.91234219364904\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "action : 1  next_temperatures :  [ 0.46082427  0.11901746  0.36121455  0.10064099  0.77551149 -0.82219644\n",
      "  0.26172739  0.23029587  0.60062223]  energy_before :  40  energy_after :  50  reward :  -205.91234219364904\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step\n",
      "action : 1  next_temperatures :  [ 0.46082427  0.11901746  0.36121455  0.10064099  0.77551149 -0.82219644\n",
      "  0.26172739  0.23029587  0.60062223]  energy_before :  50  energy_after :  50  reward :  -195.91234219364904\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "action : 1  next_temperatures :  [ 0.46082427  0.11901746  0.36121455  0.10064099  0.77551149 -0.82219644\n",
      "  0.26172739  0.23029587  0.60062223]  energy_before :  50  energy_after :  50  reward :  -195.91234219364904\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "Episode 424/500, Total Reward: -999.5617109682452\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "action : 1  next_temperatures :  [-0.18466176  0.56299302 -0.29240467  0.61746741 -0.54880935  0.62913003\n",
      "  0.49424765  0.10840207 -0.54869305]  energy_before :  30  energy_after :  50  reward :  -217.16232864814646\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "action : 1  next_temperatures :  [-0.18466176  0.56299302 -0.29240467  0.61746741 -0.54880935  0.62913003\n",
      "  0.49424765  0.10840207 -0.54869305]  energy_before :  50  energy_after :  40  reward :  -187.16232864814646\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "action : 1  next_temperatures :  [-0.18466176  0.56299302 -0.29240467  0.61746741 -0.54880935  0.62913003\n",
      "  0.49424765  0.10840207 -0.54869305]  energy_before :  40  energy_after :  50  reward :  -207.16232864814646\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "action : 1  next_temperatures :  [-0.18466176  0.56299302 -0.29240467  0.61746741 -0.54880935  0.62913003\n",
      "  0.49424765  0.10840207 -0.54869305]  energy_before :  50  energy_after :  50  reward :  -197.16232864814646\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "action : 1  next_temperatures :  [-0.18466176  0.56299302 -0.29240467  0.61746741 -0.54880935  0.62913003\n",
      "  0.49424765  0.10840207 -0.54869305]  energy_before :  50  energy_after :  50  reward :  -197.16232864814646\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "Episode 425/500, Total Reward: -1005.8116432407323\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step\n",
      "action : 1  next_temperatures :  [ 0.43799358 -0.41040245  1.07563555 -0.94120243  0.01116069 -0.41250654\n",
      "  0.16871929 -0.41391767  0.05849238]  energy_before :  30  energy_after :  50  reward :  -218.42602760279317\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "action : 1  next_temperatures :  [ 0.43799358 -0.41040245  1.07563555 -0.94120243  0.01116069 -0.41250654\n",
      "  0.16871929 -0.41391767  0.05849238]  energy_before :  50  energy_after :  40  reward :  -188.42602760279317\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "action : 1  next_temperatures :  [ 0.43799358 -0.41040245  1.07563555 -0.94120243  0.01116069 -0.41250654\n",
      "  0.16871929 -0.41391767  0.05849238]  energy_before :  40  energy_after :  50  reward :  -208.42602760279317\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step\n",
      "action : 1  next_temperatures :  [ 0.43799358 -0.41040245  1.07563555 -0.94120243  0.01116069 -0.41250654\n",
      "  0.16871929 -0.41391767  0.05849238]  energy_before :  50  energy_after :  50  reward :  -198.42602760279317\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step\n",
      "action : 1  next_temperatures :  [ 0.43799358 -0.41040245  1.07563555 -0.94120243  0.01116069 -0.41250654\n",
      "  0.16871929 -0.41391767  0.05849238]  energy_before :  50  energy_after :  50  reward :  -198.42602760279317\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "Episode 426/500, Total Reward: -1012.1301380139658\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "action : 1  next_temperatures :  [ 0.48365497 -0.45898845  1.31732266 -1.28275016  0.16569248 -0.1666926\n",
      "  0.50648556 -0.48993333  0.54640924]  energy_before :  30  energy_after :  50  reward :  -217.37879962627042\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "action : 1  next_temperatures :  [ 0.48365497 -0.45898845  1.31732266 -1.28275016  0.16569248 -0.1666926\n",
      "  0.50648556 -0.48993333  0.54640924]  energy_before :  50  energy_after :  40  reward :  -187.37879962627042\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "action : 1  next_temperatures :  [ 0.48365497 -0.45898845  1.31732266 -1.28275016  0.16569248 -0.1666926\n",
      "  0.50648556 -0.48993333  0.54640924]  energy_before :  40  energy_after :  50  reward :  -207.37879962627042\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "action : 1  next_temperatures :  [ 0.48365497 -0.45898845  1.31732266 -1.28275016  0.16569248 -0.1666926\n",
      "  0.50648556 -0.48993333  0.54640924]  energy_before :  50  energy_after :  50  reward :  -197.37879962627042\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "action : 1  next_temperatures :  [ 0.48365497 -0.45898845  1.31732266 -1.28275016  0.16569248 -0.1666926\n",
      "  0.50648556 -0.48993333  0.54640924]  energy_before :  50  energy_after :  50  reward :  -197.37879962627042\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step\n",
      "Episode 427/500, Total Reward: -1006.8939981313521\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "action : 1  next_temperatures :  [-0.55825495 -0.74380297 -1.29563417  0.26527191 -0.33279717 -1.12229429\n",
      " -0.17394215 -1.00668626 -0.04993359]  energy_before :  30  energy_after :  50  reward :  -223.01807364377316\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "action : 1  next_temperatures :  [-0.55825495 -0.74380297 -1.29563417  0.26527191 -0.33279717 -1.12229429\n",
      " -0.17394215 -1.00668626 -0.04993359]  energy_before :  50  energy_after :  40  reward :  -193.01807364377316\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "action : 1  next_temperatures :  [-0.55825495 -0.74380297 -1.29563417  0.26527191 -0.33279717 -1.12229429\n",
      " -0.17394215 -1.00668626 -0.04993359]  energy_before :  40  energy_after :  50  reward :  -213.01807364377316\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "action : 1  next_temperatures :  [-0.55825495 -0.74380297 -1.29563417  0.26527191 -0.33279717 -1.12229429\n",
      " -0.17394215 -1.00668626 -0.04993359]  energy_before :  50  energy_after :  50  reward :  -203.01807364377316\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "action : 1  next_temperatures :  [-0.55825495 -0.74380297 -1.29563417  0.26527191 -0.33279717 -1.12229429\n",
      " -0.17394215 -1.00668626 -0.04993359]  energy_before :  50  energy_after :  50  reward :  -203.01807364377316\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "Episode 428/500, Total Reward: -1035.090368218866\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "action : 1  next_temperatures :  [-1.8596046   0.0754576  -1.4324382   0.14241301 -1.52917232  0.20202831\n",
      " -1.39773301 -0.19047769 -1.51910548]  energy_before :  30  energy_after :  50  reward :  -225.50863237809227\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "action : 1  next_temperatures :  [-1.8596046   0.0754576  -1.4324382   0.14241301 -1.52917232  0.20202831\n",
      " -1.39773301 -0.19047769 -1.51910548]  energy_before :  50  energy_after :  40  reward :  -195.50863237809227\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "action : 1  next_temperatures :  [-1.8596046   0.0754576  -1.4324382   0.14241301 -1.52917232  0.20202831\n",
      " -1.39773301 -0.19047769 -1.51910548]  energy_before :  40  energy_after :  50  reward :  -215.50863237809227\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "action : 1  next_temperatures :  [-1.8596046   0.0754576  -1.4324382   0.14241301 -1.52917232  0.20202831\n",
      " -1.39773301 -0.19047769 -1.51910548]  energy_before :  50  energy_after :  50  reward :  -205.50863237809227\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "action : 1  next_temperatures :  [-1.8596046   0.0754576  -1.4324382   0.14241301 -1.52917232  0.20202831\n",
      " -1.39773301 -0.19047769 -1.51910548]  energy_before :  50  energy_after :  50  reward :  -205.50863237809227\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "Episode 429/500, Total Reward: -1047.5431618904613\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "action : 1  next_temperatures :  [-0.98788713 -0.02590286 -0.59641361  0.13422242 -0.88113578 -0.10523912\n",
      "  0.38084303 -0.43772055 -0.92276265]  energy_before :  30  energy_after :  50  reward :  -221.44199624433875\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "action : 1  next_temperatures :  [-0.98788713 -0.02590286 -0.59641361  0.13422242 -0.88113578 -0.10523912\n",
      "  0.38084303 -0.43772055 -0.92276265]  energy_before :  50  energy_after :  40  reward :  -191.44199624433875\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "action : 1  next_temperatures :  [-0.98788713 -0.02590286 -0.59641361  0.13422242 -0.88113578 -0.10523912\n",
      "  0.38084303 -0.43772055 -0.92276265]  energy_before :  40  energy_after :  50  reward :  -211.44199624433875\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "action : 1  next_temperatures :  [-0.98788713 -0.02590286 -0.59641361  0.13422242 -0.88113578 -0.10523912\n",
      "  0.38084303 -0.43772055 -0.92276265]  energy_before :  50  energy_after :  50  reward :  -201.44199624433875\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "action : 1  next_temperatures :  [-0.98788713 -0.02590286 -0.59641361  0.13422242 -0.88113578 -0.10523912\n",
      "  0.38084303 -0.43772055 -0.92276265]  energy_before :  50  energy_after :  50  reward :  -201.44199624433875\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "Episode 430/500, Total Reward: -1027.2099812216939\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step\n",
      "action : 1  next_temperatures :  [ 1.19140653 -0.56034891  0.61962214 -0.25845801  1.20055699 -0.27116353\n",
      "  1.53936504 -0.74562237  1.89811967]  energy_before :  30  energy_after :  50  reward :  -213.38652243859786\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "action : 1  next_temperatures :  [ 1.19140653 -0.56034891  0.61962214 -0.25845801  1.20055699 -0.27116353\n",
      "  1.53936504 -0.74562237  1.89811967]  energy_before :  50  energy_after :  40  reward :  -183.38652243859786\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "action : 1  next_temperatures :  [ 1.19140653 -0.56034891  0.61962214 -0.25845801  1.20055699 -0.27116353\n",
      "  1.53936504 -0.74562237  1.89811967]  energy_before :  40  energy_after :  50  reward :  -203.38652243859786\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "action : 1  next_temperatures :  [ 1.19140653 -0.56034891  0.61962214 -0.25845801  1.20055699 -0.27116353\n",
      "  1.53936504 -0.74562237  1.89811967]  energy_before :  50  energy_after :  50  reward :  -193.38652243859786\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step\n",
      "action : 1  next_temperatures :  [ 1.19140653 -0.56034891  0.61962214 -0.25845801  1.20055699 -0.27116353\n",
      "  1.53936504 -0.74562237  1.89811967]  energy_before :  50  energy_after :  50  reward :  -193.38652243859786\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "Episode 431/500, Total Reward: -986.9326121929894\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "action : 1  next_temperatures :  [ 0.74932124 -0.34171189  0.62988245 -0.47249575  0.36508834 -0.68904722\n",
      "  0.85404217 -0.15285378  0.27534432]  energy_before :  30  energy_after :  50  reward :  -216.78243012927737\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step\n",
      "action : 1  next_temperatures :  [ 0.74932124 -0.34171189  0.62988245 -0.47249575  0.36508834 -0.68904722\n",
      "  0.85404217 -0.15285378  0.27534432]  energy_before :  50  energy_after :  40  reward :  -186.78243012927737\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "action : 1  next_temperatures :  [ 0.74932124 -0.34171189  0.62988245 -0.47249575  0.36508834 -0.68904722\n",
      "  0.85404217 -0.15285378  0.27534432]  energy_before :  40  energy_after :  50  reward :  -206.78243012927737\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step\n",
      "action : 1  next_temperatures :  [ 0.74932124 -0.34171189  0.62988245 -0.47249575  0.36508834 -0.68904722\n",
      "  0.85404217 -0.15285378  0.27534432]  energy_before :  50  energy_after :  50  reward :  -196.78243012927737\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "action : 1  next_temperatures :  [ 0.74932124 -0.34171189  0.62988245 -0.47249575  0.36508834 -0.68904722\n",
      "  0.85404217 -0.15285378  0.27534432]  energy_before :  50  energy_after :  50  reward :  -196.78243012927737\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "Episode 432/500, Total Reward: -1003.9121506463869\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "action : 1  next_temperatures :  [-0.55825495  0.87042516 -0.17232114  0.52737088 -0.33002778  1.15609366\n",
      " -0.09398782  0.90752631 -0.48363747]  energy_before :  30  energy_after :  50  reward :  -216.1768131543031\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step\n",
      "action : 1  next_temperatures :  [-0.55825495  0.87042516 -0.17232114  0.52737088 -0.33002778  1.15609366\n",
      " -0.09398782  0.90752631 -0.48363747]  energy_before :  50  energy_after :  40  reward :  -186.1768131543031\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "action : 1  next_temperatures :  [-0.55825495  0.87042516 -0.17232114  0.52737088 -0.33002778  1.15609366\n",
      " -0.09398782  0.90752631 -0.48363747]  energy_before :  40  energy_after :  50  reward :  -206.1768131543031\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step\n",
      "action : 1  next_temperatures :  [-0.55825495  0.87042516 -0.17232114  0.52737088 -0.33002778  1.15609366\n",
      " -0.09398782  0.90752631 -0.48363747]  energy_before :  50  energy_after :  50  reward :  -196.1768131543031\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "action : 1  next_temperatures :  [-0.55825495  0.87042516 -0.17232114  0.52737088 -0.33002778  1.15609366\n",
      " -0.09398782  0.90752631 -0.48363747]  energy_before :  50  energy_after :  50  reward :  -196.1768131543031\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "Episode 433/500, Total Reward: -1000.8840657715155\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "action : 1  next_temperatures :  [-0.05390414 -0.09040497  0.16360874 -0.39161365 -0.48732896  1.05111062\n",
      " -0.32079706  0.65337293 -0.65169772]  energy_before :  30  energy_after :  50  reward :  -218.12765419393136\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step\n",
      "action : 1  next_temperatures :  [-0.05390414 -0.09040497  0.16360874 -0.39161365 -0.48732896  1.05111062\n",
      " -0.32079706  0.65337293 -0.65169772]  energy_before :  50  energy_after :  40  reward :  -188.12765419393136\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "action : 1  next_temperatures :  [-0.05390414 -0.09040497  0.16360874 -0.39161365 -0.48732896  1.05111062\n",
      " -0.32079706  0.65337293 -0.65169772]  energy_before :  40  energy_after :  50  reward :  -208.12765419393136\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "action : 1  next_temperatures :  [-0.05390414 -0.09040497  0.16360874 -0.39161365 -0.48732896  1.05111062\n",
      " -0.32079706  0.65337293 -0.65169772]  energy_before :  50  energy_after :  50  reward :  -198.12765419393136\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "action : 1  next_temperatures :  [-0.05390414 -0.09040497  0.16360874 -0.39161365 -0.48732896  1.05111062\n",
      " -0.32079706  0.65337293 -0.65169772]  energy_before :  50  energy_after :  50  reward :  -198.12765419393136\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "Episode 434/500, Total Reward: -1010.6382709696568\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "action : 1  next_temperatures :  [ 0.25742353  0.3116861  -0.33800601  0.95082454  1.00813999  0.10677541\n",
      "  0.85404217 -0.21581625  0.74622282]  energy_before :  30  energy_after :  50  reward :  -214.3187077111234\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "action : 1  next_temperatures :  [ 0.25742353  0.3116861  -0.33800601  0.95082454  1.00813999  0.10677541\n",
      "  0.85404217 -0.21581625  0.74622282]  energy_before :  50  energy_after :  40  reward :  -184.3187077111234\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "action : 1  next_temperatures :  [ 0.25742353  0.3116861  -0.33800601  0.95082454  1.00813999  0.10677541\n",
      "  0.85404217 -0.21581625  0.74622282]  energy_before :  40  energy_after :  50  reward :  -204.3187077111234\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "action : 1  next_temperatures :  [ 0.25742353  0.3116861  -0.33800601  0.95082454  1.00813999  0.10677541\n",
      "  0.85404217 -0.21581625  0.74622282]  energy_before :  50  energy_after :  50  reward :  -194.3187077111234\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "action : 1  next_temperatures :  [ 0.25742353  0.3116861  -0.33800601  0.95082454  1.00813999  0.10677541\n",
      "  0.85404217 -0.21581625  0.74622282]  energy_before :  50  energy_after :  50  reward :  -194.3187077111234\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step\n",
      "Episode 435/500, Total Reward: -991.593538555617\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "action : 1  next_temperatures :  [ 0.48365497 -0.29396358 -0.1404002   0.24070013  0.11584352 -0.29267225\n",
      "  0.11976765  0.24488473  0.29341531]  energy_before :  30  energy_after :  50  reward :  -217.2287697117512\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "action : 1  next_temperatures :  [ 0.48365497 -0.29396358 -0.1404002   0.24070013  0.11584352 -0.29267225\n",
      "  0.11976765  0.24488473  0.29341531]  energy_before :  50  energy_after :  40  reward :  -187.2287697117512\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "action : 1  next_temperatures :  [ 0.48365497 -0.29396358 -0.1404002   0.24070013  0.11584352 -0.29267225\n",
      "  0.11976765  0.24488473  0.29341531]  energy_before :  40  energy_after :  50  reward :  -207.2287697117512\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "action : 1  next_temperatures :  [ 0.48365497 -0.29396358 -0.1404002   0.24070013  0.11584352 -0.29267225\n",
      "  0.11976765  0.24488473  0.29341531]  energy_before :  50  energy_after :  50  reward :  -197.2287697117512\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "action : 1  next_temperatures :  [ 0.48365497 -0.29396358 -0.1404002   0.24070013  0.11584352 -0.29267225\n",
      "  0.11976765  0.24488473  0.29341531]  energy_before :  50  energy_after :  50  reward :  -197.2287697117512\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "Episode 436/500, Total Reward: -1006.143848558756\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step\n",
      "action : 1  next_temperatures :  [ 0.63101673 -1.42484472 -0.09479886 -0.96331703  0.61433317 -0.68904722\n",
      "  0.85404217 -1.41133529  0.66748491]  energy_before :  30  energy_after :  50  reward :  -219.8164661543321\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "action : 1  next_temperatures :  [ 0.63101673 -1.42484472 -0.09479886 -0.96331703  0.61433317 -0.68904722\n",
      "  0.85404217 -1.41133529  0.66748491]  energy_before :  50  energy_after :  40  reward :  -189.8164661543321\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "action : 1  next_temperatures :  [ 0.63101673 -1.42484472 -0.09479886 -0.96331703  0.61433317 -0.68904722\n",
      "  0.85404217 -1.41133529  0.66748491]  energy_before :  40  energy_after :  50  reward :  -209.8164661543321\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "action : 1  next_temperatures :  [ 0.63101673 -1.42484472 -0.09479886 -0.96331703  0.61433317 -0.68904722\n",
      "  0.85404217 -1.41133529  0.66748491]  energy_before :  50  energy_after :  50  reward :  -199.8164661543321\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "action : 1  next_temperatures :  [ 0.63101673 -1.42484472 -0.09479886 -0.96331703  0.61433317 -0.68904722\n",
      "  0.85404217 -1.41133529  0.66748491]  energy_before :  50  energy_after :  50  reward :  -199.8164661543321\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "Episode 437/500, Total Reward: -1019.0823307716605\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "action : 1  next_temperatures :  [ 0.21591317  0.51943316  0.10280695  0.84516589  0.69741478 -0.33159279\n",
      "  0.16871929  0.68485417  0.47231816]  energy_before :  30  energy_after :  50  reward :  -214.6249672238095\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "action : 1  next_temperatures :  [ 0.21591317  0.51943316  0.10280695  0.84516589  0.69741478 -0.33159279\n",
      "  0.16871929  0.68485417  0.47231816]  energy_before :  50  energy_after :  40  reward :  -184.6249672238095\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step\n",
      "action : 1  next_temperatures :  [ 0.21591317  0.51943316  0.10280695  0.84516589  0.69741478 -0.33159279\n",
      "  0.16871929  0.68485417  0.47231816]  energy_before :  40  energy_after :  50  reward :  -204.6249672238095\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "action : 1  next_temperatures :  [ 0.21591317  0.51943316  0.10280695  0.84516589  0.69741478 -0.33159279\n",
      "  0.16871929  0.68485417  0.47231816]  energy_before :  50  energy_after :  50  reward :  -194.6249672238095\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step\n",
      "action : 1  next_temperatures :  [ 0.21591317  0.51943316  0.10280695  0.84516589  0.69741478 -0.33159279\n",
      "  0.16871929  0.68485417  0.47231816]  energy_before :  50  energy_after :  50  reward :  -194.6249672238095\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step\n",
      "Episode 438/500, Total Reward: -993.1248361190476\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step\n",
      "action : 1  next_temperatures :  [ 0.08515556 -1.74149144 -0.15560065 -2.01253199  0.38004303 -0.71977397\n",
      "  0.01696922 -1.66702433 -0.80891538]  energy_before :  30  energy_after :  50  reward :  -224.62316994745117\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step\n",
      "action : 1  next_temperatures :  [ 0.08515556 -1.74149144 -0.15560065 -2.01253199  0.38004303 -0.71977397\n",
      "  0.01696922 -1.66702433 -0.80891538]  energy_before :  50  energy_after :  40  reward :  -194.62316994745117\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step\n",
      "action : 1  next_temperatures :  [ 0.08515556 -1.74149144 -0.15560065 -2.01253199  0.38004303 -0.71977397\n",
      "  0.01696922 -1.66702433 -0.80891538]  energy_before :  40  energy_after :  50  reward :  -214.62316994745117\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step\n",
      "action : 1  next_temperatures :  [ 0.08515556 -1.74149144 -0.15560065 -2.01253199  0.38004303 -0.71977397\n",
      "  0.01696922 -1.66702433 -0.80891538]  energy_before :  50  energy_after :  50  reward :  -204.62316994745117\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step\n",
      "action : 1  next_temperatures :  [ 0.08515556 -1.74149144 -0.15560065 -2.01253199  0.38004303 -0.71977397\n",
      "  0.01696922 -1.66702433 -0.80891538]  energy_before :  50  energy_after :  50  reward :  -204.62316994745117\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "Episode 439/500, Total Reward: -1043.1158497372558\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "action : 1  next_temperatures :  [ 1.62103871  0.03524849  0.80202751  0.24070013  1.46176557 -0.05607633\n",
      "  1.69764199  0.40613008  1.19154376]  energy_before :  30  energy_after :  50  reward :  -210.59998009056613\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "action : 1  next_temperatures :  [ 1.62103871  0.03524849  0.80202751  0.24070013  1.46176557 -0.05607633\n",
      "  1.69764199  0.40613008  1.19154376]  energy_before :  50  energy_after :  40  reward :  -180.59998009056613\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "action : 1  next_temperatures :  [ 1.62103871  0.03524849  0.80202751  0.24070013  1.46176557 -0.05607633\n",
      "  1.69764199  0.40613008  1.19154376]  energy_before :  40  energy_after :  50  reward :  -200.59998009056613\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "action : 1  next_temperatures :  [ 1.62103871  0.03524849  0.80202751  0.24070013  1.46176557 -0.05607633\n",
      "  1.69764199  0.40613008  1.19154376]  energy_before :  50  energy_after :  50  reward :  -190.59998009056613\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "action : 1  next_temperatures :  [ 1.62103871  0.03524849  0.80202751  0.24070013  1.46176557 -0.05607633\n",
      "  1.69764199  0.40613008  1.19154376]  energy_before :  50  energy_after :  50  reward :  -190.59998009056613\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "Episode 440/500, Total Reward: -972.9999004528306\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "action : 1  next_temperatures :  [-0.07465931  0.38456511 -0.46416972  1.26288613  0.47974096  0.21227056\n",
      " -0.56555523  0.21263566 -0.18004475]  energy_before :  30  energy_after :  50  reward :  -216.73233059750186\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "action : 1  next_temperatures :  [-0.07465931  0.38456511 -0.46416972  1.26288613  0.47974096  0.21227056\n",
      " -0.56555523  0.21263566 -0.18004475]  energy_before :  50  energy_after :  40  reward :  -186.73233059750186\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step\n",
      "action : 1  next_temperatures :  [-0.07465931  0.38456511 -0.46416972  1.26288613  0.47974096  0.21227056\n",
      " -0.56555523  0.21263566 -0.18004475]  energy_before :  40  energy_after :  50  reward :  -206.73233059750186\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "action : 1  next_temperatures :  [-0.07465931  0.38456511 -0.46416972  1.26288613  0.47974096  0.21227056\n",
      " -0.56555523  0.21263566 -0.18004475]  energy_before :  50  energy_after :  50  reward :  -196.73233059750186\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "action : 1  next_temperatures :  [-0.07465931  0.38456511 -0.46416972  1.26288613  0.47974096  0.21227056\n",
      " -0.56555523  0.21263566 -0.18004475]  energy_before :  50  energy_after :  50  reward :  -196.73233059750186\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step\n",
      "Episode 441/500, Total Reward: -1003.6616529875093\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "action : 1  next_temperatures :  [-0.61429393 -0.86275491 -0.06439797 -1.2336066  -0.98581861 -0.67061118\n",
      "  0.57664957 -0.98134771 -1.02576732]  energy_before :  30  energy_after :  50  reward :  -223.8619486470472\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step\n",
      "action : 1  next_temperatures :  [-0.61429393 -0.86275491 -0.06439797 -1.2336066  -0.98581861 -0.67061118\n",
      "  0.57664957 -0.98134771 -1.02576732]  energy_before :  50  energy_after :  40  reward :  -193.8619486470472\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step\n",
      "action : 1  next_temperatures :  [-0.61429393 -0.86275491 -0.06439797 -1.2336066  -0.98581861 -0.67061118\n",
      "  0.57664957 -0.98134771 -1.02576732]  energy_before :  40  energy_after :  50  reward :  -213.8619486470472\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "action : 1  next_temperatures :  [-0.61429393 -0.86275491 -0.06439797 -1.2336066  -0.98581861 -0.67061118\n",
      "  0.57664957 -0.98134771 -1.02576732]  energy_before :  50  energy_after :  50  reward :  -203.8619486470472\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "action : 1  next_temperatures :  [-0.61429393 -0.86275491 -0.06439797 -1.2336066  -0.98581861 -0.67061118\n",
      "  0.57664957 -0.98134771 -1.02576732]  energy_before :  50  energy_after :  50  reward :  -203.8619486470472\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "Episode 442/500, Total Reward: -1039.309743235236\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "action : 1  next_temperatures :  [-0.30296627  0.3116861  -0.83962076  1.04255918  0.38170466  0.11804188\n",
      "  0.01696922  0.08594289  0.43256198]  energy_before :  30  energy_after :  50  reward :  -216.75312111681095\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "action : 1  next_temperatures :  [-0.30296627  0.3116861  -0.83962076  1.04255918  0.38170466  0.11804188\n",
      "  0.01696922  0.08594289  0.43256198]  energy_before :  50  energy_after :  40  reward :  -186.75312111681095\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step\n",
      "action : 1  next_temperatures :  [-0.30296627  0.3116861  -0.83962076  1.04255918  0.38170466  0.11804188\n",
      "  0.01696922  0.08594289  0.43256198]  energy_before :  40  energy_after :  50  reward :  -206.75312111681095\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "action : 1  next_temperatures :  [-0.30296627  0.3116861  -0.83962076  1.04255918  0.38170466  0.11804188\n",
      "  0.01696922  0.08594289  0.43256198]  energy_before :  50  energy_after :  50  reward :  -196.75312111681095\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step\n",
      "action : 1  next_temperatures :  [-0.30296627  0.3116861  -0.83962076  1.04255918  0.38170466  0.11804188\n",
      "  0.01696922  0.08594289  0.43256198]  energy_before :  50  energy_after :  50  reward :  -196.75312111681095\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "Episode 443/500, Total Reward: -1003.7656055840547\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "action : 1  next_temperatures :  [ 0.06440038 -1.35615416 -0.30760512 -1.2336066  -0.88113578 -0.69928947\n",
      " -0.41870032 -1.02895347  0.0042794 ]  energy_before :  30  energy_after :  50  reward :  -223.85676515903768\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "action : 1  next_temperatures :  [ 0.06440038 -1.35615416 -0.30760512 -1.2336066  -0.88113578 -0.69928947\n",
      " -0.41870032 -1.02895347  0.0042794 ]  energy_before :  50  energy_after :  40  reward :  -193.85676515903768\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "action : 1  next_temperatures :  [ 0.06440038 -1.35615416 -0.30760512 -1.2336066  -0.88113578 -0.69928947\n",
      " -0.41870032 -1.02895347  0.0042794 ]  energy_before :  40  energy_after :  50  reward :  -213.85676515903768\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "action : 1  next_temperatures :  [ 0.06440038 -1.35615416 -0.30760512 -1.2336066  -0.88113578 -0.69928947\n",
      " -0.41870032 -1.02895347  0.0042794 ]  energy_before :  50  energy_after :  50  reward :  -203.85676515903768\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step\n",
      "action : 1  next_temperatures :  [ 0.06440038 -1.35615416 -0.30760512 -1.2336066  -0.88113578 -0.69928947\n",
      " -0.41870032 -1.02895347  0.0042794 ]  energy_before :  50  energy_after :  50  reward :  -203.85676515903768\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "Episode 444/500, Total Reward: -1039.2838257951885\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "action : 1  next_temperatures :  [-0.03314896 -0.90296402 -0.02031667 -1.16071032 -0.79805417 -0.26092128\n",
      " -1.34878137  0.75165581 -0.86312836]  energy_before :  30  energy_after :  50  reward :  -222.63636934780953\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "action : 1  next_temperatures :  [-0.03314896 -0.90296402 -0.02031667 -1.16071032 -0.79805417 -0.26092128\n",
      " -1.34878137  0.75165581 -0.86312836]  energy_before :  50  energy_after :  40  reward :  -192.63636934780953\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "action : 1  next_temperatures :  [-0.03314896 -0.90296402 -0.02031667 -1.16071032 -0.79805417 -0.26092128\n",
      " -1.34878137  0.75165581 -0.86312836]  energy_before :  40  energy_after :  50  reward :  -212.63636934780953\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step\n",
      "action : 1  next_temperatures :  [-0.03314896 -0.90296402 -0.02031667 -1.16071032 -0.79805417 -0.26092128\n",
      " -1.34878137  0.75165581 -0.86312836]  energy_before :  50  energy_after :  50  reward :  -202.63636934780953\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "action : 1  next_temperatures :  [-0.03314896 -0.90296402 -0.02031667 -1.16071032 -0.79805417 -0.26092128\n",
      " -1.34878137  0.75165581 -0.86312836]  energy_before :  50  energy_after :  50  reward :  -202.63636934780953\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "Episode 445/500, Total Reward: -1033.1818467390476\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "action : 1  next_temperatures :  [ 0.195158   -1.02024058 -0.10999931 -0.75118068  0.21554145 -1.48794253\n",
      "  0.41347746 -1.07304914  0.47231816]  energy_before :  30  energy_after :  50  reward :  -221.14591716250067\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "action : 1  next_temperatures :  [ 0.195158   -1.02024058 -0.10999931 -0.75118068  0.21554145 -1.48794253\n",
      "  0.41347746 -1.07304914  0.47231816]  energy_before :  50  energy_after :  40  reward :  -191.14591716250067\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "action : 1  next_temperatures :  [ 0.195158   -1.02024058 -0.10999931 -0.75118068  0.21554145 -1.48794253\n",
      "  0.41347746 -1.07304914  0.47231816]  energy_before :  40  energy_after :  50  reward :  -211.14591716250067\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "action : 1  next_temperatures :  [ 0.195158   -1.02024058 -0.10999931 -0.75118068  0.21554145 -1.48794253\n",
      "  0.41347746 -1.07304914  0.47231816]  energy_before :  50  energy_after :  50  reward :  -201.14591716250067\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "action : 1  next_temperatures :  [ 0.195158   -1.02024058 -0.10999931 -0.75118068  0.21554145 -1.48794253\n",
      "  0.41347746 -1.07304914  0.47231816]  energy_before :  50  energy_after :  50  reward :  -201.14591716250067\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "Episode 446/500, Total Reward: -1025.7295858125033\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "action : 1  next_temperatures :  [-0.71806982  0.25891165 -0.22096257 -0.10330477 -0.63189095  0.26040912\n",
      " -0.78094242  0.33932843 -0.3806328 ]  energy_before :  30  energy_after :  50  reward :  -219.97715413869187\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "action : 1  next_temperatures :  [-0.71806982  0.25891165 -0.22096257 -0.10330477 -0.63189095  0.26040912\n",
      " -0.78094242  0.33932843 -0.3806328 ]  energy_before :  50  energy_after :  40  reward :  -189.97715413869187\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "action : 1  next_temperatures :  [-0.71806982  0.25891165 -0.22096257 -0.10330477 -0.63189095  0.26040912\n",
      " -0.78094242  0.33932843 -0.3806328 ]  energy_before :  40  energy_after :  50  reward :  -209.97715413869187\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "action : 1  next_temperatures :  [-0.71806982  0.25891165 -0.22096257 -0.10330477 -0.63189095  0.26040912\n",
      " -0.78094242  0.33932843 -0.3806328 ]  energy_before :  50  energy_after :  50  reward :  -199.97715413869187\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "action : 1  next_temperatures :  [-0.71806982  0.25891165 -0.22096257 -0.10330477 -0.63189095  0.26040912\n",
      " -0.78094242  0.33932843 -0.3806328 ]  energy_before :  50  energy_after :  50  reward :  -199.97715413869187\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "Episode 447/500, Total Reward: -1019.8857706934593\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "action : 1  next_temperatures :  [ 0.25742353 -0.84432573  0.22745061 -0.95225973 -0.03370338 -0.93486116\n",
      "  0.26172739 -0.92068874 -0.16378086]  energy_before :  30  energy_after :  50  reward :  -221.10301807306266\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "action : 1  next_temperatures :  [ 0.25742353 -0.84432573  0.22745061 -0.95225973 -0.03370338 -0.93486116\n",
      "  0.26172739 -0.92068874 -0.16378086]  energy_before :  50  energy_after :  40  reward :  -191.10301807306266\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step\n",
      "action : 1  next_temperatures :  [ 0.25742353 -0.84432573  0.22745061 -0.95225973 -0.03370338 -0.93486116\n",
      "  0.26172739 -0.92068874 -0.16378086]  energy_before :  40  energy_after :  50  reward :  -211.10301807306266\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "action : 1  next_temperatures :  [ 0.25742353 -0.84432573  0.22745061 -0.95225973 -0.03370338 -0.93486116\n",
      "  0.26172739 -0.92068874 -0.16378086]  energy_before :  50  energy_after :  50  reward :  -201.10301807306266\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "action : 1  next_temperatures :  [ 0.25742353 -0.84432573  0.22745061 -0.95225973 -0.03370338 -0.93486116\n",
      "  0.26172739 -0.92068874 -0.16378086]  energy_before :  50  energy_after :  50  reward :  -201.10301807306266\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "Episode 448/500, Total Reward: -1025.5150903653132\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "action : 1  next_temperatures :  [0.85932368 2.2132418  1.89493964 1.32022028 1.00813999 1.60419199\n",
      " 1.14775197 1.4826347  1.54067539]  energy_before :  30  energy_after :  50  reward :  -204.9288805559728\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "action : 1  next_temperatures :  [0.85932368 2.2132418  1.89493964 1.32022028 1.00813999 1.60419199\n",
      " 1.14775197 1.4826347  1.54067539]  energy_before :  50  energy_after :  40  reward :  -174.9288805559728\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "action : 1  next_temperatures :  [0.85932368 2.2132418  1.89493964 1.32022028 1.00813999 1.60419199\n",
      " 1.14775197 1.4826347  1.54067539]  energy_before :  40  energy_after :  50  reward :  -194.9288805559728\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "action : 1  next_temperatures :  [0.85932368 2.2132418  1.89493964 1.32022028 1.00813999 1.60419199\n",
      " 1.14775197 1.4826347  1.54067539]  energy_before :  50  energy_after :  50  reward :  -184.9288805559728\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "action : 1  next_temperatures :  [0.85932368 2.2132418  1.89493964 1.32022028 1.00813999 1.60419199\n",
      " 1.14775197 1.4826347  1.54067539]  energy_before :  50  energy_after :  50  reward :  -184.9288805559728\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "Episode 449/500, Total Reward: -944.644402779864\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "action : 1  next_temperatures :  [-0.32372145 -0.71867227 -0.80921987 -0.12787655 -0.43747999 -0.49649297\n",
      " -0.76625693 -0.63735764 -0.48363747]  energy_before :  30  energy_after :  50  reward :  -222.80071514247282\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "action : 1  next_temperatures :  [-0.32372145 -0.71867227 -0.80921987 -0.12787655 -0.43747999 -0.49649297\n",
      " -0.76625693 -0.63735764 -0.48363747]  energy_before :  50  energy_after :  40  reward :  -192.80071514247282\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "action : 1  next_temperatures :  [-0.32372145 -0.71867227 -0.80921987 -0.12787655 -0.43747999 -0.49649297\n",
      " -0.76625693 -0.63735764 -0.48363747]  energy_before :  40  energy_after :  50  reward :  -212.80071514247282\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "action : 1  next_temperatures :  [-0.32372145 -0.71867227 -0.80921987 -0.12787655 -0.43747999 -0.49649297\n",
      " -0.76625693 -0.63735764 -0.48363747]  energy_before :  50  energy_after :  50  reward :  -202.80071514247282\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "action : 1  next_temperatures :  [-0.32372145 -0.71867227 -0.80921987 -0.12787655 -0.43747999 -0.49649297\n",
      " -0.76625693 -0.63735764 -0.48363747]  energy_before :  50  energy_after :  50  reward :  -202.80071514247282\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "Episode 450/500, Total Reward: -1034.0035757123642\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "action : 1  next_temperatures :  [ 0.46082427 -0.29145051  0.88867006 -1.21886353  1.67777775 -0.71977397\n",
      "  0.80509053 -0.9967044   0.63315002]  energy_before :  30  energy_after :  50  reward :  -216.76127978171073\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "action : 1  next_temperatures :  [ 0.46082427 -0.29145051  0.88867006 -1.21886353  1.67777775 -0.71977397\n",
      "  0.80509053 -0.9967044   0.63315002]  energy_before :  50  energy_after :  40  reward :  -186.76127978171073\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "action : 1  next_temperatures :  [ 0.46082427 -0.29145051  0.88867006 -1.21886353  1.67777775 -0.71977397\n",
      "  0.80509053 -0.9967044   0.63315002]  energy_before :  40  energy_after :  50  reward :  -206.76127978171073\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "action : 1  next_temperatures :  [ 0.46082427 -0.29145051  0.88867006 -1.21886353  1.67777775 -0.71977397\n",
      "  0.80509053 -0.9967044   0.63315002]  energy_before :  50  energy_after :  50  reward :  -196.76127978171073\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "action : 1  next_temperatures :  [ 0.46082427 -0.29145051  0.88867006 -1.21886353  1.67777775 -0.71977397\n",
      "  0.80509053 -0.9967044   0.63315002]  energy_before :  50  energy_after :  50  reward :  -196.76127978171073\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "Episode 451/500, Total Reward: -1003.8063989085537\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step\n",
      "action : 1  next_temperatures :  [-1.61054246  0.23461865 -1.16339028  0.28738651 -1.48430825  0.30342656\n",
      " -1.20682164 -0.19047769 -1.24804056]  energy_before :  30  energy_after :  50  reward :  -224.07814917268928\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "action : 1  next_temperatures :  [-1.61054246  0.23461865 -1.16339028  0.28738651 -1.48430825  0.30342656\n",
      " -1.20682164 -0.19047769 -1.24804056]  energy_before :  50  energy_after :  40  reward :  -194.07814917268928\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "action : 1  next_temperatures :  [-1.61054246  0.23461865 -1.16339028  0.28738651 -1.48430825  0.30342656\n",
      " -1.20682164 -0.19047769 -1.24804056]  energy_before :  40  energy_after :  50  reward :  -214.07814917268928\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "action : 1  next_temperatures :  [-1.61054246  0.23461865 -1.16339028  0.28738651 -1.48430825  0.30342656\n",
      " -1.20682164 -0.19047769 -1.24804056]  energy_before :  50  energy_after :  50  reward :  -204.07814917268928\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step\n",
      "action : 1  next_temperatures :  [-1.61054246  0.23461865 -1.16339028  0.28738651 -1.48430825  0.30342656\n",
      " -1.20682164 -0.19047769 -1.24804056]  energy_before :  50  energy_after :  50  reward :  -204.07814917268928\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "Episode 452/500, Total Reward: -1040.3907458634465\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "action : 1  next_temperatures :  [0.5687512  0.84529446 0.20464994 0.96802478 1.86055729 0.25016687\n",
      " 0.65823563 0.52130532 0.54640924]  energy_before :  30  energy_after :  50  reward :  -211.57660526112736\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step\n",
      "action : 1  next_temperatures :  [0.5687512  0.84529446 0.20464994 0.96802478 1.86055729 0.25016687\n",
      " 0.65823563 0.52130532 0.54640924]  energy_before :  50  energy_after :  40  reward :  -181.57660526112736\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "action : 1  next_temperatures :  [0.5687512  0.84529446 0.20464994 0.96802478 1.86055729 0.25016687\n",
      " 0.65823563 0.52130532 0.54640924]  energy_before :  40  energy_after :  50  reward :  -201.57660526112736\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "action : 1  next_temperatures :  [0.5687512  0.84529446 0.20464994 0.96802478 1.86055729 0.25016687\n",
      " 0.65823563 0.52130532 0.54640924]  energy_before :  50  energy_after :  50  reward :  -191.57660526112736\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "action : 1  next_temperatures :  [0.5687512  0.84529446 0.20464994 0.96802478 1.86055729 0.25016687\n",
      " 0.65823563 0.52130532 0.54640924]  energy_before :  50  energy_after :  50  reward :  -191.57660526112736\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step\n",
      "Episode 453/500, Total Reward: -977.8830263056368\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "action : 1  next_temperatures :  [-0.49598942 -0.83846191 -0.4565695  -1.38226586 -1.08053164 -1.56271093\n",
      " -0.36974869 -1.38830024 -0.70591071]  energy_before :  30  energy_after :  50  reward :  -226.28048889608894\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "action : 1  next_temperatures :  [-0.49598942 -0.83846191 -0.4565695  -1.38226586 -1.08053164 -1.56271093\n",
      " -0.36974869 -1.38830024 -0.70591071]  energy_before :  50  energy_after :  40  reward :  -196.28048889608894\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "action : 1  next_temperatures :  [-0.49598942 -0.83846191 -0.4565695  -1.38226586 -1.08053164 -1.56271093\n",
      " -0.36974869 -1.38830024 -0.70591071]  energy_before :  40  energy_after :  50  reward :  -216.28048889608894\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "action : 1  next_temperatures :  [-0.49598942 -0.83846191 -0.4565695  -1.38226586 -1.08053164 -1.56271093\n",
      " -0.36974869 -1.38830024 -0.70591071]  energy_before :  50  energy_after :  50  reward :  -206.28048889608894\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "action : 1  next_temperatures :  [-0.49598942 -0.83846191 -0.4565695  -1.38226586 -1.08053164 -1.56271093\n",
      " -0.36974869 -1.38830024 -0.70591071]  energy_before :  50  energy_after :  50  reward :  -206.28048889608894\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "Episode 454/500, Total Reward: -1051.4024444804447\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "action : 1  next_temperatures :  [1.44046866 1.21387795 0.5740208  1.83786575 1.61131247 0.56972499\n",
      " 1.34355851 0.91520466 1.95594685]  energy_before :  30  energy_after :  50  reward :  -206.538019360522\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "action : 1  next_temperatures :  [1.44046866 1.21387795 0.5740208  1.83786575 1.61131247 0.56972499\n",
      " 1.34355851 0.91520466 1.95594685]  energy_before :  50  energy_after :  40  reward :  -176.538019360522\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "action : 1  next_temperatures :  [1.44046866 1.21387795 0.5740208  1.83786575 1.61131247 0.56972499\n",
      " 1.34355851 0.91520466 1.95594685]  energy_before :  40  energy_after :  50  reward :  -196.538019360522\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "action : 1  next_temperatures :  [1.44046866 1.21387795 0.5740208  1.83786575 1.61131247 0.56972499\n",
      " 1.34355851 0.91520466 1.95594685]  energy_before :  50  energy_after :  50  reward :  -186.538019360522\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "action : 1  next_temperatures :  [1.44046866 1.21387795 0.5740208  1.83786575 1.61131247 0.56972499\n",
      " 1.34355851 0.91520466 1.95594685]  energy_before :  50  energy_after :  50  reward :  -186.538019360522\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "Episode 455/500, Total Reward: -952.6900968026099\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "action : 1  next_temperatures :  [ 0.83856851 -1.43992314  0.17728914 -1.1451482   0.61433317 -0.81502687\n",
      "  0.94705027 -1.41133529  0.76326118]  energy_before :  30  energy_after :  50  reward :  -219.47093122086483\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "action : 1  next_temperatures :  [ 0.83856851 -1.43992314  0.17728914 -1.1451482   0.61433317 -0.81502687\n",
      "  0.94705027 -1.41133529  0.76326118]  energy_before :  50  energy_after :  40  reward :  -189.47093122086483\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "action : 1  next_temperatures :  [ 0.83856851 -1.43992314  0.17728914 -1.1451482   0.61433317 -0.81502687\n",
      "  0.94705027 -1.41133529  0.76326118]  energy_before :  40  energy_after :  50  reward :  -209.47093122086483\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "action : 1  next_temperatures :  [ 0.83856851 -1.43992314  0.17728914 -1.1451482   0.61433317 -0.81502687\n",
      "  0.94705027 -1.41133529  0.76326118]  energy_before :  50  energy_after :  50  reward :  -199.47093122086483\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "action : 1  next_temperatures :  [ 0.83856851 -1.43992314  0.17728914 -1.1451482   0.61433317 -0.81502687\n",
      "  0.94705027 -1.41133529  0.76326118]  energy_before :  50  energy_after :  50  reward :  -199.47093122086483\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "Episode 456/500, Total Reward: -1017.3546561043241\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "action : 1  next_temperatures :  [-1.74130008  0.997754   -1.00682568  0.77882209 -1.39790338  1.35837805\n",
      " -0.68303915  1.15937618 -0.70591071]  energy_before :  30  energy_after :  50  reward :  -219.24064869623746\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "action : 1  next_temperatures :  [-1.74130008  0.997754   -1.00682568  0.77882209 -1.39790338  1.35837805\n",
      " -0.68303915  1.15937618 -0.70591071]  energy_before :  50  energy_after :  40  reward :  -189.24064869623746\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "action : 1  next_temperatures :  [-1.74130008  0.997754   -1.00682568  0.77882209 -1.39790338  1.35837805\n",
      " -0.68303915  1.15937618 -0.70591071]  energy_before :  40  energy_after :  50  reward :  -209.24064869623746\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "action : 1  next_temperatures :  [-1.74130008  0.997754   -1.00682568  0.77882209 -1.39790338  1.35837805\n",
      " -0.68303915  1.15937618 -0.70591071]  energy_before :  50  energy_after :  50  reward :  -199.24064869623746\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "action : 1  next_temperatures :  [-1.74130008  0.997754   -1.00682568  0.77882209 -1.39790338  1.35837805\n",
      " -0.68303915  1.15937618 -0.70591071]  energy_before :  50  energy_after :  50  reward :  -199.24064869623746\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "Episode 457/500, Total Reward: -1016.2032434811873\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "action : 1  next_temperatures :  [-0.80731709 -0.87196949 -0.79401942 -0.61931213 -0.33279717 -0.96866058\n",
      " -1.05507157 -0.65117867 -1.28289176]  energy_before :  30  energy_after :  50  reward :  -225.383217880547\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "action : 1  next_temperatures :  [-0.80731709 -0.87196949 -0.79401942 -0.61931213 -0.33279717 -0.96866058\n",
      " -1.05507157 -0.65117867 -1.28289176]  energy_before :  50  energy_after :  40  reward :  -195.383217880547\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "action : 1  next_temperatures :  [-0.80731709 -0.87196949 -0.79401942 -0.61931213 -0.33279717 -0.96866058\n",
      " -1.05507157 -0.65117867 -1.28289176]  energy_before :  40  energy_after :  50  reward :  -215.383217880547\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "action : 1  next_temperatures :  [-0.80731709 -0.87196949 -0.79401942 -0.61931213 -0.33279717 -0.96866058\n",
      " -1.05507157 -0.65117867 -1.28289176]  energy_before :  50  energy_after :  50  reward :  -205.383217880547\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "action : 1  next_temperatures :  [-0.80731709 -0.87196949 -0.79401942 -0.61931213 -0.33279717 -0.96866058\n",
      " -1.05507157 -0.65117867 -1.28289176]  energy_before :  50  energy_after :  50  reward :  -205.383217880547\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "Episode 458/500, Total Reward: -1046.916089402735\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "action : 1  next_temperatures :  [ 0.02704106 -0.34338727 -0.29240467 -0.88304922 -0.63189095 -0.77405788\n",
      " -0.71730529 -1.11187965 -0.03186259]  energy_before :  30  energy_after :  50  reward :  -222.75879647939217\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step\n",
      "action : 1  next_temperatures :  [ 0.02704106 -0.34338727 -0.29240467 -0.88304922 -0.63189095 -0.77405788\n",
      " -0.71730529 -1.11187965 -0.03186259]  energy_before :  50  energy_after :  40  reward :  -192.75879647939217\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "action : 1  next_temperatures :  [ 0.02704106 -0.34338727 -0.29240467 -0.88304922 -0.63189095 -0.77405788\n",
      " -0.71730529 -1.11187965 -0.03186259]  energy_before :  40  energy_after :  50  reward :  -212.75879647939217\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "action : 1  next_temperatures :  [ 0.02704106 -0.34338727 -0.29240467 -0.88304922 -0.63189095 -0.77405788\n",
      " -0.71730529 -1.11187965 -0.03186259]  energy_before :  50  energy_after :  50  reward :  -202.75879647939217\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "action : 1  next_temperatures :  [ 0.02704106 -0.34338727 -0.29240467 -0.88304922 -0.63189095 -0.77405788\n",
      " -0.71730529 -1.11187965 -0.03186259]  energy_before :  50  energy_after :  50  reward :  -202.75879647939217\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "Episode 459/500, Total Reward: -1033.793982396961\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "action : 1  next_temperatures :  [-0.11616967 -0.87029412 -0.74841808 -0.21879213  0.31025448 -1.51047547\n",
      "  0.41347746 -1.10773334  0.58255123]  energy_before :  30  energy_after :  50  reward :  -221.26559964053234\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step\n",
      "action : 1  next_temperatures :  [-0.11616967 -0.87029412 -0.74841808 -0.21879213  0.31025448 -1.51047547\n",
      "  0.41347746 -1.10773334  0.58255123]  energy_before :  50  energy_after :  40  reward :  -191.26559964053234\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "action : 1  next_temperatures :  [-0.11616967 -0.87029412 -0.74841808 -0.21879213  0.31025448 -1.51047547\n",
      "  0.41347746 -1.10773334  0.58255123]  energy_before :  40  energy_after :  50  reward :  -211.26559964053234\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "action : 1  next_temperatures :  [-0.11616967 -0.87029412 -0.74841808 -0.21879213  0.31025448 -1.51047547\n",
      "  0.41347746 -1.10773334  0.58255123]  energy_before :  50  energy_after :  50  reward :  -201.26559964053234\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "action : 1  next_temperatures :  [-0.11616967 -0.87029412 -0.74841808 -0.21879213  0.31025448 -1.51047547\n",
      "  0.41347746 -1.10773334  0.58255123]  energy_before :  50  energy_after :  50  reward :  -201.26559964053234\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "Episode 460/500, Total Reward: -1026.3279982026618\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "action : 1  next_temperatures :  [-0.22617211  0.22707944  0.60822181 -0.1340195   0.01116069 -0.25887283\n",
      "  0.18340478 -0.0061973   0.45244007]  energy_before :  30  energy_after :  50  reward :  -217.14295495074384\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "action : 1  next_temperatures :  [-0.22617211  0.22707944  0.60822181 -0.1340195   0.01116069 -0.25887283\n",
      "  0.18340478 -0.0061973   0.45244007]  energy_before :  50  energy_after :  40  reward :  -187.14295495074384\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "action : 1  next_temperatures :  [-0.22617211  0.22707944  0.60822181 -0.1340195   0.01116069 -0.25887283\n",
      "  0.18340478 -0.0061973   0.45244007]  energy_before :  40  energy_after :  50  reward :  -207.14295495074384\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step\n",
      "action : 1  next_temperatures :  [-0.22617211  0.22707944  0.60822181 -0.1340195   0.01116069 -0.25887283\n",
      "  0.18340478 -0.0061973   0.45244007]  energy_before :  50  energy_after :  50  reward :  -197.14295495074384\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "action : 1  next_temperatures :  [-0.22617211  0.22707944  0.60822181 -0.1340195   0.01116069 -0.25887283\n",
      "  0.18340478 -0.0061973   0.45244007]  energy_before :  50  energy_after :  50  reward :  -197.14295495074384\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step\n",
      "Episode 461/500, Total Reward: -1005.7147747537192\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "action : 1  next_temperatures :  [ 0.06440038 -1.23971529  0.84762885 -1.97976962  0.06100966 -1.30358207\n",
      "  0.80509053 -1.35743327  0.27534432]  energy_before :  30  energy_after :  50  reward :  -221.82702651691187\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step\n",
      "action : 1  next_temperatures :  [ 0.06440038 -1.23971529  0.84762885 -1.97976962  0.06100966 -1.30358207\n",
      "  0.80509053 -1.35743327  0.27534432]  energy_before :  50  energy_after :  40  reward :  -191.82702651691187\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "action : 1  next_temperatures :  [ 0.06440038 -1.23971529  0.84762885 -1.97976962  0.06100966 -1.30358207\n",
      "  0.80509053 -1.35743327  0.27534432]  energy_before :  40  energy_after :  50  reward :  -211.82702651691187\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "action : 1  next_temperatures :  [ 0.06440038 -1.23971529  0.84762885 -1.97976962  0.06100966 -1.30358207\n",
      "  0.80509053 -1.35743327  0.27534432]  energy_before :  50  energy_after :  50  reward :  -201.82702651691187\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "action : 1  next_temperatures :  [ 0.06440038 -1.23971529  0.84762885 -1.97976962  0.06100966 -1.30358207\n",
      "  0.80509053 -1.35743327  0.27534432]  energy_before :  50  energy_after :  50  reward :  -201.82702651691187\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "Episode 462/500, Total Reward: -1029.1351325845594\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "action : 1  next_temperatures :  [ 0.06440038 -0.34171189 -0.60021372  0.32547277  0.09756556 -0.08475462\n",
      " -0.35343148  0.08594289  0.07475628]  energy_before :  30  energy_after :  50  reward :  -218.73197383769363\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "action : 1  next_temperatures :  [ 0.06440038 -0.34171189 -0.60021372  0.32547277  0.09756556 -0.08475462\n",
      " -0.35343148  0.08594289  0.07475628]  energy_before :  50  energy_after :  40  reward :  -188.73197383769363\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "action : 1  next_temperatures :  [ 0.06440038 -0.34171189 -0.60021372  0.32547277  0.09756556 -0.08475462\n",
      " -0.35343148  0.08594289  0.07475628]  energy_before :  40  energy_after :  50  reward :  -208.73197383769363\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "action : 1  next_temperatures :  [ 0.06440038 -0.34171189 -0.60021372  0.32547277  0.09756556 -0.08475462\n",
      " -0.35343148  0.08594289  0.07475628]  energy_before :  50  energy_after :  50  reward :  -198.73197383769363\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "action : 1  next_temperatures :  [ 0.06440038 -0.34171189 -0.60021372  0.32547277  0.09756556 -0.08475462\n",
      " -0.35343148  0.08594289  0.07475628]  energy_before :  50  energy_after :  50  reward :  -198.73197383769363\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "Episode 463/500, Total Reward: -1013.6598691884682\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "action : 1  next_temperatures :  [ 0.12666591  1.71649179  0.30041276  1.49386085 -0.23808413  2.21975106\n",
      " -0.85926503  2.41248284  0.10728407]  energy_before :  30  energy_after :  50  reward :  -210.72039988939\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "action : 1  next_temperatures :  [ 0.12666591  1.71649179  0.30041276  1.49386085 -0.23808413  2.21975106\n",
      " -0.85926503  2.41248284  0.10728407]  energy_before :  50  energy_after :  40  reward :  -180.72039988939\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "action : 1  next_temperatures :  [ 0.12666591  1.71649179  0.30041276  1.49386085 -0.23808413  2.21975106\n",
      " -0.85926503  2.41248284  0.10728407]  energy_before :  40  energy_after :  50  reward :  -200.72039988939\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "action : 1  next_temperatures :  [ 0.12666591  1.71649179  0.30041276  1.49386085 -0.23808413  2.21975106\n",
      " -0.85926503  2.41248284  0.10728407]  energy_before :  50  energy_after :  50  reward :  -190.72039988939\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "action : 1  next_temperatures :  [ 0.12666591  1.71649179  0.30041276  1.49386085 -0.23808413  2.21975106\n",
      " -0.85926503  2.41248284  0.10728407]  energy_before :  50  energy_after :  50  reward :  -190.72039988939\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "Episode 464/500, Total Reward: -973.60199944695\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "action : 1  next_temperatures :  [-0.18466176 -1.71636075 -0.05071757 -1.75780455 -0.78143785 -1.6108495\n",
      "  0.11976765 -1.70311257 -0.10821255]  energy_before :  30  energy_after :  50  reward :  -225.7933894354528\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "action : 1  next_temperatures :  [-0.18466176 -1.71636075 -0.05071757 -1.75780455 -0.78143785 -1.6108495\n",
      "  0.11976765 -1.70311257 -0.10821255]  energy_before :  50  energy_after :  40  reward :  -195.7933894354528\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "action : 1  next_temperatures :  [-0.18466176 -1.71636075 -0.05071757 -1.75780455 -0.78143785 -1.6108495\n",
      "  0.11976765 -1.70311257 -0.10821255]  energy_before :  40  energy_after :  50  reward :  -215.7933894354528\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "action : 1  next_temperatures :  [-0.18466176 -1.71636075 -0.05071757 -1.75780455 -0.78143785 -1.6108495\n",
      "  0.11976765 -1.70311257 -0.10821255]  energy_before :  50  energy_after :  50  reward :  -205.7933894354528\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step\n",
      "action : 1  next_temperatures :  [-0.18466176 -1.71636075 -0.05071757 -1.75780455 -0.78143785 -1.6108495\n",
      "  0.11976765 -1.70311257 -0.10821255]  energy_before :  50  energy_after :  50  reward :  -205.7933894354528\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "Episode 465/500, Total Reward: -1048.966947177264\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "action : 1  next_temperatures :  [-0.55825495 -0.40286324 -0.66177553  0.01054447 -0.22146781 -1.17043285\n",
      "  0.11976765 -0.55120656  0.16149705]  energy_before :  30  energy_after :  50  reward :  -221.27419178428985\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step\n",
      "action : 1  next_temperatures :  [-0.55825495 -0.40286324 -0.66177553  0.01054447 -0.22146781 -1.17043285\n",
      "  0.11976765 -0.55120656  0.16149705]  energy_before :  50  energy_after :  40  reward :  -191.27419178428985\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step\n",
      "action : 1  next_temperatures :  [-0.55825495 -0.40286324 -0.66177553  0.01054447 -0.22146781 -1.17043285\n",
      "  0.11976765 -0.55120656  0.16149705]  energy_before :  40  energy_after :  50  reward :  -211.27419178428985\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "action : 1  next_temperatures :  [-0.55825495 -0.40286324 -0.66177553  0.01054447 -0.22146781 -1.17043285\n",
      "  0.11976765 -0.55120656  0.16149705]  energy_before :  50  energy_after :  50  reward :  -201.27419178428985\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "action : 1  next_temperatures :  [-0.55825495 -0.40286324 -0.66177553  0.01054447 -0.22146781 -1.17043285\n",
      "  0.11976765 -0.55120656  0.16149705]  energy_before :  50  energy_after :  50  reward :  -201.27419178428985\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "Episode 466/500, Total Reward: -1026.3709589214493\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "action : 1  next_temperatures :  [-1.27845962  0.59482523 -0.65237026  0.45017454 -1.26497281  1.5509323\n",
      " -0.8103134   0.94591806 -1.19382757]  energy_before :  30  energy_after :  50  reward :  -219.6580935231343\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "action : 1  next_temperatures :  [-1.27845962  0.59482523 -0.65237026  0.45017454 -1.26497281  1.5509323\n",
      " -0.8103134   0.94591806 -1.19382757]  energy_before :  50  energy_after :  40  reward :  -189.6580935231343\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "action : 1  next_temperatures :  [-1.27845962  0.59482523 -0.65237026  0.45017454 -1.26497281  1.5509323\n",
      " -0.8103134   0.94591806 -1.19382757]  energy_before :  40  energy_after :  50  reward :  -209.6580935231343\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "action : 1  next_temperatures :  [-1.27845962  0.59482523 -0.65237026  0.45017454 -1.26497281  1.5509323\n",
      " -0.8103134   0.94591806 -1.19382757]  energy_before :  50  energy_after :  50  reward :  -199.6580935231343\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "action : 1  next_temperatures :  [-1.27845962  0.59482523 -0.65237026  0.45017454 -1.26497281  1.5509323\n",
      " -0.8103134   0.94591806 -1.19382757]  energy_before :  50  energy_after :  50  reward :  -199.6580935231343\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "Episode 467/500, Total Reward: -1018.2904676156716\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step\n",
      "action : 1  next_temperatures :  [ 0.06440038  0.50267936 -0.61161406  1.64948212  0.7140311  -0.20971004\n",
      " -0.04299653  0.44298615  0.63315002]  energy_before :  30  energy_after :  50  reward :  -214.85759150569842\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "action : 1  next_temperatures :  [ 0.06440038  0.50267936 -0.61161406  1.64948212  0.7140311  -0.20971004\n",
      " -0.04299653  0.44298615  0.63315002]  energy_before :  50  energy_after :  40  reward :  -184.85759150569842\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "action : 1  next_temperatures :  [ 0.06440038  0.50267936 -0.61161406  1.64948212  0.7140311  -0.20971004\n",
      " -0.04299653  0.44298615  0.63315002]  energy_before :  40  energy_after :  50  reward :  -204.85759150569842\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step\n",
      "action : 1  next_temperatures :  [ 0.06440038  0.50267936 -0.61161406  1.64948212  0.7140311  -0.20971004\n",
      " -0.04299653  0.44298615  0.63315002]  energy_before :  50  energy_after :  50  reward :  -194.85759150569842\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step\n",
      "action : 1  next_temperatures :  [ 0.06440038  0.50267936 -0.61161406  1.64948212  0.7140311  -0.20971004\n",
      " -0.04299653  0.44298615  0.63315002]  energy_before :  50  energy_after :  50  reward :  -194.85759150569842\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "Episode 468/500, Total Reward: -994.2879575284921\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "action : 1  next_temperatures :  [-1.18091029 -0.40202555 -0.61161406 -0.50546289 -1.21844711  0.11804188\n",
      " -0.63082407 -0.81242401 -0.23064354]  energy_before :  30  energy_after :  50  reward :  -223.47430964144678\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "action : 1  next_temperatures :  [-1.18091029 -0.40202555 -0.61161406 -0.50546289 -1.21844711  0.11804188\n",
      " -0.63082407 -0.81242401 -0.23064354]  energy_before :  50  energy_after :  40  reward :  -193.47430964144678\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "action : 1  next_temperatures :  [-1.18091029 -0.40202555 -0.61161406 -0.50546289 -1.21844711  0.11804188\n",
      " -0.63082407 -0.81242401 -0.23064354]  energy_before :  40  energy_after :  50  reward :  -213.47430964144678\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "action : 1  next_temperatures :  [-1.18091029 -0.40202555 -0.61161406 -0.50546289 -1.21844711  0.11804188\n",
      " -0.63082407 -0.81242401 -0.23064354]  energy_before :  50  energy_after :  50  reward :  -203.47430964144678\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "action : 1  next_temperatures :  [-1.18091029 -0.40202555 -0.61161406 -0.50546289 -1.21844711  0.11804188\n",
      " -0.63082407 -0.81242401 -0.23064354]  energy_before :  50  energy_after :  50  reward :  -203.47430964144678\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "Episode 469/500, Total Reward: -1037.371548207234\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "action : 1  next_temperatures :  [-0.30296627  1.26413933  0.07240605  0.3881308  -0.43747999  1.15455732\n",
      " -0.96206346  0.71825499 -0.32099851]  energy_before :  30  energy_after :  50  reward :  -216.4260197372765\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "action : 1  next_temperatures :  [-0.30296627  1.26413933  0.07240605  0.3881308  -0.43747999  1.15455732\n",
      " -0.96206346  0.71825499 -0.32099851]  energy_before :  50  energy_after :  40  reward :  -186.4260197372765\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "action : 1  next_temperatures :  [-0.30296627  1.26413933  0.07240605  0.3881308  -0.43747999  1.15455732\n",
      " -0.96206346  0.71825499 -0.32099851]  energy_before :  40  energy_after :  50  reward :  -206.4260197372765\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "action : 1  next_temperatures :  [-0.30296627  1.26413933  0.07240605  0.3881308  -0.43747999  1.15455732\n",
      " -0.96206346  0.71825499 -0.32099851]  energy_before :  50  energy_after :  50  reward :  -196.4260197372765\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "action : 1  next_temperatures :  [-0.30296627  1.26413933  0.07240605  0.3881308  -0.43747999  1.15455732\n",
      " -0.96206346  0.71825499 -0.32099851]  energy_before :  50  energy_after :  50  reward :  -196.4260197372765\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "Episode 470/500, Total Reward: -1002.1300986863826\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "action : 1  next_temperatures :  [-0.30296627  1.16612963 -0.29240467  1.11709357 -0.18823517  1.30819104\n",
      " -0.07603889  1.1378768  -0.59206344]  energy_before :  30  energy_after :  50  reward :  -214.72241739179344\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "action : 1  next_temperatures :  [-0.30296627  1.16612963 -0.29240467  1.11709357 -0.18823517  1.30819104\n",
      " -0.07603889  1.1378768  -0.59206344]  energy_before :  50  energy_after :  40  reward :  -184.72241739179344\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "action : 1  next_temperatures :  [-0.30296627  1.16612963 -0.29240467  1.11709357 -0.18823517  1.30819104\n",
      " -0.07603889  1.1378768  -0.59206344]  energy_before :  40  energy_after :  50  reward :  -204.72241739179344\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step\n",
      "action : 1  next_temperatures :  [-0.30296627  1.16612963 -0.29240467  1.11709357 -0.18823517  1.30819104\n",
      " -0.07603889  1.1378768  -0.59206344]  energy_before :  50  energy_after :  50  reward :  -194.72241739179344\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step\n",
      "action : 1  next_temperatures :  [-0.30296627  1.16612963 -0.29240467  1.11709357 -0.18823517  1.30819104\n",
      " -0.07603889  1.1378768  -0.59206344]  energy_before :  50  energy_after :  50  reward :  -194.72241739179344\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "Episode 471/500, Total Reward: -993.6120869589672\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "action : 1  next_temperatures :  [ 0.68705571 -2.2022208   0.72298518 -3.10188085  0.34514876 -0.80171195\n",
      "  0.9029938  -1.91942265  0.43256198]  energy_before :  30  energy_after :  50  reward :  -222.93449081975038\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "action : 1  next_temperatures :  [ 0.68705571 -2.2022208   0.72298518 -3.10188085  0.34514876 -0.80171195\n",
      "  0.9029938  -1.91942265  0.43256198]  energy_before :  50  energy_after :  40  reward :  -192.93449081975038\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "action : 1  next_temperatures :  [ 0.68705571 -2.2022208   0.72298518 -3.10188085  0.34514876 -0.80171195\n",
      "  0.9029938  -1.91942265  0.43256198]  energy_before :  40  energy_after :  50  reward :  -212.93449081975038\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "action : 1  next_temperatures :  [ 0.68705571 -2.2022208   0.72298518 -3.10188085  0.34514876 -0.80171195\n",
      "  0.9029938  -1.91942265  0.43256198]  energy_before :  50  energy_after :  50  reward :  -202.93449081975038\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "action : 1  next_temperatures :  [ 0.68705571 -2.2022208   0.72298518 -3.10188085  0.34514876 -0.80171195\n",
      "  0.9029938  -1.91942265  0.43256198]  energy_before :  50  energy_after :  50  reward :  -202.93449081975038\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "Episode 472/500, Total Reward: -1034.6724540987518\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "action : 1  next_temperatures :  [-2.44282509  0.22624175 -1.42217789 -0.55358262 -2.19881008 -0.46679045\n",
      " -2.27886242 -0.56134198 -1.90823424]  energy_before :  30  energy_after :  50  reward :  -229.60638303756377\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "action : 1  next_temperatures :  [-2.44282509  0.22624175 -1.42217789 -0.55358262 -2.19881008 -0.46679045\n",
      " -2.27886242 -0.56134198 -1.90823424]  energy_before :  50  energy_after :  40  reward :  -199.60638303756377\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "action : 1  next_temperatures :  [-2.44282509  0.22624175 -1.42217789 -0.55358262 -2.19881008 -0.46679045\n",
      " -2.27886242 -0.56134198 -1.90823424]  energy_before :  40  energy_after :  50  reward :  -219.60638303756377\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "action : 1  next_temperatures :  [-2.44282509  0.22624175 -1.42217789 -0.55358262 -2.19881008 -0.46679045\n",
      " -2.27886242 -0.56134198 -1.90823424]  energy_before :  50  energy_after :  50  reward :  -209.60638303756377\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "action : 1  next_temperatures :  [-2.44282509  0.22624175 -1.42217789 -0.55358262 -2.19881008 -0.46679045\n",
      " -2.27886242 -0.56134198 -1.90823424]  energy_before :  50  energy_after :  50  reward :  -209.60638303756377\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "Episode 473/500, Total Reward: -1068.0319151878189\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "action : 1  next_temperatures :  [-1.80356562  1.59083833 -1.02202613  1.51597545 -1.2799275   1.79674624\n",
      " -1.45157981  1.95178186 -1.24804056]  energy_before :  30  energy_after :  50  reward :  -217.94979772485408\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "action : 1  next_temperatures :  [-1.80356562  1.59083833 -1.02202613  1.51597545 -1.2799275   1.79674624\n",
      " -1.45157981  1.95178186 -1.24804056]  energy_before :  50  energy_after :  40  reward :  -187.94979772485408\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "action : 1  next_temperatures :  [-1.80356562  1.59083833 -1.02202613  1.51597545 -1.2799275   1.79674624\n",
      " -1.45157981  1.95178186 -1.24804056]  energy_before :  40  energy_after :  50  reward :  -207.94979772485408\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "action : 1  next_temperatures :  [-1.80356562  1.59083833 -1.02202613  1.51597545 -1.2799275   1.79674624\n",
      " -1.45157981  1.95178186 -1.24804056]  energy_before :  50  energy_after :  50  reward :  -197.94979772485408\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "action : 1  next_temperatures :  [-1.80356562  1.59083833 -1.02202613  1.51597545 -1.2799275   1.79674624\n",
      " -1.45157981  1.95178186 -1.24804056]  energy_before :  50  energy_after :  50  reward :  -197.94979772485408\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "Episode 474/500, Total Reward: -1009.7489886242704\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step\n",
      "action : 1  next_temperatures :  [ 0.31968906 -0.29396358 -0.29240467  0.40287387  0.21554145 -0.1666926\n",
      "  0.07081602  0.16886907  0.27534432]  energy_before :  30  energy_after :  50  reward :  -217.29992706188108\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "action : 1  next_temperatures :  [ 0.31968906 -0.29396358 -0.29240467  0.40287387  0.21554145 -0.1666926\n",
      "  0.07081602  0.16886907  0.27534432]  energy_before :  50  energy_after :  40  reward :  -187.29992706188108\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "action : 1  next_temperatures :  [ 0.31968906 -0.29396358 -0.29240467  0.40287387  0.21554145 -0.1666926\n",
      "  0.07081602  0.16886907  0.27534432]  energy_before :  40  energy_after :  50  reward :  -207.29992706188108\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step\n",
      "action : 1  next_temperatures :  [ 0.31968906 -0.29396358 -0.29240467  0.40287387  0.21554145 -0.1666926\n",
      "  0.07081602  0.16886907  0.27534432]  energy_before :  50  energy_after :  50  reward :  -197.29992706188108\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "action : 1  next_temperatures :  [ 0.31968906 -0.29396358 -0.29240467  0.40287387  0.21554145 -0.1666926\n",
      "  0.07081602  0.16886907  0.27534432]  energy_before :  50  energy_after :  50  reward :  -197.29992706188108\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "Episode 475/500, Total Reward: -1006.4996353094054\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "action : 1  next_temperatures :  [ 0.0083614   0.45995719 -0.06439797  0.65596319  0.97823061 -0.12674784\n",
      " -0.27674059  0.39921956  0.22113133]  energy_before :  30  energy_after :  50  reward :  -215.74502310895383\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "action : 1  next_temperatures :  [ 0.0083614   0.45995719 -0.06439797  0.65596319  0.97823061 -0.12674784\n",
      " -0.27674059  0.39921956  0.22113133]  energy_before :  50  energy_after :  40  reward :  -185.74502310895383\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step\n",
      "action : 1  next_temperatures :  [ 0.0083614   0.45995719 -0.06439797  0.65596319  0.97823061 -0.12674784\n",
      " -0.27674059  0.39921956  0.22113133]  energy_before :  40  energy_after :  50  reward :  -205.74502310895383\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step\n",
      "action : 1  next_temperatures :  [ 0.0083614   0.45995719 -0.06439797  0.65596319  0.97823061 -0.12674784\n",
      " -0.27674059  0.39921956  0.22113133]  energy_before :  50  energy_after :  50  reward :  -195.74502310895383\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "action : 1  next_temperatures :  [ 0.0083614   0.45995719 -0.06439797  0.65596319  0.97823061 -0.12674784\n",
      " -0.27674059  0.39921956  0.22113133]  energy_before :  50  energy_after :  50  reward :  -195.74502310895383\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "Episode 476/500, Total Reward: -998.7251155447691\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "action : 1  next_temperatures :  [-0.67655947  0.58561065 -0.33800601  0.57487632 -0.86451946  1.74860768\n",
      " -1.54458791  1.85733816 -0.97968628]  energy_before :  30  energy_after :  50  reward :  -217.636926327586\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "action : 1  next_temperatures :  [-0.67655947  0.58561065 -0.33800601  0.57487632 -0.86451946  1.74860768\n",
      " -1.54458791  1.85733816 -0.97968628]  energy_before :  50  energy_after :  40  reward :  -187.636926327586\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "action : 1  next_temperatures :  [-0.67655947  0.58561065 -0.33800601  0.57487632 -0.86451946  1.74860768\n",
      " -1.54458791  1.85733816 -0.97968628]  energy_before :  40  energy_after :  50  reward :  -207.636926327586\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "action : 1  next_temperatures :  [-0.67655947  0.58561065 -0.33800601  0.57487632 -0.86451946  1.74860768\n",
      " -1.54458791  1.85733816 -0.97968628]  energy_before :  50  energy_after :  50  reward :  -197.636926327586\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "action : 1  next_temperatures :  [-0.67655947  0.58561065 -0.33800601  0.57487632 -0.86451946  1.74860768\n",
      " -1.54458791  1.85733816 -0.97968628]  energy_before :  50  energy_after :  50  reward :  -197.636926327586\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "Episode 477/500, Total Reward: -1008.18463163793\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step\n",
      "action : 1  next_temperatures :  [ 0.43799358  0.16844116  0.36121455  0.26527191  0.80874413 -0.74230691\n",
      "  0.21277576  0.2771338   0.60062223]  energy_before :  30  energy_after :  50  reward :  -215.6101098042281\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "action : 1  next_temperatures :  [ 0.43799358  0.16844116  0.36121455  0.26527191  0.80874413 -0.74230691\n",
      "  0.21277576  0.2771338   0.60062223]  energy_before :  50  energy_after :  40  reward :  -185.6101098042281\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "action : 1  next_temperatures :  [ 0.43799358  0.16844116  0.36121455  0.26527191  0.80874413 -0.74230691\n",
      "  0.21277576  0.2771338   0.60062223]  energy_before :  40  energy_after :  50  reward :  -205.6101098042281\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "action : 1  next_temperatures :  [ 0.43799358  0.16844116  0.36121455  0.26527191  0.80874413 -0.74230691\n",
      "  0.21277576  0.2771338   0.60062223]  energy_before :  50  energy_after :  50  reward :  -195.6101098042281\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "action : 1  next_temperatures :  [ 0.43799358  0.16844116  0.36121455  0.26527191  0.80874413 -0.74230691\n",
      "  0.21277576  0.2771338   0.60062223]  energy_before :  50  energy_after :  50  reward :  -195.6101098042281\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step\n",
      "Episode 478/500, Total Reward: -998.0505490211406\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "action : 1  next_temperatures :  [ 1.56499973 -0.09040497  0.99963332  0.14241301  1.75587446 -0.07451237\n",
      "  1.55568226 -0.19047769  1.46260869]  energy_before :  30  energy_after :  50  reward :  -210.87418357042793\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "action : 1  next_temperatures :  [ 1.56499973 -0.09040497  0.99963332  0.14241301  1.75587446 -0.07451237\n",
      "  1.55568226 -0.19047769  1.46260869]  energy_before :  50  energy_after :  40  reward :  -180.87418357042793\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "action : 1  next_temperatures :  [ 1.56499973 -0.09040497  0.99963332  0.14241301  1.75587446 -0.07451237\n",
      "  1.55568226 -0.19047769  1.46260869]  energy_before :  40  energy_after :  50  reward :  -200.87418357042793\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "action : 1  next_temperatures :  [ 1.56499973 -0.09040497  0.99963332  0.14241301  1.75587446 -0.07451237\n",
      "  1.55568226 -0.19047769  1.46260869]  energy_before :  50  energy_after :  50  reward :  -190.87418357042793\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "action : 1  next_temperatures :  [ 1.56499973 -0.09040497  0.99963332  0.14241301  1.75587446 -0.07451237\n",
      "  1.55568226 -0.19047769  1.46260869]  energy_before :  50  energy_after :  50  reward :  -190.87418357042793\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "Episode 479/500, Total Reward: -974.3709178521397\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "action : 1  next_temperatures :  [-1.05015267 -0.11804873 -0.88978224  0.16452762 -0.78143785 -0.04685831\n",
      " -1.05507157 -0.07530245 -0.59206344]  energy_before :  30  energy_after :  50  reward :  -222.44418963327547\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "action : 1  next_temperatures :  [-1.05015267 -0.11804873 -0.88978224  0.16452762 -0.78143785 -0.04685831\n",
      " -1.05507157 -0.07530245 -0.59206344]  energy_before :  50  energy_after :  40  reward :  -192.44418963327547\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step\n",
      "action : 1  next_temperatures :  [-1.05015267 -0.11804873 -0.88978224  0.16452762 -0.78143785 -0.04685831\n",
      " -1.05507157 -0.07530245 -0.59206344]  energy_before :  40  energy_after :  50  reward :  -212.44418963327547\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "action : 1  next_temperatures :  [-1.05015267 -0.11804873 -0.88978224  0.16452762 -0.78143785 -0.04685831\n",
      " -1.05507157 -0.07530245 -0.59206344]  energy_before :  50  energy_after :  50  reward :  -202.44418963327547\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "action : 1  next_temperatures :  [-1.05015267 -0.11804873 -0.88978224  0.16452762 -0.78143785 -0.04685831\n",
      " -1.05507157 -0.07530245 -0.59206344]  energy_before :  50  energy_after :  50  reward :  -202.44418963327547\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "Episode 480/500, Total Reward: -1032.2209481663774\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "action : 1  next_temperatures :  [ 0.54799602  0.97932482  0.55882036  0.5027991  -0.15472559  1.64311253\n",
      "  0.52443449  0.29940102 -0.26678553]  energy_before :  30  energy_after :  50  reward :  -213.36562277486814\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "action : 1  next_temperatures :  [ 0.54799602  0.97932482  0.55882036  0.5027991  -0.15472559  1.64311253\n",
      "  0.52443449  0.29940102 -0.26678553]  energy_before :  50  energy_after :  40  reward :  -183.36562277486814\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "action : 1  next_temperatures :  [ 0.54799602  0.97932482  0.55882036  0.5027991  -0.15472559  1.64311253\n",
      "  0.52443449  0.29940102 -0.26678553]  energy_before :  40  energy_after :  50  reward :  -203.36562277486814\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "action : 1  next_temperatures :  [ 0.54799602  0.97932482  0.55882036  0.5027991  -0.15472559  1.64311253\n",
      "  0.52443449  0.29940102 -0.26678553]  energy_before :  50  energy_after :  50  reward :  -193.36562277486814\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "action : 1  next_temperatures :  [ 0.54799602  0.97932482  0.55882036  0.5027991  -0.15472559  1.64311253\n",
      "  0.52443449  0.29940102 -0.26678553]  energy_before :  50  energy_after :  50  reward :  -193.36562277486814\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "Episode 481/500, Total Reward: -986.8281138743407\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "action : 1  next_temperatures :  [ 1.56499973  0.33430373  2.36387343 -1.1119763   2.03835193 -0.53541351\n",
      "  1.78412322  0.20111814  1.19154376]  energy_before :  30  energy_after :  50  reward :  -210.16907587087798\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step\n",
      "action : 1  next_temperatures :  [ 1.56499973  0.33430373  2.36387343 -1.1119763   2.03835193 -0.53541351\n",
      "  1.78412322  0.20111814  1.19154376]  energy_before :  50  energy_after :  40  reward :  -180.16907587087798\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "action : 1  next_temperatures :  [ 1.56499973  0.33430373  2.36387343 -1.1119763   2.03835193 -0.53541351\n",
      "  1.78412322  0.20111814  1.19154376]  energy_before :  40  energy_after :  50  reward :  -200.16907587087798\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "action : 1  next_temperatures :  [ 1.56499973  0.33430373  2.36387343 -1.1119763   2.03835193 -0.53541351\n",
      "  1.78412322  0.20111814  1.19154376]  energy_before :  50  energy_after :  50  reward :  -190.16907587087798\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "action : 1  next_temperatures :  [ 1.56499973  0.33430373  2.36387343 -1.1119763   2.03835193 -0.53541351\n",
      "  1.78412322  0.20111814  1.19154376]  energy_before :  50  energy_after :  50  reward :  -190.16907587087798\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "Episode 482/500, Total Reward: -970.8453793543899\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step\n",
      "action : 1  next_temperatures :  [ 0.08515556 -0.29396358 -0.15560065  0.09081228 -0.23808413 -0.55589801\n",
      " -0.22778895 -0.44616674 -0.04993359]  energy_before :  30  energy_after :  50  reward :  -219.79146780803183\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "action : 1  next_temperatures :  [ 0.08515556 -0.29396358 -0.15560065  0.09081228 -0.23808413 -0.55589801\n",
      " -0.22778895 -0.44616674 -0.04993359]  energy_before :  50  energy_after :  40  reward :  -189.79146780803183\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "action : 1  next_temperatures :  [ 0.08515556 -0.29396358 -0.15560065  0.09081228 -0.23808413 -0.55589801\n",
      " -0.22778895 -0.44616674 -0.04993359]  energy_before :  40  energy_after :  50  reward :  -209.79146780803183\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "action : 1  next_temperatures :  [ 0.08515556 -0.29396358 -0.15560065  0.09081228 -0.23808413 -0.55589801\n",
      " -0.22778895 -0.44616674 -0.04993359]  energy_before :  50  energy_after :  50  reward :  -199.79146780803183\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step\n",
      "action : 1  next_temperatures :  [ 0.08515556 -0.29396358 -0.15560065  0.09081228 -0.23808413 -0.55589801\n",
      " -0.22778895 -0.44616674 -0.04993359]  energy_before :  50  energy_after :  50  reward :  -199.79146780803183\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "Episode 483/500, Total Reward: -1018.9573390401591\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step\n",
      "action : 1  next_temperatures :  [1.91368671 1.86978901 1.25804092 2.30227237 1.9317701  1.15455732\n",
      " 1.92608295 1.49108088 2.33001645]  energy_before :  30  energy_after :  50  reward :  -201.82270328247375\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "action : 1  next_temperatures :  [1.91368671 1.86978901 1.25804092 2.30227237 1.9317701  1.15455732\n",
      " 1.92608295 1.49108088 2.33001645]  energy_before :  50  energy_after :  40  reward :  -171.82270328247375\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "action : 1  next_temperatures :  [1.91368671 1.86978901 1.25804092 2.30227237 1.9317701  1.15455732\n",
      " 1.92608295 1.49108088 2.33001645]  energy_before :  40  energy_after :  50  reward :  -191.82270328247375\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "action : 1  next_temperatures :  [1.91368671 1.86978901 1.25804092 2.30227237 1.9317701  1.15455732\n",
      " 1.92608295 1.49108088 2.33001645]  energy_before :  50  energy_after :  50  reward :  -181.82270328247375\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "action : 1  next_temperatures :  [1.91368671 1.86978901 1.25804092 2.30227237 1.9317701  1.15455732\n",
      " 1.92608295 1.49108088 2.33001645]  energy_before :  50  energy_after :  50  reward :  -181.82270328247375\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "Episode 484/500, Total Reward: -929.1135164123688\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "action : 1  next_temperatures :  [ 0.43799358 -0.24370219  0.10280695  0.09982193  0.46478627 -0.47396003\n",
      "  0.85404217 -0.0061973   0.22113133]  energy_before :  30  energy_after :  50  reward :  -216.54327729201685\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "action : 1  next_temperatures :  [ 0.43799358 -0.24370219  0.10280695  0.09982193  0.46478627 -0.47396003\n",
      "  0.85404217 -0.0061973   0.22113133]  energy_before :  50  energy_after :  40  reward :  -186.54327729201685\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "action : 1  next_temperatures :  [ 0.43799358 -0.24370219  0.10280695  0.09982193  0.46478627 -0.47396003\n",
      "  0.85404217 -0.0061973   0.22113133]  energy_before :  40  energy_after :  50  reward :  -206.54327729201685\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step\n",
      "action : 1  next_temperatures :  [ 0.43799358 -0.24370219  0.10280695  0.09982193  0.46478627 -0.47396003\n",
      "  0.85404217 -0.0061973   0.22113133]  energy_before :  50  energy_after :  50  reward :  -196.54327729201685\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "action : 1  next_temperatures :  [ 0.43799358 -0.24370219  0.10280695  0.09982193  0.46478627 -0.47396003\n",
      "  0.85404217 -0.0061973   0.22113133]  energy_before :  50  energy_after :  50  reward :  -196.54327729201685\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "Episode 485/500, Total Reward: -1002.7163864600843\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "action : 1  next_temperatures :  [ 1.03989373  0.49514016  1.27628145  0.16108757  0.91342696 -0.13058868\n",
      "  1.19180844  0.27022329  0.87168715]  energy_before :  30  energy_after :  50  reward :  -211.91103993685815\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "action : 1  next_temperatures :  [ 1.03989373  0.49514016  1.27628145  0.16108757  0.91342696 -0.13058868\n",
      "  1.19180844  0.27022329  0.87168715]  energy_before :  50  energy_after :  40  reward :  -181.91103993685815\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "action : 1  next_temperatures :  [ 1.03989373  0.49514016  1.27628145  0.16108757  0.91342696 -0.13058868\n",
      "  1.19180844  0.27022329  0.87168715]  energy_before :  40  energy_after :  50  reward :  -201.91103993685815\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step\n",
      "action : 1  next_temperatures :  [ 1.03989373  0.49514016  1.27628145  0.16108757  0.91342696 -0.13058868\n",
      "  1.19180844  0.27022329  0.87168715]  energy_before :  50  energy_after :  50  reward :  -191.91103993685815\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "action : 1  next_temperatures :  [ 1.03989373  0.49514016  1.27628145  0.16108757  0.91342696 -0.13058868\n",
      "  1.19180844  0.27022329  0.87168715]  energy_before :  50  energy_after :  50  reward :  -191.91103993685815\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "Episode 486/500, Total Reward: -979.5551996842908\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "action : 1  next_temperatures :  [-1.05015267 -0.62820178 -0.93538358 -0.93219278 -0.98581861 -1.275928\n",
      " -0.74993972 -1.38830024 -1.02576732]  energy_before :  30  energy_after :  50  reward :  -226.97168468812978\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "action : 1  next_temperatures :  [-1.05015267 -0.62820178 -0.93538358 -0.93219278 -0.98581861 -1.275928\n",
      " -0.74993972 -1.38830024 -1.02576732]  energy_before :  50  energy_after :  40  reward :  -196.97168468812978\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "action : 1  next_temperatures :  [-1.05015267 -0.62820178 -0.93538358 -0.93219278 -0.98581861 -1.275928\n",
      " -0.74993972 -1.38830024 -1.02576732]  energy_before :  40  energy_after :  50  reward :  -216.97168468812978\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "action : 1  next_temperatures :  [-1.05015267 -0.62820178 -0.93538358 -0.93219278 -0.98581861 -1.275928\n",
      " -0.74993972 -1.38830024 -1.02576732]  energy_before :  50  energy_after :  50  reward :  -206.97168468812978\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "action : 1  next_temperatures :  [-1.05015267 -0.62820178 -0.93538358 -0.93219278 -0.98581861 -1.275928\n",
      " -0.74993972 -1.38830024 -1.02576732]  energy_before :  50  energy_after :  50  reward :  -206.97168468812978\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "Episode 487/500, Total Reward: -1054.858423440649\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step\n",
      "action : 1  next_temperatures :  [ 1.63660509 -1.27217577  2.3524731  -2.43926188  0.86357799 -1.1806751\n",
      "  1.58831668 -0.92759926  0.27534432]  energy_before :  30  energy_after :  50  reward :  -217.10339483190188\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "action : 1  next_temperatures :  [ 1.63660509 -1.27217577  2.3524731  -2.43926188  0.86357799 -1.1806751\n",
      "  1.58831668 -0.92759926  0.27534432]  energy_before :  50  energy_after :  40  reward :  -187.10339483190188\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "action : 1  next_temperatures :  [ 1.63660509 -1.27217577  2.3524731  -2.43926188  0.86357799 -1.1806751\n",
      "  1.58831668 -0.92759926  0.27534432]  energy_before :  40  energy_after :  50  reward :  -207.10339483190188\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "action : 1  next_temperatures :  [ 1.63660509 -1.27217577  2.3524731  -2.43926188  0.86357799 -1.1806751\n",
      "  1.58831668 -0.92759926  0.27534432]  energy_before :  50  energy_after :  50  reward :  -197.10339483190188\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "action : 1  next_temperatures :  [ 1.63660509 -1.27217577  2.3524731  -2.43926188  0.86357799 -1.1806751\n",
      "  1.58831668 -0.92759926  0.27534432]  energy_before :  50  energy_after :  50  reward :  -197.10339483190188\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "Episode 488/500, Total Reward: -1005.5169741595093\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step\n",
      "action : 1  next_temperatures :  [-0.63504911  0.23629403 -0.66177553  0.19892811 -1.03068267  0.75510967\n",
      " -0.82663061  0.33932843 -0.44297773]  energy_before :  30  energy_after :  50  reward :  -220.06745542311342\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "action : 1  next_temperatures :  [-0.63504911  0.23629403 -0.66177553  0.19892811 -1.03068267  0.75510967\n",
      " -0.82663061  0.33932843 -0.44297773]  energy_before :  50  energy_after :  40  reward :  -190.06745542311342\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "action : 1  next_temperatures :  [-0.63504911  0.23629403 -0.66177553  0.19892811 -1.03068267  0.75510967\n",
      " -0.82663061  0.33932843 -0.44297773]  energy_before :  40  energy_after :  50  reward :  -210.06745542311342\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step\n",
      "action : 1  next_temperatures :  [-0.63504911  0.23629403 -0.66177553  0.19892811 -1.03068267  0.75510967\n",
      " -0.82663061  0.33932843 -0.44297773]  energy_before :  50  energy_after :  50  reward :  -200.06745542311342\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "action : 1  next_temperatures :  [-0.63504911  0.23629403 -0.66177553  0.19892811 -1.03068267  0.75510967\n",
      " -0.82663061  0.33932843 -0.44297773]  energy_before :  50  energy_after :  50  reward :  -200.06745542311342\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "Episode 489/500, Total Reward: -1020.3372771155671\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "action : 1  next_temperatures :  [ 0.29893389 -1.36536875 -0.29240467 -0.85683933 -0.34941349 -1.47770028\n",
      " -0.27674059 -0.78324628  0.29341531]  energy_before :  30  energy_after :  50  reward :  -222.80936418472155\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "action : 1  next_temperatures :  [ 0.29893389 -1.36536875 -0.29240467 -0.85683933 -0.34941349 -1.47770028\n",
      " -0.27674059 -0.78324628  0.29341531]  energy_before :  50  energy_after :  40  reward :  -192.80936418472155\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "action : 1  next_temperatures :  [ 0.29893389 -1.36536875 -0.29240467 -0.85683933 -0.34941349 -1.47770028\n",
      " -0.27674059 -0.78324628  0.29341531]  energy_before :  40  energy_after :  50  reward :  -212.80936418472155\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "action : 1  next_temperatures :  [ 0.29893389 -1.36536875 -0.29240467 -0.85683933 -0.34941349 -1.47770028\n",
      " -0.27674059 -0.78324628  0.29341531]  energy_before :  50  energy_after :  50  reward :  -202.80936418472155\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step\n",
      "action : 1  next_temperatures :  [ 0.29893389 -1.36536875 -0.29240467 -0.85683933 -0.34941349 -1.47770028\n",
      " -0.27674059 -0.78324628  0.29341531]  energy_before :  50  energy_after :  50  reward :  -202.80936418472155\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "Episode 490/500, Total Reward: -1034.0468209236078\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "action : 1  next_temperatures :  [ 0.195158    0.38456511  0.49497848  0.19155657 -0.83128681  1.52327823\n",
      " -1.20682164  1.72143137 -0.29991569]  energy_before :  30  energy_after :  50  reward :  -215.82705637640726\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "action : 1  next_temperatures :  [ 0.195158    0.38456511  0.49497848  0.19155657 -0.83128681  1.52327823\n",
      " -1.20682164  1.72143137 -0.29991569]  energy_before :  50  energy_after :  40  reward :  -185.82705637640726\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "action : 1  next_temperatures :  [ 0.195158    0.38456511  0.49497848  0.19155657 -0.83128681  1.52327823\n",
      " -1.20682164  1.72143137 -0.29991569]  energy_before :  40  energy_after :  50  reward :  -205.82705637640726\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "action : 1  next_temperatures :  [ 0.195158    0.38456511  0.49497848  0.19155657 -0.83128681  1.52327823\n",
      " -1.20682164  1.72143137 -0.29991569]  energy_before :  50  energy_after :  50  reward :  -195.82705637640726\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "action : 1  next_temperatures :  [ 0.195158    0.38456511  0.49497848  0.19155657 -0.83128681  1.52327823\n",
      " -1.20682164  1.72143137 -0.29991569]  energy_before :  50  energy_after :  50  reward :  -195.82705637640726\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step\n",
      "Episode 491/500, Total Reward: -999.1352818820362\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "action : 1  next_temperatures :  [-0.67655947 -1.22128612 -0.53561182 -1.26800709 -0.68672482 -0.98709662\n",
      " -0.59818965 -1.26621448 -0.80891538]  energy_before :  30  energy_after :  50  reward :  -226.04860544501605\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "action : 1  next_temperatures :  [-0.67655947 -1.22128612 -0.53561182 -1.26800709 -0.68672482 -0.98709662\n",
      " -0.59818965 -1.26621448 -0.80891538]  energy_before :  50  energy_after :  40  reward :  -196.04860544501605\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "action : 1  next_temperatures :  [-0.67655947 -1.22128612 -0.53561182 -1.26800709 -0.68672482 -0.98709662\n",
      " -0.59818965 -1.26621448 -0.80891538]  energy_before :  40  energy_after :  50  reward :  -216.04860544501605\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "action : 1  next_temperatures :  [-0.67655947 -1.22128612 -0.53561182 -1.26800709 -0.68672482 -0.98709662\n",
      " -0.59818965 -1.26621448 -0.80891538]  energy_before :  50  energy_after :  50  reward :  -206.04860544501605\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step\n",
      "action : 1  next_temperatures :  [-0.67655947 -1.22128612 -0.53561182 -1.26800709 -0.68672482 -0.98709662\n",
      " -0.59818965 -1.26621448 -0.80891538]  energy_before :  50  energy_after :  50  reward :  -206.04860544501605\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "Episode 492/500, Total Reward: -1050.2430272250804\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "action : 1  next_temperatures :  [2.28520439 2.19648801 1.66845298 2.05655459 2.05496825 1.73836543\n",
      " 2.17084113 1.60625612 2.46193471]  energy_before :  30  energy_after :  50  reward :  -199.76093438285494\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "action : 1  next_temperatures :  [2.28520439 2.19648801 1.66845298 2.05655459 2.05496825 1.73836543\n",
      " 2.17084113 1.60625612 2.46193471]  energy_before :  50  energy_after :  40  reward :  -169.76093438285494\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "action : 1  next_temperatures :  [2.28520439 2.19648801 1.66845298 2.05655459 2.05496825 1.73836543\n",
      " 2.17084113 1.60625612 2.46193471]  energy_before :  40  energy_after :  50  reward :  -189.76093438285494\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "action : 1  next_temperatures :  [2.28520439 2.19648801 1.66845298 2.05655459 2.05496825 1.73836543\n",
      " 2.17084113 1.60625612 2.46193471]  energy_before :  50  energy_after :  50  reward :  -179.76093438285494\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step\n",
      "action : 1  next_temperatures :  [2.28520439 2.19648801 1.66845298 2.05655459 2.05496825 1.73836543\n",
      " 2.17084113 1.60625612 2.46193471]  energy_before :  50  energy_after :  50  reward :  -179.76093438285494\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "Episode 493/500, Total Reward: -918.8046719142746\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "action : 1  next_temperatures :  [ 0.06440038 -0.41961704 -0.18904163  0.23169048  0.29363816 -0.60915769\n",
      " -0.32079706 -0.0545709   0.49219626]  energy_before :  30  energy_after :  50  reward :  -218.51125904993702\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "action : 1  next_temperatures :  [ 0.06440038 -0.41961704 -0.18904163  0.23169048  0.29363816 -0.60915769\n",
      " -0.32079706 -0.0545709   0.49219626]  energy_before :  50  energy_after :  40  reward :  -188.51125904993702\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step\n",
      "action : 1  next_temperatures :  [ 0.06440038 -0.41961704 -0.18904163  0.23169048  0.29363816 -0.60915769\n",
      " -0.32079706 -0.0545709   0.49219626]  energy_before :  40  energy_after :  50  reward :  -208.51125904993702\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step\n",
      "action : 1  next_temperatures :  [ 0.06440038 -0.41961704 -0.18904163  0.23169048  0.29363816 -0.60915769\n",
      " -0.32079706 -0.0545709   0.49219626]  energy_before :  50  energy_after :  50  reward :  -198.51125904993702\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "action : 1  next_temperatures :  [ 0.06440038 -0.41961704 -0.18904163  0.23169048  0.29363816 -0.60915769\n",
      " -0.32079706 -0.0545709   0.49219626]  energy_before :  50  energy_after :  50  reward :  -198.51125904993702\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "Episode 494/500, Total Reward: -1012.5562952496851\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "action : 1  next_temperatures :  [ 0.74932124 -0.01501289  0.30041276  0.20629964  0.31025448 -0.00384087\n",
      "  0.45753393 -0.02923235  0.76326118]  energy_before :  30  energy_after :  50  reward :  -215.2610028781095\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "action : 1  next_temperatures :  [ 0.74932124 -0.01501289  0.30041276  0.20629964  0.31025448 -0.00384087\n",
      "  0.45753393 -0.02923235  0.76326118]  energy_before :  50  energy_after :  40  reward :  -185.2610028781095\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "action : 1  next_temperatures :  [ 0.74932124 -0.01501289  0.30041276  0.20629964  0.31025448 -0.00384087\n",
      "  0.45753393 -0.02923235  0.76326118]  energy_before :  40  energy_after :  50  reward :  -205.2610028781095\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "action : 1  next_temperatures :  [ 0.74932124 -0.01501289  0.30041276  0.20629964  0.31025448 -0.00384087\n",
      "  0.45753393 -0.02923235  0.76326118]  energy_before :  50  energy_after :  50  reward :  -195.2610028781095\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "action : 1  next_temperatures :  [ 0.74932124 -0.01501289  0.30041276  0.20629964  0.31025448 -0.00384087\n",
      "  0.45753393 -0.02923235  0.76326118]  energy_before :  50  energy_after :  50  reward :  -195.2610028781095\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "Episode 495/500, Total Reward: -996.3050143905475\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step\n",
      "action : 1  next_temperatures :  [-1.05015267 -1.29919126 -1.06762747 -1.06406133 -0.83128681 -0.78122745\n",
      " -1.0110151  -1.25239345 -1.11250809]  energy_before :  30  energy_after :  50  reward :  -227.46946362721525\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step\n",
      "action : 1  next_temperatures :  [-1.05015267 -1.29919126 -1.06762747 -1.06406133 -0.83128681 -0.78122745\n",
      " -1.0110151  -1.25239345 -1.11250809]  energy_before :  50  energy_after :  40  reward :  -197.46946362721525\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "action : 1  next_temperatures :  [-1.05015267 -1.29919126 -1.06762747 -1.06406133 -0.83128681 -0.78122745\n",
      " -1.0110151  -1.25239345 -1.11250809]  energy_before :  40  energy_after :  50  reward :  -217.46946362721525\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "action : 1  next_temperatures :  [-1.05015267 -1.29919126 -1.06762747 -1.06406133 -0.83128681 -0.78122745\n",
      " -1.0110151  -1.25239345 -1.11250809]  energy_before :  50  energy_after :  50  reward :  -207.46946362721525\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "action : 1  next_temperatures :  [-1.05015267 -1.29919126 -1.06762747 -1.06406133 -0.83128681 -0.78122745\n",
      " -1.0110151  -1.25239345 -1.11250809]  energy_before :  50  energy_after :  50  reward :  -207.46946362721525\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "Episode 496/500, Total Reward: -1057.3473181360762\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "action : 1  next_temperatures :  [ 0.5687512  -0.72872455 -0.06439797 -0.67009381  0.66418213 -1.04957433\n",
      "  0.45753393 -1.19787717 -0.48363747]  energy_before :  30  energy_after :  50  reward :  -220.50383803789546\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "action : 1  next_temperatures :  [ 0.5687512  -0.72872455 -0.06439797 -0.67009381  0.66418213 -1.04957433\n",
      "  0.45753393 -1.19787717 -0.48363747]  energy_before :  50  energy_after :  40  reward :  -190.50383803789546\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "action : 1  next_temperatures :  [ 0.5687512  -0.72872455 -0.06439797 -0.67009381  0.66418213 -1.04957433\n",
      "  0.45753393 -1.19787717 -0.48363747]  energy_before :  40  energy_after :  50  reward :  -210.50383803789546\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step\n",
      "action : 1  next_temperatures :  [ 0.5687512  -0.72872455 -0.06439797 -0.67009381  0.66418213 -1.04957433\n",
      "  0.45753393 -1.19787717 -0.48363747]  energy_before :  50  energy_after :  50  reward :  -200.50383803789546\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step\n",
      "action : 1  next_temperatures :  [ 0.5687512  -0.72872455 -0.06439797 -0.67009381  0.66418213 -1.04957433\n",
      "  0.45753393 -1.19787717 -0.48363747]  energy_before :  50  energy_after :  50  reward :  -200.50383803789546\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "Episode 497/500, Total Reward: -1022.5191901894773\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "action : 1  next_temperatures :  [ 1.03989373 -1.14589404  0.43265665 -0.90680194  0.75889517 -0.78122745\n",
      "  0.94705027 -1.15794975  0.3458212 ]  energy_before :  30  energy_after :  50  reward :  -218.46755616633462\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "action : 1  next_temperatures :  [ 1.03989373 -1.14589404  0.43265665 -0.90680194  0.75889517 -0.78122745\n",
      "  0.94705027 -1.15794975  0.3458212 ]  energy_before :  50  energy_after :  40  reward :  -188.46755616633462\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "action : 1  next_temperatures :  [ 1.03989373 -1.14589404  0.43265665 -0.90680194  0.75889517 -0.78122745\n",
      "  0.94705027 -1.15794975  0.3458212 ]  energy_before :  40  energy_after :  50  reward :  -208.46755616633462\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "action : 1  next_temperatures :  [ 1.03989373 -1.14589404  0.43265665 -0.90680194  0.75889517 -0.78122745\n",
      "  0.94705027 -1.15794975  0.3458212 ]  energy_before :  50  energy_after :  50  reward :  -198.46755616633462\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step\n",
      "action : 1  next_temperatures :  [ 1.03989373 -1.14589404  0.43265665 -0.90680194  0.75889517 -0.78122745\n",
      "  0.94705027 -1.15794975  0.3458212 ]  energy_before :  50  energy_after :  50  reward :  -198.46755616633462\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "Episode 498/500, Total Reward: -1012.3377808316731\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "action : 1  next_temperatures :  [ 0.43799358 -0.67092396 -0.70737688  0.37994021  0.50965034 -0.53541351\n",
      " -0.17394215  0.24488473  0.0042794 ]  energy_before :  30  energy_after :  50  reward :  -218.51090824334386\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "action : 1  next_temperatures :  [ 0.43799358 -0.67092396 -0.70737688  0.37994021  0.50965034 -0.53541351\n",
      " -0.17394215  0.24488473  0.0042794 ]  energy_before :  50  energy_after :  40  reward :  -188.51090824334386\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "action : 1  next_temperatures :  [ 0.43799358 -0.67092396 -0.70737688  0.37994021  0.50965034 -0.53541351\n",
      " -0.17394215  0.24488473  0.0042794 ]  energy_before :  40  energy_after :  50  reward :  -208.51090824334386\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "action : 1  next_temperatures :  [ 0.43799358 -0.67092396 -0.70737688  0.37994021  0.50965034 -0.53541351\n",
      " -0.17394215  0.24488473  0.0042794 ]  energy_before :  50  energy_after :  50  reward :  -198.51090824334386\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "action : 1  next_temperatures :  [ 0.43799358 -0.67092396 -0.70737688  0.37994021  0.50965034 -0.53541351\n",
      " -0.17394215  0.24488473  0.0042794 ]  energy_before :  50  energy_after :  50  reward :  -198.51090824334386\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "Episode 499/500, Total Reward: -1012.5545412167194\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "action : 1  next_temperatures :  [1.81406186 1.76675318 1.11667676 2.30227237 2.20950004 1.27746429\n",
      " 1.97503459 1.46804583 2.33001645]  energy_before :  30  energy_after :  50  reward :  -201.7401746276057\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "action : 1  next_temperatures :  [1.81406186 1.76675318 1.11667676 2.30227237 2.20950004 1.27746429\n",
      " 1.97503459 1.46804583 2.33001645]  energy_before :  50  energy_after :  40  reward :  -171.7401746276057\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "action : 1  next_temperatures :  [1.81406186 1.76675318 1.11667676 2.30227237 2.20950004 1.27746429\n",
      " 1.97503459 1.46804583 2.33001645]  energy_before :  40  energy_after :  50  reward :  -191.7401746276057\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "action : 1  next_temperatures :  [1.81406186 1.76675318 1.11667676 2.30227237 2.20950004 1.27746429\n",
      " 1.97503459 1.46804583 2.33001645]  energy_before :  50  energy_after :  50  reward :  -181.7401746276057\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step\n",
      "action : 1  next_temperatures :  [1.81406186 1.76675318 1.11667676 2.30227237 2.20950004 1.27746429\n",
      " 1.97503459 1.46804583 2.33001645]  energy_before :  50  energy_after :  50  reward :  -181.7401746276057\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step\n",
      "Episode 500/500, Total Reward: -928.7008731380286\n"
     ]
    }
   ],
   "source": [
    "# Train the Actor-Critic models\n",
    "\n",
    "def train_function(episodes, gamma):\n",
    "    actor_losses, critic_losses = [], []\n",
    "    \n",
    "    for episode in range(episodes):\n",
    "        state = X_train[np.random.choice(len(X_train))]  # Random initial state from the training set\n",
    "        total_reward = 0\n",
    "        \n",
    "        for step in range(5):  # Arbitrary number of steps per episode\n",
    "            state_input = state.reshape(1, -1)\n",
    "            # Actor predicts the action probabilities\n",
    "            action_probs = actor_model.predict(state_input)\n",
    "            action = np.random.choice(action_space, p=action_probs[0])\n",
    "            \n",
    "            # Simulate the environment and get reward\n",
    "            next_state, reward = simulate_environment(state, action, step)\n",
    "            \n",
    "            total_reward += reward\n",
    "            \n",
    "            # Critic evaluates the value of the next state\n",
    "            next_state_input = next_state.reshape(1, -1)\n",
    "            value_next = critic_model.predict(next_state_input)\n",
    "            \n",
    "            # Compute critic target values with discount factor and rewards and the next values obtained from critic model for next state\n",
    "            target_value = reward + gamma * value_next\n",
    "            \n",
    "            # Update Critic Model (value function) losses\n",
    "            critic_loss = critic_model.train_on_batch(state_input, target_value)\n",
    "            critic_losses.append(critic_loss)\n",
    "            \n",
    "            # Compute the advantage (difference between reward and critic's value)\n",
    "            advantage = target_value - critic_model.predict(state_input)\n",
    "            \n",
    "            # Update Actor Model (policy) losses\n",
    "            actor_loss = actor_model.fit(state_input, tf.keras.utils.to_categorical([action], num_classes=action_space), \n",
    "                                         sample_weight=advantage, verbose=0)\n",
    "            actor_losses.append(actor_loss.history['loss'][0])\n",
    "            \n",
    "            # Update the state for the next step\n",
    "            state = next_state \n",
    "            \n",
    "        # Print the mean reward of all states for each episode\n",
    "        print(f\"Episode {episode+1}/{episodes}, Total Reward: {total_reward}\")\n",
    "    \n",
    "    return actor_losses, critic_losses\n",
    "\n",
    "actor_losses, critic_losses = train_function(episodes=500, gamma=0.99)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae48b2f0",
   "metadata": {
    "id": "ae48b2f0"
   },
   "source": [
    "#### Evaluate the performance of the model on test set (0.5 M)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5a6c0a8b",
   "metadata": {
    "id": "5a6c0a8b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "action : 1  next_temperatures :  [-0.30296627 -1.75154372 -0.23616302 -2.12064782  0.59605521 -0.31110829\n",
      " -0.17394215 -1.68084536 -0.21257254]  energy_before :  30  energy_after :  50  reward :  -224.19373395669498\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step\n",
      "action : 1  next_temperatures :  [ 0.06440038 -0.44223466 -0.38360736  0.05231649  0.11584352 -0.41250654\n",
      "  0.07081602 -0.25958284  0.23920233]  energy_before :  50  energy_after :  40  reward :  -188.95535266049225\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "action : 1  next_temperatures :  [ 0.43799358  0.28404234 -0.06439797  0.82796564  1.11282282  0.0279101\n",
      " -0.36974869 -0.17665666 -0.10956787]  energy_before :  40  energy_after :  50  reward :  -206.02963671689477\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "action : 1  next_temperatures :  [ 1.44046866 -2.51300369  1.84629821 -3.30664568  0.55949931 -1.79520995\n",
      "  0.94705027 -1.80293112  0.78133218]  energy_before :  50  energy_after :  50  reward :  -201.84314180385752\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "action : 1  next_temperatures :  [-1.0190199  -0.50631792 -1.25003283  0.14241301 -0.58204199 -0.62759374\n",
      " -0.47254712 -0.60510857 -0.75470239]  energy_before :  50  energy_after :  50  reward :  -203.674951459202\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "action : 1  next_temperatures :  [ 2.16689988 -0.6432802   2.89968919 -2.14276242  1.93889138 -0.39055887\n",
      "  2.0451986  -0.54444961  2.17279879]  energy_before :  50  energy_after :  60  reward :  -200.49757325843993\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "action : 1  next_temperatures :  [-1.36148033 -0.67092396 -1.39139699 -0.1712867  -0.98581861 -1.04957433\n",
      " -1.07138878 -0.81242401 -1.0799803 ]  energy_before :  60  energy_after :  50  reward :  -196.59427401161793\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "action : 1  next_temperatures :  [ 0.68705571 -0.79657742  0.39161544 -0.71022771  0.50965034 -0.63886021\n",
      "  0.98201572 -0.97597286  0.52833825]  energy_before :  50  energy_after :  100  reward :  -248.0229627392132\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "action : 1  next_temperatures :  [0.9423444  1.68549727 1.39028481 0.91789835 1.16267178 0.80529668\n",
      " 1.43656661 1.16628669 1.36734873]  energy_before :  100  energy_after :  50  reward :  -137.12580467720846\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step\n",
      "action : 1  next_temperatures :  [0.74932124 0.28655541 0.25025128 0.68741507 1.21252075 0.23275505\n",
      " 0.94705027 0.33932843 1.24575675]  energy_before :  50  energy_after :  60  reward :  -202.049045746386\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "action : 1  next_temperatures :  [-0.30296627 -0.45898845 -0.83962076  0.55849514  0.16569248 -0.42479724\n",
      " -0.47254712  0.00416847  0.10728407]  energy_before :  60  energy_after :  70  reward :  -209.6632796905763\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "action : 1  next_temperatures :  [-0.67655947  0.91482271 -0.67697598  1.14739877 -0.43747999  0.79403021\n",
      " -0.36974869  0.66181912 -0.43484578]  energy_before :  70  energy_after :  50  reward :  -177.0775391010291\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "action : 1  next_temperatures :  [-1.49223795  0.28655541 -0.97642479  0.24070013 -1.2799275   0.43657578\n",
      " -0.97838068 -0.15285378 -1.0799803 ]  energy_before :  50  energy_after :  70  reward :  -222.9959736787581\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "action : 1  next_temperatures :  [ 0.0083614   0.03524849  0.77162661 -0.4407572   0.04854742 -0.28422239\n",
      "  0.31557419 -0.06839193  0.43256198]  energy_before :  70  energy_after :  50  reward :  -177.18145144621508\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "action : 1  next_temperatures :  [-1.672808   -1.35699185 -1.57380235 -1.00427    -1.36300911 -1.11102782\n",
      " -1.29982974 -1.20632335 -1.24804056]  energy_before :  50  energy_after :  40  reward :  -199.83610277330456\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "action : 1  next_temperatures :  [ 0.31968906 -0.69354158 -0.83962076  0.45938896  0.50965034 -0.53541351\n",
      " -0.26042337  0.15504804 -0.03788626]  energy_before :  40  energy_after :  40  reward :  -198.92310908243266\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "action : 1  next_temperatures :  [ 0.25742353 -0.55280971  0.41897624 -0.94857397 -0.08355234 -0.00384087\n",
      "  0.31557419 -0.02923235 -0.80891538]  energy_before :  40  energy_after :  40  reward :  -199.43495064392562\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "action : 1  next_temperatures :  [-0.05390414  1.08068528  0.28369227  0.87055673 -0.88113578  2.01183344\n",
      " -0.37138041  1.96713856 -0.23516129]  energy_before :  40  energy_after :  190  reward :  -343.32767534425676\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "action : 1  next_temperatures :  [-1.11864475  0.67189269 -0.49305057  0.18254692 -0.91769169  0.67317169\n",
      " -1.05507157  0.68485417 -0.53182679]  energy_before :  190  energy_after :  70  reward :  -79.90381990270396\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "action : 1  next_temperatures :  [-0.30296627 -1.07050196 -0.33800601 -0.76019033 -0.23808413 -1.06084081\n",
      " -0.32079706 -0.85235143 -0.16378086]  energy_before :  70  energy_after :  30  reward :  -163.10751885823444\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "action : 1  next_temperatures :  [ 0.06440038 -0.04265666 -0.36840691  0.57487632  0.29363816 -0.4852265\n",
      "  0.49016835 -0.20583439  0.12535506]  energy_before :  30  energy_after :  50  reward :  -217.55368618255602\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "action : 1  next_temperatures :  [-0.49598942 -0.69354158 -0.47937017 -0.63733143 -0.14536506 -0.67306932\n",
      " -1.07138878 -0.83545906 -1.24804056]  energy_before :  50  energy_after :  60  reward :  -214.2795553811601\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "action : 1  next_temperatures :  [-0.3652318   0.13493357  0.37641499  0.00317293 -0.18823517 -0.45347553\n",
      " -0.0466679   0.13815567  0.43256198]  energy_before :  60  energy_after :  60  reward :  -197.9683712605129\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "action : 1  next_temperatures :  [-1.49223795  0.11817977 -0.74841808 -0.12787655 -1.51421763  0.8268054\n",
      " -0.99469789  0.23950989 -1.24804056]  energy_before :  60  energy_after :  40  reward :  -182.94099359762305\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "action : 1  next_temperatures :  [ 0.5687512  -1.42484472 -0.15560065 -0.92318313  0.64756581 -0.68904722\n",
      "  0.85404217 -1.41133529  0.64941392]  energy_before :  40  energy_after :  50  reward :  -209.88423792161848\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "action : 1  next_temperatures :  [ 0.14949661 -1.5655766  -0.1404002  -1.95519784  0.63094949 -0.79249392\n",
      "  0.03491815 -1.65934598 -0.80891538]  energy_before :  50  energy_after :  100  reward :  -254.10656567261725\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "action : 1  next_temperatures :  [-2.05262775 -0.37689486 -1.29563417 -0.37359434 -1.87811508 -0.01305889\n",
      " -2.23480595 -0.12137255 -1.83896209]  energy_before :  100  energy_after :  110  reward :  -218.18506568213095\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "action : 1  next_temperatures :  [ 1.64179388 -1.49856142  3.6846837  -3.00277468  1.30723378 -0.77405788\n",
      "  1.43656661 -0.69724877  1.19154376]  energy_before :  110  energy_after :  40  reward :  -124.71082100128984\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "action : 1  next_temperatures :  [-0.42749733  0.997754    0.03896507  0.7403263  -0.93596964  1.32201807\n",
      " -0.33711427  1.49108088 -0.97697563]  energy_before :  40  energy_after :  100  reward :  -256.08741255770553\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "action : 1  next_temperatures :  [-0.30296627 -0.47657994 -0.83962076  0.5109897   0.19892513 -0.36334375\n",
      " -0.47254712 -0.02923235  0.10728407]  energy_before :  100  energy_after :  60  reward :  -159.66709130693286\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n",
      "action : 1  next_temperatures :  [ 2.20633472  0.02687159  2.98633174 -1.52846795  1.98717366 -0.47396003\n",
      "  2.07783302 -0.03767853  2.00473854]  energy_before :  60  energy_after :  120  reward :  -248.7508232416888\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "action : 1  next_temperatures :  [-0.05390414  0.56299302  0.3156132   0.24889072  0.41493731  1.15455732\n",
      " -0.27674059  0.87950033  0.3295573 ]  energy_before :  120  energy_after :  50  reward :  -124.42459550299279\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "action : 1  next_temperatures :  [ 0.37572804  1.36549979  0.6044217   0.56586667 -0.20762088  1.57892778\n",
      "  0.66924975  0.62669067 -0.26678553]  energy_before :  50  energy_after :  70  reward :  -212.6880220114533\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "action : 1  next_temperatures :  [ 0.64969639  1.6586912   0.66066335 -0.01484637 -0.10016866  1.19245364\n",
      " -0.96206346  1.70607467 -1.35104523]  energy_before :  70  energy_after :  50  reward :  -174.56054447619312\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "action : 1  next_temperatures :  [-1.33034757  0.91482271 -0.66177553  0.77882209 -1.1303806   1.70456601\n",
      " -2.08305589  1.69839632 -1.56789717]  energy_before :  50  energy_after :  50  reward :  -199.67684962561742\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "action : 1  next_temperatures :  [0.0083614  1.57575992 0.16360874 1.34643018 0.01116069 1.62467648\n",
      " 0.13608486 2.11993772 0.01331489]  energy_before :  50  energy_after :  100  reward :  -241.0006651276563\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "action : 1  next_temperatures :  [-0.32372145 -0.04265666 -0.10999931  0.07606921 -0.23808413 -0.43503949\n",
      " -0.47254712 -0.02923235 -0.10956787]  energy_before :  100  energy_after :  60  reward :  -159.68477916312023\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "action : 1  next_temperatures :  [ 1.29103138 -2.08494423  1.34468346 -2.79800985  0.55949931 -1.42956172\n",
      "  1.24076008 -1.52651053  0.87168715]  energy_before :  60  energy_after :  100  reward :  -240.53136495344742\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "action : 1  next_temperatures :  [-0.34447662  1.18120805  0.07240605  0.63384859  0.40939853  1.78957667\n",
      " -0.19189109  1.05111145 -0.53785045]  energy_before :  100  energy_after :  40  reward :  -133.93666882288488\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "action : 1  next_temperatures :  [-1.05015267  0.91482271 -0.67697598  0.73213571 -1.23506343  1.60521621\n",
      " -0.33874599  1.1071634  -1.0799803 ]  energy_before :  40  energy_after :  270  reward :  -428.02158033917135\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "action : 1  next_temperatures :  [ 0.48365497  0.20111106  0.5740208  -0.11149537 -0.38264613  0.98043912\n",
      "  0.13608486  0.63648056 -0.05324661]  energy_before :  270  energy_after :  90  reward :  -15.535596730484144\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "action : 1  next_temperatures :  [-0.49598942 -1.18107701 -1.14818984 -0.31789831 -0.58204199 -1.24212859\n",
      " -0.12499052 -1.30460623 -0.53785045]  energy_before :  90  energy_after :  30  reward :  -144.93477235132366\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "action : 1  next_temperatures :  [1.20830717 2.53539334 2.17006773 0.8397835  1.89782533 1.49547785\n",
      " 1.48969353 1.71465635 1.66973418]  energy_before :  30  energy_after :  40  reward :  -192.97906100946932\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "action : 1  next_temperatures :  [-0.3652318  -1.04788434 -0.15560065 -1.26800709 -0.83128681 -0.88467415\n",
      "  0.36452582 -1.29616004 -1.02576732]  energy_before :  40  energy_after :  50  reward :  -214.51008638324143\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "action : 1  next_temperatures :  [-0.55825495 -0.04265666 -0.53561182  0.28001498 -0.83128681 -0.20049202\n",
      " -0.76625693  0.08594289 -0.32099851]  energy_before :  50  energy_after :  120  reward :  -270.88959983845996\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "action : 1  next_temperatures :  [-0.49598942 -0.32579579 -0.47937017 -0.25319263 -0.33279717 -0.46679045\n",
      " -0.52149876 -0.82010236 -0.76825564]  energy_before :  120  energy_after :  60  reward :  -142.46379238127258\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step\n",
      "action : 1  next_temperatures :  [-1.18091029 -0.56788812 -1.4324382   0.14241301 -0.83128681 -0.66139315\n",
      " -1.20682164 -0.44616674 -0.70591071]  energy_before :  60  energy_after :  80  reward :  -224.89040263496145\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "action : 1  next_temperatures :  [ 1.37197657 -0.04265666  2.31325594 -1.50094755  1.05798895 -0.47396003\n",
      "  1.55568226 -0.19047769  0.41087678]  energy_before :  80  energy_after :  50  reward :  -163.49826141767625\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "action : 1  next_temperatures :  [ 0.68705571  0.45995719  0.80202751 -0.00501766  0.11584352  1.24366488\n",
      " -0.8103134   0.31629338 -0.10956787]  energy_before :  50  energy_after :  50  reward :  -195.30005674765553\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "action : 1  next_temperatures :  [-1.42997242 -1.74065375 -0.66177553 -2.22712553 -0.88113578 -1.47770028\n",
      " -0.82663061 -1.53572455 -1.35104523]  energy_before :  50  energy_after :  60  reward :  -220.13176367537793\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "action : 1  next_temperatures :  [-0.42749733 -1.51699059 -0.06439797 -1.62921224 -0.98581861 -1.43877974\n",
      "  0.01696922 -1.68775587 -0.48363747]  energy_before :  60  energy_after :  80  reward :  -226.21712060177435\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "action : 1  next_temperatures :  [-0.01239378  0.42896267 -0.53561182  0.86318519  0.26040552  0.09755738\n",
      "  0.21277576  0.12970949  0.60062223]  energy_before :  80  energy_after :  50  reward :  -165.9547873717045\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "action : 1  next_temperatures :  [-0.05390414 -0.81919504 -0.52041138 -0.32690796 -0.43747999 -0.7627914\n",
      " -0.41870032 -0.83545906 -0.32099851]  energy_before :  50  energy_after :  40  reward :  -192.4958478145071\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "action : 1  next_temperatures :  [ 0.46082427 -0.99762296 -0.06439797 -0.41536637 -0.18823517 -1.02704139\n",
      " -0.22778895 -1.11187965 -0.59206344]  energy_before :  40  energy_after :  80  reward :  -242.16357161468102\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "action : 1  next_temperatures :  [ 0.63101673 -1.07050196 -0.22096257 -0.32690796  0.06100966 -1.24212859\n",
      " -0.07603889 -1.17330645  0.22113133]  energy_before :  80  energy_after :  80  reward :  -201.19668869470047\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "action : 1  next_temperatures :  [-1.02939749  1.53303774 -0.43376883  1.05894036 -0.98581861  1.95037995\n",
      " -0.58187244  1.75905528 -0.65169772]  energy_before :  80  energy_after :  780  reward :  -895.3811417458592\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "action : 1  next_temperatures :  [2.37445166 1.42581345 2.5804798  0.30283163 2.85753659 0.44784225\n",
      " 1.88202648 1.48340253 1.90173387]  energy_before :  780  energy_after :  50  reward :  547.2561182548338\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "action : 1  next_temperatures :  [-0.30296627 -0.49500911 -0.82442032  0.24070013  0.46478627 -0.90720709\n",
      " -0.52149876 -0.23654779 -0.04993359]  energy_before :  50  energy_after :  80  reward :  -230.63209652749742\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "action : 1  next_temperatures :  [-1.672808    1.04047617 -0.93538358  0.95082454 -1.1303806   1.76909217\n",
      " -2.13200752  1.78823301 -1.56789717]  energy_before :  80  energy_after :  100  reward :  -219.88985097523255\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "action : 1  next_temperatures :  [-0.18466176 -0.29396358  0.46457759 -0.23435426 -0.18823517 -0.53541351\n",
      " -0.26042337  0.05369383  0.10728407]  energy_before :  100  energy_after :  100  reward :  -199.07149616725613\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "action : 1  next_temperatures :  [ 0.68705571 -0.09040497 -0.06439797  0.625658    0.50965034  0.10677541\n",
      " -0.47254712  0.47523522  0.37834899]  energy_before :  100  energy_after :  90  reward :  -185.84462639479491\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "action : 1  next_temperatures :  [ 1.68330424  0.78079236  2.1518272  -0.810972    2.44212855 -0.03559183\n",
      "  1.86570927  0.3232039   1.413817  ]  energy_before :  90  energy_after :  60  reward :  -158.18578132550832\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "action : 1  next_temperatures :  [-0.18466176 -0.11804873 -0.30760512  0.10883158 -0.38264613  0.44784225\n",
      " -0.90821667  0.47523522 -0.80891538]  energy_before :  60  energy_after :  100  reward :  -239.6781847307063\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "action : 1  next_temperatures :  [-1.23694927  1.44256725 -0.66177553  1.31940122 -1.18521446  1.83054566\n",
      " -1.1040232   1.90340826 -1.13419329]  energy_before :  100  energy_after :  370  reward :  -466.8262333757002\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "action : 1  next_temperatures :  [-2.05262775 -0.98840837 -1.21963194 -1.07143286 -2.11074358 -0.3817798\n",
      " -1.20682164 -0.90686771 -1.54892262]  energy_before :  370  energy_after :  50  reward :  110.51276373303571\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "action : 1  next_temperatures :  [ 0.43799358  0.90560813 -0.20576213  1.6658633   1.25738481  0.52978023\n",
      "  0.26172739  0.86683105  0.81747417]  energy_before :  50  energy_after :  70  reward :  -211.46309946620752\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "action : 1  next_temperatures :  [-2.05262775  1.44256725 -1.16339028  0.96884384 -1.41618134  1.61545846\n",
      " -1.02570059  1.0918067  -2.27808727]  energy_before :  70  energy_after :  40  reward :  -170.81731097965874\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "action : 1  next_temperatures :  [ 1.68330424  1.08068528  1.30364226  0.8191198   2.22445473 -0.00384087\n",
      "  1.97503459  0.99889867  1.59452695]  energy_before :  40  energy_after :  340  reward :  -486.32417434354954\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "action : 1  next_temperatures :  [-1.76205526 -0.19092774 -1.57380235  0.19892811 -1.18521446 -0.53541351\n",
      " -1.17092377 -0.36784757 -1.0799803 ]  energy_before :  340  energy_after :  320  reward :  -185.66723686607588\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "action : 1  next_temperatures :  [0.70781089 0.31922531 0.5740208  0.20793776 0.61433317 0.05863684\n",
      " 0.9960019  0.0398728  0.87168715]  energy_before :  320  energy_after :  40  reward :  86.38952662366273\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "action : 1  next_temperatures :  [-0.18466176  0.88717895 -0.20576213  1.02453987 -0.13340131  1.39729859\n",
      "  0.08713323  1.15246566 -0.59206344]  energy_before :  40  energy_after :  90  reward :  -244.56727232081073\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "action : 1  next_temperatures :  [ 0.31968906 -1.29919126 -0.35320646 -0.88304922 -0.03370338 -1.09694473\n",
      "  0.01696922 -1.1372182   0.25727332]  energy_before :  90  energy_after :  50  reward :  -162.2093816451938\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "action : 1  next_temperatures :  [2.24369404 2.12863514 1.54923805 2.15659683 2.10980211 1.67691195\n",
      " 2.17084113 1.57815336 2.44386372]  energy_before :  50  energy_after :  40  reward :  -169.94226367676146\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "action : 1  next_temperatures :  [-0.49598942  0.12571898 -1.10106845  1.18917079  0.41493731  0.16822889\n",
      " -0.27674059 -0.16974615  0.3295573 ]  energy_before :  40  energy_after :  90  reward :  -247.81593132895827\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "action : 1  next_temperatures :  [0.25742353 0.51943316 0.3460141  0.56750479 0.79378944 0.00435293\n",
      " 0.11976765 0.57658944 0.49219626]  energy_before :  90  energy_after :  30  reward :  -134.32292870470593\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "action : 1  next_temperatures :  [ 0.31968906 -0.19092774  0.43265665 -0.52348219 -0.43747999  0.97019687\n",
      " -0.07603889  0.54664387 -0.57399244]  energy_before :  30  energy_after :  40  reward :  -207.53273479937272\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "action : 1  next_temperatures :  [-0.30296627 -0.56788812 -1.02202613  0.24070013  0.06100966 -0.41250654\n",
      "  0.26172739 -0.88152916  0.16149705]  energy_before :  40  energy_after :  50  reward :  -210.4619819886992\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "action : 1  next_temperatures :  [ 0.5687512  -0.21605843 -0.33800601  0.88693791  0.52626666  0.07912134\n",
      " -0.52149876  0.40613008  0.27534432]  energy_before :  50  energy_after :  120  reward :  -266.33301169750814\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "action : 1  next_temperatures :  [ 0.37572804  0.3116861  -0.25136347  1.07368343  0.86357799  0.10677541\n",
      "  0.45753393  0.2617771   0.7036269 ]  energy_before :  120  energy_after :  60  reward :  -134.09697456043156\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "action : 1  next_temperatures :  [-0.03314896  0.36027211  0.54361991 -0.29414559 -0.03370338 -0.30189027\n",
      " -0.10867331 -0.28492139  0.22113133]  energy_before :  60  energy_after :  90  reward :  -227.9314595411384\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "action : 1  next_temperatures :  [-1.2992148  -1.03113054 -1.29563417 -0.70285618 -1.19518426 -0.438317\n",
      " -1.50053144 -0.92068874 -0.86312836]  energy_before :  90  energy_after :  50  reward :  -167.2466855046449\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "action : 1  next_temperatures :  [ 0.43799358 -1.2305007  -0.56601272 -0.44976686 -0.48732896 -1.1806751\n",
      "  0.75124373 -1.36756869 -0.3607547 ]  energy_before :  50  energy_after :  170  reward :  -322.453370421851\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "action : 1  next_temperatures :  [ 0.14949661  0.0829968  -0.43376883  0.89430945  0.29363816  0.12930835\n",
      " -0.20984002 -0.09219482  0.22113133]  energy_before :  170  energy_after :  120  reward :  -146.9649229627508\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "action : 1  next_temperatures :  [-1.80356562  1.06560687 -1.02202613  0.87137579 -1.37962543  1.43109801\n",
      " -1.20682164  1.16628669 -0.15835956]  energy_before :  120  energy_after :  50  reward :  -129.03603102048\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "action : 1  next_temperatures :  [ 0.74932124  1.54309002  0.70626469  1.23995247 -0.18823517  2.31910086\n",
      " -0.59818965  2.57372818  0.51327909]  energy_before :  50  energy_after :  60  reward :  -199.14168826997445\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "action : 1  next_temperatures :  [2.12538953 0.86456133 1.44044628 1.05156883 2.25436411 0.3218626\n",
      " 2.27363956 0.80002941 2.11858581]  energy_before :  60  energy_after :  50  reward :  -174.74955254378733\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "action : 1  next_temperatures :  [-0.26560695 -0.10045725 -0.52041138 -0.05416122 -0.33279717 -0.71977397\n",
      " -1.39773301 -0.97597286 -1.19382757]  energy_before :  50  energy_after :  60  reward :  -213.56074136215545\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "action : 1  next_temperatures :  [-0.69731464 -0.79657742 -0.43376883 -0.71759925 -1.18521446 -0.53541351\n",
      " -0.85926503 -0.47457663 -1.0799803 ]  energy_before :  60  energy_after :  40  reward :  -184.77971007921363\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "action : 1  next_temperatures :  [1.93236637 3.10956982 1.66845298 2.71180202 1.91040625 2.01183344\n",
      " 1.68132478 2.67354672 1.84752088]  energy_before :  40  energy_after :  80  reward :  -218.45317671647857\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "action : 1  next_temperatures :  [ 0.06440038 -1.07050196 -0.77881898 -0.51447254  0.16569248 -1.00399633\n",
      " -0.03198241 -1.52651053 -0.53785045]  energy_before :  80  energy_after :  70  reward :  -193.234040349635\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "action : 1  next_temperatures :  [-0.47315873  1.33953141 -0.02335676  0.95082454 -1.047299    1.93194391\n",
      "  0.50648556  1.82892826 -0.32099851]  energy_before :  70  energy_after :  50  reward :  -173.30709931607316\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "action : 1  next_temperatures :  [-0.18466176 -0.11804873 -0.35320646  0.12603183 -0.38264613  0.44784225\n",
      " -0.90821667  0.50057378 -0.80891538]  energy_before :  50  energy_after :  60  reward :  -209.68124727258547\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "action : 1  next_temperatures :  [-0.3652318  -1.10484724 -0.66177553 -0.64634109 -0.53219302 -1.33430881\n",
      " -0.06502477 -1.32668148 -0.59206344]  energy_before :  60  energy_after :  70  reward :  -214.62846719066198\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "action : 1  next_temperatures :  [1.46122384 1.17450653 0.9342714  1.19654233 2.20950004 0.3218626\n",
      " 1.78412322 0.73092426 1.51682167]  energy_before :  70  energy_after :  70  reward :  -186.67022410675804\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "action : 1  next_temperatures :  [ 2.12538953 -0.07448887  1.3915877  -0.87626273  0.74394048 -2.08404133\n",
      "  1.97503459 -1.12723635  2.38887626]  energy_before :  70  energy_after :  70  reward :  -193.5372007262601\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "action : 1  next_temperatures :  [ 1.99463191 -0.35092648  1.65173249 -0.68647499  1.5564786  -0.50775944\n",
      "  1.73027642 -0.35172303  1.68488193]  energy_before :  70  energy_after :  60  reward :  -181.2788826016006\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "action : 1  next_temperatures :  [ 0.9423444  -0.96997919  0.22745061 -0.57262575  0.16569248 -0.90720709\n",
      " -0.47254712 -0.16974615 -0.21257254]  energy_before :  60  energy_after :  60  reward :  -199.96919036250407\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "action : 1  next_temperatures :  [-0.05390414 -1.20453232 -0.38360736 -0.81834354  0.04439334 -1.41829524\n",
      " -0.11030503 -1.14412872 -0.76825564]  energy_before :  60  energy_after :  100  reward :  -243.85697864463629\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "action : 1  next_temperatures :  [-0.91161185  0.05346824 -0.85634126  0.32915853 -0.54880935  0.40482481\n",
      " -1.07138878  0.42916512 -0.92276265]  energy_before :  100  energy_after :  50  reward :  -151.09429717782237\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "action : 1  next_temperatures :  [ 0.79498263 -0.53605591  1.25804092 -1.07143286  0.21554145 -0.30189027\n",
      "  0.56033236 -0.51527188  0.7036269 ]  energy_before :  50  energy_after :  50  reward :  -196.8921266632287\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "action : 1  next_temperatures :  [-0.30296627 -0.9616023  -1.02202613 -0.00501766 -0.03370338 -1.30358207\n",
      " -0.2620551  -0.96387946  0.0042794 ]  energy_before :  50  energy_after :  330  reward :  -482.8505529597973\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "action : 1  next_temperatures :  [-1.92187013 -0.33417268 -1.6604449   0.24070013 -1.1303806  -0.50775944\n",
      " -1.49889972 -0.20583439 -1.0799803 ]  energy_before :  330  energy_after :  60  reward :  63.90135795465696\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "action : 1  next_temperatures :  [ 0.0083614   0.97932482 -0.05071757  1.05894036 -0.23808413  1.0623771\n",
      "  0.36452582  0.86836672 -0.43484578]  energy_before :  60  energy_after :  70  reward :  -204.38175125322817\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "action : 1  next_temperatures :  [-0.24692729 -1.20453232 -0.49305057 -0.77657151  0.11584352 -1.62109174\n",
      "  0.08713323 -1.16639593 -0.59206344]  energy_before :  70  energy_after :  180  reward :  -313.89765606374453\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "action : 1  next_temperatures :  [ 0.195158   -0.14988094  2.31903211 -1.66770803  0.46478627 -0.52619549\n",
      "  0.75124373 -0.16974615  0.3620851 ]  energy_before :  180  energy_after :  50  reward :  -66.42122539218744\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "action : 1  next_temperatures :  [-0.30296627  0.34519369 -1.02202613  1.41338827  0.58691624 -0.059149\n",
      "  0.21277576 -0.19047769  0.43256198]  energy_before :  50  energy_after :  110  reward :  -256.5837831548863\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "action : 1  next_temperatures :  [-0.05390414  0.11817977 -0.05071757  0.58224786  0.06100966 -0.32032631\n",
      "  0.07081602  0.14660186  0.16149705]  energy_before :  110  energy_after :  60  reward :  -147.2845958038396\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "action : 1  next_temperatures :  [ 0.12666591 -1.02945517 -0.47937017 -0.47188146 -0.22146781 -1.11102782\n",
      " -0.10867331 -0.97597286 -0.59206344]  energy_before :  60  energy_after :  30  reward :  -172.86324612006726\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "action : 1  next_temperatures :  [-1.2992148  -0.57626502 -1.46283909  0.04166872 -0.88113578 -0.85292318\n",
      " -1.02570059 -0.88152916 -1.02576732]  energy_before :  30  energy_after :  470  reward :  -645.9637062143765\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "action : 1  next_temperatures :  [-0.30296627  1.76675318 -0.02335676  1.71500686 -0.33279717  2.31910086\n",
      " -1.04038608  2.34337769 -0.10956787]  energy_before :  470  energy_after :  80  reward :  198.33516443955628\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "action : 1  next_temperatures :  [ 2.15652229 -1.03406246  2.6108807  -2.21893493  1.97820085 -0.56614025\n",
      "  2.02888139 -0.79860298  2.5143406 ]  energy_before :  80  energy_after :  120  reward :  -231.32891481182668\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "action : 1  next_temperatures :  [ 0.5687512  -0.62820178  1.30364226 -1.44738108  2.1762674  -0.03354338\n",
      "  1.21278771 -0.96873327  0.54640924]  energy_before :  120  energy_after :  100  reward :  -175.27000170546867\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "action : 1  next_temperatures :  [-0.42749733  0.19357185 -0.96274438  1.15640842  0.41493731  0.20202831\n",
      " -0.22778895 -0.12137255  0.37834899]  energy_before :  100  energy_after :  60  reward :  -157.39410833817047\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "action : 1  next_temperatures :  [ 0.46082427  0.03357311  0.25025128 -0.26711663 -0.63189095  0.37614652\n",
      "  0.15240207 -0.31563479  0.60062223]  energy_before :  60  energy_after :  170  reward :  -307.3408228953524\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "action : 1  next_temperatures :  [-1.61054246  0.18603264 -1.16339028  0.25626226 -1.48430825  0.31264458\n",
      " -1.20682164 -0.19892388 -1.24804056]  energy_before :  170  energy_after :  60  reward :  -94.15708759247963\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "action : 1  next_temperatures :  [ 0.0083614   0.47838636  0.26279165  0.19708522 -0.73657378  1.62467648\n",
      " -1.0110151   0.85992054 -0.59206344]  energy_before :  60  energy_after :  50  reward :  -186.90843066422855\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "action : 1  next_temperatures :  [1.99463191 1.88486743 1.25804092 2.1464873  2.15965108 1.6976525\n",
      " 2.17084113 1.31568544 2.34989454]  energy_before :  50  energy_after :  130  reward :  -261.022247775314\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "action : 1  next_temperatures :  [ 0.0083614  -1.24892988 -0.93538358 -0.32690796  0.50965034 -1.275928\n",
      "  0.38550509 -1.51663837  0.60062223]  energy_before :  130  energy_after :  60  reward :  -131.79964872595784\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "action : 1  next_temperatures :  [-0.01239378 -0.77814824 -0.40032785 -0.34902256 -0.43747999 -1.07927685\n",
      " -0.12499052 -1.18943098 -0.59206344]  energy_before :  60  energy_after :  50  reward :  -192.96313421687103\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "action : 1  next_temperatures :  [-0.05390414 -0.39197328 -0.66177553  0.33653007  0.11584352 -0.06529435\n",
      "  0.07081602 -0.42082818 -0.04993359]  energy_before :  50  energy_after :  50  reward :  -199.12051946577978\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "action : 1  next_temperatures :  [ 0.11109953 -0.12370314  0.28369227 -0.47188146 -0.43747999  1.00783713\n",
      " -0.20984002  0.61574902 -0.61194153]  energy_before :  50  energy_after :  290  reward :  -437.83646819544947\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "action : 1  next_temperatures :  [ 1.99463191 -0.09040497  3.3557026  -1.84790107  1.9901646  -0.50775944\n",
      "  2.01093245 -0.11522987  1.91980486]  energy_before :  290  energy_after :  90  reward :  10.709941065435999\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "action : 1  next_temperatures :  [ 0.25742353  0.44487877  0.07240605  0.30540581 -0.43747999  0.60147596\n",
      " -0.56555523  1.02961207 -0.72488525]  energy_before :  90  energy_after :  50  reward :  -157.01671827626603\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "action : 1  next_temperatures :  [ 0.195158   -0.00914907 -0.38360736  0.82059411  0.31025448 -0.10523912\n",
      "  0.11976765 -0.0699276   0.43256198]  energy_before :  50  energy_after :  70  reward :  -216.6895869245923\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "action : 1  next_temperatures :  [-0.3652318  -0.04265666 -0.58121317  0.16452762 -0.63189095  0.38638876\n",
      " -0.22778895 -0.11446203 -0.3806328 ]  energy_before :  70  energy_after :  190  reward :  -319.79295997950004\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "action : 1  next_temperatures :  [-0.18466176 -0.08286576  1.74445522 -1.62675506 -0.10016866 -0.55692223\n",
      "  0.80509053 -0.65716778  0.05849238]  energy_before :  190  energy_after :  460  reward :  -468.6005031269551\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "action : 1  next_temperatures :  [ 0.02704106  0.51021857  0.20464994  0.45938896 -0.43747999  1.3358451\n",
      "  0.21277576  0.6986752  -0.10956787]  energy_before :  460  energy_after :  70  reward :  194.90154672398424\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "action : 1  next_temperatures :  [2.06312399 1.93680419 1.34468346 2.13026992 2.10980211 1.78568461\n",
      " 2.21979276 1.42197573 2.38965073]  energy_before :  70  energy_after :  120  reward :  -230.59821247893538\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "action : 1  next_temperatures :  [ 0.52724084  0.34519369  0.5740208  -0.11231443  0.21554145  0.08833936\n",
      "  0.01696922 -0.74562237  0.32181259]  energy_before :  120  energy_after :  70  reward :  -146.7688188402096\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "action : 1  next_temperatures :  [-0.38598698  1.29178309  0.02224458  1.18179926 -0.33279717  1.00092361\n",
      "  0.45753393  1.32062152 -0.32099851]  energy_before :  70  energy_after :  210  reward :  -333.76487666944263\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "action : 1  next_temperatures :  [-0.738825    0.93995341 -0.29240467  0.82796564 -0.88113578  1.5509323\n",
      " -0.71730529  1.53715098 -1.07395664]  energy_before :  210  energy_after :  50  reward :  -36.847625056208756\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "action : 1  next_temperatures :  [ 0.50648566  0.17765574  0.47825799 -0.25073545  0.21554145 -0.00384087\n",
      " -0.0156652  -0.7594434   0.31406788]  energy_before :  50  energy_after :  290  reward :  -437.3376761935507\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "action : 1  next_temperatures :  [2.26444922 1.86057443 3.00514229 0.13412004 1.87052708 1.67691195\n",
      " 2.56734936 1.16628669 2.33001645]  energy_before :  290  energy_after :  50  reward :  58.875377497286166\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "action : 1  next_temperatures :  [ 0.50648566  1.9116735   0.40529584  1.28663885  1.37868396  0.16822889\n",
      "  0.52956276 -0.100641    0.7036269 ]  energy_before :  50  energy_after :  470  reward :  -611.2104446331807\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "action : 1  next_temperatures :  [-1.54827693 -0.84432573 -1.57380235 -0.22616367 -1.2799275  -0.20049202\n",
      " -1.1040232  -0.60510857 -1.24804056]  energy_before :  470  energy_after :  70  reward :  193.36983946501726\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "action : 1  next_temperatures :  [-0.47315873 -0.6432802  -1.03722657  0.1809088  -0.18823517 -0.89594062\n",
      "  0.16871929 -0.92759926  0.18137515]  energy_before :  70  energy_after :  130  reward :  -261.6344373117743\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "action : 1  next_temperatures :  [-0.738825   -1.02024058 -1.61940369  0.28001498 -0.93596964 -0.64449345\n",
      " -0.47254712 -1.15794975 -0.97697563]  energy_before :  130  energy_after :  70  reward :  -145.2863898844565\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "action : 1  next_temperatures :  [-0.30296627 -1.2305007   0.10280695 -1.59399269 -0.98581861 -0.96866058\n",
      "  0.07081602 -1.1656281  -0.86312836]  energy_before :  70  energy_after :  400  reward :  -534.9370723407206\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "action : 1  next_temperatures :  [ 0.25742353  0.36194749  0.46305754  0.23087142  0.55949931 -0.35412573\n",
      "  0.43865258  0.29819442  0.63721599]  energy_before :  400  energy_after :  50  reward :  154.8927365456364\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "action : 1  next_temperatures :  [-0.738825   -0.52684132 -0.88978224 -0.2597451  -0.58204199  0.2511911\n",
      " -1.0110151   0.01453424 -0.3806328 ]  energy_before :  50  energy_after :  100  reward :  -252.12315820955135\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "action : 1  next_temperatures :  [-0.11616967  1.41743656  0.28369227  0.8549946   0.16569248  1.79674624\n",
      " -0.56555523  1.85733816 -0.48363747]  energy_before :  100  energy_after :  60  reward :  -152.7894620609434\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "action : 1  next_temperatures :  [-1.18091029  1.44256725 -0.52041138  1.1326557  -1.23506343  1.71583249\n",
      " -0.96206346  1.80512538 -1.0799803 ]  energy_before :  60  energy_after :  40  reward :  -176.8822480462776\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "action : 1  next_temperatures :  [-0.13900036 -0.21605843 -1.11778894  1.07368343  0.61433317 -0.32032631\n",
      "  0.07081602 -0.30565294  0.49219626]  energy_before :  40  energy_after :  50  reward :  -207.8477981133326\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "action : 1  next_temperatures :  [-0.86958262 -0.33333499 -0.87306175 -0.02303696 -0.48732896 -0.13903853\n",
      " -0.27674059 -0.63044713 -0.43484578]  energy_before :  50  energy_after :  60  reward :  -212.06741730971478\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "action : 1  next_temperatures :  [-1.05015267 -1.14589404 -1.20443149 -0.72578984 -0.81467049 -1.11102782\n",
      " -0.45459819 -1.28848169 -0.86312836]  energy_before :  60  energy_after :  50  reward :  -196.65817459057166\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "action : 1  next_temperatures :  [ 0.14949661 -1.12327642 -0.61161406 -0.50546289  0.46478627 -0.62759374\n",
      "  0.56033236 -1.27312499  0.54640924]  energy_before :  50  energy_after :  50  reward :  -200.4200476110681\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "action : 1  next_temperatures :  [-0.24692729 -0.34171189 -0.66177553  0.45938896 -0.08355234 -0.59993967\n",
      " -0.32079706 -0.21581625 -0.10956787]  energy_before :  50  energy_after :  80  reward :  -230.12069893995803\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "action : 1  next_temperatures :  [ 0.29893389  1.16612963 -0.36840691  2.11552686  0.96327592  0.26040912\n",
      "  0.22909297  1.09027103  0.7036269 ]  energy_before :  80  energy_after :  50  reward :  -161.5411405966724\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "action : 1  next_temperatures :  [-0.88826228 -0.21605843 -0.52041138 -0.61931213 -0.48732896  0.07912134\n",
      " -0.8103134  -0.52909291 -1.0799803 ]  energy_before :  50  energy_after :  50  reward :  -203.07163845008995\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "action : 1  next_temperatures :  [1.30971104 1.52466084 1.42372579 0.06869768 1.27400114 1.3563296\n",
      " 0.19809027 0.99198815 0.44310339]  energy_before :  50  energy_after :  60  reward :  -199.4096921076454\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "action : 1  next_temperatures :  [-0.10060329 -0.19721041 -0.74841808  0.79520327 -0.03370338 -0.42377301\n",
      " -0.19189109 -0.49837951  0.17640562]  energy_before :  60  energy_after :  50  reward :  -189.2223698742049\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "action : 1  next_temperatures :  [ 0.46082427  0.22540406  0.20921008  0.64941072  0.39001283 -0.04685831\n",
      " -0.47132333  0.25755401  0.22113133]  energy_before :  50  energy_after :  130  reward :  -276.1046343420743\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "action : 1  next_temperatures :  [ 0.0083614  -0.01501289 -0.70737688  1.00242527  0.13245984 -0.2701393\n",
      " -0.17394215  0.23797422  0.65302811]  energy_before :  130  energy_after :  70  reward :  -137.1322223810468\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "action : 1  next_temperatures :  [-0.42749733  0.94749261 -0.06439797  0.80585104 -0.2829482   1.52327823\n",
      " -0.52149876  1.1225201  -0.34418962]  energy_before :  70  energy_after :  50  reward :  -175.24138989940795\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "action : 1  next_temperatures :  [-0.18466176 -0.44259367 -0.47937017 -0.25073545 -0.23808413 -0.66139315\n",
      " -0.96206346 -0.77585587 -0.80891538]  energy_before :  50  energy_after :  150  reward :  -302.8036730465536\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "action : 1  next_temperatures :  [0.74932124 0.78916925 0.71629699 0.83435431 1.05798895 0.0483946\n",
      " 1.19180844 0.75165581 1.19154376]  energy_before :  150  energy_after :  90  reward :  -130.66946664688032\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "action : 1  next_temperatures :  [-0.80731709 -0.25878061 -0.56601272 -0.33264138  0.37505814  0.89030734\n",
      " -1.05507157 -0.67651722 -1.24804056]  energy_before :  90  energy_after :  230  reward :  -341.67901566562495\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "action : 1  next_temperatures :  [-0.42749733 -0.19092774 -0.1404002   0.04166872 -0.22146781 -0.55589801\n",
      " -0.47254712 -0.18356718 -0.10956787]  energy_before :  230  energy_after :  50  reward :  -20.26020454589232\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "action : 1  next_temperatures :  [ 0.5687512   0.72885559  0.30041276  0.49297039  0.31025448  0.11804188\n",
      "  0.26172739 -0.12137255  0.3295573 ]  energy_before :  50  energy_after :  70  reward :  -215.01080155181197\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "action : 1  next_temperatures :  [ 0.43799358 -0.19092774  0.61962214 -0.48826264  0.19892513 -0.23838833\n",
      "  0.36452582 -0.23654779  0.37834899]  energy_before :  70  energy_after :  390  reward :  -517.1547108446505\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "action : 1  next_temperatures :  [ 0.195158    0.43733956  0.17728914  0.46839861  0.41493731 -0.02432536\n",
      "  0.26172739  0.31629338  0.54640924]  energy_before :  390  energy_after :  20  reward :  174.79322727716217\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "action : 1  next_temperatures :  [ 1.45340695 -0.13808801  1.21477887 -0.31487736  1.32477803 -0.36721452\n",
      "  1.44673838  0.02252172  0.94582517]  energy_before :  20  energy_after :  580  reward :  -752.4121307835056\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "action : 1  next_temperatures :  [-0.55825495 -0.9448485  -0.97642479 -0.13463379 -0.10016866 -1.53095997\n",
      "  0.01696922 -0.91213287  0.16149705]  energy_before :  580  energy_after :  60  reward :  317.02104273915575\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "action : 1  next_temperatures :  [-0.98788713 -0.27720978 -0.96274438 -0.08692359 -0.78143785 -0.51697747\n",
      " -0.48886433 -0.75253289 -0.65169772]  energy_before :  60  energy_after :  40  reward :  -183.50627514454993\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "action : 1  next_temperatures :  [ 2.30595957e+00 -7.72168941e-04  2.62608114e+00 -1.21722542e+00\n",
      "  2.09413530e+00 -4.46305958e-01  2.37154283e+00 -7.53024476e-02\n",
      "  2.11858581e+00]  energy_before :  40  energy_after :  80  reward :  -228.22330134637818\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "action : 1  next_temperatures :  [-0.55825495  0.31042957 -1.10106845  1.33660147  0.24545083 -0.14825656\n",
      " -0.36974869 -0.16974615  0.3295573 ]  energy_before :  80  energy_after :  70  reward :  -188.12503563499754\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "action : 1  next_temperatures :  [ 1.56499973 -0.51762674  1.89645969 -1.38349445  1.41191661 -0.37387864\n",
      "  1.63726831  0.02298043  0.43256198]  energy_before :  70  energy_after :  40  reward :  -163.30881308695083\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "action : 1  next_temperatures :  [-0.05390414 -0.18422622 -0.00815632 -0.30888866 -0.26051617 -0.47396003\n",
      "  0.01696922 -0.52064673 -0.94599678]  energy_before :  40  energy_after :  240  reward :  -400.73932581153764\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "action : 1  next_temperatures :  [-0.20541693 -1.02024058 -0.79401942 -0.34902256 -0.08355234 -0.87340768\n",
      " -0.27674059 -0.97597286 -0.63181963]  energy_before :  240  energy_after :  40  reward :  -3.2101925897326\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "action : 1  next_temperatures :  [-1.05015267 -0.24370219 -0.79401942 -0.69548464 -1.01572798 -0.61837572\n",
      " -0.94411453 -1.28848169 -1.02576732]  energy_before :  40  energy_after :  190  reward :  -355.6758261670434\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "action : 1  next_temperatures :  [-0.42749733 -1.31426968 -0.43376883 -1.28275016 -0.54880935 -1.58319543\n",
      " -0.25226477 -1.26275922 -0.32099851]  energy_before :  190  energy_after :  60  reward :  -75.42631327654749\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "action : 1  next_temperatures :  [-0.30296627  0.28655541 -0.83962076  1.05894036  0.41493731  0.11804188\n",
      "  0.01696922  0.08594289  0.43256198]  energy_before :  60  energy_after :  190  reward :  -326.72863797975856\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "action : 1  next_temperatures :  [-0.42749733 -0.8795087   0.20464994 -1.22541601 -0.23808413 -1.25339506\n",
      "  0.01696922 -0.97597286 -0.10956787]  energy_before :  190  energy_after :  120  reward :  -132.88782280834275\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "action : 1  next_temperatures :  [ 0.81781333 -1.04788434  0.16360874 -0.59474035  0.80874413 -0.61837572\n",
      "  0.85404217 -1.06580955 -0.03186259]  energy_before :  120  energy_after :  60  reward :  -138.71446419296376\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "action : 1  next_temperatures :  [-0.0850369   0.29912076 -0.61161406  1.23995247 -0.68672482 -0.10523912\n",
      " -0.03198241 -0.42082818 -0.3806328 ]  energy_before :  60  energy_after :  120  reward :  -258.7829850622153\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "action : 1  next_temperatures :  [-1.54827693  1.11586825 -0.77881898  0.61746741 -1.43445929  1.3563296\n",
      " -0.61450686  1.05341495 -1.02576732]  energy_before :  120  energy_after :  30  reward :  -109.25874917232596\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "action : 1  next_temperatures :  [-0.61429393 -0.40286324 -0.43376883 -0.59474035 -0.16995721 -0.33364124\n",
      " -0.8103134  -0.58207352 -1.0799803 ]  energy_before :  30  energy_after :  70  reward :  -243.02163203190338\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "action : 1  next_temperatures :  [ 1.87632739  0.11817977  1.30364226 -0.19503942  1.50662964 -0.17795907\n",
      "  1.68132478  0.27559813  2.20532658]  energy_before :  70  energy_after :  100  reward :  -219.4059699300906\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "action : 1  next_temperatures :  [ 0.4172384  -0.77898593  0.00704413 -0.76838092 -0.70334114 -0.90413442\n",
      "  0.04389262 -0.73410485 -0.57399244]  energy_before :  100  energy_after :  70  reward :  -171.99476455526917\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "action : 1  next_temperatures :  [-0.11616967 -1.20453232 -0.33800601 -0.84045814 -0.93596964 -1.14994836\n",
      " -0.41870032 -1.28848169 -0.97697563]  energy_before :  70  energy_after :  50  reward :  -185.26924179055175\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "action : 1  next_temperatures :  [ 0.10591073  0.24467092 -0.25136347  0.82223223 -0.08355234  0.10677541\n",
      "  0.22909297  0.31398988  0.05849238]  energy_before :  50  energy_after :  40  reward :  -186.453751288325\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "action : 1  next_temperatures :  [-1.18091029 -0.18422622 -0.72105728 -0.33264138 -0.98581861 -0.59993967\n",
      " -0.27674059 -0.63582197 -0.79342595]  energy_before :  40  energy_after :  50  reward :  -213.7105819479942\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "action : 1  next_temperatures :  [-1.11864475 -1.11238645 -1.00682568 -0.8814111  -0.98581861 -1.34557529\n",
      " -0.71730529 -1.38830024 -1.02576732]  energy_before :  50  energy_after :  40  reward :  -197.5820347268541\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "action : 1  next_temperatures :  [ 0.74932124 -2.32075389  0.98443287 -2.8332294   0.06100966 -1.14994836\n",
      "  0.94705027 -1.86835066  0.18137515]  energy_before :  40  energy_after :  40  reward :  -203.24909312714612\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "action : 1  next_temperatures :  [ 1.21216171 -1.07301503  0.5740208  -1.2336066   0.26040552 -1.275928\n",
      "  0.36452582 -0.58437703  0.27534432]  energy_before :  40  energy_after :  40  reward :  -199.4804684974256\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "action : 1  next_temperatures :  [-1.23694927 -0.89458712 -1.11778894 -0.61112154 -0.73657378 -0.91510826\n",
      " -1.34878137 -0.52909291 -1.35104523]  energy_before :  40  energy_after :  60  reward :  -226.74104841531818\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "action : 1  next_temperatures :  [0.74932124 1.39900738 0.39161544 1.7887222  1.36206764 0.91796141\n",
      " 1.09880034 1.13019845 1.57645596]  energy_before :  60  energy_after :  280  reward :  -407.5858499534289\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "action : 1  next_temperatures :  [ 0.99838337 -1.53374439  0.8324284  -2.03792283  0.55949931 -1.06084081\n",
      "  0.96336748 -1.23550108  1.26563484]  energy_before :  280  energy_after :  20  reward :  60.751304307339126\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "action : 1  next_temperatures :  [ 0.96102406  0.33430373  2.12446639 -1.02966084  1.05798895 -0.1666926\n",
      "  1.29460687  0.20111814  0.92047884]  energy_before :  20  energy_after :  60  reward :  -232.30236645639982\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "action : 1  next_temperatures :  [-4.27497334e-01 -4.10402450e-01 -7.34737680e-01 -1.69648577e-01\n",
      " -6.50168908e-01  2.12270555e-01  6.52008481e-04 -2.59582839e-01\n",
      " -4.83637469e-01]  energy_before :  60  energy_after :  360  reward :  -500.92275269443917\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "action : 1  next_temperatures :  [-1.42997242 -0.05019586 -1.16339028 -0.11149537 -1.1303806   0.06785487\n",
      " -1.25577327 -0.26802902 -0.97697563]  energy_before :  360  energy_after :  60  reward :  95.68164240397485\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "action : 1  next_temperatures :  [ 0.46082427  0.57890913  0.92059099 -0.01484637  1.69439407  1.11153988\n",
      "  0.41347746  0.86145621  0.60062223]  energy_before :  60  energy_after :  40  reward :  -171.3730321231015\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "action : 1  next_temperatures :  [-0.30296627 -1.90902939 -0.33800601 -1.90605428 -0.98581861 -1.43877974\n",
      " -0.61450686 -1.66587258 -1.19382757]  energy_before :  40  energy_after :  30  reward :  -198.35486130616476\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "action : 1  next_temperatures :  [-0.18466176 -0.58045347 -0.62833455  0.02692565  0.16569248 -0.86316543\n",
      " -0.76625693 -0.10601585 -0.26678553]  energy_before :  30  energy_after :  100  reward :  -271.2030553695556\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "action : 1  next_temperatures :  [ 0.27817871 -1.10484724 -0.32280557 -0.59474035 -0.16995721 -1.1806751\n",
      " -0.0156652  -0.97597286 -0.55592145]  energy_before :  100  energy_after :  240  reward :  -342.6424062803678\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "action : 1  next_temperatures :  [-0.45032803  1.30015999 -0.00815632  1.24814306 -0.38264613  0.97019687\n",
      "  0.56033236  1.30680049 -0.26678553]  energy_before :  240  energy_after :  50  reward :  -3.7222832340031573\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "action : 1  next_temperatures :  [-0.94637678 -0.56034891  0.11800739 -1.18692022 -1.08053164 -0.66139315\n",
      "  0.56033236 -0.79169247 -0.97697563]  energy_before :  50  energy_after :  120  reward :  -273.5258990516743\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "action : 1  next_temperatures :  [-0.3652318  -0.47741763 -1.11778894  0.52573276 -0.01874869 -0.65934471\n",
      "  0.21277576 -0.89673229  0.16149705]  energy_before :  120  energy_after :  50  reward :  -130.63525848629033\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "action : 1  next_temperatures :  [ 0.31968906  1.12340746 -0.10999931  1.86980907  1.36206764  0.14979285\n",
      "  0.21277576  0.89216961  0.76326118]  energy_before :  50  energy_after :  70  reward :  -211.41702668811334\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "action : 1  next_temperatures :  [-0.88826228  0.25053475 -0.59641361 -0.05416122 -0.09651307  0.25549284\n",
      " -1.05507157 -0.72028382 -1.21706171]  energy_before :  70  energy_after :  30  reward :  -162.12173968387148\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "action : 1  next_temperatures :  [ 2.12538953  2.04319079  3.81171601 -0.53085373  2.65814073  1.45304568\n",
      "  2.46455093  1.31272379  2.44386372]  energy_before :  30  energy_after :  250  reward :  -400.2182325668159\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "action : 1  next_temperatures :  [-0.3652318  -1.02191596 -0.38360736 -1.3744848  -0.93596964 -1.08849487\n",
      "  0.19809027 -1.25853613 -0.97697563]  energy_before :  250  energy_after :  100  reward :  -55.20712592200837\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "action : 1  next_temperatures :  [-0.3652318  -0.5452705  -1.06762747  0.46839861 -0.23808413 -0.86316543\n",
      " -0.27674059 -0.74562237 -0.26678553]  energy_before :  100  energy_after :  230  reward :  -331.9001292028619\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "action : 1  next_temperatures :  [ 0.43799358  0.18603264  0.55882036 -0.09593324 -0.38264613  1.00092361\n",
      "  0.10345044  0.61574902 -0.08968978]  energy_before :  230  energy_after :  60  reward :  -25.665299502154937\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "action : 1  next_temperatures :  [ 0.5687512   0.01849469  0.3460141  -0.08856171  0.09756556 -0.32032631\n",
      "  0.16871929 -0.67574939  0.10909117]  energy_before :  60  energy_after :  90  reward :  -227.77600140366076\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "action : 1  next_temperatures :  [-0.11616967 -0.77999116 -0.58881339 -0.30069806 -0.43747999 -0.68904722\n",
      " -0.56555523 -0.79169247 -0.42129254]  energy_before :  90  energy_after :  60  reward :  -172.69073973177316\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "action : 1  next_temperatures :  [-0.24692729 -0.81919504 -0.02335676 -1.10255711 -0.78143785 -0.59993967\n",
      " -0.10867331 -0.91224256 -0.80891538]  energy_before :  60  energy_after :  60  reward :  -203.4032449701678\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "action : 1  next_temperatures :  [ 1.56499973  0.36194749  2.30231162 -1.01491777  1.9436389  -0.62759374\n",
      "  1.78412322  0.21647484  1.24575675]  energy_before :  60  energy_after :  50  reward :  -180.2232589697917\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "action : 1  next_temperatures :  [-1.36148033  0.71126411 -0.70737688  0.59985763 -1.23506343  1.64311253\n",
      " -0.85926503  1.0303799  -1.24804056]  energy_before :  50  energy_after :  390  reward :  -539.426612058747\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "action : 1  next_temperatures :  [-0.11616967  0.33430373 -0.79401942  1.4848512  -0.73657378 -0.15747458\n",
      "  0.11976765 -0.40009664 -0.43484578]  energy_before :  390  energy_after :  50  reward :  141.29974270385756\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "action : 1  next_temperatures :  [-0.49598942  0.3116861  -1.08434796  1.26288613  0.21554145 -0.14825656\n",
      " -0.17394215 -0.06148142  0.31148631]  energy_before :  50  energy_after :  50  reward :  -197.86241751914665\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "action : 1  next_temperatures :  [-0.18466176 -0.2998274  -0.85634126  0.78127926  0.36508834 -0.66139315\n",
      " -0.36974869  0.21647484 -0.10956787]  energy_before :  50  energy_after :  120  reward :  -269.1186976885459\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "action : 1  next_temperatures :  [ 0.195158   -0.51008753  0.30041276 -0.94775491 -0.18823517 -0.01305889\n",
      "  0.26172739 -0.14440759 -0.80891538]  energy_before :  120  energy_after :  20  reward :  -99.8551613188207\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "action : 1  next_temperatures :  [ 1.75179633 -1.93499777  0.75642617 -1.64641249  0.86357799 -1.64157624\n",
      "  1.63726831 -1.75916452  2.38965073]  energy_before :  20  energy_after :  60  reward :  -237.5834314914179\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "action : 1  next_temperatures :  [-0.24692729  0.30330921 -0.87306175  1.37755443  0.31025448 -0.22814609\n",
      "  0.41347746 -0.03767853  0.43256198]  energy_before :  60  energy_after :  40  reward :  -176.5486561061339\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "action : 1  next_temperatures :  [1.87632739 1.76675318 1.34468346 1.94270534 2.10980211 0.80690618\n",
      " 2.07783302 1.55788252 2.24327567]  energy_before :  40  energy_after :  340  reward :  -482.2738311161903\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "action : 1  next_temperatures :  [-1.61054246 -0.36935565 -0.93538358 -0.52348219 -1.73355308  0.20202831\n",
      " -1.45157981 -0.21581625 -1.71939234]  energy_before :  340  energy_after :  50  reward :  83.64292294523412\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "action : 1  next_temperatures :  [-0.49598942 -0.6181495  -0.29240467 -0.73398043 -0.73657378 -0.85292318\n",
      " -0.71730529 -1.0120611  -0.49912689]  energy_before :  50  energy_after :  60  reward :  -213.95851428479713\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "action : 1  next_temperatures :  [-0.47315873 -0.67846317 -0.27872427 -0.7749334  -0.73657378 -0.87340768\n",
      " -0.61613858 -0.89074318 -0.46412079]  energy_before :  60  energy_after :  50  reward :  -193.78626357386756\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "action : 1  next_temperatures :  [ 0.37572804  1.44256725  0.47825799  1.24814306  0.46478627  2.04563285\n",
      " -0.17394215  2.29730759  0.16149705]  energy_before :  50  energy_after :  100  reward :  -239.6600220425987\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "action : 1  next_temperatures :  [-0.20541693 -0.21605843 -1.16339028  1.05156883  0.55949931 -0.3817798\n",
      "  0.01696922 -0.30565294  0.49219626]  energy_before :  100  energy_after :  20  reward :  -118.1520647677905\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "action : 1  next_temperatures :  [-0.90694194 -0.59301881 -0.83962076 -0.4006233  -0.68672482  0.01459518\n",
      " -0.8103134  -0.51527188 -0.92276265]  energy_before :  20  energy_after :  220  reward :  -403.6606823791454\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "action : 1  next_temperatures :  [-1.672808    1.71649179 -0.93538358  1.59214797 -1.2799275   1.85819973\n",
      " -1.39773301  2.07386762 -1.24804056]  energy_before :  220  energy_after :  80  reward :  -57.29318554077315\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "action : 1  next_temperatures :  [ 2.24369404  0.02687159  2.97113129 -1.52109641  2.00511929 -0.47396003\n",
      "  2.07783302 -0.0545709   2.02280953]  energy_before :  80  energy_after :  70  reward :  -178.70216858199575\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "action : 1  next_temperatures :  [-0.49598942  0.16090195 -0.77881898  0.87137579  0.01116069 -0.32237476\n",
      " -0.32079706 -0.16974615  0.27534432]  energy_before :  70  energy_after :  80  reward :  -208.76894361639216\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "action : 1  next_temperatures :  [-0.42749733 -0.71867227 -0.56601272 -0.64634109 -0.71995746 -0.15747458\n",
      " -0.56555523 -0.60510857 -0.77277339]  energy_before :  80  energy_after :  20  reward :  -143.17939263983612\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "action : 1  next_temperatures :  [2.32879027 2.68988726 2.3524731  1.73957864 2.00511929 2.19882761\n",
      " 2.46455093 1.90939737 2.36977264]  energy_before :  20  energy_after :  50  reward :  -207.9416028952307\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "action : 1  next_temperatures :  [ 0.02704106 -1.95175157 -0.27872427 -2.25743072  0.01282232 -0.90720709\n",
      "  0.05286708 -1.65166763 -0.80891538]  energy_before :  50  energy_after :  40  reward :  -195.76296619097258\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "action : 1  next_temperatures :  [ 0.195158   -1.19615542 -0.47937017 -0.73398043  0.06100966 -1.61853118\n",
      "  0.26172739 -1.56843432  0.51930275]  energy_before :  40  energy_after :  60  reward :  -222.5592737297486\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "action : 1  next_temperatures :  [ 1.44046866  0.11064057  0.95099189  0.32014888  1.36206764 -0.07451237\n",
      "  1.24076008  0.52130532  2.11858581]  energy_before :  60  energy_after :  90  reward :  -220.00954353683431\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "action : 1  next_temperatures :  [-2.02979705  0.77074008 -1.16339028  0.44464589 -1.48430825  0.97019687\n",
      " -1.12034042  0.54664387 -1.26430445]  energy_before :  90  energy_after :  290  reward :  -402.32991374481264\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "action : 1  next_temperatures :  [-0.9256216  -1.07050196 -0.88978224 -0.81834354 -1.03068267 -0.37071817\n",
      " -1.29982974 -0.58207352 -1.37273042]  energy_before :  290  energy_after :  40  reward :  43.639716129113424\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "action : 1  next_temperatures :  [-0.9256216   0.59650061 -0.52041138  0.41925506 -0.70334114  1.5509323\n",
      " -1.45157981  1.09027103 -1.0799803 ]  energy_before :  40  energy_after :  30  reward :  -189.0239752262528\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "action : 1  next_temperatures :  [ 0.64969639 -0.26799519  0.61962214 -0.59474035 -0.38264613  0.85650792\n",
      "  0.29762526  0.43146863 -0.53785045]  energy_before :  30  energy_after :  50  reward :  -216.92831178957886\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "action : 1  next_temperatures :  [-0.30296627 -0.11804873 -0.02335676 -0.22616367 -0.83128681  0.90874338\n",
      " -0.61613858  0.92211517 -0.40773929]  energy_before :  50  energy_after :  80  reward :  -228.69484156259762\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "action : 1  next_temperatures :  [-1.2992148  -0.74631603 -0.79401942 -0.81834354 -1.57902129  0.16822889\n",
      " -2.03410425 -0.19047769 -1.36610439]  energy_before :  80  energy_after :  100  reward :  -226.65937252707474\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "action : 1  next_temperatures :  [ 1.50273419 -0.05773507  1.03003421  0.09081228  1.75587446 -0.10523912\n",
      "  1.57199947 -0.14440759  1.46260869]  energy_before :  100  energy_after :  240  reward :  -330.8933184786841\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "action : 1  next_temperatures :  [-0.18466176  0.38707818  0.10280695 -0.34165103  0.06100966  1.37988677\n",
      "  0.19972199 -0.01464349 -0.80891538]  energy_before :  240  energy_after :  60  reward :  -17.219368108048684\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "action : 1  next_temperatures :  [-1.07298336 -0.65333247 -0.74841808 -1.06406133 -1.27351835 -0.83873035\n",
      " -0.41870032 -0.77633577 -1.1016655 ]  energy_before :  60  energy_after :  40  reward :  -185.94774553574103\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "action : 1  next_temperatures :  [-0.11616967  1.01283241  0.26697177  0.5109897  -0.29956452  1.90121717\n",
      "  0.24541018  1.51181242  0.10728407]  energy_before :  40  energy_after :  50  reward :  -202.85921647206925\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "action : 1  next_temperatures :  [1.87632739 1.81952763 1.39028481 1.91158109 2.14968129 0.82270851\n",
      " 2.07783302 1.58322108 2.22701178]  energy_before :  50  energy_after :  60  reward :  -192.14182342014846\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "action : 1  next_temperatures :  [-1.36148033  0.26812624 -0.61161406  0.01955412 -1.52917232  0.93639745\n",
      " -1.02570059  0.51593047 -0.70048941]  energy_before :  60  energy_after :  320  reward :  -461.4884484278857\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "action : 1  next_temperatures :  [-2.36395542  1.04047617 -1.47803954  1.05894036 -1.62887025  0.88621044\n",
      " -1.99004778  1.30680049 -1.61909832]  energy_before :  320  energy_after :  350  reward :  -232.78758384065816\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "action : 1  next_temperatures :  [ 0.43799358 -0.36935565 -0.43376883  0.28738651  0.11584352 -0.35412573\n",
      "  0.51417796 -0.7311432   0.63315002]  energy_before :  350  energy_after :  240  reward :  -87.89984182556523\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "action : 1  next_temperatures :  [-0.80731709 -0.62820178 -0.43376883 -0.81834354 -1.03068267 -0.75357338\n",
      " -0.14130773 -1.12723635 -0.86312836]  energy_before :  240  energy_after :  40  reward :  -4.603559735820824\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "action : 1  next_temperatures :  [-1.4507276  -0.81165583 -1.47803954 -0.17702011 -1.23506343 -0.07451237\n",
      " -0.97838068 -0.56825249 -1.19382757]  energy_before :  40  energy_after :  110  reward :  -275.9674796229804\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "action : 1  next_temperatures :  [ 0.50648566  0.33430373 -0.15560065  1.04255918  0.80874413  0.06887909\n",
      "  0.50648556  0.27022329  0.76326118]  energy_before :  110  energy_after :  90  reward :  -173.8546588300794\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "action : 1  next_temperatures :  [-0.49598942 -1.19615542 -1.52364088  0.32014888 -0.2829482  -1.02704139\n",
      " -0.52149876 -1.34223014 -0.14570986]  energy_before :  90  energy_after :  60  reward :  -174.21506518925622\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "action : 1  next_temperatures :  [ 0.31968906 -1.07050196 -0.15560065 -0.84045814  0.14907616 -1.62109174\n",
      "  0.41347746 -1.14551082  0.64941392]  energy_before :  60  energy_after :  50  reward :  -191.3015067199952\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "action : 1  next_temperatures :  [1.87632739 2.92527808 1.75965567 2.54799016 1.91040625 1.98417937\n",
      " 1.63726831 2.54838963 1.84752088]  energy_before :  50  energy_after :  90  reward :  -218.96298425370267\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "action : 1  next_temperatures :  [ 0.68705571 -0.06527428  0.00704413  0.59125751  0.47974096  0.08833936\n",
      " -0.47254712  0.50057378  0.41449098]  energy_before :  90  energy_after :  20  reward :  -125.76931897299096\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "action : 1  next_temperatures :  [-1.49223795  0.99021479 -0.88978224  0.91069063 -1.23506343  1.48947882\n",
      " -1.43363087  1.23769534 -1.31490324]  energy_before :  20  energy_after :  50  reward :  -229.7375381520766\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "action : 1  next_temperatures :  [-1.2992148  -0.92223088 -1.11778894 -0.61112154 -1.08053164 -0.99631465\n",
      " -1.25577327 -0.69782464 -0.61194153]  energy_before :  50  energy_after :  80  reward :  -236.5927418925377\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "action : 1  next_temperatures :  [ 0.81781333  1.46518487  0.80202751  1.0843312  -0.18823517  2.25764738\n",
      " -0.50518155  2.64974384  0.90963624]  energy_before :  80  energy_after :  210  reward :  -318.7070323412846\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "action : 1  next_temperatures :  [-0.18466176  0.06791839 -0.32280557  0.76325996  0.64756581  0.34541977\n",
      " -0.36974869  0.40766575  0.3295573 ]  energy_before :  210  energy_after :  60  reward :  -46.31582903127597\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "action : 1  next_temperatures :  [ 0.5687512  -0.9532254   1.89493964 -1.65951743  0.74394048 -1.11102782\n",
      "  0.97968469 -0.75253289  0.0042794 ]  energy_before :  60  energy_after :  50  reward :  -188.28470813438042\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "action : 1  next_temperatures :  [-0.55825495  0.83691757 -0.06439797  0.49460851 -0.13340131  2.0763596\n",
      " -0.26042337  1.44270728 -0.16378086]  energy_before :  50  energy_after :  140  reward :  -284.32966550851063\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "action : 1  next_temperatures :  [-0.59561427  0.25137244 -0.29240467  0.37093056 -0.73657378 -0.04685831\n",
      " -1.54458791  0.92211517 -1.02576732]  energy_before :  140  energy_after :  520  reward :  -580.697388093743\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "action : 1  next_temperatures :  [ 0.12666591 -0.96997919  2.04390402 -2.50396757  0.16569248 -1.24212859\n",
      "  0.82140774 -1.0427745   0.0042794 ]  energy_before :  520  energy_after :  100  reward :  219.40309970530257\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "action : 1  next_temperatures :  [-0.61429393 -0.87783332 -0.06439797 -1.07880439 -0.43747999 -1.07927685\n",
      " -0.07603889 -0.72028382 -0.26678553]  energy_before :  100  energy_after :  50  reward :  -153.2151946962724\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "action : 1  next_temperatures :  [-2.05262775 -0.36935565 -1.34579565 -0.34902256 -1.87811508  0.01459518\n",
      " -2.27886242 -0.100641   -1.86004492]  energy_before :  50  energy_after :  70  reward :  -228.21986985665657\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "action : 1  next_temperatures :  [-0.26560695  1.33953141  0.20464994  0.96802478 -0.73657378  1.79674624\n",
      "  0.31557419  1.29144379 -0.83602187]  energy_before :  70  energy_after :  40  reward :  -163.92223224656712\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "action : 1  next_temperatures :  [-0.61429393 -0.14066635 -0.80921987  0.11784124 -0.58204199  0.36590427\n",
      " -0.36974869 -0.13749708 -0.53785045]  energy_before :  40  energy_after :  80  reward :  -240.70757287001294\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "action : 1  next_temperatures :  [-0.3652318   0.88717895  0.07240605  0.48641792 -0.16995721  2.04563285\n",
      " -0.12499052  1.46804583 -0.04993359]  energy_before :  80  energy_after :  140  reward :  -253.7504315150481\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "action : 1  next_temperatures :  [-0.42749733 -1.69206775 -0.59641361 -1.62921224  0.23049614 -1.34557529\n",
      " -0.32079706 -1.71079092 -0.32099851]  energy_before :  140  energy_after :  60  reward :  -125.81285657555645\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "action : 1  next_temperatures :  [-0.32372145 -1.24892988 -1.11778894 -0.2777644   0.21554145 -1.275928\n",
      "  0.01696922 -1.36756869  0.3295573 ]  energy_before :  60  energy_after :  40  reward :  -183.04963339361476\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "action : 1  next_temperatures :  [ 0.12666591  0.35105752 -0.25136347  0.91806217 -0.08355234  0.06785487\n",
      "  0.26172739  0.40766575  0.08288822]  energy_before :  40  energy_after :  70  reward :  -226.11899398535678\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "action : 1  next_temperatures :  [ 0.77215194  0.84529446  0.95251193 -0.11968596  1.14605546  1.10129764\n",
      "  0.11976765  0.80693993 -0.3806328 ]  energy_before :  70  energy_after :  120  reward :  -242.75629974776066\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "action : 1  next_temperatures :  [-0.30296627 -0.15993322  1.25652087 -1.02310836 -0.13340131 -0.91437667\n",
      "  0.63026327 -0.84269865  0.05849238]  energy_before :  120  energy_after :  60  reward :  -139.43120795405855\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "action : 1  next_temperatures :  [-0.9256216   0.61325441 -0.29240467  0.14241301 -0.68672482  0.7438432\n",
      " -0.96206346  0.86683105 -0.32099851]  energy_before :  60  energy_after :  40  reward :  -178.82147139257336\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "action : 1  next_temperatures :  [-0.24692729  0.03524849 -0.38360736 -0.17702011 -0.53219302 -0.12777206\n",
      " -0.8103134  -0.48993333 -0.65169772]  energy_before :  40  energy_after :  90  reward :  -251.38421579944952\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "action : 1  next_temperatures :  [-0.98788713  0.93995341 -0.43376883  0.70510675 -1.03068267  1.53019175\n",
      " -1.29982974  1.47572418 -0.80891538]  energy_before :  90  energy_after :  60  reward :  -167.91010767045674\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "action : 1  next_temperatures :  [ 0.97970371  0.3770259   0.36425464  0.92870994  1.05798895 -0.22814609\n",
      "  1.06616591  0.09362124  1.08853909]  energy_before :  60  energy_after :  420  reward :  -552.2721366910837\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "action : 1  next_temperatures :  [-0.42749733  0.16090195 -1.02202613  1.17442773  0.43155363  0.17949536\n",
      " -0.22778895 -0.14440759  0.36440851]  energy_before :  420  energy_after :  40  reward :  182.48906716983478\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "action : 1  next_temperatures :  [-0.80731709 -1.55049818 -0.74841808 -1.3744848  -1.23506343 -0.84707047\n",
      " -0.82663061 -1.25239345 -1.19382757]  energy_before :  40  energy_after :  90  reward :  -257.83570367883493\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "action : 1  next_temperatures :  [-0.07465931 -0.10883414 -0.66177553  0.8549946  -0.08355234 -0.3817798\n",
      "  0.16871929 -0.34481252  0.29341531]  energy_before :  90  energy_after :  20  reward :  -128.3382844515112\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "action : 1  next_temperatures :  [-2.27470815  0.59482523 -1.39139699  0.4102454  -1.93294894  1.30819104\n",
      " -2.52851576  1.69839632 -2.27808727]  energy_before :  20  energy_after :  70  reward :  -254.39399911381471\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "action : 1  next_temperatures :  [-0.05390414  0.03524849 -0.52041138  0.58224786  0.41493731 -0.04685831\n",
      "  0.11976765  0.10897794  0.25727332]  energy_before :  70  energy_after :  60  reward :  -187.10272124619598\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "action : 1  next_temperatures :  [ 0.81781333 -0.5611866   0.16360874 -0.50546289  0.7140311  -1.64157624\n",
      "  0.75124373 -1.52321981  1.30539103]  energy_before :  60  energy_after :  90  reward :  -228.4793576114445\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "action : 1  next_temperatures :  [-0.11616967 -0.07365118 -0.70737688  0.87137579 -0.08355234 -0.41250654\n",
      " -0.22778895 -0.47457663  0.22113133]  energy_before :  90  energy_after :  70  reward :  -179.00311506145903\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "action : 1  next_temperatures :  [-0.11616967 -1.06484756 -0.30760512 -0.70285618 -0.08355234 -1.47770028\n",
      "  0.56033236 -1.01359677 -0.59206344]  energy_before :  70  energy_after :  90  reward :  -222.7980589971616\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "action : 1  next_temperatures :  [-0.18466176  0.51021857  0.11800739  0.31441547  0.11584352  1.37425353\n",
      " -0.27674059  0.66181912 -0.34418962]  energy_before :  90  energy_after :  80  reward :  -185.71103436512735\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "action : 1  next_temperatures :  [-2.05262775  0.58561065 -1.16339028  0.35454937 -1.23506343  1.27746429\n",
      " -1.34878137  0.82076096 -1.24804056]  energy_before :  80  energy_after :  40  reward :  -162.00951812754897\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "action : 1  next_temperatures :  [-0.31853265  0.36194749  0.0876065  -0.10330477  0.06100966  1.15455732\n",
      " -1.02570059  0.45450368 -0.26678553]  energy_before :  40  energy_after :  50  reward :  -207.59469889767598\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "action : 1  next_temperatures :  [1.72009751 3.24724794 1.40511551 3.02340612 2.54289898 2.31574885\n",
      " 1.42117551 2.32972268 1.66558992]  energy_before :  50  energy_after :  40  reward :  -168.32899697091088\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "action : 1  next_temperatures :  [ 1.22253929  1.22769983  0.81722795 -0.28431688  0.75889517 -0.12572361\n",
      "  0.36452582  0.12970949  0.37834899]  energy_before :  40  energy_after :  60  reward :  -213.51109394395257\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "action : 1  next_temperatures :  [-0.11616967 -0.7886792  -0.15560065 -0.9559455  -0.83128681 -0.63886021\n",
      "  0.16871929 -1.05659553 -0.88300646]  energy_before :  60  energy_after :  50  reward :  -193.25742474903208\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "action : 1  next_temperatures :  [ 1.97387673 -0.36935565  1.61829151 -0.65371262  1.5564786  -0.4852265\n",
      "  1.73027642 -0.36707973  1.66681093]  energy_before :  50  energy_after :  210  reward :  -351.32964031484755\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "action : 1  next_temperatures :  [-0.3652318  -0.5452705  -0.59641361 -0.37359434 -0.68672482  0.11804188\n",
      " -0.76625693  0.10897794 -0.07975073]  energy_before :  210  energy_after :  70  reward :  -61.186222906004105\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "action : 1  next_temperatures :  [-0.24692729 -1.24892988 -1.02202613 -0.30888866  0.21554145 -1.30358207\n",
      "  0.03235402 -1.41133529  0.3295573 ]  energy_before :  70  energy_after :  90  reward :  -222.96423653522191\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "action : 1  next_temperatures :  [ 0.43799358 -2.02546826  2.79176602 -3.64164093  0.55949931 -1.67537566\n",
      "  0.9960019  -1.71846927  0.61688612]  energy_before :  90  energy_after :  90  reward :  -201.65880718982575\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "action : 1  next_temperatures :  [1.44046866 1.24152171 0.5740208  1.83786575 1.5564786  0.5492405\n",
      " 1.31092408 0.91520466 1.93271272]  energy_before :  90  energy_after :  50  reward :  -146.641562514748\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "action : 1  next_temperatures :  [ 0.63101673 -0.17417394  1.03003421 -0.77657151  0.46478627 -0.3817798\n",
      "  1.19180844 -0.23654779  0.54640924]  energy_before :  50  energy_after :  460  reward :  -605.7050181480965\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "action : 1  next_temperatures :  [0.43799358 1.21555333 0.96771238 0.59125751 1.36206764 0.77559417\n",
      " 0.38084303 1.0303799  0.60062223]  energy_before :  460  energy_after :  40  reward :  229.3620237641882\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "action : 1  next_temperatures :  [ 0.195158   -1.39720096 -0.33800601 -0.92318313  0.21554145 -0.93486116\n",
      "  0.71627828 -1.38830024  0.3458212 ]  energy_before :  40  energy_after :  60  reward :  -221.50875257609835\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "action : 1  next_temperatures :  [-0.24692729  0.72047869  0.11800739  0.3881308  -0.03370338  0.69365619\n",
      " -0.41870032  0.9359362   0.22113133]  energy_before :  60  energy_after :  60  reward :  -195.62199037555848\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "action : 1  next_temperatures :  [-0.42749733 -0.52684132 -0.61161406 -0.59474035 -0.2829482  -1.02704139\n",
      " -1.34878137 -0.92759926 -1.19382757]  energy_before :  60  energy_after :  90  reward :  -234.94089086317024\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "action : 1  next_temperatures :  [0.85932368 2.28025698 2.07582496 1.13347476 1.00813999 1.64311253\n",
      " 1.17712295 1.55941819 1.57645596]  energy_before :  90  energy_after :  60  reward :  -154.6868699899417\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "action : 1  next_temperatures :  [0.37572804 0.99021479 0.66066335 0.3037677  1.2258138  0.5369498\n",
      " 0.4323588  0.29095483 0.64941392]  energy_before :  60  energy_after :  60  reward :  -192.53413496969804\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "action : 1  next_temperatures :  [-2.29546333 -0.09040497 -1.52364088  0.00317293 -2.02766197  0.10677541\n",
      " -2.43061249  0.14660186 -1.94738806]  energy_before :  60  energy_after :  640  reward :  -788.0586215036724\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "action : 1  next_temperatures :  [-0.05390414 -1.47259304 -0.07959842 -1.38349445 -0.95258596 -1.21447452\n",
      " -0.27674059 -0.92759926 -1.19382757]  energy_before :  640  energy_after :  50  reward :  384.445182065037\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "action : 1  next_temperatures :  [ 0.12666591 -0.2755344  -0.27872427  0.25708132  0.26040552 -0.34567588\n",
      "  0.11976765 -0.23654779  0.37834899]  energy_before :  50  energy_after :  290  reward :  -437.9942129546765\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "action : 1  next_temperatures :  [-0.42749733 -0.93730929 -0.88978224 -0.19503942 -1.03068267 -0.5886732\n",
      "  0.26172739 -1.06580955 -0.30292752]  energy_before :  290  energy_after :  250  reward :  -163.1759938346994\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "action : 1  next_temperatures :  [-0.01239378 -0.05103355 -0.30760512 -1.01246059 -0.64559942 -0.95176087\n",
      " -0.71730529 -1.1349147  -0.12763887]  energy_before :  250  energy_after :  70  reward :  -22.960712195946883\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "action : 1  next_temperatures :  [ 0.06440038 -1.02024058 -0.33800601 -0.53822526 -0.93596964 -0.9778786\n",
      " -0.36974869 -0.86770813 -0.12763887]  energy_before :  70  energy_after :  20  reward :  -153.11101540684757\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "action : 1  next_temperatures :  [ 0.61026155  0.76152549  0.37641499  1.07614061  0.39832099  0.01459518\n",
      " -0.14946634  0.93823971  0.72350499]  energy_before :  20  energy_after :  310  reward :  -483.2504628253615\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "action : 1  next_temperatures :  [0.12666591 1.06560687 0.07240605 1.37100196 0.41493731 0.78276374\n",
      " 0.11976765 1.14555515 0.10728407]  energy_before :  310  energy_after :  60  reward :  57.20598869800256\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "action : 1  next_temperatures :  [ 1.64262948 -0.57000954  1.41572088 -1.05330718  1.29784664 -0.67847244\n",
      "  1.59550049 -0.15637385  0.96413085]  energy_before :  60  energy_after :  50  reward :  -183.5423346760701\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "action : 1  next_temperatures :  [-1.38431103 -0.81165583 -1.8610908   0.25708132 -0.83128681 -0.40226429\n",
      " -1.20682164 -0.88152916 -1.13419329]  energy_before :  50  energy_after :  70  reward :  -226.25607153721805\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "action : 1  next_temperatures :  [ 0.5687512   0.18603264 -0.35320646  1.27926732  0.97823061 -0.15747458\n",
      "  0.11976765  0.50057378  0.7036269 ]  energy_before :  70  energy_after :  330  reward :  -454.1744309478196\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "action : 1  next_temperatures :  [-1.11864475 -1.37458334 -1.34579565 -1.09518558 -1.02427352 -0.75664606\n",
      " -0.68140743 -1.20478768 -0.55592145]  energy_before :  330  energy_after :  40  reward :  82.84275454757076\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "action : 1  next_temperatures :  [-2.11489328 -0.40118786 -1.34579565 -0.44976686 -1.87811508  0.01459518\n",
      " -2.21848874 -0.12137255 -1.7901704 ]  energy_before :  40  energy_after :  40  reward :  -208.30519524102075\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "action : 1  next_temperatures :  [ 0.31968906  1.17450653  0.54361991  0.80585104  0.16569248  1.79674624\n",
      " -0.36974869  1.99785196 -0.48363747]  energy_before :  40  energy_after :  50  reward :  -202.0494289316727\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "action : 1  next_temperatures :  [-0.18466176 -0.04265666 -0.80921987  0.91069063 -0.0503197  -0.22814609\n",
      " -0.17394215 -0.44616674 -0.10956787]  energy_before :  50  energy_after :  110  reward :  -259.1339901948015\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "action : 1  next_temperatures :  [-0.98788713  1.16612963 -0.47937017  0.97785349 -0.88113578  1.5509323\n",
      " -0.32079706  1.55097201 -1.0799803 ]  energy_before :  110  energy_after :  50  reward :  -136.503283005181\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "action : 1  next_temperatures :  [-1.11864475 -0.84432573 -0.49305057 -0.98788881 -1.82826611 -0.32032631\n",
      " -1.22313885 -0.48993333 -0.8480692 ]  energy_before :  50  energy_after :  50  reward :  -206.15364367374704\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "action : 1  next_temperatures :  [ 0.43799358  1.16612963  0.54361991  1.01716834 -0.13340131  1.61545846\n",
      "  0.47385114  1.54406149 -0.48363747]  energy_before :  50  energy_after :  60  reward :  -201.8187562219802\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "action : 1  next_temperatures :  [-0.47315873 -1.2715475  -0.87306175 -0.93219278 -0.83128681 -0.3817798\n",
      " -0.8103134  -0.94295596 -0.46737357]  energy_before :  60  energy_after :  70  reward :  -214.9836702946945\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "action : 1  next_temperatures :  [-0.05390414  1.42581345  0.30041276  0.8549946   0.16569248  1.83054566\n",
      " -0.56555523  1.85733816 -0.48363747]  energy_before :  70  energy_after :  280  reward :  -402.66829972206426\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "action : 1  next_temperatures :  [ 0.99838337  0.03524849  3.05169366 -1.78319539  0.98891253 -0.58545421\n",
      "  1.43656661 -0.16974615  0.07800905]  energy_before :  280  energy_after :  380  reward :  -293.9495820196005\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "action : 1  next_temperatures :  [-0.49598942 -0.96997919 -0.97642479 -0.15490551 -0.08355234 -1.48794253\n",
      " -0.03198241 -0.96583744  0.16149705]  energy_before :  380  energy_after :  50  reward :  126.99488341829465\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "action : 1  next_temperatures :  [0.63101673 0.27273353 0.25025128 0.56013325 0.55949931 0.14979285\n",
      " 0.85404217 0.11588846 0.64941392]  energy_before :  50  energy_after :  340  reward :  -483.9572285125021\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "action : 1  next_temperatures :  [ 0.39129443  0.92675979  0.16360874  1.00242527  0.39832099 -0.05607633\n",
      " -0.22778895  1.19008957  0.96204213]  energy_before :  340  energy_after :  80  reward :  66.75067563567796\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "action : 1  next_temperatures :  [0.5687512  0.28655541 0.16360874 0.69036368 0.55949931 0.16822889\n",
      " 0.82140774 0.16886907 0.64941392]  energy_before :  80  energy_after :  70  reward :  -183.92330204965174\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "action : 1  next_temperatures :  [-1.74130008 -1.2305007  -1.37771659 -0.96393133 -1.43445929 -1.1806751\n",
      " -1.26678739 -1.28464252 -1.24804056]  energy_before :  70  energy_after :  40  reward :  -179.72805355261755\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "action : 1  next_temperatures :  [-0.45032803  0.42896267 -0.02335676  0.09982193 -0.15167926  0.52978023\n",
      " -1.1040232   0.47523522 -0.32099851]  energy_before :  40  energy_after :  40  reward :  -198.51658572391113\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "action : 1  next_temperatures :  [ 0.12666591  0.17765574  0.07240605  0.39550234  0.36508834 -0.22814609\n",
      "  0.36452582  0.41611193  0.51026725]  energy_before :  40  energy_after :  50  reward :  -205.7999226914145\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "action : 1  next_temperatures :  [ 0.12666591 -0.5452705  -0.1404002  -0.22616367  0.06100966 -0.56614025\n",
      " -0.12499052 -0.32254531  0.0042794 ]  energy_before :  50  energy_after :  60  reward :  -209.73355548580867\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "action : 1  next_temperatures :  [ 0.195158   -0.01501289 -0.78261909  1.15415601  0.80874413 -0.1666926\n",
      "  0.20648198 -0.2187779   0.60062223]  energy_before :  60  energy_after :  120  reward :  -256.21794013957617\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "action : 1  next_temperatures :  [ 0.195158    0.671055    0.13320784  0.77882209  0.75889517 -0.34285926\n",
      " -0.22778895  0.40075523  0.16149705]  energy_before :  120  energy_after :  60  reward :  -135.47125783774123\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "action : 1  next_temperatures :  [ 0.12666591 -1.43238393 -0.29240467 -1.08617593 -0.20485149 -1.40702877\n",
      "  0.11976765 -1.57258063 -0.3806328 ]  energy_before :  60  energy_after :  70  reward :  -214.1296246538336\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "action : 1  next_temperatures :  [ 0.31968906  1.44256725  0.43265665  1.31940122  0.46478627  2.0763596\n",
      " -0.22778895  2.31803914  0.14944972]  energy_before :  70  energy_after :  60  reward :  -179.70484004582815\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "action : 1  next_temperatures :  [-0.49598942 -0.38443407 -0.52041138 -0.34902256 -0.15167926 -0.80376039\n",
      "  0.22909297 -0.9967044  -0.94599678]  energy_before :  60  energy_after :  80  reward :  -222.4189053040179\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "action : 1  next_temperatures :  [ 0.63101673  0.56299302  1.07563555 -0.08856171  0.21554145  0.47549632\n",
      "  0.31557419  0.70558571  0.05849238]  energy_before :  80  energy_after :  80  reward :  -194.04822635695592\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "action : 1  next_temperatures :  [-1.11864475 -1.46421614 -0.77881898 -1.38349445 -1.2799275  -0.94162105\n",
      " -1.1040232  -1.09805862 -1.24804056]  energy_before :  80  energy_after :  50  reward :  -178.4168452433516\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "action : 1  next_temperatures :  [-0.30296627  0.88717895  0.11800739  0.45938896 -0.23808413  1.95037995\n",
      " -0.03198241  1.49108088  0.0042794 ]  energy_before :  50  energy_after :  30  reward :  -173.66271727914227\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "action : 1  next_temperatures :  [ 0.0083614   0.06791839 -0.61161406  0.943453    0.28533     0.06375797\n",
      " -0.27674059 -0.100641    0.20409297]  energy_before :  30  energy_after :  80  reward :  -247.41608192105548\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "action : 1  next_temperatures :  [ 0.0083614  -0.71867227 -0.77121875  0.20261387 -0.08355234 -0.71977397\n",
      " -0.52149876 -0.52909291 -0.10956787]  energy_before :  80  energy_after :  100  reward :  -221.24240160374717\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "action : 1  next_temperatures :  [ 0.63101673  0.56299302  1.11667676 -0.12787655  0.21554145  0.47549632\n",
      "  0.31557419  0.69176468  0.04042139]  energy_before :  100  energy_after :  100  reward :  -194.07839202062272\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "action : 1  next_temperatures :  [ 1.12914099  0.3770259   0.95935213  0.15347031  1.05798895 -0.13903853\n",
      "  1.16243746  0.2310637   1.63066894]  energy_before :  100  energy_after :  40  reward :  -131.43789012731693\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "action : 1  next_temperatures :  [0.72856606 1.59921523 0.78682706 0.78946986 0.50965034 0.44784225\n",
      " 0.62560121 0.67717582 0.87168715]  energy_before :  40  energy_after :  50  reward :  -200.96396502490066\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "action : 2  next_temperatures :  [ 0.34419571 -1.10337341  0.43398728 -1.25087824 -0.2799275  -1.03283009\n",
      "  0.87500948 -0.36756869  0.2778254 ]  energy_before :  50  energy_after :  40  reward :  -199.10356006618213\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "action : 1  next_temperatures :  [ 0.08515556 -1.28997667 -0.88978224 -0.34902256  0.43155363 -1.36810823\n",
      "  0.41347746 -1.52651053  0.61688612]  energy_before :  40  energy_after :  80  reward :  -241.87632747048968\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "action : 1  next_temperatures :  [-0.61429393  0.93995341 -0.15560065  0.7141164  -0.78143785  1.61545846\n",
      " -0.41870032  1.44270728 -1.02576732]  energy_before :  80  energy_after :  50  reward :  -166.2835645322486\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "action : 1  next_temperatures :  [ 0.1723273   3.93050576  0.52841946  1.28090543 -0.12271938  2.20255872\n",
      " -0.17394215  1.54406149  0.35937445]  energy_before :  50  energy_after :  160  reward :  -298.2785089194407\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "action : 1  next_temperatures :  [-0.16183106 -0.56788812 -0.43376883 -0.09511418 -0.23808413 -0.4852265\n",
      " -0.0466679  -0.29797459  0.0042794 ]  energy_before :  160  energy_after :  40  reward :  -80.32227591882852\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "action : 1  next_temperatures :  [ 1.75179633 -0.44223466  1.39028481 -0.73398043  2.00511929 -0.32032631\n",
      "  1.9065023  -0.68227599  2.11858581]  energy_before :  40  energy_after :  230  reward :  -381.00652886599335\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "action : 1  next_temperatures :  [-0.55825495 -0.78568745 -1.28043373  0.00972541 -0.18823517 -0.94817608\n",
      " -0.07603889 -1.02204296  0.0042794 ]  energy_before :  230  energy_after :  110  reward :  -82.84486442416863\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "action : 1  next_temperatures :  [-0.24692729 -0.68684006  0.25025128 -1.15251973 -0.33279717 -0.53541351\n",
      "  0.21277576 -1.02895347 -0.53785045]  energy_before :  110  energy_after :  210  reward :  -302.0582746457474\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "action : 1  next_temperatures :  [-1.11864475 -0.42715624 -0.52041138 -0.63733143 -1.03068267 -0.71977397\n",
      " -0.19189109 -0.76635392 -0.86312836]  energy_before :  210  energy_after :  80  reward :  -74.27537381385264\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "action : 1  next_temperatures :  [ 0.31968906  0.32676452 -0.29240467  1.12528417  0.9466596   0.16822889\n",
      "  0.45753393  0.2617771   0.66748491]  energy_before :  80  energy_after :  80  reward :  -194.01898249315337\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "action : 1  next_temperatures :  [ 0.68705571 -0.5452705   1.25804092 -1.17627245  0.18230881 -0.22814609\n",
      "  0.54238343 -0.53600343  0.60062223]  energy_before :  80  energy_after :  130  reward :  -247.21528137346243\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "action : 1  next_temperatures :  [-0.30296627 -0.9616023  -1.06762747 -0.05416122 -0.08355234 -1.25339506\n",
      " -0.27674059 -1.09114811  0.0042794 ]  energy_before :  130  energy_after :  50  reward :  -123.08691394618972\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "action : 1  next_temperatures :  [-0.738825   -0.3165812  -0.79401942 -0.05416122 -0.48732896 -0.17795907\n",
      " -0.17394215 -0.65962486 -0.3806328 ]  energy_before :  50  energy_after :  40  reward :  -191.78307467665886\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "action : 1  next_temperatures :  [ 0.31968906 -1.51699059 -0.15560065 -1.50635335  0.93004328 -1.14175456\n",
      "  0.07081602 -1.30460623 -0.75470239]  energy_before :  40  energy_after :  60  reward :  -223.05945941042222\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "action : 1  next_temperatures :  [ 0.5687512   0.96257103 -0.06439797  1.61671974  1.21252075  0.47549632\n",
      "  0.3318914   0.9359362   0.87168715]  energy_before :  60  energy_after :  70  reward :  -201.08882418472524\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "action : 1  next_temperatures :  [-2.91811866  0.88717895 -1.8884516   0.87956638 -2.37660473  0.78276374\n",
      " -2.77327393  0.99045248 -2.27808727]  energy_before :  70  energy_after :  30  reward :  -166.6945746364662\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "action : 1  next_temperatures :  [ 0.68705571 -0.2801417   0.25025128  0.11784124 -0.13340131 -0.25887283\n",
      " -0.07603889  0.46486945  0.16149705]  energy_before :  30  energy_after :  40  reward :  -207.06693998723338\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "action : 1  next_temperatures :  [0.195158   0.695348   0.13320784 0.76407902 0.46478627 0.01459518\n",
      " 0.60928399 0.49212759 0.64941392]  energy_before :  40  energy_after :  50  reward :  -203.9820001884013\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "action : 1  next_temperatures :  [0.31968906 1.57492223 0.86130925 0.7141164  1.27400114 1.06954667\n",
      " 0.3318914  1.17626854 0.56448024]  energy_before :  50  energy_after :  40  reward :  -180.11377506918345\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "action : 1  next_temperatures :  [-2.34112472  0.63587203 -1.4324382   0.45938896 -1.93294894  1.3358451\n",
      " -2.52851576  1.69839632 -2.27808727]  energy_before :  40  energy_after :  490  reward :  -654.3836124663469\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "action : 1  next_temperatures :  [1.87632739 1.76675318 1.1622781  2.20644244 2.20950004 1.27746429\n",
      " 2.02888139 1.46804583 2.38965073]  energy_before :  490  energy_after :  120  reward :  188.3853433899936\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "action : 1  next_temperatures :  [1.98614115 1.59579593 2.13884519 0.59782474 2.07005889 0.71404757\n",
      " 1.6284482  1.41483694 1.91809544]  energy_before :  120  energy_after :  60  reward :  -123.93590593517945\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "action : 1  next_temperatures :  [ 0.63101673  0.00760473  0.70626469 -0.2597451  -0.68672482  0.8472899\n",
      " -0.0923561   1.06800381  0.22113133]  energy_before :  60  energy_after :  60  reward :  -195.55751481411994\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "action : 1  next_temperatures :  [ 0.81781333 -1.46421614  0.3460141  -1.75207113  0.66418213 -1.94884366\n",
      "  0.80509053 -1.52651053  0.90421494]  energy_before :  60  energy_after :  260  reward :  -401.15432643160864\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "action : 1  next_temperatures :  [-0.49598942 -0.79657742  0.55882036 -1.16152938 -0.18823517 -1.275928\n",
      " -0.03198241 -0.92759926 -0.04993359]  energy_before :  260  energy_after :  60  reward :  -2.3689542993255372\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "action : 1  next_temperatures :  [-0.11616967  0.99607862  0.02224458  0.49378945 -0.05198133  0.9466397\n",
      " -0.52149876  0.80693993  0.16149705]  energy_before :  60  energy_after :  40  reward :  -175.2624604296752\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "action : 1  next_temperatures :  [-0.65580429 -0.90547708 -0.50673098 -0.89779229 -0.73657378 -0.68904722\n",
      " -0.94411453 -0.58207352 -1.13419329]  energy_before :  40  energy_after :  110  reward :  -275.05180698729146\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "action : 1  next_temperatures :  [-0.01239378  0.50267936  0.25025128  0.22268083 -0.93596964  1.53249626\n",
      " -1.25577327  1.88267671 -0.55893328]  energy_before :  110  energy_after :  50  reward :  -136.37228553340515\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "action : 1  next_temperatures :  [0.43799358 0.67189269 0.84762885 0.24070013 0.16569248 0.47549632\n",
      " 0.21277576 0.91520466 0.05849238]  energy_before :  50  energy_after :  50  reward :  -193.9741231634717\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "action : 1  next_temperatures :  [-0.24692729  0.76152549 -0.15560065  0.8549946  -0.18823517  0.8472899\n",
      " -0.0923561   1.15937618 -0.75470239]  energy_before :  50  energy_after :  40  reward :  -185.8146354301367\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "action : 1  next_temperatures :  [2.32879027 2.67397116 2.37201653 1.82242064 1.98717366 2.28468691\n",
      " 2.46455093 2.13375874 2.38965073]  energy_before :  40  energy_after :  20  reward :  -157.54298043002896\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "action : 1  next_temperatures :  [1.87632739 1.77596776 1.39028481 1.91158109 2.12404468 0.81656316\n",
      " 2.07783302 1.55788252 2.25953957]  energy_before :  20  energy_after :  80  reward :  -242.209976008334\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "action : 1  next_temperatures :  [-2.00125869  1.37848398 -1.16339028  0.93608147 -1.45107561  1.56424722\n",
      " -1.12034042  1.1378768  -2.26152219]  energy_before :  80  energy_after :  60  reward :  -180.98089771383954\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "action : 1  next_temperatures :  [ 0.14949661 -0.26631982 -0.38360736  0.49460851  0.46478627  0.16822889\n",
      "  0.16871929 -0.19047769  0.43256198]  energy_before :  60  energy_after :  60  reward :  -196.96200332023835\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "action : 1  next_temperatures :  [-0.11616967 -0.29396358 -0.61161406  0.48641792  0.16569248 -0.29267225\n",
      " -0.03198241 -0.16974615  0.22113133]  energy_before :  60  energy_after :  60  reward :  -198.6429063771293\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "action : 1  next_temperatures :  [-0.96713196 -0.66170937 -0.75981842 -0.55788268 -0.88113578 -0.78122745\n",
      " -0.52149876 -0.86079762 -0.75470239]  energy_before :  60  energy_after :  100  reward :  -244.7459044222831\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "action : 1  next_temperatures :  [-0.30296627 -0.11804873 -0.76361853  0.74851689 -0.13340131 -0.36334375\n",
      "  0.13608486 -0.16974615 -0.16378086]  energy_before :  100  energy_after :  110  reward :  -209.13030383948566\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "action : 1  next_temperatures :  [ 0.12666591  0.21954023  0.4037758  -0.06398993 -0.58204199  1.20474434\n",
      " -0.64714128  1.1225201  -1.02576732]  energy_before :  110  energy_after :  70  reward :  -157.2416941470796\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "action : 1  next_temperatures :  [ 1.26665911e-01 -4.50611557e-01 -5.66012719e-01  5.10989697e-01\n",
      "  3.10254482e-01 -5.66140253e-01 -3.20797056e-01  7.13213916e-04\n",
      "  1.10661009e+00]  energy_before :  70  energy_after :  50  reward :  -177.8483281949222\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "action : 1  next_temperatures :  [-0.3652318  -0.14066635  0.07240605 -0.14589586 -0.18823517 -0.53541351\n",
      " -0.47254712 -0.11446203 -0.10956787]  energy_before :  50  energy_after :  50  reward :  -199.99961366452166\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "action : 1  next_temperatures :  [ 0.81781333  1.50036784  0.75642617  0.26527191  0.06100966  0.97019687\n",
      " -1.04038608  2.32648532 -0.97697563]  energy_before :  50  energy_after :  90  reward :  -233.31979062057948\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "action : 1  next_temperatures :  [-1.11864475  0.05116459 -1.70604624  0.61501023 -1.08053164 -0.59993967\n",
      " -0.81194512 -0.87461865 -0.75470239]  energy_before :  90  energy_after :  50  reward :  -164.28025363881056\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "action : 1  next_temperatures :  [ 2.37445166  0.63587203  2.21566908 -0.08119017  2.10980211 -0.04202982\n",
      "  2.27363956  0.53742985  2.17279879]  energy_before :  50  energy_after :  90  reward :  -225.80355691096528\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "action : 1  next_temperatures :  [ 0.0083614   0.75398628  0.25025128  0.5331043  -0.75152847  1.66564547\n",
      " -1.64249118  1.74216291 -0.24871453]  energy_before :  90  energy_after :  360  reward :  -465.6892225365841\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "action : 1  next_temperatures :  [-0.42749733 -0.24370219 -0.79401942  0.65596319 -0.23808413 -0.56614025\n",
      " -0.52149876 -0.16974615 -0.16378086]  energy_before :  360  energy_after :  30  reward :  129.53149409342024\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "action : 1  next_temperatures :  [-0.55825495  0.68026959 -0.61161406  1.31940122 -0.29956452  0.12930835\n",
      " -0.61450686  0.74474529 -0.19630865]  energy_before :  30  energy_after :  60  reward :  -227.40652459393942\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "action : 1  next_temperatures :  [ 0.25742353  0.4096958   0.58922125 -0.30888866  0.06100966  1.27746429\n",
      " -1.0110151   1.40508336 -1.35104523]  energy_before :  60  energy_after :  40  reward :  -176.67105108614908\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "action : 1  next_temperatures :  [ 1.75179633  1.11586825  1.57269017  0.5524107   2.25436411 -0.29267225\n",
      "  1.83307485  0.87527724  1.68488193]  energy_before :  40  energy_after :  50  reward :  -196.6523086786693\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "action : 1  next_temperatures :  [-0.7616557  -0.5452705  -0.44896928 -0.48826264 -1.23506343 -0.50775944\n",
      " -0.74993972 -0.79169247 -1.13419329]  energy_before :  50  energy_after :  260  reward :  -414.66280645906494\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "action : 1  next_temperatures :  [1.50273419 1.9200504  0.63330255 2.54799016 1.64454511 1.0623771\n",
      " 1.24076008 1.55788252 1.7878866 ]  energy_before :  260  energy_after :  90  reward :  -14.102471300529487\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "action : 1  next_temperatures :  [-0.38079818 -0.75762485 -0.17709843 -0.78499612 -1.02507467 -0.4086657\n",
      "  0.54494756 -0.81242401 -0.90039979]  energy_before :  90  energy_after :  50  reward :  -162.70213418746542\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "action : 1  next_temperatures :  [ 0.50648566  1.31691379  0.70626469  0.66497284  0.06100966  1.83054566\n",
      " -0.22778895  2.04392205 -0.46466292]  energy_before :  50  energy_after :  20  reward :  -161.56233752090884\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "action : 1  next_temperatures :  [-0.59561427  3.11627134 -0.07959842  1.67159672 -1.03068267  2.85374618\n",
      " -0.94411453  2.10304535 -1.31490324]  energy_before :  20  energy_after :  70  reward :  -242.2202535476208\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "action : 1  next_temperatures :  [-0.69731464 -0.01501289 -0.70737688  0.26527191 -0.43747999  0.47549632\n",
      " -1.05507157  0.47523522 -0.88631947]  energy_before :  70  energy_after :  40  reward :  -170.58257200358372\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "action : 1  next_temperatures :  [-0.42749733 -0.71867227 -0.43376883 -0.85683933 -0.88113578 -0.67061118\n",
      " -0.52149876 -0.88152916 -0.04218888]  energy_before :  40  energy_after :  90  reward :  -253.43374151427074\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "action : 1  next_temperatures :  [2.37445166 2.33889527 2.14270693 1.69338369 2.03502867 1.95037995\n",
      " 2.38413039 1.73031632 2.38965073]  energy_before :  90  energy_after :  50  reward :  -138.96105639689898\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "action : 1  next_temperatures :  [1.90434688 1.76675318 1.1622781  2.22399371 2.20950004 1.27746429\n",
      " 2.01811203 1.46804583 2.38965073]  energy_before :  50  energy_after :  60  reward :  -191.5798552090114\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "action : 1  next_temperatures :  [-0.3652318  -1.12327642 -1.16339028 -0.16227704 -0.51723834 -1.17043285\n",
      " -0.07603889 -1.28848169 -0.46737357]  energy_before :  60  energy_after :  260  reward :  -404.33374088527853\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "action : 1  next_temperatures :  [ 0.46082427 -0.77814824  0.39161544 -0.89205888  0.50965034 -1.24212859\n",
      " -0.52149876 -0.0061973  -0.26678553]  energy_before :  260  energy_after :  30  reward :  29.655272759623585\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "action : 1  next_temperatures :  [-0.34447662  1.70141338 -0.20576213  1.59214797  0.01116069  1.0623771\n",
      " -0.27674059  1.30680049 -0.59206344]  energy_before :  30  energy_after :  50  reward :  -213.7451431551727\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "action : 1  next_temperatures :  [ 0.68705571  0.32676452  0.70626469  0.14241301 -0.23808413  1.12383058\n",
      " -0.8103134   1.63543385  0.0042794 ]  energy_before :  50  energy_after :  80  reward :  -224.42235576779314\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "action : 1  next_temperatures :  [ 0.12666591 -0.04265666 -0.83962076  1.14739877  0.80874413 -0.20049202\n",
      "  0.18760063 -0.23654779  0.58255123]  energy_before :  80  energy_after :  100  reward :  -216.46635655382744\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "action : 1  next_temperatures :  [-1.00864231  0.96257103 -0.43376883  0.7141164  -1.03068267  1.5509323\n",
      " -1.29982974  1.50490191 -0.80891538]  energy_before :  100  energy_after :  40  reward :  -137.84931729325194\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "action : 1  next_temperatures :  [-0.42749733 -1.02024058 -0.97642479 -0.2777644  -0.08355234 -0.81502687\n",
      " -0.36974869 -1.02204296 -0.61194153]  energy_before :  40  energy_after :  60  reward :  -223.60423949402562\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "action : 1  next_temperatures :  [ 0.06440038  0.62833282 -0.52041138  1.05156883  0.57777726  0.41404283\n",
      "  0.45753393  0.12279897  0.68194171]  energy_before :  60  energy_after :  100  reward :  -234.52201464805137\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "action : 1  next_temperatures :  [-0.61429393  0.71126411 -0.66177553  1.00242527 -0.23808413  1.0623771\n",
      " -0.20984002  0.56967892 -0.32099851]  energy_before :  100  energy_after :  60  reward :  -156.69924673412703\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "action : 1  next_temperatures :  [ 1.50273419 -1.38212254  0.43265665 -1.05633877  0.86357799 -1.25178556\n",
      "  1.53936504 -1.48274394  2.24095226]  energy_before :  60  energy_after :  110  reward :  -246.59370467919507\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "action : 1  next_temperatures :  [-0.738825   -0.87196949 -1.28043373  0.03429719 -1.03068267 -0.75357338\n",
      " -0.6634585  -0.95063431 -0.48363747]  energy_before :  110  energy_after :  70  reward :  -164.73891736169386\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "action : 1  next_temperatures :  [0.27817871 1.11586825 0.3460141  1.09170274 0.31025448 0.87494397\n",
      " 0.16871929 1.22080297 0.10728407]  energy_before :  70  energy_after :  100  reward :  -222.48623143277618\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "action : 1  next_temperatures :  [-0.05390414 -0.12558794 -0.66177553  0.8549946  -0.08355234 -0.41250654\n",
      "  0.16871929 -0.22963728  0.3295573 ]  energy_before :  100  energy_after :  90  reward :  -188.21369257638835\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "action : 1  next_temperatures :  [ 0.50648566 -0.36014107  0.88867006 -1.13777666  1.71101039 -0.7832759\n",
      "  0.80509053 -0.9967044   0.60062223]  energy_before :  90  energy_after :  90  reward :  -196.7660191610241\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "action : 1  next_temperatures :  [0.88007886 1.6092675  0.97010102 1.4282191  1.05798895 0.60864553\n",
      " 1.53936504 1.08182484 1.24575675]  energy_before :  90  energy_after :  70  reward :  -167.57875238889\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "action : 1  next_temperatures :  [ 0.12666591 -0.07532656  0.23505084 -0.62832178  0.16569248 -0.84268094\n",
      "  0.85404217 -0.83545906  0.37834899]  energy_before :  70  energy_after :  110  reward :  -238.6219879491197\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "action : 1  next_temperatures :  [0.88007886 1.32445299 0.30041276 1.60033856 1.16267178 0.40482481\n",
      " 0.45753393 1.19162524 1.34153302]  energy_before :  110  energy_after :  370  reward :  -449.33652804396564\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "action : 1  next_temperatures :  [ 0.77215194 -0.23448761  0.30041276 -0.34902256  1.39530028 -1.14073034\n",
      "  0.84704907 -0.86079762  0.93854983]  energy_before :  370  energy_after :  110  reward :  63.66842576765961\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "action : 1  next_temperatures :  [ 0.31968906  0.93073882 -0.09479886  1.62327222  1.11282282 -0.05607633\n",
      "  0.21277576  0.81385044  0.81747417]  energy_before :  110  energy_after :  60  reward :  -142.32025190853116\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "action : 1  next_temperatures :  [1.50273419 1.84214525 0.61962214 2.32930133 2.00511929 1.61545846\n",
      " 1.34355851 1.45959965 1.7878866 ]  energy_before :  60  energy_after :  100  reward :  -223.49457458017386\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "action : 1  next_temperatures :  [-0.65580429 -0.6265264  -1.16339028  0.05067837 -1.08053164 -0.33159279\n",
      " -0.71730529 -0.88152916 -0.75470239]  energy_before :  100  energy_after :  70  reward :  -174.16070387442238\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "action : 1  next_temperatures :  [ 1.56499973 -0.14066635  0.9718925   0.15899896  1.74091977 -0.07451237\n",
      "  1.58831668 -0.21581625  1.46260869]  energy_before :  70  energy_after :  100  reward :  -220.94325864008724\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "action : 1  next_temperatures :  [-2.05262775  1.46518487 -1.03722657  1.27025766 -1.62887025  1.35837805\n",
      " -2.03410425  1.47572418 -1.62211015]  energy_before :  100  energy_after :  40  reward :  -140.80539422064368\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "action : 1  next_temperatures :  [-0.7616557  -0.56872581 -0.79401942 -0.35885127 -0.83128681 -0.3817798\n",
      " -0.78513827 -0.51823353 -0.77019182]  energy_before :  40  energy_after :  50  reward :  -213.76988243761764\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "action : 1  next_temperatures :  [-0.42749733  0.3116861  -0.56601272  0.90168098 -0.33279717 -0.1666926\n",
      " -0.55086974  0.33932843 -0.16378086]  energy_before :  50  energy_after :  80  reward :  -228.65495489902693\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "action : 1  next_temperatures :  [-0.65580429 -0.34171189 -0.43376883 -0.23435426 -0.40092408 -1.1806751\n",
      " -0.07603889 -0.69033825 -0.26678553]  energy_before :  80  energy_after :  80  reward :  -202.2804011276146\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "action : 1  next_temperatures :  [ 0.0083614   0.99021479 -0.02335676  1.00242527 -0.10016866  1.4515825\n",
      "  0.41347746  1.19162524 -0.55953565]  energy_before :  80  energy_after :  50  reward :  -163.6253744106625\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "action : 1  next_temperatures :  [-0.3652318  -0.56788812 -0.46416972 -0.60293094 -0.13340131 -0.99631465\n",
      " -1.29982974 -0.95063431 -1.15407138]  energy_before :  50  energy_after :  80  reward :  -234.5344719731939\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "action : 1  next_temperatures :  [ 0.88007886 -1.46505383  0.52841946 -1.56286844  0.41493731 -0.96866058\n",
      "  0.9029938  -1.26621448  1.12468108]  energy_before :  80  energy_after :  50  reward :  -169.41168680794607\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "action : 1  next_temperatures :  [-0.42749733  1.93680419 -0.06439797  1.73957864 -0.34941349  2.34163381\n",
      " -1.05507157  2.34337769 -0.16378086]  energy_before :  50  energy_after :  60  reward :  -201.69876689053726\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "action : 1  next_temperatures :  [-0.78448639 -1.2715475  -0.30760512 -1.41461871 -1.08053164 -1.1806751\n",
      " -0.47254712 -1.15794975 -1.19382757]  energy_before :  60  energy_after :  100  reward :  -246.8637888976108\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n",
      "action : 1  next_temperatures :  [-0.07465931 -0.5611866  -0.43376883 -0.90188759  0.49635728 -1.32406657\n",
      " -0.52149876 -1.44358435 -1.29683224]  energy_before :  100  energy_after :  120  reward :  -224.06112696888658\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "action : 1  next_temperatures :  [-0.9256216  -0.49500911 -0.94906398 -0.18602976 -0.63189095  0.29420854\n",
      " -1.05507157  0.01453424 -0.48363747]  energy_before :  120  energy_after :  70  reward :  -152.41758167323678\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "action : 1  next_temperatures :  [-0.42749733 -0.06527428 -0.56601272  0.24070013 -0.47071263  0.50929573\n",
      " -0.96206346  0.52130532 -0.81493904]  energy_before :  70  energy_after :  50  reward :  -180.03519829306572\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "action : 1  next_temperatures :  [ 1.81406186 -2.01038985  0.88867006 -1.93109409  0.86357799 -1.73682914\n",
      "  1.68132478 -1.86589358  2.38965073]  energy_before :  50  energy_after :  70  reward :  -217.90692124593554\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "action : 1  next_temperatures :  [-0.3652318   0.20111106 -0.47937017  0.68299215 -0.23808413 -0.22814609\n",
      " -0.52149876  0.18422577 -0.10956787]  energy_before :  70  energy_after :  80  reward :  -208.87356984406514\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "action : 1  next_temperatures :  [2.24369404 2.12109593 1.79248863 1.9061753  1.91040625 1.79674624\n",
      " 2.32259119 1.61514107 2.4980767 ]  energy_before :  80  energy_after :  50  reward :  -149.79358463792278\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "action : 1  next_temperatures :  [-1.49223795  1.26413933 -0.83962076  1.10890298 -1.23506343  1.58473172\n",
      " -1.29982974  1.39663718 -1.29683224]  energy_before :  50  energy_after :  40  reward :  -188.80917291623678\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "action : 1  next_temperatures :  [ 1.93236637 -2.11928951  1.11667676 -2.34179383  0.86357799 -1.89968088\n",
      "  1.68132478 -2.09547624  2.47484256]  energy_before :  40  energy_after :  480  reward :  -638.3874519821761\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "action : 1  next_temperatures :  [-0.30296627 -0.51176291 -0.97642479  0.54211395 -0.13340131 -0.81502687\n",
      " -0.61450686 -0.38320427 -0.18004475]  energy_before :  480  energy_after :  250  reward :  28.624775930383947\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "action : 1  next_temperatures :  [-0.18466176 -1.54128359 -0.02335676 -1.5374776  -0.73657378 -1.42956172\n",
      "  0.11976765 -1.38215756  0.0042794 ]  energy_before :  250  energy_after :  110  reward :  -64.71102571812312\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "action : 1  next_temperatures :  [ 0.08515556 -0.43469545 -0.40032785 -0.15490551 -0.11678498 -0.56614025\n",
      "  0.50648556 -0.76635392  0.37834899]  energy_before :  110  energy_after :  410  reward :  -499.46921785407187\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "action : 1  next_temperatures :  [-0.18466176 -0.57040119 -0.35320646 -0.69384653 -0.38264613 -0.20049202\n",
      " -0.76625693 -0.33099149 -0.65169772]  energy_before :  410  energy_after :  20  reward :  187.86579977911074\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "action : 1  next_temperatures :  [-0.05390414  0.28655541  0.20464994  0.01955412 -0.43747999  1.01014163\n",
      " -0.40238311  0.66949747 -0.32099851]  energy_before :  20  energy_after :  70  reward :  -247.0243671797155\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "action : 1  next_temperatures :  [ 0.25742353 -0.52684132  0.14840829 -0.49645324  0.06100966 -0.50775944\n",
      " -0.03198241 -0.51527188  0.04042139]  energy_before :  70  energy_after :  90  reward :  -219.57104543735733\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "action : 1  next_temperatures :  [ 1.58367939 -0.25878061  1.25652087 -0.28349782  1.86055729 -0.59993967\n",
      "  1.78412322 -0.45998776  1.84752088]  energy_before :  90  energy_after :  140  reward :  -241.26980421671735\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "action : 1  next_temperatures :  [-0.24692729 -1.20453232 -0.12519976 -1.13777666 -1.03068267 -0.84268094\n",
      " -0.56555523 -0.79860298 -1.27592152]  energy_before :  140  energy_after :  40  reward :  -105.22787936901733\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "action : 1  next_temperatures :  [1.68330424 1.13848587 0.75642617 1.56511901 1.80572343 0.97019687\n",
      " 1.48551825 0.89216961 2.05895152]  energy_before :  40  energy_after :  50  reward :  -195.64410503783165\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "action : 2  next_temperatures :  [ 0.32344053 -0.68201547  0.89000069 -0.7930241   0.01418139 -0.73682914\n",
      "  1.03491815 -0.57258063  0.51636253]  energy_before :  50  energy_after :  340  reward :  -497.0055460368926\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "action : 1  next_temperatures :  [-0.69731464 -1.47259304 -0.43376883 -1.88230156 -0.16995721 -0.84472938\n",
      " -0.6634585  -1.59791918 -1.35104523]  energy_before :  340  energy_after :  70  reward :  62.886912423386434\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "action : 1  next_temperatures :  [ 0.68705571 -0.19930464  0.30041276  0.12521277 -0.0503197  -0.25887283\n",
      " -0.07603889  0.51439481  0.22113133]  energy_before :  70  energy_after :  60  reward :  -186.73632867230293\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "action : 1  next_temperatures :  [-0.13900036 -0.50924984 -0.15560065 -0.77657151 -0.65016891 -0.42377301\n",
      " -0.32079706 -0.48225498 -0.86312836]  energy_before :  60  energy_after :  90  reward :  -232.32054468838885\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "action : 1  next_temperatures :  [ 0.88007886  0.0829968   0.25025128  0.5331043   1.21252075  0.03712812\n",
      "  1.09880034 -0.11446203  0.85000196]  energy_before :  90  energy_after :  50  reward :  -153.16957961835558\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "action : 1  next_temperatures :  [ 0.63101673 -1.94253698  0.13320784 -1.84052954 -0.2829482  -1.70302972\n",
      "  0.71860931 -1.32687344 -0.43484578]  energy_before :  50  energy_after :  70  reward :  -224.04792978181624\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "action : 1  next_temperatures :  [ 0.0083614  -1.19615542  0.61962214 -1.77418574  0.06100966 -1.35684176\n",
      "  0.75124373 -1.23791427  0.27534432]  energy_before :  70  energy_after :  160  reward :  -291.84951593975944\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "action : 1  next_temperatures :  [ 0.12666591 -1.38966175 -0.33800601 -0.9559455  -0.38264613 -1.23291056\n",
      "  0.59296678 -1.25239345 -0.32099851]  energy_before :  160  energy_after :  70  reward :  -113.15292923023071\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "action : 1  next_temperatures :  [-0.49598942  0.72969328 -0.20576213  0.68299215 -0.88113578  1.59497397\n",
      " -1.20682164  1.313711   -0.48363747]  energy_before :  70  energy_after :  120  reward :  -246.95197603196596\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "action : 1  next_temperatures :  [ 0.43799358 -0.42715624  1.04523466 -0.94120243  0.04439334 -0.41250654\n",
      "  0.13608486 -0.42082818  0.05849238]  energy_before :  120  energy_after :  40  reward :  -118.47949458568684\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "action : 1  next_temperatures :  [-0.98788713 -1.12327642 -1.39139699 -0.37359434 -0.2829482  -1.48794253\n",
      " -0.6634585  -1.20632335 -0.53785045]  energy_before :  40  energy_after :  80  reward :  -246.05467790617882\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "action : 1  next_temperatures :  [1.91538486 2.03501189 1.94370432 1.24292617 2.19581424 1.14003195\n",
      " 1.57332248 1.65815762 1.85093972]  energy_before :  80  energy_after :  40  reward :  -142.44470674255479\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "action : 1  next_temperatures :  [-0.42749733 -0.29396358 -0.83962076  0.66497284 -0.22146781 -0.55589801\n",
      " -0.47254712 -0.16974615 -0.16378086]  energy_before :  40  energy_after :  80  reward :  -240.47954877609342\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "action : 1  next_temperatures :  [-2.54452546 -0.99762296 -1.72884691 -0.93444519 -2.1273599  -0.53541351\n",
      " -2.13200752 -0.69724877 -1.77511124]  energy_before :  80  energy_after :  50  reward :  -181.47258146791506\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "action : 1  next_temperatures :  [ 0.25742353 -1.02024058 -0.15560065 -0.67746534  0.21554145 -1.45721578\n",
      "  0.36452582 -1.1372182   0.49219626]  energy_before :  50  energy_after :  230  reward :  -381.1180534958927\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "action : 1  next_temperatures :  [-0.24692729  0.36194749 -0.70737688  1.17442773  0.44816995  0.20202831\n",
      " -0.12499052 -0.02923235  0.41087678]  energy_before :  230  energy_after :  50  reward :  -16.511076779719474\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "action : 1  next_temperatures :  [-0.49598942  1.20801412 -0.58121317  0.3881308  -0.79805417  0.77354572\n",
      " -0.78094242  0.12279897 -0.81493904]  energy_before :  50  energy_after :  50  reward :  -198.9786486048194\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "action : 1  next_temperatures :  [-0.61429393  1.13848587 -0.40032785  1.27025766 -0.43747999  0.8472899\n",
      " -0.3550632   1.57477489 -0.84763894]  energy_before :  50  energy_after :  50  reward :  -195.8239955859314\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "action : 1  next_temperatures :  [-0.24692729 -0.64495558 -0.97642479  0.17517539 -0.0710901  -0.62068022\n",
      " -0.12499052 -0.69724877 -0.26678553]  energy_before :  50  energy_after :  40  reward :  -191.47392740388364\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "action : 1  next_temperatures :  [-0.3652318   1.61848209 -0.20576213  1.55774748 -0.13340131  1.09003116\n",
      " -0.32079706  1.36822729 -0.59206344]  energy_before :  40  energy_after :  70  reward :  -223.9827677107911\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "action : 1  next_temperatures :  [ 0.0083614  -0.73710145 -0.74841808  0.19155657 -0.08355234 -0.71977397\n",
      " -0.52149876 -0.52909291 -0.10956787]  energy_before :  70  energy_after :  110  reward :  -241.2490874079839\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "action : 1  next_temperatures :  [-0.80731709 -1.2715475  -1.61940369 -0.15490551 -1.03068267 -0.68904722\n",
      " -0.71730529 -1.07425574 -0.80891538]  energy_before :  110  energy_after :  60  reward :  -156.17338009399288\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "action : 1  next_temperatures :  [-0.86958262 -1.29919126 -1.70604624 -0.09593324 -1.00077329 -0.68904722\n",
      " -0.74993972 -1.09114811 -0.80891538]  energy_before :  60  energy_after :  60  reward :  -206.31057708003237\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "action : 1  next_temperatures :  [-0.3652318  -0.68600237 -1.02202613 -0.11149537 -0.18823517 -0.88467415\n",
      "  0.06312362 -0.88514895  0.05849238]  energy_before :  60  energy_after :  50  reward :  -192.0211979426055\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "action : 1  next_temperatures :  [1.06064891 0.36027211 1.1622781  0.18254692 0.80874413 1.18221139\n",
      " 0.36452582 1.15246566 0.8906617 ]  energy_before :  50  energy_after :  40  reward :  -180.83564526012933\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "action : 1  next_temperatures :  [ 0.10591073 -0.19930464 -0.41704834  0.37174962 -0.08355234 -0.22814609\n",
      " -0.27674059 -0.07530245  0.16149705]  energy_before :  40  energy_after :  110  reward :  -268.64093703454614\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "action : 1  next_temperatures :  [ 0.9423444   0.22540406  0.69106424 -0.31626019  2.23940942 -0.95534566\n",
      "  0.94705027 -0.90324792  0.64941392]  energy_before :  110  energy_after :  60  reward :  -144.4801674611053\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "action : 1  next_temperatures :  [1.50273419 1.86978901 0.83090836 2.34568252 1.5564786  1.02857768\n",
      " 1.22444286 1.46804583 1.7878866 ]  energy_before :  60  energy_after :  250  reward :  -374.38545434353364\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "action : 1  next_temperatures :  [ 0.90083404 -0.52684132  2.89968919 -2.46465272  0.75889517 -0.77200943\n",
      "  1.60463389 -0.76635392  0.10728407]  energy_before :  250  energy_after :  40  reward :  13.7414789625889\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "action : 1  next_temperatures :  [ 0.04572072 -1.24892988 -0.46416972 -0.79131458 -0.58204199 -1.25339506\n",
      "  0.45753393 -1.21323386 -0.32099851]  energy_before :  40  energy_after :  50  reward :  -213.37082896514977\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "action : 1  next_temperatures :  [ 0.5687512  -0.52684132  0.61962214 -0.56197798  0.36508834 -0.32032631\n",
      " -0.12499052  0.19267195  0.31148631]  energy_before :  50  energy_after :  70  reward :  -217.4765161879567\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "action : 1  next_temperatures :  [-0.738825   -0.52684132 -0.79401942 -0.36949905 -0.83128681 -0.41250654\n",
      " -0.76625693 -0.52304621 -0.75470239]  energy_before :  70  energy_after :  140  reward :  -273.7169836795601\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "action : 1  next_temperatures :  [-1.02939749  0.6794319  -0.66177553  0.52573276 -1.18521446  1.64311253\n",
      " -0.73199078  1.0457366  -1.11612229]  energy_before :  140  energy_after :  50  reward :  -108.83048677410497\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "action : 1  next_temperatures :  [ 0.25742353  0.47084715 -0.56601272  1.42014551  0.7140311  -0.11650559\n",
      "  0.65823563 -0.17665666  0.66025651]  energy_before :  50  energy_after :  50  reward :  -194.6782355360193\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "action : 1  next_temperatures :  [-0.30296627 -0.19930464 -0.38360736  0.26527191 -0.08355234 -0.47396003\n",
      " -0.12499052  0.22415319  0.43256198]  energy_before :  50  energy_after :  110  reward :  -258.64639407356276\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "action : 1  next_temperatures :  [-0.11616967 -1.07050196 -0.27872427 -0.69548464 -0.08355234 -1.45721578\n",
      "  0.54238343 -1.0427745  -0.59206344]  energy_before :  110  energy_after :  110  reward :  -202.79410318622627\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "action : 1  next_temperatures :  [-0.05390414 -0.44223466  0.16360874 -0.61112154 -0.75152847  0.66292944\n",
      "  0.24541018  0.27559813 -0.16378086]  energy_before :  110  energy_after :  50  reward :  -138.6750231703218\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "action : 1  next_temperatures :  [-0.49598942 -1.75908293 -0.52041138 -1.66934615 -1.03068267 -1.3957623\n",
      " -0.71730529 -1.45049487 -1.19382757]  energy_before :  50  energy_after :  50  reward :  -208.23290257685073\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "action : 1  next_temperatures :  [-0.24692729  1.79439694 -0.02335676  1.6879779  -0.29956452  2.30988284\n",
      " -1.0110151   2.34337769 -0.06318565]  energy_before :  50  energy_after :  70  reward :  -211.50841395455504\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "action : 1  next_temperatures :  [-0.84882744 -0.87196949 -1.29563417 -0.16964858 -1.08053164 -0.65012668\n",
      "  0.21277576 -0.76635392 -0.86312836]  energy_before :  70  energy_after :  70  reward :  -204.33344453059985\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "action : 1  next_temperatures :  [-0.42749733  0.71126411 -0.10999931  0.69773522 -0.88113578  1.58473172\n",
      " -1.15297484  1.32753203 -0.46466292]  energy_before :  70  energy_after :  130  reward :  -256.71500711228964\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "action : 1  next_temperatures :  [ 0.3617183  -0.52453768  2.64128159 -2.32295546  0.41493731 -1.1806751\n",
      "  0.83772495 -1.0427745   0.43256198]  energy_before :  130  energy_after :  100  reward :  -168.38271861842404\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "action : 1  next_temperatures :  [ 0.5687512  -0.24370219 -0.38360736  0.92870994  0.54288298  0.07912134\n",
      " -0.52149876  0.40613008  0.27534432]  energy_before :  100  energy_after :  350  reward :  -446.3478684540482\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "action : 1  next_temperatures :  [-1.05015267 -1.29919126 -1.06762747 -1.06406133 -0.83128681 -0.78122745\n",
      " -1.0110151  -1.25239345 -1.13419329]  energy_before :  350  energy_after :  90  reward :  52.50885117882615\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "action : 1  next_temperatures :  [-1.25770444  0.17765574 -1.13298939  0.35454937 -0.98581861  0.4253093\n",
      " -1.1040232   0.27022329 -0.86312836]  energy_before :  90  energy_after :  30  reward :  -142.11592630034716\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "action : 1  next_temperatures :  [-1.05015267 -1.67363857 -0.58121317 -1.70866099 -1.13370387 -1.54120221\n",
      " -0.43664926 -1.44204868 -0.75470239]  energy_before :  30  energy_after :  20  reward :  -198.32197181275035\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "action : 1  next_temperatures :  [ 1.91368671  1.92675191  2.89968919 -0.09888185  3.08850346  1.2651736\n",
      "  1.78412322  1.30680049  1.68488193]  energy_before :  20  energy_after :  40  reward :  -202.22927135345608\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "action : 1  next_temperatures :  [-1.05015267 -0.53438053 -0.52041138 -0.69548464 -1.03068267 -0.71977397\n",
      " -0.17394215 -0.8055135  -0.86312836]  energy_before :  40  energy_after :  50  reward :  -214.39346987420927\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "action : 1  next_temperatures :  [ 0.37572804  0.88885433  0.5740208   0.43563624 -0.56542567  1.85819973\n",
      " -0.61450686  0.66949747 -0.11559154]  energy_before :  50  energy_after :  120  reward :  -264.4935874545558\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "action : 1  next_temperatures :  [-0.24692729 -1.70714616 -0.02335676 -1.80121469 -0.78143785 -1.6108495\n",
      "  0.11976765 -1.71079092 -0.16378086]  energy_before :  120  energy_after :  110  reward :  -195.92573637875816\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "action : 1  next_temperatures :  [-1.2992148  -0.89458712 -1.70604624  0.06869768 -0.93596964 -0.53541351\n",
      " -0.52149876 -0.86079762 -1.06190931]  energy_before :  110  energy_after :  70  reward :  -165.74673931181346\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "action : 1  next_temperatures :  [-0.40674216 -0.29396358 -0.33800601  0.01955412 -0.18823517 -0.56614025\n",
      " -0.07603889 -0.61144321 -0.16378086]  energy_before :  70  energy_after :  30  reward :  -160.62479600308606\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "action : 1  next_temperatures :  [-0.49598942 -0.9448485  -1.06762747 -0.04678968 -0.06693602 -1.47770028\n",
      " -0.07603889 -1.01697525  0.22113133]  energy_before :  30  energy_after :  60  reward :  -232.97177417141654\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "action : 1  next_temperatures :  [ 0.31968906 -0.51762674  0.11800739 -0.49645324 -0.38264613 -0.13903853\n",
      " -0.8103134  -0.12981873 -0.68482788]  energy_before :  60  energy_after :  50  reward :  -190.7230281856758\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "action : 1  next_temperatures :  [ 1.50273419 -1.43070855  0.50835487 -1.13777666  0.86357799 -1.33430881\n",
      "  1.53936504 -1.57258063  2.23677011]  energy_before :  50  energy_after :  60  reward :  -206.8245724401439\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "action : 1  next_temperatures :  [-2.27470815  0.79754615 -1.47803954  0.92870994 -1.57902129  0.8268054\n",
      " -1.94109615  1.09718154 -1.56789717]  energy_before :  60  energy_after :  50  reward :  -193.19051925707174\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "action : 1  next_temperatures :  [-1.21826961  1.11586825 -0.44896928  0.8549946  -1.34639278  1.39729859\n",
      " -2.03410425  1.55788252 -1.57392083]  energy_before :  50  energy_after :  40  reward :  -189.6956127921445\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "action : 1  next_temperatures :  [ 1.87632739 -0.36014107  1.39028481 -0.51447254  1.66116143 -0.24863058\n",
      "  1.68132478 -0.37475808  1.57645596]  energy_before :  40  energy_after :  40  reward :  -191.31244790297427\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "action : 1  next_temperatures :  [-0.55825495 -0.92223088 -0.68783344 -0.54559679 -0.63189095 -0.1666926\n",
      " -0.7295432  -0.69724877 -0.75470239]  energy_before :  40  energy_after :  70  reward :  -233.6939939906501\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "action : 1  next_temperatures :  [-0.5167446  -0.92223088 -0.10999931 -1.20903482 -0.93596964 -0.7627914\n",
      "  0.45753393 -1.11187965 -1.02576732]  energy_before :  70  energy_after :  60  reward :  -194.1368836947671\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "action : 1  next_temperatures :  [-0.24692729  0.91482271  0.16360874  0.46839861 -0.18823517  1.95037995\n",
      "  0.01696922  1.51181242  0.0042794 ]  energy_before :  60  energy_after :  70  reward :  -203.40489140172267\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "action : 1  next_temperatures :  [ 0.27817871  0.83691757 -0.17232114  1.31940122  0.75889517  0.0483946\n",
      "  0.60928399  0.28404432  0.7036269 ]  energy_before :  70  energy_after :  650  reward :  -773.3335786751575\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "action : 1  next_temperatures :  [ 0.12666591 -1.22128612 -0.56601272 -0.69548464  0.06100966 -1.62109174\n",
      "  0.21277576 -1.55184908  0.49219626]  energy_before :  650  energy_after :  80  reward :  367.2369232775293\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "action : 1  next_temperatures :  [ 0.77215194 -0.41961704  0.75642617 -0.68483687  0.36508834 -0.75357338\n",
      "  0.85404217 -0.12137255  0.27534432]  energy_before :  80  energy_after :  140  reward :  -256.95634690606107\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "action : 1  next_temperatures :  [ 0.50648566  0.3527329   1.21243958 -0.58736882  0.50965034  0.02586165\n",
      "  1.14775197 -0.02923235  0.84070831]  energy_before :  140  energy_after :  60  reward :  -114.02097076085741\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "action : 1  next_temperatures :  [-1.672808   -1.21290922 -1.52364088 -0.84864873 -1.41618134 -1.14073034\n",
      " -1.29982974 -1.1809848  -1.21189857]  energy_before :  60  energy_after :  80  reward :  -229.50763160080427\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "action : 1  next_temperatures :  [-0.45032803 -0.36935565  0.02224458 -0.84864873 -0.78143785 -0.09499687\n",
      "  0.13608486 -0.54368178 -0.75470239]  energy_before :  80  energy_after :  60  reward :  -181.68482186130444\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "action : 1  next_temperatures :  [-0.05390414 -0.69354158 -0.27872427 -0.44976686 -0.83128681 -0.20049202\n",
      "  0.76919267 -0.48225498 -0.3607547 ]  energy_before :  60  energy_after :  140  reward :  -280.5815326922643\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "action : 1  next_temperatures :  [ 0.39648322  1.21387795  0.61962214  0.75670749  0.11584352  1.91248364\n",
      " -0.32079706  2.0185835  -0.47821617]  energy_before :  140  energy_after :  300  reward :  -351.76541177093725\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "action : 1  next_temperatures :  [-0.49598942 -1.18107701 -0.03703716 -1.63658377 -0.38264613 -1.33430881\n",
      " -0.07603889 -1.17522603 -0.48363747]  energy_before :  300  energy_after :  80  reward :  15.197455300060426\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "action : 1  next_temperatures :  [-0.98788713 -1.17940163 -1.25003283 -0.94693585 -0.88113578 -0.23838833\n",
      " -1.05507157 -1.10573697 -0.75470239]  energy_before :  80  energy_after :  60  reward :  -186.39929248674335\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "action : 1  next_temperatures :  [-0.42749733 -1.5731158  -0.38360736 -1.54648725 -1.03068267 -1.04056116\n",
      " -0.61450686 -1.30460623 -0.97697563]  energy_before :  60  energy_after :  110  reward :  -256.8980402946228\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "action : 1  next_temperatures :  [ 1.93236637 -0.15909553  3.41194425 -1.92407359  1.96025522 -0.53541351\n",
      "  1.94240017 -0.17512099  1.90173387]  energy_before :  110  energy_after :  50  reward :  -129.6450037439823\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "action : 1  next_temperatures :  [-0.65580429 -0.8795087  -1.29563417  0.04166872 -0.33279717 -1.30358207\n",
      " -0.61450686 -0.91377823 -0.3806328 ]  energy_before :  50  energy_after :  60  reward :  -214.33457556941167\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "action : 1  next_temperatures :  [-0.24692729 -1.02024058 -0.35320646 -0.92318313 -0.48732896 -0.99631465\n",
      " -0.41870032 -0.86079762 -0.43484578]  energy_before :  60  energy_after :  50  reward :  -193.7415447835983\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "action : 1  next_temperatures :  [ 0.99838337  0.60403982  1.19419904  0.43563624  0.80874413 -0.04685831\n",
      "  1.14775197  0.29940102  0.83296359]  energy_before :  50  energy_after :  50  reward :  -191.7257391204479\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "action : 1  next_temperatures :  [ 0.12666591 -0.86945643 -0.70737688 -0.08119017  0.36508834 -0.93486116\n",
      "  0.50648556 -1.20632335  0.52833825]  energy_before :  50  energy_after :  100  reward :  -250.27262992256675\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "action : 1  next_temperatures :  [ 0.81781333 -1.5982465   1.98766237 -2.88810638  0.36508834 -1.76448321\n",
      "  1.14775197 -1.38830024  0.54640924]  energy_before :  100  energy_after :  50  reward :  -150.77441106093843\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "action : 1  next_temperatures :  [-0.22617211  0.23629403 -0.83962076  1.26288613  0.26040552 -0.28140577\n",
      "  0.52606622 -0.01387565  0.43256198]  energy_before :  50  energy_after :  40  reward :  -186.64286043446967\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "action : 1  next_temperatures :  [ 0.37572804  1.24906092  0.66066335  0.68299215 -0.18823517  1.96094227\n",
      "  0.26172739  1.26073039  0.53135008]  energy_before :  40  energy_after :  50  reward :  -201.20504057235877\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "action : 1  next_temperatures :  [ 0.25742353  0.12739436 -0.02335676  0.07299774 -0.68672482 -0.01305889\n",
      "  0.49016835 -0.45307725 -0.43484578]  energy_before :  50  energy_after :  90  reward :  -238.66307951949707\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "action : 1  next_temperatures :  [-1.672808   -0.16705358 -1.29563417 -0.16964858 -1.32977646  0.36590427\n",
      " -1.20682164 -0.23654779 -1.40525821]  energy_before :  90  energy_after :  60  reward :  -175.11764416281602\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "action : 1  next_temperatures :  [-0.42749733 -0.71867227 -0.55081227 -0.66845569 -0.68672482 -0.15747458\n",
      " -0.56555523 -0.62200094 -0.75470239]  energy_before :  60  energy_after :  40  reward :  -183.15189552482406\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "action : 1  next_temperatures :  [-0.67655947 -0.87196949 -0.69217643 -0.81834354 -0.88113578 -0.62759374\n",
      " -0.6634585  -0.88152916 -0.26678553]  energy_before :  40  energy_after :  50  reward :  -214.37955163174905\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "action : 1  next_temperatures :  [0.90083404 1.24152171 0.54796289 1.53914313 1.27400114 0.86777439\n",
      " 1.19180844 1.07645    1.63066894]  energy_before :  50  energy_after :  60  reward :  -197.729835314878\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "action : 1  next_temperatures :  [ 0.5687512  -1.02024058 -0.06439797 -0.45713839 -0.20485149 -1.0065569\n",
      " -0.27674059 -1.05045285 -0.59206344]  energy_before :  60  energy_after :  60  reward :  -202.1036910011832\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "action : 1  next_temperatures :  [-0.55825495 -0.27720978 -0.83962076  0.12603183 -1.00077329 -0.42377301\n",
      " -0.27510886 -0.47457663 -0.79445858]  energy_before :  60  energy_after :  90  reward :  -232.51774405582765\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "action : 1  next_temperatures :  [ 0.68705571 -0.69605465  0.16360874 -0.37359434  0.80874413 -0.71977397\n",
      "  0.80509053 -0.86079762 -0.03186259]  energy_before :  90  energy_after :  50  reward :  -158.2175840625109\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "action : 1  next_temperatures :  [-0.67655947  0.45995719 -0.46416972  0.5511236  -0.53219302  0.60147596\n",
      "  0.36452582  0.22415319 -0.53785045]  energy_before :  50  energy_after :  60  reward :  -208.0095369106698\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "action : 1  next_temperatures :  [-1.63129764 -1.37290796 -0.87306175 -1.54648725 -1.49926294 -1.23495901\n",
      " -1.05507157 -1.38830024 -1.29683224]  energy_before :  60  energy_after :  40  reward :  -189.8981806046711\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n",
      "action : 1  next_temperatures :  [ 0.74932124 -0.81919504  0.64698295 -1.09518558  0.39832099 -0.82424489\n",
      "  0.9960019  -1.06580955  0.60062223]  energy_before :  40  energy_after :  100  reward :  -258.4131857525523\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n",
      "action : 1  next_temperatures :  [ 1.37197657 -0.18422622  1.38116454 -0.93579664  1.16267178 -0.56614025\n",
      "  1.29460687 -0.1290509   1.30539103]  energy_before :  100  energy_after :  50  reward :  -143.2994032132683\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "action : 1  next_temperatures :  [-0.80731709  2.50643321 -0.23616302  1.96072465 -0.88113578  2.01183344\n",
      " -1.15297484  1.64388004 -1.13419329]  energy_before :  50  energy_after :  160  reward :  -304.08891267470983\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "action : 1  next_temperatures :  [1.95783864 1.77148231 2.06078885 0.85586531 2.12036103 0.88444132\n",
      " 1.60639791 1.51216521 1.89123315]  energy_before :  160  energy_after :  90  reward :  -113.3394262581296\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "action : 1  next_temperatures :  [-0.49598942 -0.71867227 -0.61161406 -0.61931213 -0.68672482 -0.13903853\n",
      " -0.61450686 -0.61355476 -0.75470239]  energy_before :  90  energy_after :  50  reward :  -163.25411524561548\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "action : 1  next_temperatures :  [0.63101673 0.94665492 0.43265665 0.74851689 0.41493731 0.46627829\n",
      " 0.85404217 0.70558571 0.86084456]  energy_before :  50  energy_after :  80  reward :  -221.93946677535723\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "action : 1  next_temperatures :  [-0.98788713 -0.19930464 -0.97642479 -0.09593324 -0.63189095 -1.23188634\n",
      " -1.25577327 -0.79706731 -0.80891538]  energy_before :  80  energy_after :  50  reward :  -174.98508305341053\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "action : 1  next_temperatures :  [ 0.195158   -0.29396358 -0.47937017  0.60927681  0.31025448 -0.07451237\n",
      " -0.03198241  0.10897794  0.22113133]  energy_before :  50  energy_after :  50  reward :  -197.43502996694588\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "action : 1  next_temperatures :  [0.43799358 0.81178688 0.80202751 0.33653007 0.18230881 0.56050697\n",
      " 0.21277576 1.01425537 0.05849238]  energy_before :  50  energy_after :  80  reward :  -223.58332269474994\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "action : 1  next_temperatures :  [ 2.18765506 -1.01270137  2.62608114 -2.21893493  1.96025522 -0.53541351\n",
      "  2.02888139 -0.78324628  2.44386372]  energy_before :  80  energy_after :  50  reward :  -161.30355957598928\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "action : 1  next_temperatures :  [-0.69731464  0.29493231 -0.38588742  0.46184614 -0.78143785 -0.06661121\n",
      " -1.54458791  0.82306446 -0.98307459]  energy_before :  50  energy_after :  50  reward :  -200.87907072443542\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "action : 1  next_temperatures :  [ 0.02237114 -0.37501006 -0.97642479  0.69036368  0.06100966 -0.55589801\n",
      "  0.94705027 -0.44616674  0.45244007]  energy_before :  50  energy_after :  40  reward :  -188.18026476441275\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "action : 1  next_temperatures :  [0.81781333 2.6220344  2.27191073 0.69036368 1.69730193 2.01260161\n",
      " 1.39251014 1.7813225  1.57645596]  energy_before :  40  energy_after :  50  reward :  -193.13768573278495\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "action : 1  next_temperatures :  [ 0.43799358 -0.59992975  0.69613106 -0.80332745 -0.53219302  0.14979285\n",
      " -0.31233628  0.41887045  0.31750997]  energy_before :  50  energy_after :  110  reward :  -258.2274886040873\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "action : 1  next_temperatures :  [-1.18091029 -0.41961704 -0.66177553 -0.38260399 -1.48430825 -0.01305889\n",
      " -1.0110151  -0.5068257  -0.88300646]  energy_before :  110  energy_after :  90  reward :  -184.543121248714\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "action : 1  next_temperatures :  [ 0.81781333  1.90622852  1.01483377  0.82223223  0.01116069  2.14600688\n",
      " -0.27674059  2.67892157 -0.44839903]  energy_before :  90  energy_after :  70  reward :  -169.3279426331707\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "action : 1  next_temperatures :  [ 1.19140653  0.23629403  1.89645969 -0.96331703  1.16267178 -0.18922555\n",
      "  1.34355851  0.04678331  1.00876856]  energy_before :  70  energy_after :  50  reward :  -172.26660017802493\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "action : 1  next_temperatures :  [ 0.50648566 -0.16831012 -0.07959842  0.4102454   0.31025448  0.10677541\n",
      "  0.31557419 -0.12137255  0.60062223]  energy_before :  50  energy_after :  100  reward :  -246.11932370576397\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "action : 1  next_temperatures :  [1.37197657 1.28256851 0.84762885 1.39852235 2.1247568  0.26348179\n",
      " 1.68132478 0.75165581 1.51682167]  energy_before :  100  energy_after :  60  reward :  -146.76126285933654\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "action : 1  next_temperatures :  [-1.11656923  0.42896267 -0.70737688 -0.75118068 -0.38264613 -0.64910246\n",
      " -1.12034042 -0.79169247 -1.19382757]  energy_before :  60  energy_after :  90  reward :  -234.28377316453714\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "action : 1  next_temperatures :  [-0.34447662 -1.2715475  -0.43376883 -1.31551253 -0.68672482 -0.96866058\n",
      " -0.76625693 -1.33531962 -0.97697563]  energy_before :  90  energy_after :  120  reward :  -236.09924306209922\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "action : 1  next_temperatures :  [-0.24692729  1.08236066  0.02224458  0.60927681  0.88019431  1.2651736\n",
      "  0.19809027  1.00734485 -0.39569196]  energy_before :  120  energy_after :  60  reward :  -133.5779341686386\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "action : 1  next_temperatures :  [1.87632739 1.70895258 1.05739502 2.17056764 2.15965108 1.58473172\n",
      " 2.07783302 1.19162524 2.33001645]  energy_before :  60  energy_after :  250  reward :  -371.8428998597142\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "action : 1  next_temperatures :  [-0.5167446  -1.39720096  0.54361991 -1.74142336 -0.47071263 -1.48794253\n",
      "  0.31557419 -1.47429775 -0.63181963]  energy_before :  250  energy_after :  60  reward :  -14.860947365850137\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "action : 1  next_temperatures :  [ 0.43799358 -0.01501289  0.21985039  0.19892811 -0.38264613  0.4253093\n",
      " -0.71730529  0.20111814 -0.7330172 ]  energy_before :  60  energy_after :  110  reward :  -248.36478200387793\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "action : 1  next_temperatures :  [ 0.50648566 -1.1735378   1.58789062 -2.34179383  0.31025448 -1.17043285\n",
      "  0.82140774 -1.27312499  0.62501807]  energy_before :  110  energy_after :  800  reward :  -890.1078328986496\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "action : 1  next_temperatures :  [2.06312399 0.93995341 1.39028481 1.17442773 2.15965108 0.3218626\n",
      " 2.21979276 0.82076096 2.11858581]  energy_before :  800  energy_after :  100  reward :  515.2084431316841\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "action : 1  next_temperatures :  [-0.55825495 -0.42401491 -0.26675392 -0.55849698 -0.79390009 -0.3330011\n",
      " -0.90821667 -0.60510857 -0.86312836]  energy_before :  100  energy_after :  150  reward :  -253.31087554752526\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "action : 1  next_temperatures :  [ 2.22501438  2.11020597  3.6551514  -0.39161365  3.03200796  1.57797183\n",
      "  2.4547606   1.26073039  2.44386372]  energy_before :  150  energy_after :  70  reward :  -99.63190738912223\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "action : 1  next_temperatures :  [-0.24692729 -1.24892988 -0.36840691 -1.3564655  -0.68672482 -1.0065569\n",
      " -0.76625693 -1.35067632 -0.96613303]  energy_before :  70  energy_after :  70  reward :  -205.99707756471122\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "action : 1  next_temperatures :  [-0.42749733 -0.48411915 -0.35320646 -0.59474035  0.01116069 -0.65473569\n",
      " -1.04038608 -0.88152916 -1.24804056]  energy_before :  70  energy_after :  80  reward :  -213.6730940908928\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "action : 1  next_temperatures :  [-0.01239378 -0.61228568 -0.22096257 -0.75118068 -0.26799351 -1.22164409\n",
      "  0.26172739 -0.69033825 -0.24871453]  energy_before :  80  energy_after :  80  reward :  -201.76378570648464\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "action : 1  next_temperatures :  [ 0.33836872  0.24467092  0.52841946 -1.24998779  0.01116069 -0.89594062\n",
      "  0.60928399 -0.52711848  1.39032471]  energy_before :  80  energy_after :  50  reward :  -167.55081838281146\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "action : 1  next_temperatures :  [ 0.195158    0.46079488 -0.29240467  0.43563624 -0.53219302  0.38638876\n",
      "  0.26172739 -0.82010236 -0.97697563]  energy_before :  50  energy_after :  60  reward :  -208.88197042469054\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "action : 1  next_temperatures :  [-0.24692729  1.55984381  0.02224458  1.22357128 -0.18214252  1.61545846\n",
      " -0.47254712  1.81357156 -0.48363747]  energy_before :  60  energy_after :  510  reward :  -643.1505646983334\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "action : 1  next_temperatures :  [2.37445166 2.08591296 1.94206103 1.85401292 1.96025522 1.76909217\n",
      " 2.21979276 1.49963676 2.44386372]  energy_before :  510  energy_after :  100  reward :  230.14907919782567\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "action : 1  next_temperatures :  [ 0.12666591 -0.3165812   0.81266782 -0.42355696  0.31025448 -0.50775944\n",
      "  0.39716025 -0.19892388  0.43256198]  energy_before :  100  energy_after :  250  reward :  -347.36751104314993\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "action : 1  next_temperatures :  [ 0.195158   -1.07050196 -0.43376883 -0.50546289 -0.22146781 -1.12946386\n",
      " -0.07603889 -0.97597286 -0.59206344]  energy_before :  250  energy_after :  50  reward :  -2.809582543528876\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "action : 1  next_temperatures :  [-0.11616967 -0.56788812  1.06423522 -1.111362   -0.18823517 -0.81502687\n",
      "  0.47385114 -0.76635392 -0.32099851]  energy_before :  50  energy_after :  120  reward :  -270.3479478973029\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "action : 1  next_temperatures :  [ 1.06064891  0.15252505  1.72925477 -0.59474035  1.30723378 -0.25887283\n",
      "  1.39251014  0.10897794 -0.10956787]  energy_before :  120  energy_after :  110  reward :  -183.21203045499792\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "action : 1  next_temperatures :  [ 1.12914099  0.34351831  0.92515113  0.16108757  1.05798895 -0.13903853\n",
      "  1.16243746  0.2310637   1.60898375]  energy_before :  110  energy_after :  80  reward :  -161.5196666649644\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "action : 1  next_temperatures :  [-0.82807226 -0.9038017  -0.83962076 -0.64634109 -0.38264613 -0.97211734\n",
      " -1.1040232  -0.65117867 -1.29683224]  energy_before :  80  energy_after :  80  reward :  -205.62463340532656\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "action : 1  next_temperatures :  [ 0.06440038 -0.55280971 -0.47937017 -0.02139884 -0.2829482  -0.81502687\n",
      "  0.21277576 -0.32085607  0.22113133]  energy_before :  80  energy_after :  60  reward :  -179.97410238912198\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "action : 1  next_temperatures :  [ 1.93236637 -0.39197328  0.80202751  0.14241301  1.21252075 -1.82900937\n",
      "  2.02888139 -0.16974615  2.33001645]  energy_before :  60  energy_after :  70  reward :  -201.94250331830273\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "action : 1  next_temperatures :  [-0.32372145  1.18037036  0.07240605  0.35454937 -0.40092408  1.17299337\n",
      " -0.96206346  0.76605271 -0.32099851]  energy_before :  70  energy_after :  120  reward :  -246.4613356401536\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n",
      "action : 1  next_temperatures :  [-0.30296627 -1.2715475  -1.06762747 -0.299879    0.21554145 -1.275928\n",
      "  0.01696922 -1.38830024  0.3295573 ]  energy_before :  120  energy_after :  310  reward :  -393.04418050879474\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "action : 1  next_temperatures :  [ 0.74932124 -0.65249478  1.80069687 -1.85691072  0.46478627 -0.53541351\n",
      "  1.0498487  -0.48225498  0.7036269 ]  energy_before :  310  energy_after :  60  reward :  53.241205992853196\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "action : 1  next_temperatures :  [ 0.5687512  -0.30150278  0.61962214 -0.67746534  0.91342696 -0.84268094\n",
      "  0.80509053 -0.12086066  0.60062223]  energy_before :  60  energy_after :  100  reward :  -236.43499665814534\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "action : 1  next_temperatures :  [ 1.83481704e+00 -5.00872942e-01  7.56426167e-01  2.00284935e-03\n",
      "  1.09454486e+00 -2.04409657e+00  1.97503459e+00 -2.46419954e-01\n",
      "  2.27580346e+00]  energy_before :  100  energy_after :  50  reward :  -142.85276049398232\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "action : 1  next_temperatures :  [1.56499973 0.01681932 0.66066335 0.36355902 1.5564786  0.08833936\n",
      " 1.60463389 0.20879649 1.00024937]  energy_before :  50  energy_after :  50  reward :  -190.9354608648023\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "action : 1  next_temperatures :  [ 0.54799602  0.46247026  0.95099189 -0.26711663  0.44816995 -0.09499687\n",
      "  0.60928399  0.35314946  0.87168715]  energy_before :  50  energy_after :  50  reward :  -194.11836477944078\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "action : 1  next_temperatures :  [-0.30296627 -0.56034891 -0.38360736 -0.67910346 -0.003794   -0.9778786\n",
      " -1.25577327 -0.95908049 -1.13419329]  energy_before :  50  energy_after :  50  reward :  -204.25674564308994\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "action : 1  next_temperatures :  [ 0.81781333  1.21471564  0.91907095  0.39550234 -0.23808413  1.91965321\n",
      " -0.36974869  1.95869237  0.7036269 ]  energy_before :  50  energy_after :  50  reward :  -190.6787580853679\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "action : 1  next_temperatures :  [-0.67655947  0.19357185 -0.52041138 -0.29250747 -0.15334089  0.05658839\n",
      " -1.29982974 -0.83545906 -1.19382757]  energy_before :  50  energy_after :  100  reward :  -252.7217753385761\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "action : 1  next_temperatures :  [-1.11864475 -1.12327642 -1.13298939 -0.79131458 -0.96920228 -1.36810823\n",
      " -0.6634585  -1.38138972 -0.97697563]  energy_before :  100  energy_after :  60  reward :  -167.5253595049205\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "action : 1  next_temperatures :  [-0.9256216  -0.79657742 -1.32907516  0.01955412 -0.76648316 -0.52619549\n",
      " -1.1040232  -0.63044713 -0.65169772]  energy_before :  60  energy_after :  60  reward :  -204.71056675549474\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "action : 1  next_temperatures :  [ 0.02704106  2.60695598  0.55882036  0.5593142   0.41493731 -0.56614025\n",
      "  0.47921251 -0.08616183  1.12468108]  energy_before :  60  energy_after :  50  reward :  -182.88133959146754\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "action : 1  next_temperatures :  [-0.61429393  0.78916925 -0.10999931  0.23169048 -0.63189095  0.87494397\n",
      " -0.71730529  1.0303799  -0.16378086]  energy_before :  50  energy_after :  50  reward :  -197.31108675157284\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "action : 1  next_temperatures :  [ 0.1723273  -0.13312715  1.50124807 -1.20166329  0.16569248 -0.1666926\n",
      "  0.49016835 -0.35940138  0.6927843 ]  energy_before :  50  energy_after :  90  reward :  -236.8386639143792\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "action : 1  next_temperatures :  [-1.36148033 -0.76139445 -1.6604449   0.01136353 -1.18521446 -0.67061118\n",
      " -0.96206346 -1.1372182  -1.13419329]  energy_before :  90  energy_after :  50  reward :  -166.86125675276523\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "action : 1  next_temperatures :  [1.12914099 1.348746   1.44044628 0.60387102 1.16267178 0.60147596\n",
      " 1.39251014 0.96127475 2.37261236]  energy_before :  50  energy_after :  50  reward :  -186.98725070736856\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "action : 1  next_temperatures :  [ 0.50648566 -1.07050196 -0.37220702 -0.50321047  0.66418213 -1.42956172\n",
      "  0.59529781 -1.62589031  0.81747417]  energy_before :  50  energy_after :  50  reward :  -200.4179317097663\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "action : 1  next_temperatures :  [ 0.0083614   0.99021479 -0.02335676  0.99423468 -0.08355234  1.46182475\n",
      "  0.49016835  1.20544627 -0.55953565]  energy_before :  50  energy_after :  90  reward :  -233.51619451153374\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "action : 1  next_temperatures :  [-1.672808    0.90560813 -1.02202613  0.92870994 -1.2799275   1.36964452\n",
      " -1.54458791  1.18317906 -1.35104523]  energy_before :  90  energy_after :  70  reward :  -180.48325311963356\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "action : 1  next_temperatures :  [ 0.5687512   1.16445425  0.75642617 -0.21961119 -0.43747999  1.37681409\n",
      " -0.28816263  0.49212759  0.49219626]  energy_before :  70  energy_after :  760  reward :  -884.094484257078\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "action : 1  next_temperatures :  [-0.55825495 -0.99762296 -1.06762747 -0.19503942 -0.13340131 -0.78122745\n",
      " -0.41870032 -1.0427745  -0.65169772]  energy_before :  760  energy_after :  40  reward :  516.1536539008363\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "action : 1  next_temperatures :  [-0.24692729  0.73723249 -0.35320646  0.39550234 -0.76648316  0.80427246\n",
      " -0.71730529 -0.25958284 -0.93782181]  energy_before :  40  energy_after :  100  reward :  -259.3443195659853\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "action : 1  next_temperatures :  [ 0.0083614  -0.12558794  0.3460141  -0.39161365  0.11584352 -0.22814609\n",
      "  0.31557419  0.0705862   0.27534432]  energy_before :  100  energy_after :  250  reward :  -347.6136239530244\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "action : 1  next_temperatures :  [-1.16015511 -1.31426968 -1.13298939 -1.03703237 -0.91769169 -0.79454237\n",
      " -1.05507157 -1.25239345 -1.13419329]  energy_before :  250  energy_after :  50  reward :  -7.7983389085538874\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "action : 1  next_temperatures :  [ 0.06440038 -0.07365118 -0.02335676  0.12603183 -0.53219302  0.30342656\n",
      "  0.01696922 -0.25958284  0.13903739]  energy_before :  50  energy_after :  60  reward :  -208.23891843245207\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "action : 1  next_temperatures :  [-1.09581406 -0.75385524 -1.02202613 -0.61931213 -0.43581836 -0.08475462\n",
      " -1.1040232  -0.58207352 -0.75470239]  energy_before :  60  energy_after :  120  reward :  -264.45237965908933\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n",
      "action : 1  next_temperatures :  [-0.11616967  0.76152549 -0.06439797  0.80585104 -0.18823517  0.87494397\n",
      "  0.31557419  1.05111145 -0.70591071]  energy_before :  120  energy_after :  60  reward :  -135.26570737661316\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "action : 1  next_temperatures :  [-1.13939993 -0.46066383 -1.05242702 -0.69548464 -1.11376428 -0.80376039\n",
      " -1.02570059 -1.33531962 -1.13419329]  energy_before :  60  energy_after :  80  reward :  -226.76071360806867\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "action : 1  next_temperatures :  [-1.88035977  0.81178688 -0.93538358  0.4102454  -1.51421763  1.02140811\n",
      " -1.05507157  0.74474529 -1.13419329]  energy_before :  80  energy_after :  60  reward :  -181.5310401654021\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "action : 1  next_temperatures :  [ 0.90083404 -0.11804873  0.80202751 -0.40799483  0.38170466 -0.09499687\n",
      "  0.65823563 -0.02923235  0.82831677]  energy_before :  60  energy_after :  60  reward :  -195.07915417699064\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "action : 1  next_temperatures :  [2.18765506 2.07837376 1.89645969 1.80767757 1.86055729 1.51651835\n",
      " 2.21979276 1.75905528 2.80347652]  energy_before :  60  energy_after :  50  reward :  -169.87043373019935\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "action : 1  next_temperatures :  [1.70594625 3.33509113 1.36608734 3.15242641 2.56805005 2.40094573\n",
      " 1.41015037 2.37838681 1.65215877]  energy_before :  50  energy_after :  70  reward :  -198.03075713238601\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "action : 1  next_temperatures :  [2.06312399 1.94518109 1.35771242 2.12079224 2.10980211 1.79674624\n",
      " 2.21979276 1.43974563 2.38965073]  energy_before :  70  energy_after :  60  reward :  -170.55745279098383\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "action : 1  next_temperatures :  [-0.57693461 -0.3165812  -0.62833455 -0.09593324 -0.48732896 -0.22814609\n",
      " -0.07603889 -0.67651722 -0.32099851]  energy_before :  60  energy_after :  50  reward :  -191.40681327262558\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "action : 1  next_temperatures :  [-0.47315873 -0.71867227 -0.56601272 -0.64634109 -0.68672482 -0.12777206\n",
      " -0.61450686 -0.63044713 -0.80891538]  energy_before :  50  energy_after :  70  reward :  -223.27255104783796\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "action : 1  next_temperatures :  [-1.69563869  0.97932482 -0.79401942  0.65022978 -2.23204273  1.4515825\n",
      " -2.54320125  2.24202347 -2.24827013]  energy_before :  70  energy_after :  50  reward :  -182.1900116456968\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "action : 1  next_temperatures :  [-0.11616967 -0.19092774 -0.58121317  0.5027991   0.01116069 -0.10523912\n",
      " -0.32079706 -0.12137255  0.05849238]  energy_before :  50  energy_after :  50  reward :  -198.86326711573662\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "action : 1  next_temperatures :  [-0.34447662  1.76675318  0.05568556  1.49386085 -0.40092408  2.19926657\n",
      " -0.55086974  2.13375874  0.01843501]  energy_before :  50  energy_after :  340  reward :  -481.62851053754036\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "action : 1  next_temperatures :  [ 0.195158   -0.06527428  0.3460141  -0.20404907 -0.88113578  0.78276374\n",
      " -0.52149876  0.96127475 -0.16378086]  energy_before :  340  energy_after :  50  reward :  92.44947185071331\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "action : 1  next_temperatures :  [ 0.81781333  0.03524849  1.98614233 -0.74380914  0.96327592 -0.69519257\n",
      "  1.0498487  -0.0545709  -0.04993359]  energy_before :  50  energy_after :  50  reward :  -194.69117743937926\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "action : 1  next_temperatures :  [-0.49598942 -0.96997919 -0.99162523 -0.11968596 -0.08355234 -1.48794253\n",
      " -0.03198241 -0.97597286  0.20125324]  energy_before :  50  energy_after :  60  reward :  -212.95547671160264\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "action : 1  next_temperatures :  [ 0.74932124 -0.03344207  0.80202751 -0.36540375 -0.63189095  0.81656316\n",
      "  0.13608486  1.09718154  0.3295573 ]  energy_before :  60  energy_after :  50  reward :  -185.10000115430594\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "action : 1  next_temperatures :  [-1.74130008  0.997754   -0.97642479  0.87956638 -1.18521446  1.79674624\n",
      " -1.15297484  1.19162524 -1.29683224]  energy_before :  50  energy_after :  110  reward :  -259.487054555334\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "action : 1  next_temperatures :  [-1.672808    0.96257103 -0.93538358  0.8549946  -1.18521446  1.78752822\n",
      " -1.13665763  1.19162524 -1.29683224]  energy_before :  110  energy_after :  50  reward :  -139.43017682115885\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "action : 1  next_temperatures :  [-0.61429393 -0.84432573 -0.15560065 -0.98788881 -1.08053164  0.35566202\n",
      " -1.80566329 -0.28492139 -0.82397454]  energy_before :  50  energy_after :  100  reward :  -254.24153797721965\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "action : 1  next_temperatures :  [ 0.52724084  0.14247278  0.43265665  0.36355902  0.36508834  0.00537716\n",
      " -0.29142608  0.42302244  0.49219626]  energy_before :  100  energy_after :  220  reward :  -315.5398125859999\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "action : 1  next_temperatures :  [-0.05390414  1.16612963  0.25025128  0.97785349  0.01116069  1.76909217\n",
      " -0.96206346  1.49108088 -0.31497485]  energy_before :  220  energy_after :  50  reward :  -23.66537429267069\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "action : 1  next_temperatures :  [ 0.195158   -0.10715877 -0.38360736  0.5511236   0.26040552 -0.1666926\n",
      "  0.11976765 -0.19047769  0.40158313]  energy_before :  50  energy_after :  50  reward :  -197.31989851940875\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step\n",
      "action : 1  next_temperatures :  [-0.09541449 -0.77814824 -0.43376883 -0.34902256 -0.48732896 -1.12229429\n",
      " -0.12499052 -1.20632335 -0.63181963]  energy_before :  50  energy_after :  40  reward :  -193.22911087352117\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "action : 1  next_temperatures :  [-1.36148033 -0.76893366 -1.8474104   0.18254692 -1.03068267 -0.58303996\n",
      " -0.63082407 -0.87461865 -1.02576732]  energy_before :  40  energy_after :  100  reward :  -265.94021013921065\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "action : 1  next_temperatures :  [-1.40714172 -0.93730929 -1.6604449  -0.14589586 -1.1303806  -0.62759374\n",
      " -1.05507157 -1.09114811 -1.19382757]  energy_before :  100  energy_after :  110  reward :  -217.24881336274353\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "action : 1  next_temperatures :  [-1.11864475  1.32445299 -0.52041138  1.02453987 -0.88113578  1.52327823\n",
      " -0.96206346  1.62698767 -1.08299214]  energy_before :  110  energy_after :  60  reward :  -147.0659887390966\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "action : 1  next_temperatures :  [-0.11616967 -1.35615416 -0.15560065 -1.31715065 -0.71995746 -1.12229429\n",
      " -0.71730529 -1.47429775 -0.92276265]  energy_before :  60  energy_after :  40  reward :  -185.9016925746478\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "action : 1  next_temperatures :  [-0.16183106 -0.23448761 -0.70737688  0.625658    0.11584352 -0.25887283\n",
      " -0.0466679  -0.12137255  0.16149705]  energy_before :  40  energy_after :  60  reward :  -218.6276102516819\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "action : 1  next_temperatures :  [2.06312399 0.91482271 1.39028481 1.10890298 2.2287275  0.3218626\n",
      " 2.27363956 0.82076096 2.11858581]  energy_before :  60  energy_after :  50  reward :  -174.7592890835819\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "action : 1  next_temperatures :  [-0.30296627 -0.68600237 -0.56601272 -0.39161365 -0.43747999 -0.87340768\n",
      " -0.58187244 -0.89074318 -1.19382757]  energy_before :  50  energy_after :  70  reward :  -223.92392586535027\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "action : 1  next_temperatures :  [ 2.0402933  -0.76223214  2.12446639 -1.60990584  1.30723378 -1.3957623\n",
      "  2.00734267 -1.2279763   2.33001645]  energy_before :  70  energy_after :  40  reward :  -163.18652399372655\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "action : 1  next_temperatures :  [-0.24692729  0.71126411  0.16360874  0.5109897  -0.83128681  1.58473172\n",
      "  0.32699624  1.33751389 -0.92276265]  energy_before :  40  energy_after :  100  reward :  -255.3658723684135\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "action : 1  next_temperatures :  [ 0.21591317  1.45932104  0.3460141   1.31940122  0.46478627  2.13781308\n",
      " -0.32079706  2.34337769  0.10728407]  energy_before :  100  energy_after :  90  reward :  -179.9268864086051\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n",
      "action : 1  next_temperatures :  [ 0.9423444  -0.25878061  0.29038046  0.04707451  1.66116143 -0.47396003\n",
      "  1.34355851 -0.58207352  1.84752088]  energy_before :  90  energy_after :  80  reward :  -183.18277396872344\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n",
      "action : 1  next_temperatures :  [ 1.54074043 -0.33743641  1.30752133 -0.65569113  1.31234815 -0.51087202\n",
      "  1.51539782 -0.06004547  0.95427395]  energy_before :  80  energy_after :  60  reward :  -172.9337633493045\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "action : 1  next_temperatures :  [-0.24692729  0.78916925  0.25025128  0.31441547 -0.73657378  0.93639745\n",
      " -0.47254712  1.42197573  0.18468816]  energy_before :  60  energy_after :  350  reward :  -485.55915084299716\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "action : 1  next_temperatures :  [-0.42749733  1.24906092  0.02224458  0.82059411 -0.18823517  1.58473172\n",
      " -0.71730529  1.89649774 -0.53785045]  energy_before :  350  energy_after :  90  reward :  65.70224081671302\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "action : 1  next_temperatures :  [-0.11616967 -0.24370219 -0.66177553  0.58224786  0.12830576 -0.25887283\n",
      " -0.03198241 -0.14440759  0.16149705]  energy_before :  90  energy_after :  50  reward :  -158.58485956697083\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "action : 1  next_temperatures :  [-0.80731709 -0.19092774 -1.00682568  0.16452762 -0.53219302  0.41404283\n",
      " -0.48886433 -0.16974615 -0.59206344]  energy_before :  50  energy_after :  50  reward :  -201.20936700634394\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "action : 1  next_temperatures :  [ 0.99838337 -0.14234173  0.03896507  0.50034193  0.7140311  -0.47396003\n",
      " -0.22778895  0.12203114  0.16149705]  energy_before :  50  energy_after :  90  reward :  -236.3088410537318\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "action : 1  next_temperatures :  [ 0.43799358 -0.23448761 -0.47937017  0.86973767  0.43155363 -0.01305889\n",
      " -0.56555523  0.27022329  0.22113133]  energy_before :  90  energy_after :  90  reward :  -197.0618323982992\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "action : 1  next_temperatures :  [-0.24692729  1.40068276  0.07240605  0.71575452 -0.2829482   1.41983153\n",
      " -1.0110151   1.16628669 -0.21859621]  energy_before :  90  energy_after :  60  reward :  -164.98452523929058\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "action : 1  next_temperatures :  [-1.18091029 -0.13312715 -0.77881898 -0.25073545 -0.98581861 -0.62759374\n",
      " -0.27674059 -0.55903848 -0.75470239]  energy_before :  60  energy_after :  30  reward :  -173.54748565418794\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "action : 1  next_temperatures :  [ 0.0083614   2.43020345  0.07240605 -0.17783917 -0.63189095  0.5492405\n",
      " -0.52149876 -0.21351274 -0.86312836]  energy_before :  30  energy_after :  60  reward :  -227.34765859033126\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "action : 1  next_temperatures :  [1.37197657 2.04570386 2.98633174 0.02299417 2.52188689 1.46182475\n",
      " 1.73027642 1.23769534 1.57645596]  energy_before :  60  energy_after :  40  reward :  -163.04485430867868\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "action : 1  next_temperatures :  [-2.67528308  0.58561065 -1.75164758  0.60927681 -2.2769068   0.47549632\n",
      " -2.67537066  0.68485417 -2.16424   ]  energy_before :  40  energy_after :  340  reward :  -507.1882101806678\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "action : 1  next_temperatures :  [ 0.5687512  -0.58464192 -0.10999931 -0.54723491  0.82702208 -0.88569837\n",
      "  0.41347746 -1.28157118 -0.48363747]  energy_before :  340  energy_after :  60  reward :  79.9164675798637\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "action : 1  next_temperatures :  [ 0.06440038 -0.46736535 -0.44896928  0.45365555  0.31025448 -0.59993967\n",
      " -0.32079706 -0.021554    0.60062223]  energy_before :  60  energy_after :  100  reward :  -238.42969272151558\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "action : 1  next_temperatures :  [-0.98788713 -0.17417394 -0.83962076 -0.52921561 -0.93596964 -1.01679914\n",
      " -0.89189946 -0.91224256 -1.13419329]  energy_before :  100  energy_after :  40  reward :  -145.4220015338543\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "action : 1  next_temperatures :  [-0.05390414  0.76152549  0.00704413  0.77882209 -0.19535645  0.85519106\n",
      "  0.64191842  0.94438239 -0.67338292]  energy_before :  40  energy_after :  100  reward :  -254.93375992699256\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "action : 1  next_temperatures :  [-1.05015267 -1.32264657 -1.4324382  -0.59719753 -0.15167926 -1.33635726\n",
      " -0.6634585  -1.36756869 -0.53785045]  energy_before :  100  energy_after :  60  reward :  -166.4593491297958\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "action : 1  next_temperatures :  [-1.02939749 -1.31510737 -0.93538358 -0.96413609 -1.08053164 -1.15097258\n",
      " -0.3819866  -1.2633351  -0.97697563]  energy_before :  60  energy_after :  50  reward :  -197.09782607679577\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "action : 1  next_temperatures :  [ 1.85557221 -0.38610945  1.71405433 -1.08617593  1.91040625 -0.62759374\n",
      "  1.97503459 -0.7571399   2.27580346]  energy_before :  50  energy_after :  50  reward :  -191.12614816410843\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "action : 1  next_temperatures :  [-0.3652318  -0.82757194 -0.36840691 -0.83308661 -0.78143785 -0.50775944\n",
      " -0.3860659  -0.66116053 -0.86312836]  energy_before :  50  energy_after :  230  reward :  -383.59384933677507\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "action : 1  next_temperatures :  [1.56499973 1.84214525 0.66066335 2.35387311 2.00511929 1.63389451\n",
      " 1.34355851 1.49108088 1.7878866 ]  energy_before :  230  energy_after :  80  reward :  -33.31677878236425\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "action : 1  next_temperatures :  [0.46082427 0.34351831 0.02224458 0.89430945 0.61433317 0.23275505\n",
      " 0.80509053 0.27022329 0.60062223]  energy_before :  80  energy_after :  60  reward :  -173.7560791261072\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "action : 1  next_temperatures :  [1.74556977 3.08913019 1.47536623 2.79116961 2.49762706 2.16239448\n",
      " 1.44102077 2.24212724 1.68976598]  energy_before :  60  energy_after :  80  reward :  -198.86582868025573\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "action : 1  next_temperatures :  [-2.67528308  0.42896267 -1.75164758  0.48641792 -2.23204273  0.41404283\n",
      " -2.62152386  0.59041047 -2.13442286]  energy_before :  80  energy_after :  90  reward :  -217.49508623338536\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "action : 1  next_temperatures :  [ 0.96102406  2.38915665  1.13339725 -0.20404907  1.34378969  1.26619782\n",
      "  0.16871929  0.93056136 -0.3806328 ]  energy_before :  90  energy_after :  50  reward :  -150.3918357592414\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "action : 1  next_temperatures :  [ 1.23291688  0.92319961  0.39161544  0.80421292  1.44514925 -0.29267225\n",
      " -0.07603889  1.08412835  0.05849238]  energy_before :  50  energy_after :  60  reward :  -202.4289962956039\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n",
      "action : 1  next_temperatures :  [-0.05390414  0.03524849 -0.50673098  0.59125751  0.41493731 -0.04685831\n",
      "  0.16871929  0.10897794  0.25727332]  energy_before :  60  energy_after :  70  reward :  -207.03107955746975\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n",
      "action : 1  next_temperatures :  [ 0.1723273   0.68864648 -0.17232114  1.2555146   0.80874413  0.0279101\n",
      "  0.36452582  0.29095483  0.61688612]  energy_before :  70  energy_after :  460  reward :  -583.9468117522099\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "action : 1  next_temperatures :  [ 0.58950637  0.42058577  0.07240605  0.69036368  1.61131247  0.41404283\n",
      "  1.01395084 -0.06839193  0.87168715]  energy_before :  460  energy_after :  80  reward :  187.61546323141786\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "action : 1  next_temperatures :  [-1.09581406 -1.04788434 -1.02202613 -0.74217102 -0.60198158 -0.97972221\n",
      " -1.25577327 -0.58975187 -1.29683224]  energy_before :  80  energy_after :  80  reward :  -206.631956716809\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "action : 1  next_temperatures :  [-2.09413811  1.50790705 -1.23483239  0.93608147 -1.24835649  1.81006116\n",
      " -0.84294782  1.0150232  -2.27808727]  energy_before :  80  energy_after :  100  reward :  -220.42928918624597\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "action : 1  next_temperatures :  [-0.30296627 -0.58045347 -0.38360736 -0.62832178 -0.06693602 -0.99631465\n",
      " -1.25577327 -0.92759926 -1.13419329]  energy_before :  100  energy_after :  80  reward :  -184.2761653546118\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "action : 1  next_temperatures :  [ 0.33836872  0.3937797   0.47825799  0.17517539 -0.2829482   1.19347786\n",
      "  0.01696922  0.5758216   0.74488901]  energy_before :  80  energy_after :  610  reward :  -724.3662087149189\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "action : 1  next_temperatures :  [-0.05390414 -1.22128612 -0.74841808 -0.72578984 -0.43747999 -1.32406657\n",
      " -0.12499052 -0.69724877 -0.04993359]  energy_before :  610  energy_after :  50  reward :  356.6168823923101\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "action : 1  next_temperatures :  [ 1.93236637 -1.28997667  2.17006773 -2.15177207  0.96327592 -0.94612763\n",
      "  1.52141611 -0.88152916  0.51026725]  energy_before :  50  energy_after :  60  reward :  -206.17201214465138\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "action : 1  next_temperatures :  [1.50273419 1.13848587 0.98443287 1.10562674 2.23940942 0.24197307\n",
      " 1.83307485 0.70558571 1.51682167]  energy_before :  60  energy_after :  50  reward :  -176.73185558775947\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "action : 1  next_temperatures :  [ 1.06064891  1.0304239   1.1622781  -0.45222403  1.20255095 -0.6779856\n",
      "  1.29460687 -0.686883    1.63066894]  energy_before :  50  energy_after :  60  reward :  -202.43591495260455\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "action : 1  next_temperatures :  [-0.49598942  0.43733956 -0.56601272  1.02453987 -0.33279717 -0.07451237\n",
      " -0.56555523  0.45450368 -0.16378086]  energy_before :  60  energy_after :  90  reward :  -228.28226464909224\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "action : 1  next_temperatures :  [-1.02939749 -0.11804873 -1.02202613  0.19892811 -0.73657378  0.12009033\n",
      " -1.1040232   0.16119072 -0.55893328]  energy_before :  90  energy_after :  50  reward :  -162.08879345916517\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "action : 1  next_temperatures :  [-0.24692729  0.7447717   0.07240605  0.3881308  -0.08355234  0.72131026\n",
      " -0.47254712  0.9359362   0.16149705]  energy_before :  50  energy_after :  60  reward :  -205.778974691794\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "action : 1  next_temperatures :  [ 0.81781333  0.31922531  1.72773473 -0.37359434  1.00813999 -0.20049202\n",
      "  1.01395084  0.31629338  0.87168715]  energy_before :  60  energy_after :  60  reward :  -192.49924162814764\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "action : 1  next_temperatures :  [ 0.50648566  0.36194749  1.40282517 -0.7120706   0.46478627  0.01459518\n",
      "  1.22444286 -0.06839193  0.87168715]  energy_before :  60  energy_after :  270  reward :  -403.93369273483904\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "action : 1  next_temperatures :  [-0.71806982 -0.5452705  -0.97642479 -0.17702011 -0.68672482  0.30342656\n",
      " -0.45459819 -0.25958284 -0.70591071]  energy_before :  270  energy_after :  60  reward :  7.779824788237619\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "action : 1  next_temperatures :  [-1.36148033  1.49282863 -0.74841808  1.39311656 -1.18521446  1.83054566\n",
      " -1.20682164  1.96560289 -1.13419329]  energy_before :  60  energy_after :  420  reward :  -556.9540340687465\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "action : 1  next_temperatures :  [-0.42749733 -1.19615542 -0.43376883 -1.01491777 -1.1303806  -0.59317979\n",
      " -1.05507157 -0.58207352 -1.29683224]  energy_before :  420  energy_after :  50  reward :  164.27012291695834\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "action : 1  next_temperatures :  [ 0.21591317  1.07314607  0.20464994  0.97785349 -0.18823517  1.48026079\n",
      "  0.7022921   1.43733243 -0.53785045]  energy_before :  50  energy_after :  50  reward :  -192.63463761117384\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "action : 1  next_temperatures :  [-0.3652318  -0.5285167  -0.90346264  0.45201743 -0.23808413 -0.81502687\n",
      " -0.12499052 -0.69724877 -0.32099851]  energy_before :  50  energy_after :  230  reward :  -381.54154251971926\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "action : 1  next_temperatures :  [-1.05015267  1.26413933 -0.52041138  1.10071239 -0.88113578  1.58473172\n",
      " -0.76625693  1.69839632 -1.13419329]  energy_before :  230  energy_after :  50  reward :  -16.704170278197523\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "action : 1  next_temperatures :  [-0.30296627  1.22769983  0.02224458  0.59576233 -0.31618084  1.40856506\n",
      " -1.0110151   1.08336051 -0.26678553]  energy_before :  50  energy_after :  330  reward :  -475.55931542292296\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "action : 1  next_temperatures :  [-1.18091029 -1.23971529 -0.53561182 -1.39823752 -1.08053164 -1.07466784\n",
      " -0.71730529 -1.22705489 -1.19382757]  energy_before :  330  energy_after :  60  reward :  62.35213784292722\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "action : 1  next_temperatures :  [ 0.5687512   0.42058577  1.81589732 -0.92318313  0.46478627  0.06887909\n",
      "  1.34355851 -0.11446203  0.87168715]  energy_before :  60  energy_after :  60  reward :  -193.48349985003043\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "action : 1  next_temperatures :  [ 0.06440038 -0.09040497 -0.10999931  0.06869768 -0.43747999  0.41404283\n",
      " -0.8103134   0.44682533 -0.76674972]  energy_before :  60  energy_after :  50  reward :  -189.22098118005886\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "action : 1  next_temperatures :  [1.71726726 3.26481658 1.39730988 3.04921018 2.5479292  2.33278823\n",
      " 1.41897048 2.33945551 1.66290369]  energy_before :  50  energy_after :  310  reward :  -438.2693490032058\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "action : 1  next_temperatures :  [-0.26560695  0.84613215  0.23657088  0.18254692 -0.33279717  1.58473172\n",
      "  0.87035938  0.90752631 -0.22763171]  energy_before :  310  energy_after :  90  reward :  25.801831535760755\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "action : 1  next_temperatures :  [-0.05390414 -0.81919504 -0.52041138 -0.33322642 -0.43747999 -0.77332629\n",
      " -0.47254712 -0.86079762 -0.33803688]  energy_before :  90  energy_after :  60  reward :  -172.6089248731924\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "action : 1  next_temperatures :  [-0.49598942 -0.55951122 -0.97642479  0.08344074  0.14907616 -0.71977397\n",
      "  0.36452582 -0.88152916  0.16149705]  energy_before :  60  energy_after :  40  reward :  -180.87468877581966\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "action : 1  next_temperatures :  [-1.05015267 -0.51762674 -0.87306175 -0.26875475 -0.88113578 -0.17795907\n",
      " -0.61450686 -0.5221824  -0.75470239]  energy_before :  40  energy_after :  60  reward :  -223.66008240634795\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "action : 1  next_temperatures :  [-0.18466176 -0.26631982 -0.87306175  0.87055673  0.34681039 -0.67061118\n",
      " -0.36974869  0.20111814 -0.10956787]  energy_before :  60  energy_after :  70  reward :  -209.05548580343518\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "action : 1  next_temperatures :  [-0.49598942 -0.84432573  0.25025128 -1.07143286 -0.25303882 -1.30358207\n",
      " -0.03198241 -0.97597286 -0.10956787]  energy_before :  70  energy_after :  80  reward :  -212.8356407739419\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "action : 1  next_temperatures :  [ 0.195158    0.03524849 -0.38360736  0.82223223  0.31025448 -0.10523912\n",
      "  0.16871929 -0.08374863  0.43256198]  energy_before :  80  energy_after :  300  reward :  -416.60842064510695\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "action : 1  next_temperatures :  [ 0.63101673 -0.09040497  0.70626469 -0.19503942 -0.11915874  0.27006609\n",
      " -1.1888727   1.78285817 -1.02576732]  energy_before :  300  energy_after :  270  reward :  -167.22903746928364\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "action : 1  next_temperatures :  [-0.738825   -0.89458712 -0.74841808 -0.76919998 -0.88113578 -0.62759374\n",
      " -0.68140743 -0.88997534 -0.35677908]  energy_before :  270  energy_after :  240  reward :  -174.5879215559631\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "action : 1  next_temperatures :  [-0.42749733  0.28655541 -0.28024432  0.71493546  0.01116069 -0.35412573\n",
      " -0.03198241  0.01453424  0.58255123]  energy_before :  240  energy_after :  510  reward :  -467.48411275377396\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "action : 1  next_temperatures :  [-0.18466176 -0.21605843 -0.80921987  0.76407902 -0.03370338 -0.24863058\n",
      " -0.12499052 -0.46689828 -0.12763887]  energy_before :  510  energy_after :  140  reward :  170.55227733786424\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "action : 1  next_temperatures :  [ 0.68705571 -0.85354032  0.61962214 -0.88304922  0.29363816 -0.45552398\n",
      " -0.07603889 -0.03767853  0.31148631]  energy_before :  140  energy_after :  60  reward :  -118.39402862056747\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "action : 1  next_temperatures :  [ 0.0083614  -0.20768153 -0.52041138  0.43727436 -0.03370338 -0.1666926\n",
      " -0.32079706 -0.12137255  0.05849238]  energy_before :  60  energy_after :  40  reward :  -178.86653035315567\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "action : 1  next_temperatures :  [ 0.88007886 -0.41961704  0.42239634 -0.4780244   1.50662964 -1.23291056\n",
      "  0.87502144 -0.84993824  1.08673199]  energy_before :  40  energy_after :  50  reward :  -206.20963196310265\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "action : 1  next_temperatures :  [-0.18466176  0.56131764 -0.29240467  0.21530929 -0.23808413 -0.89594062\n",
      " -0.19189109 -1.25930396 -0.04993359]  energy_before :  50  energy_after :  60  reward :  -210.33559288583479\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "action : 1  next_temperatures :  [ 0.21591317  0.0260339   0.37489495  0.18991845  0.11584352 -0.25887283\n",
      "  0.13608486  0.11588846  0.20125324]  energy_before :  60  energy_after :  40  reward :  -176.8830422694277\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "action : 1  next_temperatures :  [ 0.50648566 -1.08809345  1.48604762 -1.8896731   0.31025448 -0.9778786\n",
      "  1.0498487  -0.9967044   0.31148631]  energy_before :  40  energy_after :  60  reward :  -219.28822677264873\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "action : 1  next_temperatures :  [-0.738825   -0.99762296 -1.52364088  0.25708132 -0.89941373 -0.60915769\n",
      " -0.41870032 -1.1809848  -0.92276265]  energy_before :  60  energy_after :  50  reward :  -195.03402671094966\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "action : 1  next_temperatures :  [-0.5167446  -0.62820178 -0.49305057 -0.68647499 -0.33279717 -0.88467415\n",
      "  0.07081602 -1.1809848  -0.93050736]  energy_before :  50  energy_after :  60  reward :  -213.58261939861814\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "action : 1  next_temperatures :  [ 0.43799358 -1.22128612 -0.26504387 -0.71022771  0.46478627 -0.6798292\n",
      "  0.7022921  -1.25930396  0.7036269 ]  energy_before :  60  energy_after :  30  reward :  -169.82699201020492\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "action : 1  next_temperatures :  [ 1.12914099 -1.38966175  1.05853505 -1.93820236  0.91342696 -1.66659659\n",
      "  1.24076008 -1.26275922  1.68488193]  energy_before :  30  energy_after :  20  reward :  -188.23047491378838\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "action : 1  next_temperatures :  [ 0.79498263 -0.30904199  0.9342714  -0.57262575  0.39832099  0.49905348\n",
      "  0.27967632  0.21647484  0.27534432]  energy_before :  20  energy_after :  50  reward :  -225.48354375929432\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "action : 1  next_temperatures :  [1.64179388 1.08068528 1.27106987 0.85429255 2.25436411 0.03712812\n",
      " 1.97503459 0.96818527 1.57645596]  energy_before :  50  energy_after :  50  reward :  -186.3409903637365\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "action : 1  next_temperatures :  [-0.9256216  -0.71867227 -1.4324382   0.00317293 -1.03068267 -0.41250654\n",
      " -0.90821667 -0.86079762 -0.92276265]  energy_before :  50  energy_after :  40  reward :  -195.2085252789736\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "action : 1  next_temperatures :  [-0.98788713  0.86456133 -0.56601272  0.84598495 -0.95258596  1.61545846\n",
      " -1.64249118  1.86578434 -0.94384547]  energy_before :  40  energy_after :  50  reward :  -207.90103338808342\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "action : 1  next_temperatures :  [-0.46663567 -0.96997919 -0.64027776 -0.60878137 -0.63189095 -0.20049202\n",
      " -0.71730529 -0.74562237 -0.73379167]  energy_before :  50  energy_after :  50  reward :  -203.71477629935953\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "action : 1  next_temperatures :  [-0.24692729 -1.28997667 -0.15560065 -1.20903482 -1.19945703 -0.72460245\n",
      " -0.8103134  -0.63044713 -1.29683224]  energy_before :  50  energy_after :  40  reward :  -195.56319168218943\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "action : 1  next_temperatures :  [1.86727059 2.33367874 1.81100853 1.68159514 2.28132787 1.42970134\n",
      " 1.535837   1.82361568 1.80527383]  energy_before :  40  energy_after :  50  reward :  -191.4306912915701\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "action : 1  next_temperatures :  [ 6.44003775e-02  4.69171773e-01 -5.81213166e-01  1.56757619e+00\n",
      "  7.14031097e-01 -2.48630581e-01  6.52008481e-04  4.85217076e-01\n",
      "  6.33150020e-01]  energy_before :  50  energy_after :  40  reward :  -184.8956452075861\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "action : 1  next_temperatures :  [-0.26560695  1.21387795  0.11800739  0.88693791 -1.08053164  1.92272588\n",
      " -0.17394215  1.88958723 -0.23064354]  energy_before :  40  energy_after :  260  reward :  -413.71958791217764\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "action : 1  next_temperatures :  [-0.67655947 -1.02945517  0.23961097 -1.06324227 -0.36602981 -1.48794253\n",
      " -0.29142608 -0.69110609 -0.46737357]  energy_before :  260  energy_after :  50  reward :  6.166475996532256\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "action : 1  next_temperatures :  [-1.672808    0.45241798 -0.88978224  0.21367117 -1.14865856  1.23444685\n",
      " -1.13665763  0.61574902 -0.92276265]  energy_before :  50  energy_after :  50  reward :  -201.2543840415045\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "action : 1  next_temperatures :  [-0.94637678 -0.15155632 -0.97642479  0.13422242 -0.58204199 -0.20049202\n",
      " -0.40238311 -0.62200094 -0.5514037 ]  energy_before :  50  energy_after :  80  reward :  -232.29845722814167\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "action : 1  next_temperatures :  [ 0.81781333 -0.97919378  0.61962214 -1.41625682  0.91342696 -1.499209\n",
      "  0.85404217 -1.34223014  0.64941392]  energy_before :  80  energy_after :  60  reward :  -179.38257123244614\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "action : 1  next_temperatures :  [-0.42749733 -0.50254832  0.6044217  -0.6520745  -0.11678498 -1.08849487\n",
      "  0.44970167 -0.85572991  0.05849238]  energy_before :  60  energy_after :  60  reward :  -200.53051417805477\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "action : 1  next_temperatures :  [ 1.56499973  0.33430373  2.40458892 -1.15673204  2.05496825 -0.50775944\n",
      "  1.78412322  0.21647484  1.19154376]  energy_before :  60  energy_after :  30  reward :  -160.11348903885357\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "action : 1  next_temperatures :  [-0.69731464  0.29493231 -0.29240467 -0.299879   -0.33279717  0.47856899\n",
      " -0.8103134  -0.02923235 -0.65169772]  energy_before :  30  energy_after :  70  reward :  -240.34013766097243\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "action : 1  next_temperatures :  [1.93236637 1.9200504  1.78701647 1.67323484 2.1525298  0.87494397\n",
      " 2.12678465 1.50490191 2.25140762]  energy_before :  70  energy_after :  40  reward :  -151.77676397542436\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "action : 1  next_temperatures :  [-1.54827693  0.23629403 -1.10106845  0.26527191 -1.37962543  0.44784225\n",
      " -1.1040232  -0.21581625 -1.17756368]  energy_before :  40  energy_after :  50  reward :  -213.57696575430344\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "action : 1  next_temperatures :  [1.93236637 1.73492097 1.60187503 1.91649545 1.88904241 1.27746429\n",
      " 2.07783302 1.19680813 2.27580346]  energy_before :  50  energy_after :  310  reward :  -442.09739087088474\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "action : 1  next_temperatures :  [-1.18091029  0.96257103 -0.56601272  0.89430945 -1.08053164  1.52327823\n",
      " -1.54458791  1.68303962 -0.92276265]  energy_before :  310  energy_after :  50  reward :  61.76839312718624\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "action : 1  next_temperatures :  [-0.55825495 -0.79657742 -0.52041138 -0.63733143 -0.88113578 -0.98709662\n",
      " -0.90821667 -0.3686154  -1.13419329]  energy_before :  50  energy_after :  40  reward :  -194.7918329475403\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n",
      "action : 1  next_temperatures :  [-0.18466176  0.06791839 -0.15560065  0.13422242 -0.68672482  0.66292944\n",
      " -0.71730529  0.39921956 -0.92276265]  energy_before :  40  energy_after :  30  reward :  -189.4027653463738\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "action : 1  next_temperatures :  [-0.9256216   1.19879953 -0.72105728  0.16452762 -0.36769144  1.16275112\n",
      " -1.32430556 -0.79169247 -1.13419329]  energy_before :  30  energy_after :  60  reward :  -230.73848336248264\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "action : 1  next_temperatures :  [ 0.27817871  1.38392897  0.52841946  0.74769783 -0.51723834  2.20746036\n",
      " -0.41870032  0.59041047 -0.41316059]  energy_before :  60  energy_after :  100  reward :  -233.6130034481747\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "action : 1  next_temperatures :  [-0.30296627  0.53786233 -0.05071757  0.37174962 -0.91769169  1.654379\n",
      " -1.43363087  1.85733816 -0.79385622]  energy_before :  100  energy_after :  50  reward :  -147.07753350466575\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "action : 1  next_temperatures :  [-0.32372145  1.16612963 -0.02335676  0.59576233  0.33767141  1.16838436\n",
      "  0.08713323  0.94438239 -0.38665646]  energy_before :  50  energy_after :  50  reward :  -194.43427131880168\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "action : 1  next_temperatures :  [ 0.14949661 -0.28474899 -0.44896928  0.30458675  1.12943914 -0.6798292\n",
      "  0.50648556 -0.88152916  0.56448024]  energy_before :  50  energy_after :  70  reward :  -217.64058832777235\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "action : 1  next_temperatures :  [-0.18466176 -0.50254832 -0.55081227 -0.01402731  0.16569248 -0.84268094\n",
      " -0.76625693 -0.06839193 -0.19630865]  energy_before :  70  energy_after :  70  reward :  -200.9599956206946\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "action : 1  next_temperatures :  [ 0.81781333 -0.38443407 -0.25136347  0.36355902  0.55949931 -0.55589801\n",
      " -0.07603889  0.40613008  0.06662433]  energy_before :  70  energy_after :  100  reward :  -227.0541083646603\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "action : 1  next_temperatures :  [ 0.70781089  1.53303774  0.43265665  1.41932645  0.9466596  -0.03354338\n",
      "  0.31557419  0.59041047  0.64941392]  energy_before :  100  energy_after :  120  reward :  -211.4386534870881\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "action : 1  next_temperatures :  [0.79498263 0.997754   0.73636158 0.97785349 1.05798895 0.17949536\n",
      " 1.39251014 0.94860548 1.19154376]  energy_before :  120  energy_after :  40  reward :  -109.72290459665561\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "action : 1  next_temperatures :  [ 0.46082427 -0.24370219  0.52841946 -0.5636161  -0.43747999  0.90874338\n",
      "  0.11976765  0.49212759 -0.53785045]  energy_before :  40  energy_after :  120  reward :  -277.27276637440787\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "action : 1  next_temperatures :  [-0.18466176 -0.36935565 -0.58121317  0.40287387 -0.08355234 -0.5886732\n",
      " -0.27674059 -0.21581625 -0.10956787]  energy_before :  120  energy_after :  40  reward :  -120.00670694750235\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "action : 1  next_temperatures :  [ 0.5687512  -1.82442273  0.52841946 -2.23285894  0.77551149 -1.01884759\n",
      "  0.9960019  -1.62556124  1.01625511]  energy_before :  40  energy_after :  350  reward :  -510.81675133521486\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "action : 1  next_temperatures :  [-0.24692729  0.95586951 -0.33800601  0.90413816 -0.53219302  0.62913003\n",
      "  0.50648556 -0.10755152 -0.55333988]  energy_before :  350  energy_after :  50  reward :  103.21760553656227\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "action : 1  next_temperatures :  [ 1.06064891 -0.62066257  0.75642617 -0.72742796  1.00813999 -1.05118383\n",
      "  1.16243746 -0.92759926  1.69882241]  energy_before :  50  energy_after :  70  reward :  -215.64039868498236\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "action : 1  next_temperatures :  [-0.11616967  0.06037918 -0.61161406  0.90168098  0.11584352 -0.29267225\n",
      " -0.03198241  0.12970949  0.3295573 ]  energy_before :  70  energy_after :  50  reward :  -177.51526791516878\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "action : 1  next_temperatures :  [ 0.63101673  0.01849469  0.61962214 -0.34165103  0.91342696 -0.4852265\n",
      "  0.7871416   0.13866756  0.83554516]  energy_before :  50  energy_after :  20  reward :  -164.8829626777118\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "action : 1  next_temperatures :  [-0.11616967  0.10226367 -0.05071757 -0.18602976 -0.2829482  -0.42377301\n",
      "  0.01696922 -0.57516301 -0.92276265]  energy_before :  20  energy_after :  60  reward :  -240.43833097971415\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "action : 1  next_temperatures :  [-0.49598942 -0.87196949 -0.87306175 -0.22616367 -0.11844662 -0.17795907\n",
      " -0.64714128 -1.09805862 -0.66976872]  energy_before :  60  energy_after :  50  reward :  -193.17855864347263\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "action : 1  next_temperatures :  [ 0.5687512   0.96424641  0.63330255  0.60026716  0.21554145  1.58456101\n",
      "  0.3318914   0.7293886  -0.3806328 ]  energy_before :  50  energy_after :  250  reward :  -392.7526830302398\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "action : 1  next_temperatures :  [-0.05390414 -0.40579516 -0.38360736 -0.01402731  0.55949931 -0.9778786\n",
      " -0.41870032 -0.22272676  0.05849238]  energy_before :  250  energy_after :  60  reward :  -9.85864795996224\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "action : 1  next_temperatures :  [-0.24692729 -0.65710208 -0.93538358  0.44464589 -0.03370338 -0.66139315\n",
      " -0.61450686 -0.53600343 -0.21257254]  energy_before :  60  energy_after :  90  reward :  -231.45294641516193\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "action : 1  next_temperatures :  [-1.61054246  0.21786485 -1.11778894  0.28738651 -1.37962543  0.43657578\n",
      " -1.12034042 -0.19892388 -1.19382757]  energy_before :  90  energy_after :  60  reward :  -173.67922156226223\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "action : 1  next_temperatures :  [-0.80731709  0.63587203 -0.43376883  0.64859166 -0.88113578  1.79674624\n",
      " -1.59353955  1.84351713 -1.07395664]  energy_before :  60  energy_after :  40  reward :  -177.86499082148535\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "action : 1  next_temperatures :  [ 0.12666591 -0.5452705   0.16360874 -0.52921561 -0.23808413 -0.61837572\n",
      "  0.60928399 -0.61355476 -0.29931332]  energy_before :  40  energy_after :  40  reward :  -199.94425539066617\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "action : 1  next_temperatures :  [ 2.43671719  0.65346352  2.44367578 -0.4227379   2.11977191 -0.20049202\n",
      "  2.32259119  0.46986038  2.25953957]  energy_before :  40  energy_after :  80  reward :  -225.91761038893867\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "action : 1  next_temperatures :  [ 1.06064891 -0.45144925  2.01502318 -1.46376226  1.34378969 -0.31110829\n",
      "  1.42188112 -0.40009664 -0.13125307]  energy_before :  80  energy_after :  60  reward :  -174.91632661314836\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "action : 1  next_temperatures :  [ 0.63101673 -1.42484472 -0.10999931 -0.94120243  0.61433317 -0.68904722\n",
      "  0.85404217 -1.41133529  0.7036269 ]  energy_before :  60  energy_after :  60  reward :  -199.7734100104081\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "action : 1  next_temperatures :  [-2.05262775 -0.46736535 -1.39139699 -0.51447254 -1.82826611  0.00537716\n",
      " -2.27886242 -0.100641   -1.73595742]  energy_before :  60  energy_after :  240  reward :  -388.3642124333367\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "action : 1  next_temperatures :  [-2.91811866  0.86456133 -1.8884516   0.8549946  -2.37660473  0.78276374\n",
      " -2.77327393  0.96127475 -2.27146124]  energy_before :  240  energy_after :  100  reward :  -66.76431573535055\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "action : 1  next_temperatures :  [-1.61054246  0.96257103 -0.88978224  0.82796564 -1.21844711  1.74860768\n",
      " -1.05507157  1.19162524 -1.29683224]  energy_before :  100  energy_after :  400  reward :  -499.3399060304914\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "action : 1  next_temperatures :  [-1.23694927  1.45764566 -0.66177553  1.34643018 -1.18521446  1.83054566\n",
      " -1.15297484  1.92874681 -1.13419329]  energy_before :  400  energy_after :  100  reward :  103.19226091588752\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "action : 1  next_temperatures :  [0.81781333 2.53910311 2.07430492 0.97785349 1.49333658 2.36314253\n",
      " 1.34355851 1.90340826 1.57645596]  energy_before :  100  energy_after :  60  reward :  -142.91102331756477\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "action : 1  next_temperatures :  [-0.45032803 -0.19930464 -0.82442032 -0.29250747 -0.33279717 -1.17145708\n",
      " -0.52149876 -1.1809848  -0.43484578]  energy_before :  60  energy_after :  70  reward :  -213.40814403521864\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "action : 1  next_temperatures :  [ 0.06440038  0.17765574 -0.38360736  0.63384859  0.36508834 -0.07451237\n",
      "  0.31557419  0.17577959  0.27534432]  energy_before :  70  energy_after :  110  reward :  -236.45042857909453\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "action : 1  next_temperatures :  [-0.11616967 -0.46736535 -0.56601272  0.01955412  0.47600229 -1.01167802\n",
      " -0.47254712 -0.14440759  0.02235039]  energy_before :  110  energy_after :  60  reward :  -150.26027367531773\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "action : 1  next_temperatures :  [ 1.75179633  1.08822449  1.44044628  0.71591833  2.20950004 -0.20049202\n",
      "  1.88202648  0.96127475  1.63066894]  energy_before :  60  energy_after :  70  reward :  -196.52063636736838\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "action : 1  next_temperatures :  [ 0.68705571  1.3236153   0.6758638   0.1809088  -0.10016866  1.27746429\n",
      " -0.96206346  1.84274929 -1.29683224]  energy_before :  70  energy_after :  110  reward :  -234.3714071698643\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "action : 1  next_temperatures :  [2.43671719 1.6260213  2.77982281 0.23683885 3.0702255  0.67214747\n",
      " 1.88202648 1.62698767 1.7878866 ]  energy_before :  110  energy_after :  50  reward :  -121.88132613121627\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "action : 1  next_temperatures :  [-0.71806982  0.73890787 -0.38360736  0.73213571 -0.88113578  1.58473172\n",
      " -1.34878137  1.42197573 -0.59206344]  energy_before :  50  energy_after :  50  reward :  -197.44590674479963\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "action : 1  next_temperatures :  [-0.738825   -0.65249478 -0.76361853 -0.43174755 -0.63189095 -0.10523912\n",
      " -0.76625693 -0.51527188 -0.86312836]  energy_before :  50  energy_after :  80  reward :  -233.46847310927964\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "action : 1  next_temperatures :  [ 0.195158   -0.21605843 -0.15560065  0.26527191  0.46478627 -0.3817798\n",
      "  0.65823563 -0.21581625  0.16149705]  energy_before :  80  energy_after :  590  reward :  -707.2243062690693\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "action : 1  next_temperatures :  [-0.34447662 -0.45061156  0.26697177 -1.07143286 -0.38264613 -0.85394741\n",
      "  0.07081602 -1.02895347 -0.80891538]  energy_before :  590  energy_after :  50  reward :  337.39680436119687\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "action : 1  next_temperatures :  [-1.07298336  0.50267936 -0.43376883  0.05067837 -0.68672482  0.81656316\n",
      " -1.0110151   0.76163766 -0.3806328 ]  energy_before :  50  energy_after :  50  reward :  -199.4535663479667\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "action : 1  next_temperatures :  [ 1.56499973 -1.61667567  1.57269017 -2.46465272  0.66418213 -1.54222644\n",
      "  1.01395084 -1.51883218  1.28370584]  energy_before :  50  energy_after :  90  reward :  -239.04285830716682\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "action : 1  next_temperatures :  [1.81406186 1.47439946 1.84629821 0.8369753  1.75587446 0.8472899\n",
      " 1.58831668 1.52025861 2.00473854]  energy_before :  90  energy_after :  50  reward :  -144.31178698641827\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "action : 1  next_temperatures :  [-1.8596046   1.52926813 -1.11778894  1.46928907 -1.2799275   1.70456601\n",
      " -1.51521693  1.81357156 -1.24804056]  energy_before :  50  energy_after :  50  reward :  -198.50388374140874\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "action : 1  next_temperatures :  [ 0.06440038 -1.37458334 -0.36840691 -1.2336066  -0.88113578 -0.6798292\n",
      " -0.43664926 -0.98979389 -0.03186259]  energy_before :  50  energy_after :  40  reward :  -193.93146719017494\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n",
      "action : 1  next_temperatures :  [-0.67655947 -0.04265666 -0.70737688  0.27264344 -0.43747999  0.48676279\n",
      " -1.0110151   0.50057378 -0.86312836]  energy_before :  40  energy_after :  70  reward :  -230.47823644646144\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n",
      "action : 1  next_temperatures :  [-0.98788713 -1.46421614 -1.41875779 -0.68647499 -0.08355234 -1.24212859\n",
      " -0.61450686 -1.38830024 -0.51977946]  energy_before :  70  energy_after :  120  reward :  -256.4056035423037\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "action : 1  next_temperatures :  [ 0.195158   -1.09563265 -0.66177553 -0.54559679  0.16569248 -1.02704139\n",
      "  0.07081602 -1.5434029  -0.53785045]  energy_before :  120  energy_after :  70  reward :  -152.97963322786615\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "action : 1  next_temperatures :  [-0.9256216  -0.76893366 -1.34579565  0.01955412 -0.78143785 -0.50775944\n",
      " -1.1040232  -0.63044713 -0.70591071]  energy_before :  70  energy_after :  40  reward :  -174.75037511474133\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "action : 1  next_temperatures :  [-0.40674216  0.63587203  0.00704413  0.40451199 -0.89941373  0.7438432\n",
      " -0.26042337  0.82076096 -0.50200965]  energy_before :  40  energy_after :  120  reward :  -277.4565566043421\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "action : 1  next_temperatures :  [-0.11616967  0.06037918 -0.61161406  0.92870994  0.11584352 -0.29267225\n",
      " -0.03198241  0.12970949  0.3295573 ]  energy_before :  120  energy_after :  200  reward :  -277.4882389584443\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "action : 1  next_temperatures :  [ 1.12914099  2.00381937  0.3460141   0.78005068  1.66116143 -0.31110829\n",
      " -0.14130773  0.92211517  0.05849238]  energy_before :  200  energy_after :  80  reward :  -71.55162190156722\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "action : 1  next_temperatures :  [-0.80731709  0.3611098  -1.02202613  0.3881308  -1.03068267 -0.25887283\n",
      " -1.0110151  -0.55980631 -1.13419329]  energy_before :  80  energy_after :  570  reward :  -693.0746728137497\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "action : 1  next_temperatures :  [ 0.63101673 -0.17584932  0.99963332 -0.72578984  0.46478627 -0.37256178\n",
      "  1.19180844 -0.23654779  0.54640924]  energy_before :  570  energy_after :  50  reward :  324.322905277508\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "action : 1  next_temperatures :  [-0.24692729  0.07713298 -0.32280557  0.5109897   0.63094949 -0.43503949\n",
      "  0.11976765 -0.26096494  0.49219626]  energy_before :  50  energy_after :  50  reward :  -197.43470120998202\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "action : 1  next_temperatures :  [ 0.31968906 -0.53438053  0.11800739 -0.51447254 -0.38264613 -0.13903853\n",
      " -0.84294782 -0.19892388  0.52622997]  energy_before :  50  energy_after :  50  reward :  -199.64848300855263\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "action : 1  next_temperatures :  [0.27817871 0.52781005 0.3460141  0.48559886 0.93004328 0.08833936\n",
      " 0.11976765 0.60730284 0.52833825]  energy_before :  50  energy_after :  60  reward :  -204.08860690388133\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "action : 1  next_temperatures :  [-1.23694927 -1.09563265 -1.25003283 -0.59474035 -1.14604742 -0.33481178\n",
      " -1.48421423 -0.88152916 -0.75470239]  energy_before :  60  energy_after :  50  reward :  -196.77866008551266\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "action : 1  next_temperatures :  [-0.94637678 -0.16831012 -0.31520534 -0.28267876 -0.91769169 -0.24863058\n",
      "  0.16871929 -0.45998776 -0.65169772]  energy_before :  50  energy_after :  50  reward :  -201.82185946637418\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "action : 1  next_temperatures :  [-1.2992148   1.19126033 -0.70737688  1.03354953 -0.98581861  1.43109801\n",
      " -1.1040232   1.62698767 -1.13419329]  energy_before :  50  energy_after :  120  reward :  -267.9477312440128\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n",
      "action : 1  next_temperatures :  [-0.26560695 -1.02945517 -1.20443149  0.03593531 -0.43747999 -1.07005883\n",
      "  0.07081602 -1.29616004 -0.06981168]  energy_before :  120  energy_after :  60  reward :  -143.2662528278247\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n",
      "action : 1  next_temperatures :  [-0.11616967  0.58561065  0.25025128  0.28738651  0.41493731  1.18221139\n",
      " -0.32079706  0.84609951  0.27534432]  energy_before :  60  energy_after :  50  reward :  -184.5951257567981\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n",
      "action : 1  next_temperatures :  [-0.15975554  1.15607736  0.02224458  0.41188352 -0.15167926  0.66292944\n",
      " -0.52149876  0.82076096  0.16149705]  energy_before :  50  energy_after :  130  reward :  -275.59754064835397\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "action : 1  next_temperatures :  [1.68330424 1.13848587 0.75642617 1.54300441 1.80572343 1.00092361\n",
      " 1.53936504 0.92211517 2.05895152]  energy_before :  130  energy_after :  20  reward :  -75.5517005350917\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "action : 1  next_temperatures :  [-1.09581406  1.31691379 -0.47937017  1.04255918 -0.88113578  1.5509323\n",
      " -0.90821667  1.55788252 -1.09202763]  energy_before :  20  energy_after :  90  reward :  -266.9882765183789\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "action : 1  next_temperatures :  [-0.55825495  0.21954023 -0.64505504  0.19728999 -1.03068267  0.7438432\n",
      " -0.76625693  0.33932843 -0.3806328 ]  energy_before :  90  energy_after :  50  reward :  -159.88088054460658\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "action : 1  next_temperatures :  [-0.738825   -0.89458712 -0.76361853 -0.77657151 -0.91769169 -0.62759374\n",
      " -0.71730529 -0.90686771 -0.3806328 ]  energy_before :  50  energy_after :  50  reward :  -204.72369339182174\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "action : 1  next_temperatures :  [-0.18466176 -0.52600363 -0.15560065 -0.79131458 -0.65016891 -0.47396003\n",
      " -0.30611157 -0.46689828 -0.86312836]  energy_before :  50  energy_after :  190  reward :  -342.41784776452175\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "action : 1  next_temperatures :  [ 0.31968906  0.15922657  0.3156132  -0.06398993  0.93004328 -0.81297842\n",
      "  0.21277576  0.39921956  0.7036269 ]  energy_before :  190  energy_after :  90  reward :  -95.83677401080658\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "action : 1  next_temperatures :  [-0.98788713  0.10142598 -0.88978224  0.26527191 -0.76648316  0.07912134\n",
      " -0.19189109  0.06060434 -0.9558928 ]  energy_before :  90  energy_after :  20  reward :  -131.2855128556433\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "action : 1  next_temperatures :  [-1.63129764  1.05722997 -0.90498269  0.93608147 -1.1303806   1.74860768\n",
      " -2.13200752  1.76750147 -1.56789717]  energy_before :  20  energy_after :  310  reward :  -489.85714503744066\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "action : 1  next_temperatures :  [-0.24692729  0.0260339  -0.62833455  1.03354953  0.31025448 -0.59993967\n",
      " -0.41870032  0.36850616  0.47231816]  energy_before :  310  energy_after :  50  reward :  62.31676040315659\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "action : 1  next_temperatures :  [-0.55825495 -1.31615448  0.23505084 -1.74142336 -0.38264613 -1.30358207\n",
      "  0.01696922 -1.0427745  -0.48363747]  energy_before :  50  energy_after :  70  reward :  -224.57645291338054\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "action : 1  next_temperatures :  [-0.11616967 -0.80411663 -0.79401942 -0.08119017 -0.33279717 -0.84268094\n",
      " -0.41870032 -0.92759926 -0.68783971]  energy_before :  70  energy_after :  50  reward :  -183.00511328698144\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "action : 1  next_temperatures :  [-0.55825495 -0.49500911 -0.55081227 -0.20404907 -0.18823517 -1.28514603\n",
      "  0.21277576 -0.63044713  0.16149705]  energy_before :  50  energy_after :  70  reward :  -221.53768091953907\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "action : 1  next_temperatures :  [-0.55825495  0.21954023 -0.15560065 -0.20404907 -0.58204199  1.02857768\n",
      "  0.08550151  0.58503562 -0.77277339]  energy_before :  70  energy_after :  90  reward :  -218.35406500959652\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "action : 1  next_temperatures :  [ 0.0083614   0.10896519  1.50124807 -0.94120243  0.11584352 -0.22814609\n",
      "  0.3318914  -0.08374863  1.19309271]  energy_before :  90  energy_after :  110  reward :  -215.99369487354704\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "action : 1  next_temperatures :  [ 0.99838337  0.27734082  0.71343062  0.25087987  1.02475631 -0.09499687\n",
      "  1.09880034  0.33932843  1.48429388]  energy_before :  110  energy_after :  60  reward :  -141.9077832235284\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "action : 1  next_temperatures :  [-0.49598942 -0.74631603 -0.49305057 -0.84864873 -0.88113578 -0.66139315\n",
      " -0.56555523 -0.88152916 -0.10956787]  energy_before :  60  energy_after :  50  reward :  -193.6831859558402\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "action : 1  next_temperatures :  [-0.9256216  -1.62589026 -0.83962076 -1.43263801 -1.23506343 -0.88016756\n",
      " -0.96206346 -1.29616004 -1.19382757]  energy_before :  50  energy_after :  50  reward :  -208.39105269861972\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "action : 1  next_temperatures :  [ 1.60235905 -0.50254832  1.03003421 -0.52348219  2.05496825 -0.32032631\n",
      "  1.84006794 -0.65117867  1.95594685]  energy_before :  50  energy_after :  80  reward :  -221.51415919538832\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "action : 1  next_temperatures :  [ 0.0083614  -0.99762296 -0.43376883 -0.40799483 -0.98581861 -0.89594062\n",
      " -0.36974869 -0.81242401 -0.04993359]  energy_before :  80  energy_after :  50  reward :  -172.94489074105883\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n",
      "action : 1  next_temperatures :  [ 0.81781333 -0.9448485   0.03896507 -0.44976686  0.16569248 -0.90720709\n",
      " -0.52149876 -0.17665666 -0.21257254]  energy_before :  50  energy_after :  60  reward :  -210.190079533772\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n",
      "action : 1  next_temperatures :  [ 1.68330424 -0.46736535  1.21243958 -0.62832178  2.05496825 -0.3134128\n",
      "  1.88202648 -0.65117867  2.05895152]  energy_before :  60  energy_after :  20  reward :  -151.1685885275322\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "action : 1  next_temperatures :  [1.87632739 1.76675318 1.1622781  2.20644244 2.19288372 1.27746429\n",
      " 2.02888139 1.46804583 2.38965073]  energy_before :  20  energy_after :  330  reward :  -491.6312729316338\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "action : 1  next_temperatures :  [-0.80731709 -0.69354158 -1.29563417  0.33079665  0.32853244 -0.83346291\n",
      " -0.8103134  -0.56134198 -0.21257254]  energy_before :  330  energy_after :  320  reward :  -192.554854589072\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "action : 1  next_temperatures :  [-0.18466176 -1.46505383 -0.15560065 -1.31715065 -1.03068267 -1.08849487\n",
      " -0.97838068 -0.92759926 -0.32099851]  energy_before :  320  energy_after :  30  reward :  84.53137711984994\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "action : 1  next_temperatures :  [ 0.52724084  0.48676326  0.26697177  0.04166872  0.06100966 -0.25887283\n",
      "  0.15240207 -0.97597286 -0.16378086]  energy_before :  30  energy_after :  70  reward :  -237.8625702218574\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "action : 1  next_temperatures :  [-1.05015267  1.65198968 -0.33800601  1.21456163 -1.14865856  1.83054566\n",
      " -2.13200752  2.1130272  -0.45924163]  energy_before :  70  energy_after :  70  reward :  -196.31794221524183\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "action : 1  next_temperatures :  [-0.30296627  1.07230838  0.07240605  0.51836123 -0.36602981  1.3358451\n",
      " -1.0110151   1.00734485 -0.27582103]  energy_before :  70  energy_after :  40  reward :  -165.94956657837957\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "action : 1  next_temperatures :  [ 0.99838337 -1.13835483  1.03003421 -2.11245722  0.50965034 -1.07927685\n",
      "  1.0498487  -1.20401985  1.14275208]  energy_before :  40  energy_after :  50  reward :  -208.8034400444336\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "action : 1  next_temperatures :  [1.51830058 0.74330574 0.80202751 1.27926732 1.30723378 0.37870708\n",
      " 1.24076008 0.68485417 1.90173387]  energy_before :  50  energy_after :  20  reward :  -158.14380989547803\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "action : 1  next_temperatures :  [ 0.0083614  -1.14756942  0.91907095 -1.8896731   0.01116069 -1.33430881\n",
      "  0.01696922 -1.02204296 -0.04993359]  energy_before :  20  energy_after :  50  reward :  -232.48796561778462\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n",
      "action : 1  next_temperatures :  [0.99838337 0.48760095 1.08931596 0.18254692 0.75889517 1.15455732\n",
      " 0.41347746 1.21235679 0.81747417]  energy_before :  50  energy_after :  60  reward :  -200.88539190002174\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "action : 1  next_temperatures :  [ 1.19140653 -1.63342947  0.94860325 -2.12942345  0.96327592 -1.54939601\n",
      "  1.08248312 -1.61327588  1.68488193]  energy_before :  60  energy_after :  70  reward :  -209.05487406329016\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "action : 1  next_temperatures :  [ 1.1063103  -0.78568745  0.73544955 -0.40799483  1.16267178 -0.81502687\n",
      "  1.29460687 -1.08116625  1.9949802 ]  energy_before :  70  energy_after :  90  reward :  -214.79585669815987\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "action : 1  next_temperatures :  [1.81406186 2.98224098 1.58789062 2.79370795 2.23940942 1.79674624\n",
      " 1.53936504 2.36410923 1.73367361]  energy_before :  90  energy_after :  160  reward :  -249.14879503593068\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "action : 1  next_temperatures :  [ 0.195158    0.25891165 -0.40032785  0.97785349  1.05798895  0.16822889\n",
      "  0.80509053 -0.23654779  0.7036269 ]  energy_before :  160  energy_after :  80  reward :  -114.47001721869302\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "action : 1  next_temperatures :  [-0.03314896 -0.10883414  0.17728914 -0.22616367 -0.88113578  0.83704765\n",
      " -0.6634585   0.91520466 -0.26678553]  energy_before :  80  energy_after :  60  reward :  -178.24998512949838\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "action : 1  next_temperatures :  [ 1.12914099  1.10581597  1.1622781   0.48641792  1.44514925  2.0763596\n",
      " -0.47254712  2.64974384  1.03432611]  energy_before :  60  energy_after :  90  reward :  -217.38331534093115\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "action : 1  next_temperatures :  [-0.98788713  0.72969328 -0.59451356  0.51928267 -1.21844711  1.68612997\n",
      " -0.76625693  0.82076096 -1.0799803 ]  energy_before :  90  energy_after :  30  reward :  -138.89121815100307\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "action : 1  next_temperatures :  [ 1.19140653  0.46247026  0.39161544  0.60927681  1.27566277 -0.34081081\n",
      " -0.10867331  0.64415891  0.05849238]  energy_before :  30  energy_after :  100  reward :  -263.81640101941815\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "action : 1  next_temperatures :  [ 1.41763796  2.02727468  2.98633174 -0.11243143  2.62490808  1.39012902\n",
      "  1.73027642  1.23769534  1.57645596]  energy_before :  100  energy_after :  90  reward :  -173.12172223413864\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "action : 1  next_temperatures :  [ 0.195158   -0.74380297  0.11800739 -0.94120243 -0.08355234 -1.06084081\n",
      "  0.21277576 -1.02204296 -0.21257254]  energy_before :  90  energy_after :  50  reward :  -161.53807290033416\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "action : 1  next_temperatures :  [-0.24692729 -1.2715475  -1.02202613 -0.34165103  0.21554145 -1.30358207\n",
      "  0.07081602 -1.43667384  0.37834899]  energy_before :  50  energy_after :  80  reward :  -232.9577013989981\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "action : 1  next_temperatures :  [ 0.63101673  0.36781132  0.95099189 -0.34902256  0.50965034 -0.01305889\n",
      "  1.14775197 -0.14440759  0.93132144]  energy_before :  80  energy_after :  100  reward :  -213.96794536548333\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "action : 1  next_temperatures :  [ 0.12666591 -0.02590286  0.80202751 -0.47188146  0.06100966 -0.30189027\n",
      "  0.31557419 -0.100641    0.43256198]  energy_before :  100  energy_after :  60  reward :  -157.16247634743615\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "action : 1  next_temperatures :  [-0.55825495 -1.39887634 -0.32280557 -1.85772978 -1.18521446 -1.41624679\n",
      " -0.03198241 -1.23550108 -0.92276265]  energy_before :  60  energy_after :  260  reward :  -406.92937404311044\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "action : 1  next_temperatures :  [ 1.12914099 -1.35615416  1.38116454 -1.99631462  0.96327592 -1.60531868\n",
      "  1.43656661 -1.47429775  1.95594685]  energy_before :  260  energy_after :  590  reward :  -527.5659902974126\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "action : 1  next_temperatures :  [ 0.58950637 -0.14988094  0.66066335 -0.53085373  0.9466596  -0.62759374\n",
      "  0.80509053 -0.1299467   0.64941392]  energy_before :  590  energy_after :  300  reward :  94.21305866215769\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "action : 1  next_temperatures :  [-0.18466176 -1.2305007  -0.62833455 -1.17053904 -0.96920228 -0.5886732\n",
      " -0.63082407 -0.92759926 -0.26678553]  energy_before :  300  energy_after :  70  reward :  25.40287961427981\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "action : 1  next_temperatures :  [-0.42749733 -0.3165812  -0.33800601  0.00317293 -0.23808413 -0.56614025\n",
      " -0.12499052 -0.60510857 -0.16378086]  energy_before :  70  energy_after :  40  reward :  -170.77701595023055\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "action : 1  next_temperatures :  [-0.69731464 -1.08725576 -1.20595154 -0.06317087 -0.59865831 -1.43877974\n",
      " -0.52149876 -0.97597286 -0.45110968]  energy_before :  40  energy_after :  50  reward :  -215.03971215242123\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "action : 1  next_temperatures :  [ 0.68705571  0.68026959  0.6044217   0.52737088  0.01116069  0.97019687\n",
      " -0.86089675  2.33416367 -0.40231799]  energy_before :  50  energy_after :  80  reward :  -223.44857563749562\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "action : 1  next_temperatures :  [ 1.99463191 -0.40286324  1.77333607 -0.81834354  1.5564786  -0.50775944\n",
      "  1.74822535 -0.36707973  1.73367361]  energy_before :  80  energy_after :  40  reward :  -151.28970041633497\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "action : 1  next_temperatures :  [ 0.9423444  -1.47259304  0.43265665 -1.31715065  0.55949931 -0.94612763\n",
      "  0.9960019  -1.36756869  0.81747417]  energy_before :  40  energy_after :  280  reward :  -439.35546359195155\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "action : 1  next_temperatures :  [0.74932124 1.04885307 0.70626469 1.01569403 1.05798895 0.21227056\n",
      " 1.43656661 0.87527724 1.19154376]  energy_before :  280  energy_after :  60  reward :  30.293780164361237\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "action : 1  next_temperatures :  [ 0.9423444  -0.62820178  1.03003421 -1.06406133  0.31025448 -0.35412573\n",
      "  0.60928399 -0.52909291  0.92047884]  energy_before :  60  energy_after :  50  reward :  -186.76308582767348\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "action : 1  next_temperatures :  [2.1461447  2.04570386 1.34468346 2.30227237 2.14303476 1.61545846\n",
      " 2.12678465 1.53715098 2.44386372]  energy_before :  50  energy_after :  120  reward :  -250.29490303579453\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "action : 1  next_temperatures :  [-2.98661075  1.08068528 -1.8884516   0.97785349 -2.48128755  0.94766392\n",
      " -2.77327393  1.14555515 -2.27808727]  energy_before :  120  energy_after :  70  reward :  -156.25595325742754\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "action : 1  next_temperatures :  [-0.61429393 -1.03866975 -1.25003283 -0.23517332 -0.15167926 -1.2011596\n",
      " -0.61450686 -1.25239345 -0.32099851]  energy_before :  70  energy_after :  50  reward :  -184.67890751994508\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "action : 1  next_temperatures :  [ 0.0083614  -0.74631603 -1.05242702  0.61746741  0.46478627 -0.50775944\n",
      " -0.36974869  0.07749671 -0.04993359]  energy_before :  50  energy_after :  60  reward :  -209.55807299324044\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "action : 1  next_temperatures :  [-0.67655947 -1.83363731 -0.52041138 -1.88230156 -1.23506343 -1.85666344\n",
      " -0.15762494 -1.36756869 -0.53785045]  energy_before :  60  energy_after :  110  reward :  -258.0676806743076\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "action : 1  next_temperatures :  [ 0.33836872 -1.49102221 -0.06439797 -1.2342209   0.31025448 -0.96866058\n",
      "  0.88900762 -1.39488168  0.49219626]  energy_before :  110  energy_after :  100  reward :  -191.12335625099763\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "action : 1  next_temperatures :  [-0.98788713 -1.04788434 -1.3609961  -0.34165103 -0.25303882 -1.42853749\n",
      " -0.6634585  -1.1809848  -0.48363747]  energy_before :  100  energy_after :  50  reward :  -155.74807567042245\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "action : 1  next_temperatures :  [-0.23136091 -0.42527144 -1.25003283  0.8369753   0.01116069 -0.68904722\n",
      "  0.47711458 -0.71613751  0.3620851 ]  energy_before :  50  energy_after :  30  reward :  -179.62451424676473\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "action : 1  next_temperatures :  [ 1.93236637  2.0180601   3.82539641 -0.27612629  2.73490813  1.15455732\n",
      "  2.30860501  1.39663718  2.38965073]  energy_before :  30  energy_after :  50  reward :  -200.51594503089026\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "action : 1  next_temperatures :  [-0.88826228 -0.42548087 -0.44896928 -0.94120243 -1.76346246  0.00537716\n",
      " -1.56090512 -0.06839193 -0.71404265]  energy_before :  50  energy_after :  80  reward :  -234.80533986718245\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "action : 1  next_temperatures :  [-0.05390414 -0.9448485  -0.74841808 -0.16227704  0.21554145 -0.87340768\n",
      "  0.52802428 -1.21876228  0.27534432]  energy_before :  80  energy_after :  70  reward :  -190.9827076686317\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "action : 1  next_temperatures :  [-0.11616967 -0.51762674 -0.66177553  0.31441547  0.21554145 -0.32032631\n",
      " -0.40238311 -0.021554    0.16149705]  energy_before :  70  energy_after :  120  reward :  -249.34838140115082\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n",
      "action : 1  next_temperatures :  [-0.42749733  0.77995467  0.07240605  0.21367117 -0.71995746  0.91796141\n",
      " -0.41870032  1.22924916 -0.01680343]  energy_before :  120  energy_after :  110  reward :  -186.36971609510104\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n",
      "action : 1  next_temperatures :  [-0.01239378 -0.72788686 -1.11778894  0.64122012  0.46478627 -0.464742\n",
      " -0.36974869  0.06060434 -0.06318565]  energy_before :  110  energy_after :  40  reward :  -129.58913519191714\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "action : 1  next_temperatures :  [-1.18091029  0.93157651 -0.66177553  0.95082454 -1.047299    1.48947882\n",
      " -1.69633798  1.76750147 -0.92276265]  energy_before :  40  energy_after :  20  reward :  -178.36970411103817\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "action : 1  next_temperatures :  [-1.61054246 -0.33333499 -1.29563417  0.1587942  -1.18521446 -0.56614025\n",
      " -0.22615723 -0.34558035 -1.13419329]  energy_before :  20  energy_after :  60  reward :  -244.5380030229158\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "action : 1  next_temperatures :  [-0.42749733 -0.59301881 -1.02202613  0.28738651  0.46478627 -0.84268094\n",
      " -0.61450686 -0.40009664 -0.06981168]  energy_before :  60  energy_after :  100  reward :  -241.21746561146125\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "action : 1  next_temperatures :  [1.14989617 0.3937797  0.47825799 0.77882209 1.11282282 0.14057482\n",
      " 1.20812565 0.20879649 0.81747417]  energy_before :  100  energy_after :  130  reward :  -221.71145010760137\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "action : 1  next_temperatures :  [-2.09413811 -0.96997919 -1.28043373 -1.08617593 -2.1273599  -0.34285926\n",
      " -1.13665763 -0.88306483 -1.60705099]  energy_before :  130  energy_after :  80  reward :  -159.52771955875238\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "action : 1  next_temperatures :  [ 0.195158   -0.66003399 -0.38360736 -0.09593324 -0.53219302 -0.50775944\n",
      "  0.10345044 -1.1809848  -0.28485652]  energy_before :  80  energy_after :  60  reward :  -181.34675993813892\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "action : 1  next_temperatures :  [-0.3652318  -0.51762674 -1.14818984  0.47658921 -0.0503197  -0.7627914\n",
      "  0.19389441 -0.91575266  0.16149705]  energy_before :  60  energy_after :  50  reward :  -190.9279314695195\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "action : 1  next_temperatures :  [-0.3652318  -0.16831012 -0.83962076  0.70510675  0.04439334 -0.07451237\n",
      " -0.47254712 -0.100641   -0.10956787]  energy_before :  50  energy_after :  50  reward :  -199.38093096760159\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "action : 1  next_temperatures :  [1.99463191 3.29302388 1.65173249 3.09757895 2.00511929 2.06611735\n",
      " 1.68132478 2.68045724 1.86920608]  energy_before :  50  energy_after :  160  reward :  -287.6608080413084\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "action : 1  next_temperatures :  [-0.3652318  -0.5452705  -0.56601272 -0.37359434 -0.68672482  0.14057482\n",
      " -0.7336225   0.10897794 -0.04993359]  energy_before :  160  energy_after :  70  reward :  -111.07083750311037\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "action : 1  next_temperatures :  [0.31968906 1.16612963 0.43265665 1.07368343 0.24545083 0.87494397\n",
      " 0.16871929 1.30680049 0.10728407]  energy_before :  70  energy_after :  60  reward :  -182.30464258827553\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "action : 1  next_temperatures :  [-0.18466176  0.77074008  0.39161544  0.21367117 -0.63189095  0.90874338\n",
      " -0.8103134   1.39663718  0.66447308]  energy_before :  60  energy_after :  50  reward :  -185.28098577606534\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "action : 1  next_temperatures :  [ 1.75179633 -0.92223088  1.03003421 -0.7860492   0.96327592 -2.17519733\n",
      "  1.92608295 -0.67651722  2.27580346]  energy_before :  50  energy_after :  130  reward :  -274.6130017605426\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "action : 1  next_temperatures :  [-0.738825    0.63587203 -0.43376883  0.61746741 -0.86451946  1.73836543\n",
      " -1.59353955  1.85733816 -1.02576732]  energy_before :  130  energy_after :  40  reward :  -107.80737712796383\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "action : 1  next_temperatures :  [ 0.27817871  0.05200228 -0.22096257  0.3881308   0.26040552 -0.18922555\n",
      "  0.26172739  0.16886907  0.27534432]  energy_before :  40  energy_after :  20  reward :  -176.7255300253272\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "action : 1  next_temperatures :  [ 0.50648566 -0.3249581  -0.38360736  0.29803428  0.140768   -0.35412573\n",
      "  0.54494756 -0.72028382  0.64941392]  energy_before :  20  energy_after :  60  reward :  -237.64332558047008\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "action : 1  next_temperatures :  [ 1.12914099 -0.3249581   0.49497848 -0.16964858  0.57777726 -0.21892806\n",
      "  0.11976765 -0.0545709   0.37834899]  energy_before :  60  energy_after :  600  reward :  -736.0680922650957\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "action : 1  next_temperatures :  [ 0.74932124 -0.8795087   0.61962214 -0.93219278  0.27702184 -0.45347553\n",
      " -0.03198241 -0.07530245  0.27534432]  energy_before :  600  energy_after :  80  reward :  321.5488476685615\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "action : 1  next_temperatures :  [ 0.74932124 -0.76893366  0.80202751 -1.19429175  0.36508834 -0.87340768\n",
      "  0.9960019  -1.1372182   0.64941392]  energy_before :  80  energy_after :  50  reward :  -168.41199838043661\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "action : 1  next_temperatures :  [ 0.12666591  0.26980162 -0.25136347  1.04092106  0.75889517  0.0361039\n",
      " -0.47254712  0.05369383 -0.14570986]  energy_before :  50  energy_after :  80  reward :  -226.58353897442043\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "action : 1  next_temperatures :  [2.12538953 1.76675318 2.39807444 0.89536252 2.20950004 0.87494397\n",
      " 2.27363956 1.35287059 2.33001645]  energy_before :  80  energy_after :  50  reward :  -151.7734497360906\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "action : 1  next_temperatures :  [-1.42997242  1.26413933 -0.79401942  1.08269308 -1.23506343  1.59497397\n",
      " -1.28514425  1.39663718 -1.29683224]  energy_before :  50  energy_after :  80  reward :  -228.702588201867\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "action : 1  next_temperatures :  [ 0.74932124  0.72215407  0.88867006 -0.08774265  1.92702258  0.00742561\n",
      "  0.41347746  0.62957005  0.7036269 ]  energy_before :  80  energy_after :  60  reward :  -172.04647468746438\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n",
      "action : 1  next_temperatures :  [-0.42749733  0.28655541 -0.56601272  0.82796564 -0.33279717 -0.20971004\n",
      " -0.52149876  0.31629338 -0.16378086]  energy_before :  60  energy_after :  60  reward :  -198.79048243547115\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "action : 1  next_temperatures :  [-1.49223795 -0.05019586 -1.02202613 -0.03204662 -1.62887025  0.07912134\n",
      " -1.33246416 -0.37475808 -1.73595742]  energy_before :  60  energy_after :  80  reward :  -225.58943513963428\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "action : 1  next_temperatures :  [ 1.06064891  0.00760473  3.05169366 -1.82332929  1.00813999 -0.53541351\n",
      "  1.50346718 -0.17665666  0.10728407]  energy_before :  80  energy_after :  50  reward :  -163.7965609365284\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "action : 1  next_temperatures :  [-1.11864475 -0.36935565 -0.97642479 -0.03941815 -0.56542567  0.16822889\n",
      " -1.15297484 -0.05994575 -0.53785045]  energy_before :  50  energy_after :  160  reward :  -312.6518111587412\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "action : 1  next_temperatures :  [ 0.25742353  2.48967942  0.61962214  1.26452425 -0.08355234  2.31910086\n",
      "  0.03491815  1.71375302  0.68495354]  energy_before :  160  energy_after :  140  reward :  -168.69957742759513\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "action : 1  next_temperatures :  [-0.42749733  1.33953141  0.02224458  0.80585104 -0.38264613  1.36964452\n",
      " -0.50518155  1.80435755  0.04343322]  energy_before :  140  energy_after :  320  reward :  -373.9302626952756\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "action : 1  next_temperatures :  [-0.67655947  0.56299302 -0.1404002   0.22268083 -0.88113578  1.21601081\n",
      "  0.38084303  0.70558571 -1.13419329]  energy_before :  320  energy_after :  50  reward :  72.2558246650461\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "action : 1  next_temperatures :  [-2.606791   -0.92223088 -1.78508857 -0.90680194 -2.18219376 -0.59993967\n",
      " -2.18585432 -0.65117867 -1.83354079]  energy_before :  50  energy_after :  40  reward :  -201.67361959803625\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "action : 1  next_temperatures :  [ 1.46796253 -0.17131274  1.23023594 -0.37167966  1.32270638 -0.39115744\n",
      "  1.45818162  0.00876052  0.9472333 ]  energy_before :  40  energy_after :  50  reward :  -202.49906954447206\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "action : 1  next_temperatures :  [ 1.44046866 -1.36536875  0.38249517 -0.96872283  0.91342696 -1.20771464\n",
      "  1.53936504 -1.44358435  2.22701178]  energy_before :  50  energy_after :  80  reward :  -226.48262295579568\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "action : 1  next_temperatures :  [-0.42749733  0.20865027 -0.93538358  1.17442773  0.41493731  0.20202831\n",
      " -0.22778895 -0.12137255  0.35883232]  energy_before :  80  energy_after :  60  reward :  -177.35316648845827\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "action : 1  next_temperatures :  [ 0.06440038  2.40591044  0.39161544  1.39311656  0.06100966  2.10401367\n",
      " -0.03198241  1.91185444 -0.04993359]  energy_before :  60  energy_after :  50  reward :  -179.7499954227766\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "action : 1  next_temperatures :  [-0.18466176 -0.21605843  0.92059099 -0.53986338 -0.13340131 -0.50775944\n",
      " -0.0923561   0.03142661  0.10728407]  energy_before :  50  energy_after :  40  reward :  -188.61479873668097\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "action : 1  next_temperatures :  [-0.42749733  0.86456133  0.02224458  0.48641792 -0.13340131  2.0558751\n",
      " -0.17394215  1.45959965 -0.10625486]  energy_before :  40  energy_after :  60  reward :  -213.95239707748016\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "action : 1  next_temperatures :  [ 0.77215194  0.26812624  0.3460141  -0.38342305  0.26040552 -0.73104044\n",
      "  0.90928758 -0.46393663  0.78133218]  energy_before :  60  energy_after :  60  reward :  -196.24108257173538\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "action : 1  next_temperatures :  [ 0.63101673 -0.15909553 -0.02335676  0.23169048  1.1427322  -0.35412573\n",
      "  0.87035938 -0.29874242  0.07800905]  energy_before :  60  energy_after :  80  reward :  -215.8815126113676\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "action : 1  next_temperatures :  [ 2.35162096 -0.19092774  1.48604762 -0.03941815  1.75587446 -1.47565183\n",
      "  2.17084113  0.17577959  2.38965073]  energy_before :  80  energy_after :  60  reward :  -169.37618322970738\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "action : 1  next_temperatures :  [ 0.04572072 -1.4956295  -0.20348206 -1.39455175 -0.55711751 -1.35581753\n",
      " -0.49702294 -1.34223014 -0.21257254]  energy_before :  60  energy_after :  70  reward :  -215.0127032615119\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "action : 1  next_temperatures :  [-0.18466176 -0.99762296 -0.4565695  -0.4006233   0.26040552 -1.54939601\n",
      "  0.41347746 -1.20632335  0.51026725]  energy_before :  70  energy_after :  330  reward :  -461.6110466432823\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "action : 1  next_temperatures :  [-0.11616967  0.76152549 -0.07959842  0.80585104 -0.18823517  0.87494397\n",
      "  0.21277576  1.05955763 -0.75470239]  energy_before :  330  energy_after :  400  reward :  -265.4240517572327\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "action : 1  next_temperatures :  [-1.18091029 -0.37689486 -0.70737688 -0.34165103 -1.57902129 -0.05607633\n",
      " -1.15297484 -0.33099149 -1.00950342]  energy_before :  400  energy_after :  140  reward :  55.26459958183278\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "action : 1  next_temperatures :  [1.85557221 2.15460352 0.98443287 2.4988466  1.91040625 1.85819973\n",
      " 1.48551825 1.75905528 1.84752088]  energy_before :  140  energy_after :  60  reward :  -101.64584439530489\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "action : 1  next_temperatures :  [ 0.50648566  0.00760473  0.6044217  -0.2114206  -0.70334114  0.86572594\n",
      " -0.27674059  1.0303799   0.05849238]  energy_before :  60  energy_after :  60  reward :  -196.11839200969814\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "action : 1  next_temperatures :  [-1.11864475  1.31691379 -0.52041138  1.12528417 -0.88113578  1.58473172\n",
      " -0.90821667  1.75905528 -1.10407496]  energy_before :  60  energy_after :  230  reward :  -366.74649858453836\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "action : 1  next_temperatures :  [ 1.19140653 -1.32180888  0.75642617 -1.29175981  0.66418213 -1.13151231\n",
      "  0.9960019  -1.22705489  0.68555591]  energy_before :  230  energy_after :  70  reward :  -38.67856326623095\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "action : 1  next_temperatures :  [ 0.195158   -0.82757194  1.92230045 -1.69391792  0.46478627 -1.36810823\n",
      "  0.68760661 -1.15794975  0.49219626]  energy_before :  70  energy_after :  80  reward :  -209.2855002551291\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "action : 1  next_temperatures :  [ 0.25742353  0.41220887  0.47825799  0.24889072 -0.83128681  1.48947882\n",
      " -0.82663061  1.83660661  0.45093415]  energy_before :  80  energy_after :  80  reward :  -194.48411672844185\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "action : 1  next_temperatures :  [-1.63129764  1.37471438 -0.72105728  1.05894036 -1.54578864  1.38808057\n",
      " -2.03410425  1.53715098 -1.61909832]  energy_before :  80  energy_after :  50  reward :  -170.1924598501751\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "action : 1  next_temperatures :  [1.40524416 2.28789193 2.17006773 0.7569415  1.94211969 1.28829181\n",
      " 1.52511148 1.63335618 1.73191966]  energy_before :  50  energy_after :  90  reward :  -223.259055848311\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "action : 1  next_temperatures :  [-0.42749733 -0.21605843 -0.6366948   0.58347644 -0.18823517 -0.73104044\n",
      "  0.31557419 -0.56134198  0.10728407]  energy_before :  90  energy_after :  40  reward :  -149.75453344857794\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "action : 1  next_temperatures :  [ 0.74932124  0.671055    0.88867006  0.09081228  0.11584352  1.27746429\n",
      " -0.76625693  0.39230905 -0.10956787]  energy_before :  40  energy_after :  50  reward :  -204.69034936675945\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "action : 1  next_temperatures :  [ 0.23666835 -0.88872329  0.20464994 -0.96331703 -0.08355234 -0.96866058\n",
      "  0.26172739 -0.95908049 -0.16378086]  energy_before :  50  energy_after :  110  reward :  -261.32406890753475\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "action : 1  next_temperatures :  [2.06312399 2.01052089 1.66845298 1.83786575 1.86055729 1.43109801\n",
      " 2.12678465 1.58322108 2.56493938]  energy_before :  110  energy_after :  130  reward :  -200.8534359735975\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "action : 1  next_temperatures :  [-0.18466176 -0.49500911 -0.74841808  0.36355902  0.23049614 -0.35412573\n",
      " -0.41870032 -0.0061973   0.16149705]  energy_before :  130  energy_after :  60  reward :  -129.4515600940999\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "action : 1  next_temperatures :  [ 0.43799358 -0.58547961  0.9342714  -1.2336066   1.07792854 -1.0813253\n",
      "  0.80509053 -0.97597286  0.60062223]  energy_before :  60  energy_after :  60  reward :  -198.02047809493\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "action : 1  next_temperatures :  [-0.16183106 -0.36014107 -0.74841808 -0.09593324 -0.2829482  -0.90720709\n",
      "  0.21277576 -0.57838792  0.12535506]  energy_before :  60  energy_after :  50  reward :  -190.79673584164004\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "action : 1  next_temperatures :  [-1.18091029 -0.41961704 -0.61161406 -0.36540375 -1.48430825 -0.01305889\n",
      " -1.04038608 -0.47457663 -0.92276265]  energy_before :  50  energy_after :  50  reward :  -204.51263762949864\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "action : 1  next_temperatures :  [-1.2992148  -0.89458712 -1.75164758  0.09081228 -0.93596964 -0.53541351\n",
      " -0.56555523 -0.86079762 -1.0799803 ]  energy_before :  50  energy_after :  110  reward :  -265.83235351750886\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "action : 1  next_temperatures :  [-0.22617211 -1.2715475  -0.97642479 -0.34902256  0.21554145 -1.33430881\n",
      "  0.07081602 -1.43667384  0.37834899]  energy_before :  110  energy_after :  60  reward :  -152.92944315648734\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n",
      "action : 1  next_temperatures :  [ 0.0083614   0.53786233 -0.47937017  1.19654233  0.36508834  0.14057482\n",
      " -0.03198241 -0.0061973   0.47515789]  energy_before :  60  energy_after :  80  reward :  -215.7939627721036\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "action : 1  next_temperatures :  [ 0.12666591 -0.87196949 -0.70737688 -0.0484278   0.36508834 -0.93486116\n",
      "  0.50648556 -1.18943098  0.49219626]  energy_before :  80  energy_after :  370  reward :  -490.2616302407048\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step\n",
      "action : 1  next_temperatures :  [ 0.50648566 -0.24370219  0.25025128 -0.24254485 -0.68672482  0.31264458\n",
      "  0.16871929 -0.39011478  0.27534432]  energy_before :  370  energy_after :  40  reward :  131.9503584864022\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step\n",
      "action : 1  next_temperatures :  [-0.13900036  0.06037918  1.14707765 -0.49891041  0.06100966 -0.25887283\n",
      "  0.19074752 -0.0061973   0.45641569]  energy_before :  40  energy_after :  40  reward :  -196.98735120390617\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "action : 1  next_temperatures :  [ 0.43799358  1.43419035  0.77162661  0.89594757 -0.09601458  2.06867791\n",
      "  0.24541018  1.36822729  0.81416115]  energy_before :  40  energy_after :  140  reward :  -290.0597799474201\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "action : 1  next_temperatures :  [-1.74130008  1.04801538 -0.82442032  0.69773522 -2.2769068   1.46182475\n",
      " -2.57257223  2.22820245 -2.26483521]  energy_before :  140  energy_after :  240  reward :  -302.24425684263934\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "action : 1  next_temperatures :  [ 0.81781333  0.70540028  0.3460141  -0.37605152  0.26040552 -0.73104044\n",
      "  0.80509053 -0.56134198  0.64941392]  energy_before :  240  energy_after :  100  reward :  -56.084296267612984\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "action : 1  next_temperatures :  [-0.26560695  1.36717517 -0.29240467  0.13422242 -0.31618084 -0.61939994\n",
      "  0.10345044 -0.76021124 -0.93050736]  energy_before :  100  energy_after :  70  reward :  -169.57946296788464\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "action : 1  next_temperatures :  [-0.24692729  0.66351579  0.03657643  0.35127313 -0.11678498  0.67317169\n",
      " -0.47254712  0.89216961  0.16149705]  energy_before :  70  energy_after :  40  reward :  -166.05805568887467\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "action : 1  next_temperatures :  [-1.74130008  1.61848209 -1.02202613  1.51597545 -1.31316014  1.80801271\n",
      " -1.45157981  1.9725134  -1.24804056]  energy_before :  40  energy_after :  70  reward :  -227.86112305737407\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "action : 1  next_temperatures :  [-0.42749733 -1.36536875 -0.22096257 -1.52846795 -0.48732896 -1.46745803\n",
      " -0.12499052 -1.14412872 -0.26678553]  energy_before :  70  energy_after :  30  reward :  -165.0329883589642\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "action : 1  next_temperatures :  [ 1.0834796  -1.18861622  0.52841946 -0.98788881  0.7140311  -0.88467415\n",
      "  0.94705027 -1.1809848   0.45244007]  energy_before :  30  energy_after :  270  reward :  -438.5167434705911\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "action : 1  next_temperatures :  [ 0.74932124 -0.20768153  0.70626469 -0.31789831 -0.48732896  1.3358451\n",
      " -1.20682164  0.91520466 -0.66976872]  energy_before :  270  energy_after :  60  reward :  12.817136542404171\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "action : 1  next_temperatures :  [-0.24692729  0.97346099 -0.02335676  0.5027991   0.66418213  0.91693718\n",
      "  0.26172739  0.82920714 -0.41376296]  energy_before :  60  energy_after :  140  reward :  -274.5357330613631\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "action : 1  next_temperatures :  [-1.00864231 -0.31909427 -0.72105728 -0.12050502 -0.83128681 -0.09499687\n",
      " -0.55086974 -0.48993333 -0.75470239]  energy_before :  140  energy_after :  80  reward :  -142.89108801889859\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "action : 1  next_temperatures :  [ 0.0083614  -1.2715475   0.72298518 -1.87493003  0.06100966 -1.33430881\n",
      "  0.75124373 -1.38830024  0.27534432]  energy_before :  80  energy_after :  40  reward :  -162.05014228778037\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "action : 1  next_temperatures :  [ 0.5687512   0.55671035  1.39028481 -0.37359434  0.11584352  0.47549632\n",
      "  0.36452582  0.66181912 -0.04993359]  energy_before :  40  energy_after :  70  reward :  -224.29009680385275\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "action : 1  next_temperatures :  [-0.05390414  0.45995719  0.21985039  0.19892811 -0.73657378  1.64311253\n",
      " -1.05507157  0.89984796 -0.60200249]  energy_before :  70  energy_after :  110  reward :  -237.02585580526497\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "action : 1  next_temperatures :  [-1.42997242 -0.46736535 -1.80180906  0.61664835 -1.1303806  -0.6798292\n",
      " -0.6634585  -0.79169247 -1.0799803 ]  energy_before :  110  energy_after :  90  reward :  -185.4278395534982\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "action : 1  next_temperatures :  [-0.28428661  0.25891165 -0.99162523  1.60033856 -0.78143785 -0.25887283\n",
      "  0.21277576 -0.40009664 -0.48363747]  energy_before :  90  energy_after :  540  reward :  -649.1279306618072\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "action : 1  next_temperatures :  [-2.73754861  0.63587203 -1.80180906  0.63384859 -2.2769068   0.51953798\n",
      " -2.67537066  0.73092426 -2.16424   ]  energy_before :  540  energy_after :  70  reward :  262.8643077362597\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "action : 1  next_temperatures :  [-0.24692729 -0.38610945 -0.52041138 -0.16964858 -0.33279717 -0.78122745\n",
      " -1.28351253 -0.8515836  -1.19382757]  energy_before :  70  energy_after :  60  reward :  -193.7660450037493\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "action : 1  next_temperatures :  [-0.05390414 -0.19092774 -0.56601272  0.46839861 -0.01874869 -0.13903853\n",
      " -0.32079706 -0.12137255  0.05849238]  energy_before :  60  energy_after :  20  reward :  -158.88391042161078\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "action : 1  next_temperatures :  [ 2.12538953  0.34351831  1.44044628 -0.55640838  0.7140311  -2.20489985\n",
      "  1.97503459 -1.22091221  2.36579702]  energy_before :  20  energy_after :  60  reward :  -233.01800361979735\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n",
      "action : 1  next_temperatures :  [-0.05390414 -1.04788434 -0.66177553 -0.37359434 -0.08355234 -0.9778786\n",
      " -0.22778895 -0.97597286 -0.59206344]  energy_before :  60  energy_after :  50  reward :  -192.99441454511907\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "action : 1  next_temperatures :  [-0.38079818  1.28487215  0.07240605  0.92870994 -1.08053164  1.93194391\n",
      " -0.03035069  1.96560289 -0.32099851]  energy_before :  50  energy_after :  90  reward :  -233.62914409046851\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "action : 1  next_temperatures :  [-0.9256216  -0.34171189 -0.85634126 -0.23435426 -0.73657378 -0.13903853\n",
      " -0.61450686 -0.39165045 -0.95890464]  energy_before :  90  energy_after :  50  reward :  -163.1987032738972\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "action : 1  next_temperatures :  [-0.18466176  1.39816969 -0.29240467  0.88693791 -0.58204199  0.55845852\n",
      "  0.56033236  0.12970949 -0.53785045]  energy_before :  50  energy_after :  690  reward :  -836.0633509003205\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "action : 1  next_temperatures :  [-0.55825495 -0.63574099 -0.43376883 -0.71022771 -0.45409631 -0.66139315\n",
      " -0.85926503 -0.69033825 -1.0799803 ]  energy_before :  690  energy_after :  70  reward :  415.9169344571712\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "action : 1  next_temperatures :  [ 0.12666591 -0.03344207  1.53164896 -1.15251973  0.11584352 -0.1666926\n",
      "  0.45753393 -0.32254531  0.76326118]  energy_before :  70  energy_after :  60  reward :  -186.6802462041485\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "action : 1  next_temperatures :  [-0.55825495  0.57053223 -0.10999931  0.00972541 -0.47237427  0.51697742\n",
      " -0.61450686  0.29095483 -0.35744169]  energy_before :  60  energy_after :  60  reward :  -198.7243871918971\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "action : 1  next_temperatures :  [-1.11864475 -0.6022334  -1.29563417 -0.0484278  -0.81467049  0.09960583\n",
      " -0.8103134  -0.34250902 -0.92276265]  energy_before :  60  energy_after :  130  reward :  -273.8555898466368\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "action : 1  next_temperatures :  [-0.67655947 -1.13835483 -1.46283909 -0.1712867  -0.33279717 -1.42956172\n",
      "  0.1850365  -1.38830024 -0.65169772]  energy_before :  130  energy_after :  30  reward :  -105.06636042653005\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "action : 1  next_temperatures :  [-0.60028419 -0.76327925 -0.15560065 -0.94120243 -0.86451946  0.45603605\n",
      " -1.74528961 -0.30565294 -0.43484578]  energy_before :  30  energy_after :  60  reward :  -233.35463826754315\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "action : 1  next_temperatures :  [-0.98788713 -1.29919126 -1.75164758 -0.06317087 -1.03068267 -0.68904722\n",
      " -0.76625693 -1.11187965 -0.86312836]  energy_before :  60  energy_after :  60  reward :  -206.5628916814105\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "action : 1  next_temperatures :  [-0.22617211 -0.11637335 -0.38360736 -0.20404907 -0.53219302 -0.09499687\n",
      " -0.85926503 -0.48993333 -0.66073322]  energy_before :  60  energy_after :  40  reward :  -181.56732336052266\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "action : 1  next_temperatures :  [ 0.37572804  1.04717769  0.52841946 -0.75855221  0.06100966 -0.83346291\n",
      "  0.60928399 -0.50006875  1.14094498]  energy_before :  40  energy_after :  40  reward :  -196.3295200456141\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "action : 1  next_temperatures :  [ 0.68705571  0.36781132  0.28369227  0.51836123  0.26040552  0.06887909\n",
      " -0.07603889 -0.56671682  0.27534432]  energy_before :  40  energy_after :  120  reward :  -276.1812062618889\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "action : 1  next_temperatures :  [-0.3652318  -0.46736535 -0.79401942  0.11784124 -0.98581861 -0.41250654\n",
      " -0.30774329 -1.1065048  -0.32099851]  energy_before :  120  energy_after :  50  reward :  -132.64234709394566\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "action : 1  next_temperatures :  [ 0.37572804 -0.12370314  0.00704413  0.27264344 -0.08355234 -0.34285926\n",
      " -0.07603889  0.00071321  0.54640924]  energy_before :  50  energy_after :  120  reward :  -267.4236155471127\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "action : 1  next_temperatures :  [-0.96713196  2.94203188 -0.41704834  2.22855704 -0.95258596  1.91248364\n",
      " -1.15297484  1.62698767 -1.13419329]  energy_before :  120  energy_after :  50  reward :  -123.9138741624572\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "action : 1  next_temperatures :  [-0.61429393 -1.06296275 -0.52041138 -1.12876701 -0.65016891 -0.94612763\n",
      " -0.56555523 -1.15276686 -0.80891538]  energy_before :  50  energy_after :  50  reward :  -205.44996908828682\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "action : 1  next_temperatures :  [0.79498263 1.36717517 0.43265665 1.73957864 1.36206764 0.93639745\n",
      " 1.14775197 1.1225201  1.57645596]  energy_before :  50  energy_after :  80  reward :  -217.52041379326894\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "action : 1  next_temperatures :  [ 0.81781333  0.41220887  0.02224458  1.09170274  1.16267178 -0.25887283\n",
      "  0.26172739  0.66181912  0.85361616]  energy_before :  80  energy_after :  90  reward :  -202.9750688648527\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n",
      "action : 1  next_temperatures :  [ 1.06064891 -1.39720096  0.9038705  -2.04693248  0.54288298 -1.08849487\n",
      "  0.9960019  -1.22705489  1.14275208]  energy_before :  90  energy_after :  60  reward :  -169.11352683213394\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "action : 1  next_temperatures :  [ 0.25742353 -0.79657742  0.40529584 -0.97969822 -0.03370338 -0.90720709\n",
      "  0.31557419 -0.83545906 -0.26678553]  energy_before :  60  energy_after :  60  reward :  -200.8411371393985\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "action : 1  next_temperatures :  [1.88142185 2.24583555 1.8500367  1.55257486 2.2561768  1.34450446\n",
      " 1.54686214 1.77495154 1.81870497]  energy_before :  60  energy_after :  50  reward :  -171.72893113009505\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "action : 1  next_temperatures :  [-0.86958262 -0.49500911 -0.93538358 -0.20404907 -0.63189095  0.26040912\n",
      " -1.05507157  0.01453424 -0.43755643]  energy_before :  50  energy_after :  100  reward :  -252.3535999751384\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "action : 1  next_temperatures :  [-0.24692729  1.3076992   0.07240605  0.80585104 -0.23808413  1.5509323\n",
      " -1.0110151   1.33751389 -0.23094472]  energy_before :  100  energy_after :  60  reward :  -154.6525687576387\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "action : 1  next_temperatures :  [ 0.9423444  -0.33584806  0.88867006 -0.68483687  0.32853244 -0.32032631\n",
      "  0.65823563 -0.06148142  0.87168715]  energy_before :  60  energy_after :  60  reward :  -195.71302300137128\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "action : 1  next_temperatures :  [ 1.25367206 -0.20768153  1.11667676 -0.26875475 -0.53219302  1.24366488\n",
      " -1.05507157  1.13019845 -0.48363747]  energy_before :  60  energy_after :  40  reward :  -175.80312620480004\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "action : 1  next_temperatures :  [ 0.43799358  0.25891165  0.75642617 -0.11968596  0.06100966  0.78276374\n",
      " -0.71730529  0.38539853 -0.03788626]  energy_before :  40  energy_after :  100  reward :  -256.1923741921388\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "action : 1  next_temperatures :  [-0.98788713  0.61325441 -0.33800601  0.09982193 -0.63189095  0.75510967\n",
      " -0.96206346  0.82076096 -0.32099851]  energy_before :  100  energy_after :  40  reward :  -138.95189911420718\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "action : 1  next_temperatures :  [2.18765506 1.71649179 2.39807444 0.8549946  2.20950004 0.87494397\n",
      " 2.27363956 1.32753203 2.36977264]  energy_before :  40  energy_after :  50  reward :  -191.7873958744014\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "action : 1  next_temperatures :  [-1.61054246  1.81952763 -0.88978224  1.6658633  -1.2799275   1.89199914\n",
      " -1.34878137  2.19595338 -1.2058749 ]  energy_before :  50  energy_after :  60  reward :  -206.76156502744686\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "action : 1  next_temperatures :  [ 0.5687512  -0.3165812  -0.02335676 -0.14139103  1.29061746 -0.91642512\n",
      "  0.75124373 -0.88152916  0.76326118]  energy_before :  60  energy_after :  80  reward :  -216.90540970014072\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n",
      "action : 1  next_temperatures :  [-1.18091029 -1.54128359 -1.29563417 -1.30977912 -1.06628908 -0.92300942\n",
      " -0.79562791 -1.45740538 -0.70591071]  energy_before :  80  energy_after :  100  reward :  -228.27584966350705\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "action : 1  next_temperatures :  [ 0.9423444  -0.52684132  1.1049507  -0.92365116  1.21252075 -0.68904722\n",
      "  1.20812565 -0.79169247  1.63066894]  energy_before :  100  energy_after :  60  reward :  -154.8326217415222\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "action : 1  next_temperatures :  [ 1.12914099 -1.62589026  0.78682706 -1.81595776  0.41493731 -1.1806751\n",
      "  1.09880034 -1.40365694  0.81747417]  energy_before :  60  energy_after :  360  reward :  -499.77900018744447\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n",
      "action : 1  next_temperatures :  [-0.30296627  0.77074008  0.11800739  0.59125751 -0.84790314  1.63389451\n",
      " -0.71730529  1.35287059 -0.86312836]  energy_before :  360  energy_after :  40  reward :  123.73546701201204\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "action : 1  next_temperatures :  [-0.42749733 -0.9038017  -0.85634126 -0.12787655 -1.03068267 -0.56614025\n",
      "  0.26172739 -1.06580955 -0.26678553]  energy_before :  40  energy_after :  70  reward :  -232.98320746536137\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "action : 1  next_temperatures :  [-2.79358759  0.75398628 -1.8474104   0.77145055 -2.37660473  0.67061113\n",
      " -2.71942713  0.87527724 -2.21845299]  energy_before :  70  energy_after :  100  reward :  -236.8841576319099\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "action : 1  next_temperatures :  [2.35162096 2.5809876  2.33032388 2.01899487 1.94779298 2.03180582\n",
      " 2.51839773 1.7494025  2.42579272]  energy_before :  100  energy_after :  50  reward :  -128.04488094913492\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "action : 1  next_temperatures :  [ 0.0083614   0.73890787  0.25025128  0.5511236  -0.73657378  1.70456601\n",
      " -1.64249118  1.74216291 -0.25172637]  energy_before :  50  energy_after :  20  reward :  -165.6354182499542\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "action : 1  next_temperatures :  [ 0.68705571 -1.85039111  0.43265665 -1.98140774 -0.33279717 -1.36810823\n",
      "  0.56033236 -1.58102681 -0.56495695]  energy_before :  20  energy_after :  70  reward :  -253.9986432842384\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "action : 1  next_temperatures :  [ 0.37572804 -0.19092774 -0.06439797  0.18254692  0.16569248 -0.2701393\n",
      "  0.19809027 -0.12137255  0.25727332]  energy_before :  70  energy_after :  60  reward :  -187.46750651723448\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "action : 1  next_temperatures :  [-1.49223795 -0.03344207 -1.05242702  0.01054447 -1.57902129  0.10677541\n",
      " -1.28514425 -0.34481252 -1.68294917]  energy_before :  60  energy_after :  50  reward :  -195.3527143938368\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "action : 1  next_temperatures :  [-0.55825495 -0.81165583 -0.12519976 -1.01491777 -1.00077329  0.35566202\n",
      " -1.78934608 -0.32254531 -0.69988704]  energy_before :  50  energy_after :  180  reward :  -333.96691801971895\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n",
      "action : 1  next_temperatures :  [-1.11864475 -0.84432573 -0.47937017 -1.0222893  -1.84488243 -0.35412573\n",
      " -1.20682164 -0.49837951 -0.82999821]  energy_before :  180  energy_after :  50  reward :  -76.19883747841308\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "action : 1  next_temperatures :  [2.24369404 2.12109593 1.75965567 1.88455213 1.9317701  1.79279566\n",
      " 2.32259119 1.58897984 2.4980767 ]  energy_before :  50  energy_after :  90  reward :  -219.85678874196506\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "action : 1  next_temperatures :  [ 0.12666591 -0.06527428  0.30041276 -0.22616367 -0.88113578  0.78276374\n",
      " -0.56555523  0.96127475 -0.16378086]  energy_before :  90  energy_after :  50  reward :  -157.73079264840666\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "action : 1  next_temperatures :  [-0.30296627 -0.3165812  -0.74841808  0.5331043  -0.16995721 -0.62759374\n",
      " -0.3860659  -0.19892388 -0.10956787]  energy_before :  50  energy_after :  50  reward :  -200.32696985595132\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "action : 1  next_temperatures :  [ 0.5687512  -0.49333373 -0.26504387  0.22349988  0.24545083 -1.17043285\n",
      " -0.07603889 -1.09805862 -0.43213513]  energy_before :  50  energy_after :  20  reward :  -170.49734118861085\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "action : 1  next_temperatures :  [1.86444034 2.35124738 1.80320289 1.7073992  2.28635808 1.44674071\n",
      " 1.53363197 1.8333485  1.8025876 ]  energy_before :  20  energy_after :  60  reward :  -221.37104332386508\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "action : 1  next_temperatures :  [-1.38431103 -0.82757194 -1.8474104   0.30540581 -1.08053164 -0.62759374\n",
      " -0.6634585  -0.86079762 -0.97697563]  energy_before :  60  energy_after :  30  reward :  -175.96324467053702\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "action : 1  next_temperatures :  [-0.11616967 -0.84432573 -0.66177553 -0.08119017  0.16569248 -1.01679914\n",
      "  0.50648556 -1.18460459  0.22113133]  energy_before :  30  energy_after :  250  reward :  -421.0115554622927\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "action : 1  next_temperatures :  [ 0.02704106 -0.47657994 -0.10999931 -0.3342795  -0.65016891 -0.22814609\n",
      "  0.05286708 -0.53600343 -0.10956787]  energy_before :  250  energy_after :  80  reward :  -30.364836896210647\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "action : 1  next_temperatures :  [-0.38598698  1.47607484 -0.20576213  1.53399476 -0.2829482   1.13407283\n",
      " -0.32079706  1.52870479 -0.59206344]  energy_before :  80  energy_after :  90  reward :  -204.11471058619384\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "action : 1  next_temperatures :  [-1.36148033 -0.71113307 -1.6604449   0.12766995 -1.18521446 -0.70953172\n",
      " -0.96206346 -1.1372182  -1.13419329]  energy_before :  90  energy_after :  50  reward :  -166.7336094891623\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "action : 1  next_temperatures :  [-1.23694927 -1.04788434 -1.21963194 -0.8814111  -1.19945703 -0.56701816\n",
      " -1.29982974 -0.84390525 -1.40603268]  energy_before :  50  energy_after :  100  reward :  -257.7021195050197\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "action : 1  next_temperatures :  [-3.04887628  1.33953141 -1.93405295  1.24814306 -2.48128755  1.21601081\n",
      " -2.8173304   1.22924916 -2.29435116]  energy_before :  100  energy_after :  230  reward :  -335.54296390675046\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "action : 1  next_temperatures :  [0.88007886 1.29178309 0.51169897 1.6658633  1.30723378 0.90874338\n",
      " 1.14775197 1.09718154 1.57645596]  energy_before :  230  energy_after :  80  reward :  -37.61320913661157\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "action : 1  next_temperatures :  [-2.98661075  1.08822449 -1.8884516   0.97785349 -2.48128755  0.97019687\n",
      " -2.77327393  1.15246566 -2.27808727]  energy_before :  80  energy_after :  170  reward :  -296.2189705906578\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "action : 1  next_temperatures :  [ 0.23666835  1.15775274  0.80202751  0.35454937  0.38170466 -0.10523912\n",
      "  0.65823563 -0.08254203  0.81747417]  energy_before :  170  energy_after :  50  reward :  -73.77936872107611\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "action : 1  next_temperatures :  [-1.11864475  0.63587203 -0.47937017  0.16452762 -0.88113578  0.56767654\n",
      " -1.05507157  0.59041047 -0.48363747]  energy_before :  50  energy_after :  110  reward :  -260.0593730857873\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "action : 1  next_temperatures :  [-0.55825495 -0.51762674 -0.55081227 -0.2114206  -0.18823517 -1.275928\n",
      "  0.21277576 -0.60510857  0.16149705]  energy_before :  110  energy_after :  550  reward :  -641.5331134995203\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "action : 1  next_temperatures :  [ 1.06064891 -0.59553188  0.70626469 -0.69548464  1.00813999 -1.00509372\n",
      "  1.14775197 -0.92759926  1.53463451]  energy_before :  550  energy_after :  60  reward :  294.2337305709183\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "action : 1  next_temperatures :  [ 0.04572072  0.84613215  0.02224458  0.96884384 -0.31618084  0.98043912\n",
      "  0.26172739  0.88372342  0.72066527]  energy_before :  60  energy_after :  50  reward :  -183.5866843530024\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "action : 1  next_temperatures :  [ 0.25742353 -0.45061156 -0.47937017  0.24070013  1.21252075 -0.56614025\n",
      "  0.56033236 -0.86770813  0.56448024]  energy_before :  50  energy_after :  110  reward :  -257.528373108181\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "action : 1  next_temperatures :  [-1.05015267 -0.05773507 -0.88978224  0.11784124 -0.88113578 -0.1666926\n",
      " -0.40238311  0.04678331 -0.65169772]  energy_before :  110  energy_after :  70  reward :  -161.93495464517648\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "action : 1  next_temperatures :  [-1.27845962 -0.48579453  0.05568556 -0.75199974 -1.1303806  -0.70953172\n",
      "  0.07081602 -0.65117867 -0.92276265]  energy_before :  70  energy_after :  40  reward :  -173.80360594257897\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "action : 1  next_temperatures :  [ 0.25742353  0.25891165  0.52841946  0.01955412 -0.58204199  1.03984415\n",
      " -0.19189109  0.66181912  0.3620851 ]  energy_before :  40  energy_after :  80  reward :  -235.64587594816302\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n",
      "action : 1  next_temperatures :  [-0.85401624  0.62581975 -0.76361853  0.37830209 -1.08053164 -0.02432536\n",
      " -1.0110151  -0.100641   -1.0799803 ]  energy_before :  80  energy_after :  290  reward :  -411.91000632399147\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "action : 1  next_temperatures :  [-0.18466176  0.21786485 -0.80921987  1.23176188  0.26040552 -0.29267225\n",
      "  0.62560121 -0.03844637  0.43256198]  energy_before :  290  energy_after :  40  reward :  53.443195185982404\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "action : 1  next_temperatures :  [-0.05390414  1.25660013 -0.29240467  1.75432171  0.31025448  0.69365619\n",
      "  0.07081602  1.08681577  0.10728407]  energy_before :  40  energy_after :  500  reward :  -653.0665604537885\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "action : 1  next_temperatures :  [-1.36148033 -0.42715624 -0.66177553 -0.57262575 -1.82826611  0.10677541\n",
      " -1.07954739 -0.2313649  -1.56789717]  energy_before :  500  energy_after :  100  reward :  194.37666197534122\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "action : 1  next_temperatures :  [1.98048065 1.63093321 2.12323392 0.64943285 2.08011932 0.74812632\n",
      " 1.62403814 1.4343026  1.91272299]  energy_before :  100  energy_after :  50  reward :  -133.81660999976947\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "action : 1  next_temperatures :  [ 0.06440038 -0.08202807 -0.33800601  0.5109897   0.31025448 -0.44630596\n",
      "  0.45753393 -0.19047769  0.12535506]  energy_before :  50  energy_after :  240  reward :  -387.58828419269486\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "action : 1  next_temperatures :  [-0.80731709  0.96257103 -0.15560065  0.70510675 -1.14865856  1.41983153\n",
      " -2.03410425  1.62007715 -1.56789717]  energy_before :  240  energy_after :  50  reward :  -9.005991250670746\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "action : 1  next_temperatures :  [ 1.12914099  0.03524849  2.9407304  -1.93881665  0.99532168 -0.52751235\n",
      "  1.53936504 -0.20737006  0.16149705]  energy_before :  50  energy_after :  60  reward :  -203.87239540362495\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "action : 1  next_temperatures :  [ 1.19140653  0.14414816  0.23505084  0.77308867  1.49167495  0.00742561\n",
      "  1.29460687 -0.0061973   0.05849238]  energy_before :  60  energy_after :  70  reward :  -202.81030330241168\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "action : 1  next_temperatures :  [-0.63504911  0.77995467 -0.59641361  0.3701115  -0.88113578  0.3218626\n",
      " -0.58187244 -0.15285378 -0.95288097]  energy_before :  70  energy_after :  480  reward :  -610.3282769257673\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "action : 1  next_temperatures :  [-0.41193095 -1.27783017 -0.25136347 -1.45475261 -0.61527463 -1.14994836\n",
      " -0.27674059 -1.47276208 -0.86312836]  energy_before :  480  energy_after :  70  reward :  204.22626877514858\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "action : 1  next_temperatures :  [ 0.31968906 -0.29396358 -0.33800601  0.44280301  0.26040552 -0.13903853\n",
      "  0.01696922  0.15504804  0.27534432]  energy_before :  70  energy_after :  50  reward :  -177.30074895255598\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "action : 1  next_temperatures :  [-0.24692729  0.47671098 -0.30760512  0.44464589 -0.58204199  0.61991201\n",
      "  0.56033236  0.10897794 -0.53785045]  energy_before :  50  energy_after :  60  reward :  -207.4638456689053\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "action : 1  next_temperatures :  [-1.74130008  1.01283241 -0.97642479  0.87956638 -1.16693651  1.79674624\n",
      " -1.15297484  1.19162524 -1.29683224]  energy_before :  60  energy_after :  140  reward :  -279.45369818628615\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "action : 1  next_temperatures :  [ 1.01913855 -0.49500911  0.65245511 -0.66403277  1.00813999 -0.96866058\n",
      "  1.14775197 -0.90686771  1.42775748]  energy_before :  140  energy_after :  40  reward :  -95.7793270673294\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "action : 1  next_temperatures :  [-0.18466176 -1.03866975 -0.46416972 -0.62832178 -0.48732896 -1.33430881\n",
      "  0.01696922 -1.25239345 -0.59206344]  energy_before :  40  energy_after :  50  reward :  -213.96494845179183\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "action : 1  next_temperatures :  [-0.38598698 -1.43238393  0.5740208  -1.87493003 -0.48732896 -1.57192896\n",
      "  0.36452582 -1.38830024 -0.65169772]  energy_before :  50  energy_after :  210  reward :  -364.85401018147684\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "action : 1  next_temperatures :  [ 0.25742353  0.87126285  0.37641499  0.45365555  0.07928761  0.65063875\n",
      " -0.61450686  0.66181912  0.05849238]  energy_before :  210  energy_after :  50  reward :  -35.20551208861059\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "action : 1  next_temperatures :  [ 1.68629622 -0.66968374  1.46209211 -1.22371407  1.2916317  -0.75030118\n",
      "  1.62983021 -0.19765745  0.96835524]  energy_before :  50  energy_after :  100  reward :  -243.80315095896955\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "action : 1  next_temperatures :  [-0.11616967  0.67608114  0.11800739  0.3881308   0.41244486  0.7005697\n",
      " -0.03198241 -0.22618202  0.22113133]  energy_before :  100  energy_after :  20  reward :  -115.85796886741218\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "action : 1  next_temperatures :  [1.75179633 3.36841595 1.35988391 3.2957913  2.7860864  2.51677624\n",
      " 1.43656661 2.47237396 1.65235414]  energy_before :  20  energy_after :  60  reward :  -217.35995515701777\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "action : 1  next_temperatures :  [ 0.12666591  0.41220887  1.51492847 -0.42437602  0.41493731 -0.20049202\n",
      "  1.06616591  0.15504804  0.66490334]  energy_before :  60  energy_after :  110  reward :  -244.2700101811698\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "action : 1  next_temperatures :  [-0.59561427 -1.19615542 -1.39139699 -0.16227704 -0.98581861 -0.71977397\n",
      " -0.61450686 -1.02204296 -0.70591071]  energy_before :  110  energy_after :  30  reward :  -125.3934968274751\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "action : 1  next_temperatures :  [-2.20206503 -0.17961893 -1.47803954 -0.11968596 -1.9827979   0.10677541\n",
      " -2.37676569  0.06060434 -1.94738806]  energy_before :  30  energy_after :  170  reward :  -348.1189813641559\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "action : 1  next_temperatures :  [-0.61429393 -0.6432802  -1.25003283  0.28001498  0.38170466 -0.80376039\n",
      " -0.71730529 -0.51527188 -0.16378086]  energy_before :  170  energy_after :  50  reward :  -82.04600575127233\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n",
      "action : 1  next_temperatures :  [-2.67528308  0.43733956 -1.75164758  0.5109897  -2.23204273  0.41404283\n",
      " -2.62152386  0.59885665 -2.13442286]  energy_before :  50  energy_after :  120  reward :  -277.4536913725718\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "action : 1  next_temperatures :  [ 0.195158   -0.34171189  0.37641499 -0.71759925  0.11584352 -0.59993967\n",
      "  0.21277576 -0.17665666  0.27534432]  energy_before :  120  energy_after :  40  reward :  -118.66037088491771\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "action : 1  next_temperatures :  [-0.18466176  0.07713298  0.20464994 -0.52348219 -0.42377153  1.28975499\n",
      " -1.05507157  0.76010199 -1.35104523]  energy_before :  40  energy_after :  610  reward :  -769.2063923677194\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "action : 1  next_temperatures :  [ 0.9423444  -1.30673047  1.08931596 -1.63658377  0.84007777 -1.53842218\n",
      "  1.34355851 -1.1809848   1.95594685]  energy_before :  610  energy_after :  60  reward :  352.50852226122515\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "action : 1  next_temperatures :  [ 0.99838337  0.19357185  1.71405433 -0.76919998  1.05798895 -0.03559183\n",
      "  1.29460687  0.04678331  0.85000196]  energy_before :  60  energy_after :  60  reward :  -192.649401164966\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "action : 1  next_temperatures :  [-0.71806982 -0.3249581  -0.74841808 -0.03941815 -0.48732896 -0.20049202\n",
      " -0.17394215 -0.67651722 -0.3806328 ]  energy_before :  60  energy_after :  60  reward :  -201.74977730178628\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "action : 1  next_temperatures :  [ 1.60235905  0.56299302  2.26322476 -0.97454985  1.91040625 -0.66139315\n",
      "  1.83307485  0.2771338   1.26563484]  energy_before :  60  energy_after :  30  reward :  -159.92111642345142\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "action : 1  next_temperatures :  [1.87632739 1.79439694 1.39028481 1.88455213 2.1525298  0.81656316\n",
      " 2.07783302 1.55788252 2.22701178]  energy_before :  30  energy_after :  380  reward :  -532.2226184590027\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "action : 1  next_temperatures :  [-0.24692729  0.91482271  0.11800739  0.45938896 -0.23808413  1.92272588\n",
      " -0.0156652   1.49799139  0.0042794 ]  energy_before :  380  energy_after :  90  reward :  96.4165391198901\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "action : 1  next_temperatures :  [ 0.81781333 -0.34254958  0.30041276 -0.98952693  0.66418213 -1.97137661\n",
      "  0.78970573 -1.56632826  0.87168715]  energy_before :  90  energy_after :  70  reward :  -179.42598027408852\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "action : 1  next_temperatures :  [ 0.68705571 -1.03866975  0.43265665 -0.97150763  0.31025448 -0.53541351\n",
      " -0.07603889 -0.14440759  0.31148631]  energy_before :  70  energy_after :  210  reward :  -339.02458422259906\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "action : 1  next_temperatures :  [ 0.77215194  0.23629403  0.84762885  0.19892811  1.00813999 -0.22814609\n",
      "  0.94705027  0.22415319  0.83296359]  energy_before :  210  energy_after :  110  reward :  -93.16083612658207\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "action : 1  next_temperatures :  [-0.11616967  0.56299302  0.16360874  0.36355902  0.11584352  1.39729859\n",
      " -0.27674059  0.66181912 -0.33425058]  energy_before :  110  energy_after :  30  reward :  -115.46203882260971\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "action : 1  next_temperatures :  [-0.30296627 -0.08370345  0.33081365 -1.00590812 -0.33279717 -0.47396003\n",
      "  0.22909297 -0.93604544 -0.53785045]  energy_before :  30  energy_after :  60  reward :  -231.11332430564462\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "action : 1  next_temperatures :  [-0.18466176 -0.49500911 -0.43376883 -0.4227379  -0.63189095  0.07912134\n",
      " -0.55086974  0.06060434  0.18468816]  energy_before :  60  energy_after :  50  reward :  -190.39452444908022\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "action : 1  next_temperatures :  [-0.98788713 -1.04788434 -1.25003283 -0.38260399  0.47974096 -0.35412573\n",
      " -0.6634585  -1.02895347 -0.53785045]  energy_before :  50  energy_after :  50  reward :  -203.77305548958032\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "action : 1  next_temperatures :  [ 1.25367206 -2.41164323  1.44044628 -3.06174695  0.50965034 -1.37732625\n",
      "  1.29460687 -1.37294354  0.7036269 ]  energy_before :  50  energy_after :  180  reward :  -331.0216575130046\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "action : 1  next_temperatures :  [-0.67655947 -0.9616023  -1.29563417 -0.19503942 -0.38264613 -1.41829524\n",
      " -0.20984002 -0.89842153 -0.21257254]  energy_before :  180  energy_after :  60  reward :  -84.25061081883291\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "action : 1  next_temperatures :  [-0.5722647  -0.70673519 -1.29563417  0.26527191 -0.33279717 -1.14994836\n",
      " -0.17394215 -0.94295596 -0.04993359]  energy_before :  60  energy_after :  50  reward :  -192.95893938405607\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "action : 1  next_temperatures :  [-0.3652318  -0.66170937 -0.19322176 -0.68197017 -0.75152847 -0.87340768\n",
      "  0.16871929 -0.86617246 -0.0065632 ]  energy_before :  50  energy_after :  40  reward :  -192.2310856203326\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "action : 1  next_temperatures :  [ 7.49321242e-01  6.55207951e-05  3.30813652e-01  1.91556572e-01\n",
      "  2.93638160e-01 -2.43253615e-02  4.57533928e-01 -2.92323497e-02\n",
      "  7.63261184e-01]  energy_before :  40  energy_after :  90  reward :  -245.2673674528218\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "action : 1  next_temperatures :  [ 0.99838337 -1.28997667  1.37074137 -1.68151503  0.96327592 -1.30358207\n",
      "  1.45288382 -1.32687344  1.95594685]  energy_before :  90  energy_after :  80  reward :  -186.8607158666114\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "action : 1  next_temperatures :  [-1.00345352 -0.73249415 -0.56601272 -0.86502992 -1.52917232  0.10677541\n",
      " -1.94109615 -0.19047769 -1.24804056]  energy_before :  80  energy_after :  350  reward :  -475.9690016204765\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "action : 1  next_temperatures :  [0.12666591 1.06560687 0.03896507 1.37100196 0.41493731 0.78276374\n",
      " 0.11976765 1.14555515 0.10728407]  energy_before :  350  energy_after :  40  reward :  117.17254771468285\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n",
      "action : 1  next_temperatures :  [ 1.19140653 -0.01501289  0.25025128  0.63384859  1.5564786   0.20202831\n",
      "  1.34355851 -0.0061973   0.10728407]  energy_before :  40  energy_after :  90  reward :  -242.73635430834415\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "action : 1  next_temperatures :  [ 1.99463191  0.35105752  4.06708352 -2.09607604  1.92464882 -0.20049202\n",
      "  2.11046744 -0.08374863  1.84752088]  energy_before :  90  energy_after :  20  reward :  -118.08490660649034\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "action : 1  next_temperatures :  [-0.61429393 -0.76893366 -1.25003283  0.19892811 -0.33279717 -1.14994836\n",
      " -0.17394215 -0.9967044  -0.04993359]  energy_before :  20  energy_after :  100  reward :  -283.13765799135984\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "action : 1  next_temperatures :  [-0.24692729 -0.39197328 -0.62833455  0.45365555 -0.13340131 -0.61837572\n",
      " -0.47254712  0.06060434 -0.03186259]  energy_before :  100  energy_after :  240  reward :  -340.00916196680646\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "action : 1  next_temperatures :  [0.85932368 1.02372238 0.96771238 0.56586667 0.06100966 1.5881458\n",
      " 0.11976765 1.87423053 0.16812308]  energy_before :  240  energy_after :  40  reward :  9.227901831444399\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "action : 1  next_temperatures :  [-0.86958262  0.27734082 -0.52041138  0.36929244 -0.96754065  1.40037126\n",
      " -1.20192647 -0.0676241  -0.30834882]  energy_before :  40  energy_after :  120  reward :  -279.8884295115554\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "action : 1  next_temperatures :  [ 0.25742353 -0.67092396  0.05568556 -0.61931213 -0.41920204 -0.27116353\n",
      " -0.8103134  -0.12137255  0.43346553]  energy_before :  120  energy_after :  180  reward :  -260.16571297775914\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "action : 1  next_temperatures :  [-0.61429393 -0.87196949 -0.44896928 -0.84864873 -0.73657378 -0.68904722\n",
      " -0.90821667 -0.58207352 -1.13419329]  energy_before :  180  energy_after :  40  reward :  -64.83398592115407\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "action : 1  next_temperatures :  [-0.24692729  0.34812561  1.51644852 -1.17627245 -0.11678498 -0.73206466\n",
      "  0.7022921  -0.86079762  0.05849238]  energy_before :  40  energy_after :  90  reward :  -248.50748840102506\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "action : 1  next_temperatures :  [-0.24692729 -0.23741952 -0.47937017 -0.30626767 -0.23808413 -0.71977397\n",
      " -0.96206346 -0.78445288 -0.84505737]  energy_before :  90  energy_after :  70  reward :  -182.8194164593389\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n",
      "action : 1  next_temperatures :  [ 0.0083614  -0.04265666 -0.69217643  0.95983419  0.19892513 -0.24965481\n",
      " -0.12499052  0.12279897  0.16149705]  energy_before :  70  energy_after :  50  reward :  -177.6580616707321\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "action : 1  next_temperatures :  [-0.55825495 -0.46736535 -0.64505504 -0.06317087 -0.18823517 -1.1806751\n",
      "  0.11976765 -0.58207352  0.16149705]  energy_before :  50  energy_after :  470  reward :  -621.4035653086588\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "action : 1  next_temperatures :  [-0.3652318  -1.65018326 -0.1404002  -2.14358148 -0.38264613 -1.42751327\n",
      " -0.12499052 -1.56643795 -0.32099851]  energy_before :  470  energy_after :  50  reward :  213.87801687852894\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "action : 1  next_temperatures :  [ 1.44046866 -2.31028277  1.80069687 -3.08713778  0.61433317 -1.67537566\n",
      "  0.94705027 -1.76684287  0.83554516]  energy_before :  50  energy_after :  70  reward :  -221.20154495239325\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "action : 1  next_temperatures :  [ 2.41596201 -1.94253698  2.6108807  -2.57850196  1.46176557 -1.02704139\n",
      "  1.76617428 -0.92145658  1.24575675]  energy_before :  70  energy_after :  40  reward :  -164.96899759736863\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "action : 1  next_temperatures :  [-1.42997242  0.27273353 -0.93538358  0.26527191 -1.2799275   0.44784225\n",
      " -0.96206346 -0.16974615 -1.06642706]  energy_before :  40  energy_after :  100  reward :  -262.85767247996233\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "action : 1  next_temperatures :  [ 1.06064891 -0.96997919  1.03003421 -1.15989126  1.1427322  -0.91826872\n",
      "  1.31092408 -1.05045285  1.97546353]  energy_before :  100  energy_after :  40  reward :  -135.57878910670988\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "action : 1  next_temperatures :  [ 0.0083614   0.33681679 -0.09479886  0.40287387 -0.53219302  0.40482481\n",
      "  0.16871929 -0.04458905 -0.2461846 ]  energy_before :  40  energy_after :  130  reward :  -287.59616937560384\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "action : 1  next_temperatures :  [-0.80731709 -0.65165709 -1.29563417  0.46839861  0.26040552 -0.9778786\n",
      " -0.8103134  -0.41391767 -0.16378086]  energy_before :  130  energy_after :  390  reward :  -462.3916947493574\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "action : 1  next_temperatures :  [ 1.19140653 -1.5898696   1.03654869 -2.0167443   1.00813999 -1.51498206\n",
      "  1.17712295 -1.41978147  1.68488193]  energy_before :  390  energy_after :  100  reward :  91.55672266051204\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "action : 1  next_temperatures :  [-1.49223795  0.28655541 -0.97642479  0.24070013 -1.34639278  0.41404283\n",
      " -1.0110151  -0.19047769 -1.13419329]  energy_before :  100  energy_after :  50  reward :  -153.20944323069025\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "action : 1  next_temperatures :  [0.9423444  0.54623923 1.24284047 0.14241301 0.66418213 0.0361039\n",
      " 1.14775197 0.31398988 0.87168715]  energy_before :  50  energy_after :  40  reward :  -182.09244785791302\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "action : 1  next_temperatures :  [-0.22617211  0.36194749 -0.70737688  1.14739877  0.44816995  0.20202831\n",
      " -0.12499052 -0.02923235  0.42481726]  energy_before :  40  energy_after :  60  reward :  -216.5034100768931\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "action : 1  next_temperatures :  [-0.3652318  -0.80411663 -0.35320646 -0.84045814 -0.78143785 -0.50775944\n",
      " -0.36974869 -0.76635392 -0.86312836]  energy_before :  60  energy_after :  60  reward :  -203.65144128954867\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n",
      "action : 1  next_temperatures :  [ 0.37572804  0.88717895 -0.25136347  1.69698756  1.21252075  0.54002247\n",
      "  0.26172739  0.84609951  0.76326118]  energy_before :  60  energy_after :  120  reward :  -251.66783761111\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n",
      "action : 1  next_temperatures :  [-0.738825    1.49282863 -0.23616302  1.00979681 -0.98581861  1.91248364\n",
      " -0.15762494  1.60625612 -0.48363747]  energy_before :  120  energy_after :  150  reward :  -224.58070383614023\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "action : 1  next_temperatures :  [-0.05390414 -0.19930464 -0.72105728  0.7141164   0.01116069 -0.3817798\n",
      " -0.17394215 -0.48993333  0.22113133]  energy_before :  150  energy_after :  110  reward :  -159.07351290154782\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "action : 1  next_temperatures :  [-1.2992148  -0.56788812 -0.21944253 -0.60293094 -1.14865856 -0.71977397\n",
      " -0.0466679  -0.66807104 -0.80891538]  energy_before :  110  energy_after :  60  reward :  -154.081563237215\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "action : 1  next_temperatures :  [ 0.06440038 -0.3165812   0.14840829 -0.13688621  0.21554145 -0.56614025\n",
      " -0.22778895 -0.100641    0.47231816]  energy_before :  60  energy_after :  60  reward :  -198.44736933189034\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "action : 1  next_temperatures :  [-0.11616967  0.25137244 -0.56601272  1.1326557  -0.58204199  0.07912134\n",
      " -0.17394215 -0.63735764 -0.34087661]  energy_before :  60  energy_after :  30  reward :  -168.95325129979972\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "action : 1  next_temperatures :  [ 0.0083614  -1.96682998 -0.20576213 -1.97321714  0.29529979 -1.590365\n",
      " -0.55086974 -1.6355431  -1.29683224]  energy_before :  30  energy_after :  90  reward :  -266.91575813676116\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "action : 1  next_temperatures :  [-0.3652318  -1.02024058 -0.93538358 -0.299879   -0.03370338 -0.81502687\n",
      " -0.32079706 -1.02204296 -0.61194153]  energy_before :  90  energy_after :  180  reward :  -293.4242467559196\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "action : 1  next_temperatures :  [ 0.77215194 -0.12558794  0.04230917  0.32326131  1.41903789 -0.50775944\n",
      "  1.19180844 -0.46689828  1.73367361]  energy_before :  180  energy_after :  70  reward :  -83.61800330831218\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "action : 1  next_temperatures :  [-0.30296627  0.36027211  0.05568556 -0.17702011 -0.16995721  1.3358451\n",
      " -0.85926503  1.1225201  -1.35104523]  energy_before :  70  energy_after :  90  reward :  -217.98593098180103\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n",
      "action : 1  next_temperatures :  [ 0.96102406  0.11817977  0.47825799  0.31441547  1.25738481  0.01459518\n",
      "  1.14775197 -0.16974615  0.87168715]  energy_before :  90  energy_after :  100  reward :  -203.00644974886282\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "action : 1  next_temperatures :  [ 0.37572804 -0.15909553  0.11800739  0.08344074 -0.01874869 -0.40226429\n",
      " -0.07603889 -0.0545709   0.72350499]  energy_before :  100  energy_after :  50  reward :  -147.41003712054203\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "action : 1  next_temperatures :  [-1.61054246 -0.83594884 -1.57380235 -0.22616367 -1.36300911 -0.22814609\n",
      " -1.15297484 -0.59743022 -1.24804056]  energy_before :  50  energy_after :  70  reward :  -226.83605813169294\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "action : 1  next_temperatures :  [-1.11864475  0.68864648 -0.47937017  0.23394289 -0.84790314  0.55845852\n",
      " -1.05507157  0.7140319  -0.48363747]  energy_before :  70  energy_after :  130  reward :  -259.78954730738275\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "action : 1  next_temperatures :  [ 0.31968906 -1.40641555 -0.15560065 -1.50635335  0.77551149 -1.14994836\n",
      "  0.01696922 -1.37447921 -0.80891538]  energy_before :  130  energy_after :  360  reward :  -433.28954271861073\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "action : 1  next_temperatures :  [1.44046866 1.19126033 0.84762885 1.27025766 2.20950004 0.35566202\n",
      " 1.76617428 0.74474529 1.51682167]  energy_before :  360  energy_after :  30  reward :  143.3425188125861\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "action : 1  next_temperatures :  [ 0.12666591 -0.22527302 -0.33800601  0.32915853  0.26040552 -0.29267225\n",
      "  0.11976765 -0.23654779  0.37834899]  energy_before :  30  energy_after :  50  reward :  -217.87815246498715\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "action : 1  next_temperatures :  [-0.11616967 -0.39197328 -0.80921987  0.39550234  0.11584352 -0.10523912\n",
      " -0.41870032 -0.0061973   0.02235039]  energy_before :  50  energy_after :  70  reward :  -219.31380331202482\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "action : 1  next_temperatures :  [-0.24692729 -0.85354032 -0.46416972 -0.41700448 -0.23808413 -0.87340768\n",
      " -0.22778895 -0.59051971 -0.16378086]  energy_before :  70  energy_after :  50  reward :  -182.07522314516734\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "action : 1  next_temperatures :  [ 0.195158   -0.15742015  1.47084717 -1.2336066   0.140768   -0.1666926\n",
      "  0.45753393 -0.40700715  0.64941392]  energy_before :  50  energy_after :  260  reward :  -407.0510054886248\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "action : 1  next_temperatures :  [ 0.81781333 -1.42484472  0.0876065  -1.09436652  0.55949931 -0.78122745\n",
      "  0.93236478 -1.41133529  0.7036269 ]  energy_before :  260  energy_after :  50  reward :  10.389136837528923\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "action : 1  next_temperatures :  [-0.24692729  0.25891165 -0.93538358  1.22357128  0.7140311   0.10677541\n",
      "  0.31557419 -0.12137255  0.49219626]  energy_before :  50  energy_after :  70  reward :  -216.1926235300531\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n",
      "action : 1  next_temperatures :  [-0.49598942  1.21387795 -0.33800601  1.24814306 -0.38264613  1.00092361\n",
      " -0.41870032  1.15246566 -0.59206344]  energy_before :  70  energy_after :  60  reward :  -185.61199504607293\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "action : 1  next_temperatures :  [-0.67655947 -0.84432573 -1.29563417  0.03593531 -0.33279717 -1.32406657\n",
      " -0.22778895 -0.8055135  -0.16378086]  energy_before :  60  energy_after :  90  reward :  -233.63453110834962\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "action : 1  next_temperatures :  [-0.61429393  0.0829968  -0.61161406 -0.00501766 -1.01572798  0.30342656\n",
      " -0.3860659  -0.22272676 -0.53785045]  energy_before :  90  energy_after :  50  reward :  -161.0068733906009\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "action : 1  next_temperatures :  [ 0.74932124  0.72969328  0.30041276  1.05894036  0.9466596  -0.01305889\n",
      "  0.65823563  0.36005998  0.93854983]  energy_before :  50  energy_after :  40  reward :  -182.27118620259324\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "action : 1  next_temperatures :  [ 0.99838337  0.13325819  0.5740208   0.24070013  1.23046637  0.02135506\n",
      "  1.19180844 -0.16974615  0.87168715]  energy_before :  40  energy_after :  50  reward :  -202.90806662126178\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "action : 1  next_temperatures :  [ 1.50273419 -1.39720096  0.47825799 -1.12233155  0.86357799 -1.30094835\n",
      "  1.53936504 -1.5434029   2.25489274]  energy_before :  50  energy_after :  50  reward :  -196.72505579928816\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "action : 1  next_temperatures :  [-0.738825   -0.5452705  -0.79401942 -0.36867999 -0.83128681 -0.41250654\n",
      " -0.77255071 -0.51527188 -0.75470239]  energy_before :  50  energy_after :  210  reward :  -363.73311324699756\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "action : 1  next_temperatures :  [ 0.39648322 -0.37521948  0.85978921 -0.9559455   1.46176557 -0.39202205\n",
      "  1.13376579 -0.88152916  0.47231816]  energy_before :  210  energy_after :  60  reward :  -46.28059423587126\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "action : 1  next_temperatures :  [-0.24692729 -0.26631982 -0.38360736 -0.299879   -0.53219302 -0.35412573\n",
      "  0.22909297 -0.68342774 -0.21257254]  energy_before :  60  energy_after :  110  reward :  -250.74995953497015\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "action : 1  next_temperatures :  [ 0.06440038 -0.50087294  0.16360874 -0.53822526 -0.23808413 -0.59993967\n",
      "  0.65823563 -0.56134198 -0.24171202]  energy_before :  110  energy_after :  100  reward :  -189.79393126631862\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "action : 1  next_temperatures :  [-0.05390414 -0.83594884 -0.74841808 -0.02139884  0.18230881 -1.03933209\n",
      "  0.56033236 -1.15794975  0.25727332]  energy_before :  100  energy_after :  40  reward :  -140.85703724387724\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "action : 1  next_temperatures :  [-1.05015267 -0.48411915 -0.83962076 -0.25073545 -0.86451946 -0.15747458\n",
      " -0.59818965 -0.51527188 -0.75470239]  energy_before :  40  energy_after :  80  reward :  -243.5147859864062\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n",
      "action : 1  next_temperatures :  [-0.78448639 -0.05857276 -1.3609961   1.16377995 -0.73657378 -0.36334375\n",
      " -0.47254712 -0.76635392 -0.61194153]  energy_before :  80  energy_after :  100  reward :  -221.9910353975125\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "action : 1  next_temperatures :  [-1.18091029 -0.39197328 -0.66177553 -0.32690796 -1.52917232 -0.04685831\n",
      " -1.15297484 -0.34481252 -0.97697563]  energy_before :  100  energy_after :  80  reward :  -184.61236067603355\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "action : 1  next_temperatures :  [-0.98788713 -0.6022334  -0.80921987 -0.49645324 -0.88113578 -0.75357338\n",
      " -0.52149876 -0.81242401 -0.75470239]  energy_before :  80  energy_after :  50  reward :  -174.6191279632833\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "action : 1  next_temperatures :  [2.06312399 1.11586825 1.21243958 1.14002724 1.71101039 0.78276374\n",
      " 1.68132478 1.26073039 2.27580346]  energy_before :  50  energy_after :  60  reward :  -194.75690817634194\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "action : 2  next_temperatures :  [ 0.57250267 -0.71636075  0.61639264 -0.61119294 -0.03068267 -0.48794253\n",
      "  0.9843348  -0.35912251  0.02302437]  energy_before :  60  energy_after :  50  reward :  -197.00904691776665\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "action : 1  next_temperatures :  [-0.01239378  1.38979279  0.43265665  1.00242527 -0.23254536  1.61853113\n",
      " -0.47254712  2.04392205 -0.53785045]  energy_before :  50  energy_after :  50  reward :  -192.76800881178053\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "action : 1  next_temperatures :  [ 0.74932124  0.03524849  0.11800739  0.57487632  0.46478627  0.07912134\n",
      " -0.41870032  0.50057378  0.43256198]  energy_before :  50  energy_after :  50  reward :  -195.4642035140997\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "action : 1  next_temperatures :  [-0.18466176 -0.60977261 -0.06439797 -0.51447254  0.21554145 -0.77405788\n",
      " -0.47254712  0.08594289 -0.21257254]  energy_before :  50  energy_after :  20  reward :  -170.53099807250592\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "action : 1  next_temperatures :  [ 0.74932124 -1.42484472  0.05568556 -1.08617593  0.61433317 -0.75357338\n",
      "  0.9029938  -1.41133529  0.7036269 ]  energy_before :  20  energy_after :  620  reward :  -799.6499686455817\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "action : 1  next_temperatures :  [ 0.12666591  0.27650313 -0.09479886  0.58224786 -0.15167926 -0.24863058\n",
      " -0.12499052  0.40613008  0.22113133]  energy_before :  620  energy_after :  60  reward :  362.9925790863479\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "action : 1  next_temperatures :  [ 0.06440038 -0.34171189 -0.61161406  0.33653007  0.07928761 -0.09499687\n",
      " -0.35343148  0.08594289  0.05849238]  energy_before :  60  energy_after :  100  reward :  -238.7771009691798\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "action : 1  next_temperatures :  [ 0.66837605 -2.96451846  2.48471699 -4.71542766  0.41493731 -2.42664451\n",
      "  0.94705027 -2.27131045  0.87168715]  energy_before :  100  energy_after :  60  reward :  -164.9911333063163\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "action : 1  next_temperatures :  [ 1.44046866  0.12571898  1.06043511  0.21367117  1.41191661 -0.04685831\n",
      "  1.29460687  0.60730284  2.05895152]  energy_before :  60  energy_after :  70  reward :  -199.83378654840396\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "action : 1  next_temperatures :  [-0.9256216   0.85534674 -0.47937017  0.26527191 -0.89941373  0.67214747\n",
      " -1.0110151   0.84609951 -0.53785045]  energy_before :  70  energy_after :  50  reward :  -179.21440542921337\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "action : 1  next_temperatures :  [ 0.195158    0.87210054  0.43265665  0.77882209 -0.13340131  1.73836543\n",
      " -0.87558224  1.2983543  -0.23967904]  energy_before :  50  energy_after :  290  reward :  -433.93320558644353\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n",
      "action : 1  next_temperatures :  [ 0.85932368  0.83775526  0.25025128  0.75670749  0.31025448 -0.5886732\n",
      "  0.86802835 -0.62320754  0.76326118]  energy_before :  290  energy_after :  190  reward :  -94.56629901651095\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "action : 1  next_temperatures :  [-0.38598698 -1.19866849 -0.47937017 -0.8814111  -0.31618084 -1.36810823\n",
      " -0.47254712 -0.86079762 -0.21257254]  energy_before :  190  energy_after :  530  reward :  -544.1756431043976\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n",
      "action : 1  next_temperatures :  [ 0.74932124 -0.60307109  0.66066335 -1.16890092  1.04137263 -1.41829524\n",
      "  0.80509053 -1.23550108  0.64941392]  energy_before :  530  energy_after :  70  reward :  261.4800933440464\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "action : 1  next_temperatures :  [1.44046866 0.9810002  0.5740208  1.65521553 1.46176557 0.46627829\n",
      " 1.24076008 0.77699436 1.93271272]  energy_before :  70  energy_after :  40  reward :  -157.4707837860364\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "action : 1  next_temperatures :  [-0.738825   -0.76893366 -1.20443149 -0.08119017 -0.68672482 -0.47396003\n",
      " -1.05507157 -0.65117867 -0.61194153]  energy_before :  40  energy_after :  50  reward :  -214.27225693777302\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "action : 1  next_temperatures :  [0.54799602 1.39900738 0.5740208  1.17442773 0.50965034 1.9729129\n",
      " 0.10345044 2.26582636 0.25426149]  energy_before :  50  energy_after :  40  reward :  -179.1984465420191\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "action : 1  next_temperatures :  [ 0.31968906  0.3116861  -0.29240467  1.10071239  0.91342696  0.16822889\n",
      "  0.45753393  0.2617771   0.7036269 ]  energy_before :  40  energy_after :  40  reward :  -194.05572334057527\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "action : 1  next_temperatures :  [1.7908538  2.80803198 1.60025638 2.37830469 2.41714364 1.88976447\n",
      " 1.47630123 2.086402   1.73274564]  energy_before :  40  energy_after :  110  reward :  -249.82019616353546\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "action : 1  next_temperatures :  [ 0.195158    0.23629403 -0.49305057  1.01716834  1.05798895  0.16822889\n",
      "  0.75124373 -0.25958284  0.67652041]  energy_before :  110  energy_after :  50  reward :  -134.65003106092982\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n",
      "action : 1  next_temperatures :  [ 0.08515556  0.32676452 -0.12519976  0.64122012 -0.13340131 -0.25887283\n",
      " -0.12499052  0.39230905  0.27534432]  energy_before :  50  energy_after :  40  reward :  -186.92167084776446\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "action : 1  next_temperatures :  [0.81781333 0.6794319  0.25025128 1.12528417 1.16267178 0.07912134\n",
      " 0.9029938  0.40613008 1.23672125]  energy_before :  40  energy_after :  50  reward :  -201.33958107803952\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "action : 1  next_temperatures :  [ 0.85932368 -0.78736283  0.07240605 -0.1712867   0.14907616 -0.92564314\n",
      " -0.27674059 -0.23040511  0.64941392]  energy_before :  50  energy_after :  60  reward :  -208.6612185480076\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "action : 1  next_temperatures :  [-1.23694927 -1.64850788 -1.20443149 -1.33189372 -1.36300911 -1.12229429\n",
      " -1.1040232  -1.38138972 -0.97697563]  energy_before :  60  energy_after :  80  reward :  -229.36947430889757\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n",
      "action : 1  next_temperatures :  [-0.42749733  1.23230712 -0.02335676  0.79684139 -0.23808413  1.40856506\n",
      " -0.35343148  1.6891823  -0.53483862]  energy_before :  80  energy_after :  60  reward :  -174.45031245356398\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "action : 1  next_temperatures :  [-0.67655947 -0.83594884 -1.11778894 -0.11968596 -1.08053164 -0.56614025\n",
      "  0.10345044 -0.7440867  -0.75470239]  energy_before :  60  energy_after :  50  reward :  -193.7919937537034\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "action : 1  next_temperatures :  [-1.49223795  0.83691757 -0.83962076  0.77882209 -1.18521446  1.73836543\n",
      " -1.0110151   1.1225201  -1.24804056]  energy_before :  50  energy_after :  80  reward :  -229.29950365448246\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "action : 1  next_temperatures :  [-0.80731709  0.90477044 -0.74841808  0.5109897  -1.09714796 -0.03354338\n",
      " -1.0110151  -0.11446203 -1.0799803 ]  energy_before :  80  energy_after :  40  reward :  -161.4761238128716\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "action : 1  next_temperatures :  [-0.30296627 -0.14988094  1.55900977 -1.72504218  0.06100966 -1.26466153\n",
      "  0.01696922 -0.70876629 -0.16378086]  energy_before :  40  energy_after :  60  reward :  -220.67810942704912\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "action : 1  next_temperatures :  [ 0.5687512  -0.59301881  0.63330255 -0.6520745   0.31025448 -0.35412573\n",
      " -0.12499052  0.15504804  0.3295573 ]  energy_before :  60  energy_after :  140  reward :  -277.7272959936412\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "action : 1  next_temperatures :  [-1.23694927  1.46518487 -0.70737688  1.34643018 -1.23506343  1.83054566\n",
      " -1.15297484  1.95178186 -1.13419329]  energy_before :  140  energy_after :  50  reward :  -106.87261513332638\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "action : 1  next_temperatures :  [-0.86958262  0.85534674 -0.38360736  0.65596319 -1.03068267  1.5509323\n",
      " -1.29982974  1.39663718 -0.75470239]  energy_before :  50  energy_after :  60  reward :  -207.87952536881977\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "action : 1  next_temperatures :  [ 0.74932124  0.67608114  0.25025128  1.07368343  0.91342696 -0.01305889\n",
      "  0.65823563  0.34163194  0.92047884]  energy_before :  60  energy_after :  70  reward :  -202.4299484307713\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "action : 1  next_temperatures :  [ 0.61026155 -0.18422622 -0.20576213  0.05968803  0.11584352 -0.41250654\n",
      "  0.60928399 -0.83644628  0.64941392]  energy_before :  70  energy_after :  30  reward :  -157.5944501619916\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "action : 1  next_temperatures :  [ 0.25742353 -0.52684132  0.17728914 -0.52348219  0.06100966 -0.50775944\n",
      " -0.03198241 -0.51527188  0.05849238]  energy_before :  30  energy_after :  110  reward :  -279.55112254988563\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "action : 1  next_temperatures :  [ 2.81031039  0.60487751  2.56375931 -0.56279704  3.10678141 -0.90720709\n",
      "  2.27363956  0.51715901  3.08899824]  energy_before :  110  energy_after :  70  reward :  -144.50447870620354\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "action : 1  next_temperatures :  [-0.34447662  1.17366884  0.00704413  0.65022978  0.47974096  1.09310384\n",
      "  0.07081602  0.9359362  -0.3806328 ]  energy_before :  70  energy_after :  40  reward :  -164.31456965197813\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "action : 1  next_temperatures :  [-0.3652318   0.76152549 -0.25136347  0.90168098 -0.18823517  0.88942943\n",
      " -0.29142608  1.23769534 -0.80891538]  energy_before :  40  energy_after :  100  reward :  -256.1148406444017\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n",
      "action : 1  next_temperatures :  [ 1.1063103  -0.53438053  0.81505646 -0.84747865  1.05798895 -1.08849487\n",
      "  1.20812565 -0.93527761  1.95594685]  energy_before :  100  energy_after :  30  reward :  -125.26220344118357\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "action : 1  next_temperatures :  [ 0.23666835  0.49346478  0.26697177  0.64040107  0.57777726 -0.27116353\n",
      "  0.16871929  0.51593047  0.49219626]  energy_before :  30  energy_after :  60  reward :  -224.87903427764752\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "action : 1  next_temperatures :  [ 0.12666591  0.71126411 -0.33800601  1.04255918  0.61433317  0.47549632\n",
      "  0.56033236  0.15504804  0.7036269 ]  energy_before :  60  energy_after :  60  reward :  -193.9486800328586\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "action : 1  next_temperatures :  [ 1.81406186 -0.6022334   0.70626469 -0.11734579  0.96327592 -2.2069483\n",
      "  1.97503459 -0.32013211  2.27580346]  energy_before :  60  energy_after :  90  reward :  -223.51221907729266\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "action : 1  next_temperatures :  [-0.67655947  0.60403982 -0.56601272  0.74851689 -0.53219302  0.60147596\n",
      "  0.60928399  0.41611193 -0.48363747]  energy_before :  90  energy_after :  70  reward :  -177.27897408355454\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "action : 1  next_temperatures :  [ 0.52724084 -0.80411663 -0.02335676 -0.30888866 -0.18823517 -0.85292318\n",
      "  0.76919267 -0.42082818 -0.10956787]  energy_before :  70  energy_after :  70  reward :  -199.4114829441423\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "action : 1  next_temperatures :  [-0.11616967  0.62079362  0.11800739  0.58224786 -0.38264613  1.3358451\n",
      " -0.17394215  0.85301002 -0.26678553]  energy_before :  70  energy_after :  60  reward :  -185.4296394878699\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "action : 1  next_temperatures :  [-0.18466176 -0.09961956 -0.93538358  0.95082454  0.13245984 -0.09499687\n",
      " -0.36974869 -0.23654779  0.16149705]  energy_before :  60  energy_after :  100  reward :  -238.67617681319172\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "action : 1  next_temperatures :  [ 0.74932124  0.52864774  0.77162661  0.08507886  0.55949931  0.14057482\n",
      "  1.0498487  -0.07530245  0.60062223]  energy_before :  100  energy_after :  20  reward :  -113.5900829234416\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "action : 1  next_temperatures :  [ 0.25742353 -0.16831012  0.3460141  -0.14589586  0.21554145 -0.47396003\n",
      " -0.0466679   0.13969134  0.37834899]  energy_before :  20  energy_after :  90  reward :  -267.4978144934745\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "action : 1  next_temperatures :  [ 0.9423444  -1.5982465   0.68346402 -1.89950181  0.49469565 -1.06084081\n",
      "  0.94705027 -1.29616004  1.59271985]  energy_before :  90  energy_after :  60  reward :  -169.19447496071982\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "action : 1  next_temperatures :  [-0.24692729 -0.31783773  0.26975852 -0.59105458 -0.88113578  0.3218626\n",
      " -0.34255334  0.32729902 -1.02576732]  energy_before :  60  energy_after :  110  reward :  -250.48635589634432\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "action : 1  next_temperatures :  [-1.49223795  0.13325819 -0.74841808 -0.17702011 -1.48430825  0.8472899\n",
      " -0.96206346  0.22415319 -1.24804056]  energy_before :  110  energy_after :  50  reward :  -142.90738714262665\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "action : 1  next_temperatures :  [-0.49598942 -0.32914655 -0.93538358 -0.38342305 -0.33279717 -1.28514603\n",
      " -0.52149876 -1.1656281  -0.43484578]  energy_before :  50  energy_after :  50  reward :  -203.88385842768096\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "action : 1  next_temperatures :  [-0.67655947 -0.41040245  0.55730031 -0.76838092  0.36508834 -1.21447452\n",
      " -0.63082407 -0.22272676 -0.08968978]  energy_before :  50  energy_after :  60  reward :  -211.09066931536853\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "action : 1  next_temperatures :  [-0.67655947  0.12488129 -0.4565695  -0.47188146 -0.83128681 -0.3817798\n",
      " -0.88374085 -0.65540176 -0.86312836]  energy_before :  60  energy_after :  40  reward :  -183.09546672206278\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "action : 1  next_temperatures :  [-1.8596046   1.51544625 -1.11778894  1.45126977 -1.2799275   1.654379\n",
      " -1.54458791  1.78823301 -1.283279  ]  energy_before :  40  energy_after :  60  reward :  -218.67585991374597\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "action : 1  next_temperatures :  [-0.18466176 -0.61850851 -0.47937017 -0.31532412 -0.2829482  -0.66139315\n",
      " -0.92360147 -0.51724631 -0.80891538]  energy_before :  60  energy_after :  50  reward :  -192.79196907886012\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "action : 1  next_temperatures :  [ 0.06440038 -1.22128612  0.80202751 -1.93881665  0.06100966 -1.30358207\n",
      "  0.80509053 -1.36756869  0.27534432]  energy_before :  50  energy_after :  50  reward :  -201.82338114039374\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n",
      "action : 1  next_temperatures :  [-0.61429393 -0.6432802  -1.16339028  0.28001498  0.46478627 -0.78122745\n",
      " -0.71730529 -0.5068257  -0.13667437]  energy_before :  50  energy_after :  110  reward :  -261.8181959739254\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n",
      "action : 1  next_temperatures :  [-0.32372145  0.88717895  0.07240605  0.48641792 -0.18823517  2.01183344\n",
      " -0.07603889  1.49108088 -0.0228271 ]  energy_before :  110  energy_after :  50  reward :  -133.66190535449445\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "action : 1  next_temperatures :  [ 0.04572072 -0.41961704 -0.43376883  0.09982193  0.16569248 -0.41250654\n",
      "  0.07081602 -0.23654779  0.22113133]  energy_before :  50  energy_after :  60  reward :  -208.8992577145953\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "action : 1  next_temperatures :  [ 0.25742353 -0.39197328 -0.73815778  0.47966068  0.11584352 -0.45552398\n",
      "  0.53879364 -0.5235645   0.54640924]  energy_before :  60  energy_after :  60  reward :  -198.1710889245563\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "action : 1  next_temperatures :  [ 0.195158   -0.35092648 -0.38360736  0.21367117  0.01116069 -0.11650559\n",
      "  0.36452582 -0.44616674  0.05849238]  energy_before :  60  energy_after :  780  reward :  -918.4541980932058\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "action : 1  next_temperatures :  [ 0.31968906 -0.99762296 -0.06439797 -0.72988513 -0.13340131 -1.2590283\n",
      " -0.27674059 -1.43667384 -0.04993359]  energy_before :  780  energy_after :  40  reward :  537.3720053883847\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "action : 1  next_temperatures :  [ 1.50273419 -1.14673173  1.69885388 -2.98803161  0.66418213 -1.63235822\n",
      "  0.94705027 -1.75916452  1.12919883]  energy_before :  40  energy_after :  40  reward :  -199.58426677303885\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "action : 1  next_temperatures :  [ 0.21591317 -0.33333499  1.39028481 -1.07880439  0.34681039 -0.50775944\n",
      "  0.60928399 -0.25190449  0.73073339]  energy_before :  40  energy_after :  60  reward :  -216.87877756456714\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "action : 1  next_temperatures :  [-0.18466176 -0.19092774 -0.70737688  0.57487632  0.06100966 -0.08475462\n",
      " -0.3860659  -0.10755152  0.0042794 ]  energy_before :  60  energy_after :  70  reward :  -209.0211730353933\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "action : 1  next_temperatures :  [-0.40674216 -0.81165583 -0.97642479 -0.00501766 -0.43747999 -0.79249392\n",
      " -0.52149876 -0.95063431 -0.68783971]  energy_before :  70  energy_after :  50  reward :  -183.58978712622672\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "action : 1  next_temperatures :  [1.99463191 1.78518235 1.11667676 2.25453292 2.05496825 1.15455732\n",
      " 1.97503459 1.25566268 2.38965073]  energy_before :  50  energy_after :  30  reward :  -162.01910249194339\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n",
      "action : 1  next_temperatures :  [-0.80731709 -0.69354158 -0.88978224 -0.26875475 -0.73657378  0.10677541\n",
      " -0.36974869 -0.56825249 -0.75470239]  energy_before :  30  energy_after :  20  reward :  -192.98189761194797\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "action : 1  next_temperatures :  [ 1.56499973  0.49514016  2.72792414 -1.36916091  2.48865425  0.1477444\n",
      "  1.78412322  0.38539853  1.08853909]  energy_before :  20  energy_after :  120  reward :  -288.6866374118831\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n",
      "action : 1  next_temperatures :  [ 0.50648566 -1.03866975 -0.33800601 -0.53822526  0.66418213 -1.45721578\n",
      "  0.59704609 -1.62498536  0.85361616]  energy_before :  120  energy_after :  120  reward :  -200.37577213622836\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n",
      "action : 1  next_temperatures :  [-0.67655947  0.99021479 -0.20576213  0.77882209 -1.047299    1.26619782\n",
      " -0.6634585   1.60625612 -1.02576732]  energy_before :  120  energy_after :  60  reward :  -136.97735558079916\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "action : 1  next_temperatures :  [ 0.31968906  1.14016125 -0.20576213  1.90257144  1.36206764  0.38434031\n",
      "  0.19809027  0.94591806  0.72350499]  energy_before :  60  energy_after :  90  reward :  -221.22941910179827\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "action : 1  next_temperatures :  [0.9423444  0.18603264 0.16360874 0.82796564 1.16267178 0.0483946\n",
      " 1.09880034 0.2617771  0.79578897]  energy_before :  90  energy_after :  150  reward :  -252.51261579423053\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "action : 1  next_temperatures :  [-0.5167446  -0.60977261 -1.06762747  0.26527191  0.46478627 -0.81502687\n",
      " -0.6634585  -0.44616674 -0.10956787]  energy_before :  150  energy_after :  300  reward :  -351.49830646503506\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "action : 1  next_temperatures :  [-0.55825495  1.05722997 -0.25136347  0.52573276 -0.44578815  0.96268589\n",
      " -0.17394215  0.52130532 -0.53785045]  energy_before :  300  energy_after :  40  reward :  63.099754758997335\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "action : 1  next_temperatures :  [ 0.06440038 -0.09040497 -0.88978224  1.14739877  0.75889517 -0.22814609\n",
      "  0.16871929 -0.2411548   0.54640924]  energy_before :  40  energy_after :  90  reward :  -246.76366525438002\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "action : 1  next_temperatures :  [-1.92187013 -0.3165812  -1.4324382  -0.22616367 -1.68370411  0.01459518\n",
      " -1.69633798 -0.16974615 -1.51910548]  energy_before :  90  energy_after :  50  reward :  -166.95135173531742\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "action : 1  next_temperatures :  [ 0.4172384   0.82183915  0.70626469 -0.03941815  0.89681064  1.02140811\n",
      "  0.18340478  0.75165581 -0.3806328 ]  energy_before :  50  energy_after :  70  reward :  -213.6214293770574\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "action : 1  next_temperatures :  [-0.24692729 -0.99762296 -1.20443149  0.07606921 -0.43747999 -1.08849487\n",
      "  0.01696922 -1.29616004 -0.18004475]  energy_before :  70  energy_after :  50  reward :  -183.35812296484627\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n",
      "action : 1  next_temperatures :  [ 7.49321242e-01  6.55207951e-05  7.24060536e-02  5.82247855e-01\n",
      "  4.64786273e-01  7.91213381e-02 -4.18700325e-01  5.00573776e-01\n",
      "  4.32561976e-01]  energy_before :  50  energy_after :  50  reward :  -195.53761629027267\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "action : 1  next_temperatures :  [-1.38431103  1.03126159 -0.79401942  0.95082454 -1.18521446  1.56783201\n",
      " -1.34878137  1.19853576 -1.29683224]  energy_before :  50  energy_after :  100  reward :  -249.26070464031142\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "action : 1  next_temperatures :  [ 0.25742353  0.87210054 -0.10999931  1.34643018  0.66418213  0.23275505\n",
      "  0.16871929  0.07327362  0.65715863]  energy_before :  100  energy_after :  60  reward :  -153.8379563516928\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "action : 1  next_temperatures :  [1.75179633 2.07083455 0.88867006 2.4988466  1.96025522 1.80801271\n",
      " 1.43656661 1.67305777 1.84752088]  energy_before :  60  energy_after :  40  reward :  -162.0644392714365\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n",
      "action : 1  next_temperatures :  [ 0.31968906  0.80592305 -0.10999931  1.05156883  0.57777726  0.48676279\n",
      "  0.7022921   0.25333092  0.76326118]  energy_before :  40  energy_after :  50  reward :  -203.14939412043358\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "action : 1  next_temperatures :  [-1.36148033 -1.5655766  -1.31235466 -1.26063556 -1.2799275  -0.98709662\n",
      " -1.15297484 -1.32149859 -1.06190931]  energy_before :  50  energy_after :  50  reward :  -209.30345401453528\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "action : 1  next_temperatures :  [-0.42749733  1.91083581 -0.06439797  1.69698756 -0.43747999  2.22999331\n",
      " -0.45459819  2.18213235 -0.26979736]  energy_before :  50  energy_after :  110  reward :  -251.6338218244526\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "action : 1  next_temperatures :  [-1.80356562 -0.59301881 -1.6604449  -0.05416122 -1.03068267 -0.35412573\n",
      " -1.69633798 -0.40700715 -0.97697563]  energy_before :  110  energy_after :  40  reward :  -136.57631971237103\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "action : 1  next_temperatures :  [ 1.12914099 -0.55657931  1.94206103 -1.5776115   1.36206764 -0.32032631\n",
      "  1.48551825 -0.28492139 -0.15371273]  energy_before :  40  energy_after :  80  reward :  -234.97436334097483\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "action : 1  next_temperatures :  [-0.24692729 -0.06527428  0.07240605 -0.16227704 -0.83128681  0.90874338\n",
      " -0.76625693  0.86683105 -0.3806328 ]  energy_before :  80  energy_after :  140  reward :  -258.6046746584131\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "action : 1  next_temperatures :  [-0.98788713 -0.92223088 -0.97642479 -0.78394305 -0.89941373 -0.60915769\n",
      " -0.8103134  -0.91377823 -0.54869305]  energy_before :  140  energy_after :  50  reward :  -115.45184195052599\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "action : 1  next_temperatures :  [ 0.5687512   0.56215533  0.75642617 -0.3342795  -0.48732896  1.23444685\n",
      " -0.25879165  0.99198815  0.45244007]  energy_before :  50  energy_after :  420  reward :  -564.5141923304064\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "action : 1  next_temperatures :  [ 0.0083614  -0.62066257 -0.58121317 -0.13688621 -0.2829482  -0.85292318\n",
      "  0.26172739 -0.37475808  0.18137515]  energy_before :  420  energy_after :  60  reward :  159.602072522279\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n",
      "action : 1  next_temperatures :  [ 0.74932124 -0.9038017   0.6044217  -0.98788881  0.31025448 -0.47396003\n",
      " -0.03198241 -0.14440759  0.3295573 ]  energy_before :  60  energy_after :  60  reward :  -198.54848582640412\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "action : 1  next_temperatures :  [-1.47148277 -0.30150278 -1.19075109  0.12521277 -1.18521446 -0.55589801\n",
      "  0.10345044 -0.57516301 -1.13419329]  energy_before :  60  energy_after :  50  reward :  -194.18554220569\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "action : 1  next_temperatures :  [ 0.29893389  1.01283241  0.44785709  0.74851689 -0.21315965  1.50637852\n",
      "  0.05286708  1.55788252 -0.29991569]  energy_before :  50  energy_after :  110  reward :  -252.88780692128432\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "action : 1  next_temperatures :  [ 0.63101673 -2.87991179  0.75642617 -3.37298948  0.11584352 -1.43877974\n",
      "  0.82467118 -2.10837587  0.43256198]  energy_before :  110  energy_after :  90  reward :  -185.0395373019542\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "action : 1  next_temperatures :  [ 0.50648566  1.21387795  0.5740208   1.02453987 -0.13340131  1.66564547\n",
      "  0.45753393  1.53715098 -0.48363747]  energy_before :  90  energy_after :  90  reward :  -191.63778410636098\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "action : 1  next_temperatures :  [-0.55825495  1.12340746 -0.10999931  0.5331043  -0.29291799  1.64987241\n",
      " -0.22778895  1.25228421 -0.20715125]  energy_before :  90  energy_after :  90  reward :  -194.8374440817176\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "action : 1  next_temperatures :  [ 1.56499973  0.50184167  2.27647086 -0.47351958  1.91040625 -0.29267225\n",
      "  1.6209511  -0.0545709   1.46260869]  energy_before :  90  energy_after :  70  reward :  -169.48348441729715\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "action : 1  next_temperatures :  [-0.05390414 -1.18861622 -0.43376883 -0.96413609  0.06100966 -1.46745803\n",
      " -0.43501754 -1.12723635 -0.84505737]  energy_before :  70  energy_after :  60  reward :  -194.45418490172898\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "action : 1  next_temperatures :  [-2.36395542  1.20633874 -1.47803954  1.19080891 -1.66999565  0.97787855\n",
      " -1.99004778  1.38972666 -1.62211015]  energy_before :  60  energy_after :  70  reward :  -212.35939566378408\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "action : 1  next_temperatures :  [-0.18466176 -1.04788434 -0.77881898 -0.34902256 -0.08355234 -0.90720709\n",
      " -0.27674059 -0.97597286 -0.63181963]  energy_before :  70  energy_after :  60  reward :  -193.23568014304726\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "action : 1  next_temperatures :  [ 0.43799358  0.88717895 -0.25136347  1.68060637  1.25738481  0.54002247\n",
      "  0.26172739  0.84609951  0.76326118]  energy_before :  60  energy_after :  70  reward :  -201.5770891954485\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "action : 1  next_temperatures :  [ 0.63101673 -1.04788434  1.42372579 -2.01253199  0.31025448 -1.14073034\n",
      "  0.80509053 -1.05045285  0.39641999]  energy_before :  70  energy_after :  40  reward :  -169.68509200295318\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "action : 1  next_temperatures :  [ 0.195158   -0.40286324  0.3460141  -0.68647499  0.11584352 -0.56614025\n",
      "  0.21277576 -0.12137255  0.25727332]  energy_before :  40  energy_after :  560  reward :  -718.6497863372546\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "action : 1  next_temperatures :  [-0.07465931 -0.74631603  0.80050746 -1.01327965  0.23049614 -1.14994836\n",
      "  0.7022921  -0.97597286  0.22113133]  energy_before :  560  energy_after :  60  reward :  299.99425081568796\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "action : 1  next_temperatures :  [-2.54452546  0.22247215 -1.70604624  0.31441547 -2.1273599   0.29420854\n",
      " -2.57257223  0.40613008 -2.09888324]  energy_before :  60  energy_after :  30  reward :  -177.8121608478813\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "action : 1  next_temperatures :  [ 1.30971104 -2.01876674  1.34468346 -2.74149476  0.55949931 -1.42956172\n",
      "  1.22444286 -1.52651053  0.88795105]  energy_before :  30  energy_after :  40  reward :  -210.39004602891646\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "action : 1  next_temperatures :  [ 0.63101673 -1.43992314 -0.33800601 -0.75118068 -0.38264613 -1.21447452\n",
      "  0.9960019  -1.30249468 -0.21257254]  energy_before :  40  energy_after :  40  reward :  -202.01427906658392\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "action : 1  next_temperatures :  [-0.80731709  0.01681932 -1.4324382   1.37755443 -0.78143785 -0.33159279\n",
      " -0.45459819 -0.65117867 -0.65169772]  energy_before :  40  energy_after :  40  reward :  -201.71588675445824\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "action : 1  next_temperatures :  [0.0083614  1.6017283  0.16360874 1.34643018 0.02777701 1.70456601\n",
      " 0.07081602 2.05927875 0.0042794 ]  energy_before :  40  energy_after :  50  reward :  -201.01315419912004\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "action : 1  next_temperatures :  [-0.32372145  0.86456133 -0.00815632  0.72312605 -0.2829482   1.43109801\n",
      " -0.41870032  1.0150232  -0.32099851]  energy_before :  50  energy_after :  70  reward :  -215.3207162100095\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "action : 1  next_temperatures :  [-0.13900036  0.52864774  0.16360874  0.34553972  0.11584352  1.39729859\n",
      " -0.27674059  0.66181912 -0.34087661]  energy_before :  70  energy_after :  30  reward :  -155.54386013327056\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "action : 1  next_temperatures :  [ 0.68705571 -0.40118786  0.70626469 -1.04768014  1.22747544 -1.36810823\n",
      "  0.85404217 -1.14412872  0.64941392]  energy_before :  30  energy_after :  90  reward :  -257.8368530362403\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "action : 1  next_temperatures :  [ 0.63101673 -0.92223088 -0.10999931 -0.32690796  0.21554145 -0.85292318\n",
      " -0.56555523 -0.16974615 -0.24871453]  energy_before :  90  energy_after :  330  reward :  -440.3495190659164\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "action : 1  next_temperatures :  [-0.55825495 -0.52684132 -0.29240467 -0.57999728 -0.78143785 -0.06631858\n",
      " -0.27674059 -0.53600343 -0.86312836]  energy_before :  330  energy_after :  60  reward :  67.5188729648255\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "action : 1  next_temperatures :  [-1.23694927 -0.53438053 -1.06762747 -0.35721316 -0.98581861 -0.62759374\n",
      " -0.32079706 -0.75099722 -0.74494406]  energy_before :  60  energy_after :  250  reward :  -394.62632109304775\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "action : 1  next_temperatures :  [-0.80731709 -0.51762674 -0.92018313 -0.22616367 -0.58204199  0.26040912\n",
      " -1.0110151   0.01453424 -0.41075112]  energy_before :  250  energy_after :  110  reward :  -62.200155473979834\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "action : 1  next_temperatures :  [ 0.68705571 -0.79657742  0.61962214 -0.83308661  0.26040552 -0.47396003\n",
      " -0.07603889 -0.0061973   0.29341531]  energy_before :  110  energy_after :  100  reward :  -188.3253615516588\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "action : 1  next_temperatures :  [-0.67655947  0.52864774 -0.18068139  0.06869768 -0.63189095  0.43657578\n",
      " -0.76625693  0.50748429 -0.3806328 ]  energy_before :  100  energy_after :  90  reward :  -189.09461604759312\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "action : 1  next_temperatures :  [ 0.37572804 -0.14066635 -0.02335676  0.30540581 -0.08355234 -0.32032631\n",
      " -0.12499052 -0.0061973   0.47231816]  energy_before :  90  energy_after :  50  reward :  -157.54563757021066\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "action : 1  next_temperatures :  [ 0.06440038  1.01283241  0.02224458  0.97785349 -0.11678498  1.47104277\n",
      "  0.60928399  1.24537369 -0.53785045]  energy_before :  50  energy_after :  40  reward :  -183.25160411895905\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "action : 1  next_temperatures :  [ 0.25742353  1.21387795  0.66066335  0.78783174 -0.13644763  1.61545846\n",
      " -0.27674059  2.14220493 -0.48966113]  energy_before :  40  energy_after :  110  reward :  -262.225389392129\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "action : 1  next_temperatures :  [-0.61429393  1.11586825 -0.43376883  1.16377995 -0.31143332  0.8152463\n",
      " -0.69935636  1.37590564 -0.85228577]  energy_before :  110  energy_after :  80  reward :  -166.44033807864284\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "action : 1  next_temperatures :  [-0.3652318   1.11419287 -0.02335676  0.5331043   0.31025448  1.02140811\n",
      "  0.07081602  0.91520466 -0.39870379]  energy_before :  80  energy_after :  90  reward :  -204.82231192604002\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "action : 1  next_temperatures :  [-0.18466176  0.76320087  0.16360874  0.34553972  0.26040552  0.91796141\n",
      " -0.32079706  1.0303799   0.22113133]  energy_before :  90  energy_after :  40  reward :  -144.80323132654297\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "action : 1  next_temperatures :  [-1.05015267  0.99021479 -0.56601272  0.70510675 -1.18521446  1.73836543\n",
      " -0.61450686  0.96127475 -1.00950342]  energy_before :  40  energy_after :  40  reward :  -198.0304284102339\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "action : 1  next_temperatures :  [-0.80731709 -1.29919126 -1.52364088 -0.14589586 -0.93596964 -0.68904722\n",
      " -0.69935636 -1.19787717 -0.65169772]  energy_before :  40  energy_after :  70  reward :  -235.9499931944222\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n",
      "action : 1  next_temperatures :  [-0.11616967  0.33430373 -0.83962076  1.27025766  0.7140311   0.10677541\n",
      "  0.31557419 -0.07530245  0.52472405]  energy_before :  70  energy_after :  40  reward :  -165.76542674966137\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "action : 1  next_temperatures :  [-0.09541449 -0.79657742 -0.70737688 -0.05416122  0.31025448 -0.62759374\n",
      " -0.71730529 -0.32254531 -0.26678553]  energy_before :  40  energy_after :  100  reward :  -261.2775053872334\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "action : 1  next_temperatures :  [ 0.37572804 -0.39197328 -0.53561182  0.34553972  0.11584352 -0.3817798\n",
      "  0.45753393 -0.74562237  0.60062223]  energy_before :  100  energy_after :  40  reward :  -138.15971983298056\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "action : 1  next_temperatures :  [-0.18466176  0.33430373  0.16360874 -0.11968596  0.11584352  1.18221139\n",
      " -1.0110151   0.43146863 -0.25775003]  energy_before :  40  energy_after :  50  reward :  -207.34567684536975\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "action : 1  next_temperatures :  [-0.16183106 -0.67846317 -0.99162523  0.59125751  0.47974096 -0.464742\n",
      " -0.41870032  0.06060434 -0.09631581]  energy_before :  50  energy_after :  60  reward :  -209.6800747864162\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "action : 1  next_temperatures :  [-0.57693461 -0.04265666 -0.62833455  0.28738651 -0.43747999  0.49802926\n",
      " -1.0110151   0.50057378 -0.86312836]  energy_before :  60  energy_after :  50  reward :  -190.2735597296582\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "action : 1  next_temperatures :  [ 0.31968906 -1.06296275 -0.12139965 -0.92154501  0.16569248 -1.58319543\n",
      "  0.45753393 -1.0427745   0.68555591]  energy_before :  50  energy_after :  90  reward :  -241.10340596060388\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "action : 1  next_temperatures :  [ 2.74804486  1.23063174  3.3253017  -0.40635671  2.99568943  0.42062713\n",
      "  2.39797671  0.99720943  2.4980767 ]  energy_before :  90  energy_after :  560  reward :  -651.7927990044353\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "action : 1  next_temperatures :  [-0.24692729 -0.14066635 -0.99162523  0.95082454  0.06100966 -0.14825656\n",
      " -0.36974869 -0.25958284  0.16149705]  energy_before :  560  energy_after :  350  reward :  11.016524283954112\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n",
      "action : 1  next_temperatures :  [ 2.06312399 -0.04265666  3.31010126 -1.73405183  2.00511929 -0.47396003\n",
      "  2.0533572  -0.04996389  1.95594685]  energy_before :  350  energy_after :  110  reward :  51.08701618567832\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "action : 1  next_temperatures :  [ 0.9423444   0.3770259   1.635012   -0.50546289  0.97823061  0.05863684\n",
      "  1.24076008  0.17577959  0.81747417]  energy_before :  110  energy_after :  60  reward :  -142.280199305372\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "action : 1  next_temperatures :  [-0.49598942  2.74768786 -0.06439797  1.45208883 -1.03068267  2.75029948\n",
      " -0.9261656   2.21207791 -1.29683224]  energy_before :  60  energy_after :  90  reward :  -222.6519138297782\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "action : 1  next_temperatures :  [ 0.74932124  0.57807144  0.5740208   0.78783174  0.41493731  0.07912134\n",
      " -0.22778895  0.75165581  0.92047884]  energy_before :  90  energy_after :  100  reward :  -203.37235043332825\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "action : 1  next_temperatures :  [-0.30296627  1.10497828  0.02224458  0.52737088 -0.36602981  1.36964452\n",
      " -1.0110151   1.0522632  -0.26678553]  energy_before :  100  energy_after :  210  reward :  -305.87029524180355\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "action : 1  next_temperatures :  [ 0.5687512  -1.06296275  1.44044628 -1.92407359  0.31025448 -1.01679914\n",
      "  1.0498487  -1.07087726  0.3295573 ]  energy_before :  210  energy_after :  70  reward :  -59.375854781682136\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "action : 1  next_temperatures :  [-1.19958995  0.14247278 -0.56601272 -0.53822526 -0.49854497  0.05453994\n",
      " -0.85926503 -0.45998776 -1.05287381]  energy_before :  70  energy_after :  20  reward :  -152.97748678541072\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "action : 1  next_temperatures :  [-0.61429393  1.16612963  0.02224458  0.72312605 -1.08053164  1.76909217\n",
      " -0.75401902  1.54751675 -0.98781823]  energy_before :  20  energy_after :  90  reward :  -266.2085536310532\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "action : 1  next_temperatures :  [ 0.06440038  2.46371104  0.3460141   1.6658633   0.06100966  2.45225008\n",
      " -0.22778895  1.75214477  0.05849238]  energy_before :  90  energy_after :  100  reward :  -199.36390325196498\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "action : 1  next_temperatures :  [ 1.68330424 -1.1044284   1.25804092 -1.28182872  1.05798895 -1.89046285\n",
      "  1.92608295 -0.87264421  2.13407523]  energy_before :  100  energy_after :  30  reward :  -125.0898718832292\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "action : 1  next_temperatures :  [-0.42749733  1.24906092 -0.25136347  1.27926732 -0.05198133  1.43109801\n",
      " -0.27674059  1.16628669 -0.63181963]  energy_before :  30  energy_after :  50  reward :  -214.51368941544882\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "action : 1  next_temperatures :  [-0.47315873 -1.20453232 -1.16339028 -0.299879   -0.58204199 -1.22369254\n",
      " -0.12499052 -1.29616004 -0.53785045]  energy_before :  50  energy_after :  90  reward :  -244.90569588085827\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "action : 1  next_temperatures :  [ 1.75179633 -0.26631982  3.24625938 -1.77582385  1.91040625 -0.62759374\n",
      "  1.92608295 -0.25958284  1.86559188]  energy_before :  90  energy_after :  650  reward :  -750.2291834556311\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "action : 1  next_temperatures :  [-0.11616967  0.3284399  -0.46416972  0.93608147 -0.58204199 -0.21892806\n",
      " -0.07603889 -0.65962486 -0.28485652]  energy_before :  650  energy_after :  130  reward :  320.8626916570103\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "action : 1  next_temperatures :  [ 0.25742353 -1.42484472  0.02224458 -1.16890092 -0.68672482 -0.90720709\n",
      "  0.10345044 -0.87538648  0.45244007]  energy_before :  130  energy_after :  70  reward :  -142.2275054091047\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "action : 1  next_temperatures :  [ 0.88007886 -0.32663348  0.21985039 -0.43911909  0.69741478 -1.67537566\n",
      "  0.75124373 -1.48866724  1.15901597]  energy_before :  70  energy_after :  70  reward :  -198.22219171956453\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "action : 1  next_temperatures :  [ 0.0083614  -1.04620896 -0.29240467 -0.91417348 -0.53219302 -1.08849487\n",
      " -0.36974869 -0.94295596 -0.32099851]  energy_before :  70  energy_after :  40  reward :  -173.4988167737964\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "action : 1  next_temperatures :  [-0.28428661 -0.2596183  -0.79401942  0.7403263   0.11584352 -0.50775944\n",
      " -0.41870032  0.27022329  0.10728407]  energy_before :  40  energy_after :  60  reward :  -219.03070692573263\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "action : 1  next_temperatures :  [-2.34112472  0.99021479 -1.47803954  1.01716834 -1.62887025  0.87494397\n",
      " -1.99004778  1.24537369 -1.59801549]  energy_before :  60  energy_after :  50  reward :  -192.9083969953048\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "action : 1  next_temperatures :  [-0.11616967 -1.14589404 -1.16339028  0.04166872 -0.2829482  -1.24212859\n",
      " -0.22778895 -1.1809848   0.0042794 ]  energy_before :  50  energy_after :  450  reward :  -603.3133564110444\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "action : 1  next_temperatures :  [-0.05390414 -0.00747369 -0.70737688  0.96884384  0.14907616 -0.29267225\n",
      " -0.17394215  0.2617771   0.54640924]  energy_before :  450  energy_after :  50  reward :  202.69073725310236\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "action : 1  next_temperatures :  [ 0.68705571 -0.3249581   0.8324284  -0.41536637  0.16569248 -0.29267225\n",
      "  0.21277576  0.18422577  0.27534432]  energy_before :  50  energy_after :  60  reward :  -206.67547426697115\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "action : 1  next_temperatures :  [-1.18091029  1.21387795 -0.61161406  1.02453987 -0.93596964  1.46182475\n",
      " -1.02570059  1.62698767 -1.13419329]  energy_before :  60  energy_after :  40  reward :  -177.56115762241325\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "action : 1  next_temperatures :  [-0.30296627  1.17366884  0.11800739  0.28165309 -0.43747999  1.23444685\n",
      " -1.0110151   0.52130532 -0.3806328 ]  energy_before :  40  energy_after :  70  reward :  -226.8030126518315\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "action : 1  next_temperatures :  [-0.53749978  0.82183915 -0.38360736  1.30465815 -0.2829482   0.27167559\n",
      " -0.61450686  0.97663145 -0.21257254]  energy_before :  70  energy_after :  50  reward :  -176.65633038819917\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "action : 1  next_temperatures :  [-0.67655947 -0.52684132 -0.92018313  0.23824295 -1.01572798 -0.64090866\n",
      " -0.17394215 -1.24394726 -0.51977946]  energy_before :  50  energy_after :  80  reward :  -233.4796464920258\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n",
      "action : 1  next_temperatures :  [-1.05015267 -0.81165583 -0.85634126 -0.82571507 -0.98581861 -1.06084081\n",
      " -0.85926503 -1.0427745  -1.13419329]  energy_before :  80  energy_after :  150  reward :  -276.62675706303787\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "action : 1  next_temperatures :  [-2.17093226  0.71126411 -1.39139699  0.87956638 -1.52917232  0.92717943\n",
      " -1.83829772  1.05111145 -1.51910548]  energy_before :  150  energy_after :  100  reward :  -152.879783410706\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "action : 1  next_temperatures :  [-0.61429393 -0.8468388  -0.50673098 -0.99771752 -0.68672482 -0.66856273\n",
      " -0.96206346 -0.87461865 -1.0799803 ]  energy_before :  100  energy_after :  140  reward :  -245.23753119345832\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "action : 1  next_temperatures :  [2.32879027 0.58561065 1.98766237 0.19892811 2.20950004 0.06068529\n",
      " 2.43191651 0.63648056 2.1456923 ]  energy_before :  140  energy_after :  100  reward :  -145.41473390299257\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "action : 1  next_temperatures :  [-0.49598942 -0.92869306 -0.66177553 -0.57262575 -0.63189095 -0.17634958\n",
      " -0.71730529 -0.71740444 -0.75470239]  energy_before :  100  energy_after :  100  reward :  -203.65673641855813\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "action : 1  next_temperatures :  [-1.36148033 -0.76893366 -1.4324382  -0.15490551 -1.08053164 -0.05607633\n",
      " -0.83478922 -0.53600343 -1.13419329]  energy_before :  100  energy_after :  310  reward :  -415.3593515915091\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "action : 1  next_temperatures :  [ 0.43799358 -0.08202807  1.03003421 -0.73602808  0.41493731 -0.36795276\n",
      "  1.11511755 -0.41391767  0.49219626]  energy_before :  310  energy_after :  110  reward :  3.8903523191637817\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "action : 1  next_temperatures :  [ 1.3512214   0.15168736  1.84629821 -0.91803476  1.16267178 -0.20049202\n",
      "  1.39251014  0.01453424  1.03432611]  energy_before :  110  energy_after :  80  reward :  -162.16527752629185\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "action : 1  next_temperatures :  [-0.11616967  0.44487877 -0.59641361  1.19654233  0.36508834  0.14057482\n",
      " -0.0466679  -0.0061973   0.43256198]  energy_before :  80  energy_after :  50  reward :  -166.18580224777023\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "action : 1  next_temperatures :  [-1.80356562  0.04362539 -1.4324382   0.11784124 -1.52917232  0.20202831\n",
      " -1.39773301 -0.16341151 -1.51006998]  energy_before :  50  energy_after :  60  reward :  -215.4728957071006\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "action : 1  next_temperatures :  [ 0.195158    0.21786485 -0.56601272  1.15640842  0.7140311  -0.28140577\n",
      "  0.60928399 -0.25958284  0.64941392]  energy_before :  60  energy_after :  40  reward :  -175.56484105431824\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "action : 1  next_temperatures :  [-0.30296627 -1.04788434 -1.16339028 -0.00501766 -0.48732896 -1.08849487\n",
      " -0.03198241 -1.29616004 -0.43484578]  energy_before :  40  energy_after :  110  reward :  -273.85807062036906\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "action : 1  next_temperatures :  [ 0.02704106 -0.12558794  1.24284047 -0.85765838 -0.0503197  -0.44630596\n",
      "  0.07081602 -0.03767853  0.05849238]  energy_before :  110  energy_after :  80  reward :  -168.11836058920284\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n",
      "action : 1  next_temperatures :  [2.18765506 2.05408075 1.59874808 1.9849454  2.00511929 1.79674624\n",
      " 2.27363956 1.46804583 2.44386372]  energy_before :  80  energy_after :  50  reward :  -150.18715607511112\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "action : 1  next_temperatures :  [-0.71806982 -0.99762296 -0.56601272 -1.04604202 -1.08053164 -0.84268094\n",
      " -1.20682164 -0.60510857 -1.28707391]  energy_before :  50  energy_after :  100  reward :  -256.3499642068668\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n",
      "action : 1  next_temperatures :  [ 0.74932124 -1.53206901 -0.06439797 -1.06406133 -0.23808413 -1.30358207\n",
      "  0.77082439 -1.28924953 -0.32099851]  energy_before :  100  energy_after :  100  reward :  -202.29229691882193\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "action : 1  next_temperatures :  [-0.98788713 -0.20768153 -0.97642479 -0.05416122 -1.00077329 -0.07451237\n",
      " -1.1040232  -0.56671682 -0.19450155]  energy_before :  100  energy_after :  110  reward :  -213.1666819171317\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "action : 1  next_temperatures :  [-0.86958262  0.00760473 -0.83962076  0.26527191 -0.47071263  0.46627829\n",
      " -1.1040232   0.45450368 -0.92276265]  energy_before :  110  energy_after :  40  reward :  -131.01304326178322\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "action : 1  next_temperatures :  [ 1.19140653 -0.71867227  0.71343062 -0.63440622  1.00813999 -0.89368733\n",
      "  1.63726831 -0.76635392  1.80776469]  energy_before :  40  energy_after :  60  reward :  -214.6551095992449\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "action : 1  next_temperatures :  [-0.18466176 -0.40118786 -0.85634126  0.7141164   0.39832099 -0.66139315\n",
      " -0.36974869  0.25333092 -0.10956787]  energy_before :  60  energy_after :  60  reward :  -199.2171322872879\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "action : 1  next_temperatures :  [ 1.68330424 -1.13835483  1.26716118 -1.2336066   1.05798895 -1.87919638\n",
      "  1.92608295 -0.91101402  2.17279879]  energy_before :  60  energy_after :  50  reward :  -185.05483571060992\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "action : 1  next_temperatures :  [-0.3652318   1.83628142 -0.25136347  1.73138805  0.29779224  1.20064744\n",
      " -0.27674059  1.21235679 -0.65169772]  energy_before :  50  energy_after :  40  reward :  -183.2665676410157\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "action : 1  next_temperatures :  [ 0.74932124  0.3527329   0.66066335  0.07606921  0.55949931  0.11804188\n",
      "  0.9960019  -0.0545709   1.24937095]  energy_before :  40  energy_after :  80  reward :  -233.29287016199174\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "action : 1  next_temperatures :  [ 0.63101673 -1.94253698  1.1622781  -2.53591088  0.06100966 -1.14994836\n",
      "  0.94705027 -1.45740538  0.10728407]  energy_before :  80  energy_after :  50  reward :  -172.17716277710952\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "action : 1  next_temperatures :  [-0.3652318  -0.04265666 -0.33800601 -0.1712867   0.49469565 -0.52721971\n",
      "  0.60928399 -0.72873    -0.92276265]  energy_before :  50  energy_after :  100  reward :  -249.99191388333256\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "action : 1  next_temperatures :  [-1.13939993 -0.71113307 -1.03722657 -0.21797308 -1.1303806  -0.74230691\n",
      " -0.33711427 -0.81242401 -0.80891538]  energy_before :  100  energy_after :  50  reward :  -154.9368738188432\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "action : 1  next_temperatures :  [-0.42749733  0.40299428 -0.52041138  0.52573276 -0.88113578  0.87494397\n",
      " -0.85926503 -0.0061973   0.35244723]  energy_before :  50  energy_after :  120  reward :  -268.5383885778365\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "action : 1  next_temperatures :  [-0.49598942 -0.70191848 -1.23483239  0.04166872 -0.73657378 -0.47396003\n",
      " -0.29142608 -1.21323386 -0.80891538]  energy_before :  120  energy_after :  40  reward :  -123.91518068935221\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "action : 1  next_temperatures :  [ 2.37445166 -1.85960569  2.59568025 -2.41305199  1.52324596 -1.08849487\n",
      "  1.78412322 -0.88152916  1.46260869]  energy_before :  40  energy_after :  60  reward :  -214.50257194292658\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "action : 1  next_temperatures :  [ 1.12914099 -0.24370219  2.05150425 -0.93172475  1.39530028 -0.464742\n",
      "  1.29460687 -0.31409912  0.81747417]  energy_before :  60  energy_after :  350  reward :  -483.2662414956318\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "action : 1  next_temperatures :  [-0.16183106  1.19879953  0.17728914  0.92870994 -0.06693602  1.75884993\n",
      " -0.96206346  1.49108088 -0.32099851]  energy_before :  350  energy_after :  40  reward :  116.04290035568255\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "action : 1  next_temperatures :  [-2.98661075  1.04885307 -1.8884516   0.95082454 -2.43143859  0.93639745\n",
      " -2.77327393  1.10351618 -2.27808727]  energy_before :  40  energy_after :  110  reward :  -276.3182708957865\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "action : 1  next_temperatures :  [-1.27845962 -0.76893366 -1.39139699 -0.14589586 -1.08053164 -0.12777206\n",
      " -0.63082407 -0.51527188 -1.0980513 ]  energy_before :  110  energy_after :  70  reward :  -165.0371370774221\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "action : 1  next_temperatures :  [-0.42749733 -0.6181495  -0.27872427 -0.75118068 -0.70334114 -0.29267225\n",
      " -0.30611157 -0.56671682 -0.86312836]  energy_before :  70  energy_after :  40  reward :  -172.8075219239622\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "action : 1  next_temperatures :  [-0.80731709 -0.6432802  -0.79401942 -0.4227379  -0.63189095 -0.09499687\n",
      " -0.76625693 -0.48993333 -0.86312836]  energy_before :  40  energy_after :  90  reward :  -253.5135610490348\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "action : 1  next_temperatures :  [ 0.63101673 -1.11238645 -0.02335676 -0.90680194  0.49469565 -1.13151231\n",
      "  0.50648556 -1.1372182  -0.48363747]  energy_before :  90  energy_after :  90  reward :  -201.1627151974909\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "action : 1  next_temperatures :  [ 0.0083614  -0.49500911 -0.56601272  0.30540581  0.36508834 -0.25887283\n",
      " -0.33711427  0.02298043  0.16149705]  energy_before :  90  energy_after :  50  reward :  -158.7936758952159\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "action : 1  next_temperatures :  [-0.49598942 -0.8795087  -0.29240467 -0.93219278 -0.88113578 -0.59993967\n",
      " -0.40238311 -0.84390525 -0.86312836]  energy_before :  50  energy_after :  60  reward :  -214.19058774994375\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n",
      "action : 1  next_temperatures :  [-0.05390414  0.09221139  0.80202751 -0.41536637  0.01116069 -0.25887283\n",
      "  0.31557419 -0.03767853  0.39641999]  energy_before :  60  energy_after :  50  reward :  -187.1484280977292\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "action : 1  next_temperatures :  [ 0.0083614  -0.28307361 -0.05071757 -0.61931213  1.07626691 -0.68904722\n",
      " -0.59818965 -0.29183191 -0.43484578]  energy_before :  50  energy_after :  290  reward :  -439.8823895638568\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "action : 1  next_temperatures :  [ 0.43799358 -0.11804873  0.00704413 -0.03204662  0.11584352 -0.2701393\n",
      "  0.26172739 -0.16974615  0.27534432]  energy_before :  290  energy_after :  60  reward :  32.50797214034009\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "action : 1  next_temperatures :  [0.9423444  1.6503143  1.39028481 0.87500305 1.12943914 0.80529668\n",
      " 1.43656661 1.14497927 1.38128921]  energy_before :  60  energy_after :  70  reward :  -197.2444825331748\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "action : 1  next_temperatures :  [ 0.12666591 -0.46736535 -0.56601272  0.51836123  0.27702184 -0.55589801\n",
      " -0.27674059  0.02298043  0.16149705]  energy_before :  70  energy_after :  140  reward :  -268.75949020370774\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "action : 1  next_temperatures :  [ 1.1063103  -0.62820178  0.61050188 -0.34017672  1.21252075 -0.29267225\n",
      "  1.24076008 -0.52909291  0.81747417]  energy_before :  140  energy_after :  50  reward :  -104.80257649586821\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "action : 1  next_temperatures :  [-0.30296627 -0.30904199  0.25025128 -0.57631152 -0.88113578  0.29420854\n",
      " -0.34406419  0.32272045 -1.02576732]  energy_before :  50  energy_after :  40  reward :  -190.5721067994864\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "action : 1  next_temperatures :  [-1.80356562  1.24822323 -1.05242702  1.12528417 -1.16693651  1.83054566\n",
      " -2.13200752  1.90340826 -1.56789717]  energy_before :  40  energy_after :  60  reward :  -219.6153725300955\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "action : 1  next_temperatures :  [ 0.9423444  -0.42715624  0.47825799 -0.51575963  0.96327592 -0.88789314\n",
      "  1.14775197 -0.69110609  1.14275208]  energy_before :  60  energy_after :  60  reward :  -195.84753275684275\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "action : 1  next_temperatures :  [ 0.06440038 -1.2715475  -0.92018313 -0.3342795   0.46478627 -1.34557529\n",
      "  0.41347746 -1.52651053  0.60062223]  energy_before :  60  energy_after :  60  reward :  -201.85480960838126\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n",
      "action : 1  next_temperatures :  [-0.13900036  0.75398628 -0.10999931  0.80585104 -0.18823517  0.86388234\n",
      "  0.18340478  1.07645    -0.75470239]  energy_before :  60  energy_after :  60  reward :  -195.50836279287745\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "action : 1  next_temperatures :  [ 0.74932124 -0.41040245  0.70626469 -0.60375     0.39832099 -0.71977397\n",
      "  0.85404217 -0.14440759  0.27534432]  energy_before :  60  energy_after :  30  reward :  -166.89504060824004\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n",
      "action : 1  next_temperatures :  [-0.7616557  -0.67846317 -0.29240467 -0.89205888 -0.90107537  1.1330486\n",
      " -1.66044011 -0.17665666 -0.53785045]  energy_before :  30  energy_after :  40  reward :  -212.76755640044598\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n",
      "action : 1  next_temperatures :  [ 1.79330668 -1.55636201  2.30231162 -2.35817501  0.86357799 -1.10897937\n",
      "  1.53936504 -0.95063431  0.3295573 ]  energy_before :  40  energy_after :  70  reward :  -227.14603205391168\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "action : 1  next_temperatures :  [-2.2331978   0.76152549 -1.4324382   0.90168098 -1.57902129  0.87494397\n",
      " -1.88724935  1.05111145 -1.56789717]  energy_before :  70  energy_after :  60  reward :  -193.11054191318826\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "action : 1  next_temperatures :  [ 0.79498263 -0.76893366 -0.03703716 -0.10330477  0.11584352 -0.81502687\n",
      " -0.32079706 -0.38320427  0.63315002]  energy_before :  60  energy_after :  50  reward :  -188.8843276160251\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "action : 1  next_temperatures :  [-1.42997242 -1.55049818 -1.34579565 -1.2336066  -1.2799275  -0.96866058\n",
      " -1.15297484 -1.29616004 -1.0799803 ]  energy_before :  50  energy_after :  50  reward :  -209.33757610802368\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "action : 1  next_temperatures :  [ 0.10591073 -1.38212254 -0.27872427 -1.26800709 -0.88113578 -0.74230691\n",
      " -0.41870032 -1.0581312   0.02235039]  energy_before :  50  energy_after :  100  reward :  -253.900866999682\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "action : 1  next_temperatures :  [-0.47315873  0.19357185 -1.06762747  1.02453987  0.36508834  0.10677541\n",
      " -0.07603889 -0.0061973   0.37834899]  energy_before :  100  energy_after :  50  reward :  -147.5546979153938\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "action : 1  next_temperatures :  [ 0.5687512  -0.25878061  0.6044217  -0.59474035 -0.38264613  0.87494397\n",
      "  0.22909297  0.43146863 -0.53785045]  energy_before :  50  energy_after :  50  reward :  -197.0653390849856\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "action : 1  next_temperatures :  [ 1.99463191 -2.1770901   1.53164896 -2.50249326  0.36508834 -3.21888235\n",
      "  1.88202648 -1.55184908  2.32227174]  energy_before :  50  energy_after :  60  reward :  -209.3546473708208\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "action : 1  next_temperatures :  [-0.18466176  0.41891039  0.02224458 -0.5892117  -0.68672482  0.17949536\n",
      " -0.47254712 -0.45307725 -0.86312836]  energy_before :  60  energy_after :  120  reward :  -260.6287006764396\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "action : 1  next_temperatures :  [ 0.27817871  0.71126411  0.20464994  0.70510675 -0.13340131  0.87494397\n",
      "  0.65497219  1.57400706 -0.48363747]  energy_before :  120  energy_after :  50  reward :  -123.61391605871003\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "action : 1  next_temperatures :  [ 0.31968906  1.08236066 -0.33800601  2.06556424  0.89681064  0.26348179\n",
      "  0.21277576  1.07645     0.7036269 ]  energy_before :  50  energy_after :  30  reward :  -171.71724696868299\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "action : 1  next_temperatures :  [-1.74130008  1.61848209 -1.02202613  1.51597545 -1.32977646  1.80801271\n",
      " -1.45157981  1.9725134  -1.24804056]  energy_before :  30  energy_after :  130  reward :  -297.87773937900147\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "action : 1  next_temperatures :  [-1.49223795 -0.6432802  -1.47803954 -0.11149537 -1.08053164 -0.54565576\n",
      " -1.54458791 -0.42082818 -0.75470239]  energy_before :  130  energy_after :  50  reward :  -126.07135893583921\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "action : 1  next_temperatures :  [-0.30296627 -0.36935565 -0.77881898  0.59125751 -0.13340131 -0.71977397\n",
      " -0.61450686 -0.33099149 -0.04993359]  energy_before :  50  energy_after :  60  reward :  -210.70849060328277\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "action : 1  next_temperatures :  [0.85932368 1.75921397 1.28409883 1.14950492 1.16267178 0.79403021\n",
      " 1.43656661 1.28146193 1.30539103]  energy_before :  60  energy_after :  380  reward :  -506.9677370285402\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "action : 1  next_temperatures :  [ 0.43799358 -1.1735378   1.66845298 -2.37373714  0.26040552 -1.1806751\n",
      "  0.82140774 -1.25239345  0.99637702]  energy_before :  380  energy_after :  510  reward :  -329.7957066504993\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "action : 1  next_temperatures :  [ 0.06440038 -0.62066257  1.27324136 -1.4629432   0.26040552 -1.06084081\n",
      "  0.85404217 -0.86375927  0.22113133]  energy_before :  510  energy_after :  70  reward :  240.66501490828483\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "action : 1  next_temperatures :  [-0.9256216  -0.84432573 -1.75164758  0.42662659 -0.93596964 -0.52619549\n",
      " -0.56555523 -1.11187965 -0.88300646]  energy_before :  70  energy_after :  80  reward :  -215.11757478900927\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "action : 1  next_temperatures :  [-0.55825495 -1.32180888  0.23505084 -1.77418574 -0.41920204 -1.32406657\n",
      "  0.01696922 -1.0581312  -0.48363747]  energy_before :  80  energy_after :  70  reward :  -194.6872667927218\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "action : 1  next_temperatures :  [ 0.81781333  0.16844116  0.11800739  0.8549946   0.88019431 -0.28140577\n",
      "  0.94705027  0.17577959  0.81747417]  energy_before :  70  energy_after :  50  reward :  -173.50165095391532\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "action : 1  next_temperatures :  [-1.23694927 -0.86275491 -1.34579565 -0.26056416 -0.91769169 -0.82219644\n",
      " -1.25577327 -0.57170775  0.02054329]  energy_before :  50  energy_after :  70  reward :  -225.2528898385722\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "action : 1  next_temperatures :  [-1.2992148   1.19126033 -0.70737688  1.02453987 -0.98581861  1.39729859\n",
      " -1.1040232   1.62698767 -1.13419329]  energy_before :  70  energy_after :  60  reward :  -187.99054031294713\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "action : 1  next_temperatures :  [-0.24692729  1.52466084  0.02224458  1.22357128 -0.16081824  1.61545846\n",
      " -0.47254712  1.81357156 -0.48363747]  energy_before :  60  energy_after :  70  reward :  -203.16442338784609\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "action : 1  next_temperatures :  [-0.47315873  0.73890787 -0.20576213  0.70510675 -0.93596964  1.5509323\n",
      " -1.15297484  1.35287059 -0.54387412]  energy_before :  70  energy_after :  60  reward :  -186.96392194302578\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "action : 1  next_temperatures :  [-1.07298336  0.79754615 -0.47937017  0.21367117 -0.83128681  0.57894302\n",
      " -1.05507157  0.74628096 -0.48363747]  energy_before :  60  energy_after :  50  reward :  -189.58590808309674\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "action : 1  next_temperatures :  [-0.22617211  1.21387795  0.16360874  0.95082454 -0.08355234  1.83054566\n",
      " -0.96206346  1.49108088 -0.32099851]  energy_before :  50  energy_after :  30  reward :  -173.94284867055245\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "action : 1  next_temperatures :  [-0.70769223  0.04781384  0.07240605 -0.53822526 -0.83128681 -0.25887283\n",
      "  0.16871929 -0.57516301 -0.7384385 ]  energy_before :  30  energy_after :  50  reward :  -221.36073946843942\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "action : 1  next_temperatures :  [-0.55825495  0.76152549 -0.66177553  1.49386085 -0.33279717  0.23275505\n",
      " -0.64714128  0.86683105 -0.21257254]  energy_before :  50  energy_after :  40  reward :  -187.05756903733896\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "action : 1  next_temperatures :  [ 0.37572804 -0.74631603 -0.20576213 -0.18602976 -0.18823517 -0.81502687\n",
      "  0.68026386 -0.40009664 -0.14570986]  energy_before :  40  energy_after :  130  reward :  -289.63118455140983\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "action : 1  next_temperatures :  [-1.11864475  1.31691379 -0.50673098  1.02453987 -0.89941373  1.51201176\n",
      " -0.9261656   1.61316664 -1.0799803 ]  energy_before :  130  energy_after :  60  reward :  -127.06430330225032\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "action : 1  next_temperatures :  [-0.01832383  0.13900235 -0.12302826 -0.41290919 -0.78143785 -0.36334375\n",
      "  0.07897462 -1.03931925 -0.86312836]  energy_before :  60  energy_after :  280  reward :  -421.38351352365567\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "action : 1  next_temperatures :  [-0.05390414 -0.81919504 -0.74841808  0.00235387  0.18230881 -1.01679914\n",
      "  0.56033236 -1.17111263  0.22113133]  energy_before :  280  energy_after :  50  reward :  29.156697339827247\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "action : 1  next_temperatures :  [1.72896563 1.13848587 0.77162661 1.55037594 1.80572343 1.00092361\n",
      " 1.53936504 0.9359362  2.05895152]  energy_before :  50  energy_after :  20  reward :  -155.46964613413326\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "action : 1  next_temperatures :  [ 0.5687512  -0.99762296 -0.26504387 -0.55460645  0.66418213 -1.48794253\n",
      "  0.60928399 -1.64398928  0.87168715]  energy_before :  20  energy_after :  50  reward :  -230.23530060074117\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "action : 1  next_temperatures :  [ 1.06064891 -0.83594884  1.18377588 -0.79236766  1.20539947 -0.83082919\n",
      "  1.31092408 -1.01359677  1.96570519]  energy_before :  50  energy_after :  40  reward :  -184.74628893783697\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step\n",
      "action : 1  next_temperatures :  [ 0.81781333 -0.06527428  0.82482818 -0.4006233  -0.63189095  0.81656316\n",
      "  0.16871929  1.09718154  0.37834899]  energy_before :  40  energy_after :  70  reward :  -224.99433404782454\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "action : 1  next_temperatures :  [ 0.43799358  1.42581345  0.52841946  1.19080891 -0.13340131  1.73759726\n",
      "  0.44284844  1.51181242 -0.50687161]  energy_before :  70  energy_after :  40  reward :  -161.36497938547114\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "action : 1  next_temperatures :  [ 1.62103871  0.03524849  0.75642617  0.24889072  1.46176557 -0.0299586\n",
      "  1.68132478  0.36005998  1.19154376]  energy_before :  40  energy_after :  40  reward :  -190.673660416695\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "action : 1  next_temperatures :  [-0.05390414  1.67712037  0.3156132   1.10071239 -0.13340131  2.10401367\n",
      " -0.32079706  1.60625612  0.10728407]  energy_before :  40  energy_after :  30  reward :  -181.59710267411864\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "action : 1  next_temperatures :  [-0.61429393  0.71126411 -0.66177553  1.00242527 -0.20485149  1.11256411\n",
      " -0.22778895  0.59041047 -0.32099851]  energy_before :  30  energy_after :  80  reward :  -246.6130444667165\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "action : 1  next_temperatures :  [-2.17093226 -0.24370219 -1.47803954 -0.15490551 -1.9827979   0.06887909\n",
      " -2.37676569  0.03142661 -1.94738806]  energy_before :  80  energy_after :  60  reward :  -188.25422545642238\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "action : 1  next_temperatures :  [1.06064891 0.28655541 0.33689383 0.80585104 1.16267178 0.09755738\n",
      " 1.14775197 0.12970949 0.81747417]  energy_before :  60  energy_after :  280  reward :  -412.15488601618495\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "action : 1  next_temperatures :  [1.99463191 1.62434592 1.25804092 1.93615287 2.07063507 0.70155735\n",
      " 2.02888139 1.67305777 2.33001645]  energy_before :  280  energy_after :  270  reward :  -172.3826803692642\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "action : 1  next_temperatures :  [-0.49598942 -1.08725576 -0.97642479 -0.34902256 -0.63189095 -1.1806751\n",
      " -0.17394215 -1.32149859 -0.59206344]  energy_before :  270  energy_after :  60  reward :  5.191237228342629\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "action : 1  next_temperatures :  [-0.38598698 -1.35615416 -0.20576213 -1.43263801 -1.03068267 -1.24212859\n",
      " -0.36974869 -1.0427745  -1.16997386]  energy_before :  60  energy_after :  50  reward :  -196.2358495887496\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n",
      "action : 1  next_temperatures :  [ 1.06064891  0.00760473  3.03649321 -1.82332929  1.00813999 -0.53541351\n",
      "  1.53936504 -0.19047769  0.10728407]  energy_before :  50  energy_after :  110  reward :  -253.78968454775708\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n",
      "action : 1  next_temperatures :  [0.99838337 1.13848587 0.75642617 1.12493314 1.21252075 0.73257673\n",
      " 1.24076008 0.96127475 1.68488193]  energy_before :  110  energy_after :  60  reward :  -138.1497572130404\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "action : 1  next_temperatures :  [ 0.23666835  0.73807018  0.52841946 -0.2114206   0.16569248  1.51098754\n",
      " -1.04038608  1.48340253 -1.35104523]  energy_before :  60  energy_after :  90  reward :  -225.93961136424457\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "action : 1  next_temperatures :  [ 0.21591317 -1.04788434  1.98766237 -2.4892245   0.16569248 -1.24212859\n",
      "  0.85404217 -1.10496913  0.02235039]  energy_before :  90  energy_after :  60  reward :  -170.63854597679247\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n",
      "action : 1  next_temperatures :  [-0.3652318   0.23629403 -1.10106845  1.62409128 -0.73657378 -0.2701393\n",
      "  0.07081602 -0.63735764 -0.51977946]  energy_before :  60  energy_after :  60  reward :  -199.6989491133731\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "action : 1  next_temperatures :  [ 0.29893389  0.88717895 -0.33800601  1.73957864  1.21252075  0.54002247\n",
      "  0.21277576  0.84609951  0.7036269 ]  energy_before :  60  energy_after :  50  reward :  -181.89726915064762\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "action : 1  next_temperatures :  [ 0.31968906 -0.39197328 -0.38360736  0.23169048  1.25738481 -0.59993967\n",
      "  0.60928399 -0.83545906  0.60062223]  energy_before :  50  energy_after :  60  reward :  -207.19230878548183\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "action : 1  next_temperatures :  [ 0.77215194 -0.12558794  0.07240605  0.31441547  1.46176557 -0.50775944\n",
      "  1.19180844 -0.48993333  1.73367361]  energy_before :  60  energy_after :  30  reward :  -163.57705962845228\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "action : 1  next_temperatures :  [ 0.25742353 -0.21605843 -0.29240467  0.47740827  0.46478627  0.16822889\n",
      "  0.21277576 -0.16129996  0.45641569]  energy_before :  30  energy_after :  90  reward :  -256.6327246625125\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "action : 1  next_temperatures :  [-0.96713196 -0.09040497 -0.80921987  0.21367117 -0.73657378 -0.07451237\n",
      " -1.0110151  -0.02923235 -0.51977946]  energy_before :  90  energy_after :  60  reward :  -172.02419868579202\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "action : 1  next_temperatures :  [-0.61429393  1.13094667 -0.40032785  1.28827697 -0.43747999  0.8472899\n",
      " -0.17394215  1.48340253 -0.86312836]  energy_before :  60  energy_after :  40  reward :  -175.7392562274843\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "action : 1  next_temperatures :  [-1.54827693  0.88717895 -0.83962076  0.84148012 -1.18521446  1.76909217\n",
      " -1.02570059  1.16628669 -1.26430445]  energy_before :  40  energy_after :  110  reward :  -269.1990792644112\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "action : 1  next_temperatures :  [-0.11616967 -0.01501289 -0.56601272  0.58224786  0.41493731 -0.04685831\n",
      "  0.07081602  0.10897794  0.22113133]  energy_before :  110  energy_after :  90  reward :  -177.34594312858843\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "action : 1  next_temperatures :  [ 0.23666835  0.3527329   0.5740208   0.15715608  0.64756581 -0.30189027\n",
      "  0.4323588   0.33932843  0.64941392]  energy_before :  90  energy_after :  330  reward :  -434.91264517008074\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "action : 1  next_temperatures :  [ 0.9423444   2.02811237  0.75642617  1.50123238  1.19424279  1.57346525\n",
      "  1.09880034 -0.14440759  0.97469182]  energy_before :  330  energy_after :  50  reward :  91.92490792350716\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "action : 1  next_temperatures :  [-0.3652318  -1.02945517 -0.35320646 -1.71685158 -0.98581861 -1.06084081\n",
      "  0.21277576 -1.49656497 -0.97697563]  energy_before :  50  energy_after :  140  reward :  -295.772169266245\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "action : 1  next_temperatures :  [-0.45032803 -0.66003399 -0.43376883 -0.64634109 -0.16630162 -0.7892164\n",
      " -1.05507157 -0.84390525 -1.24804056]  energy_before :  140  energy_after :  60  reward :  -124.29300733697067\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "action : 1  next_temperatures :  [ 0.9423444  -0.09040497  0.84762885 -0.52921561  0.33767141 -0.26040917\n",
      "  0.65823563 -0.02923235  0.85000196]  energy_before :  60  energy_after :  60  reward :  -195.27337985016564\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "action : 1  next_temperatures :  [ 0.33369881  1.00215187 -0.10999931  1.70517815  1.1792881  -0.03559183\n",
      "  0.21277576  0.83343023  0.79940317]  energy_before :  60  energy_after :  90  reward :  -222.0796650529254\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n",
      "action : 1  next_temperatures :  [-0.67655947 -0.30904199 -0.33800601 -0.37359434 -0.73657378  0.31264458\n",
      " -0.27674059 -0.40527952 -0.80891538]  energy_before :  90  energy_after :  70  reward :  -181.61206650248428\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "action : 1  next_temperatures :  [ 0.74932124 -0.36014107  0.66066335 -0.51447254  0.36508834 -0.70953172\n",
      "  0.85404217 -0.16974615  0.27534432]  energy_before :  70  energy_after :  50  reward :  -176.84943205141326\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "action : 1  next_temperatures :  [-0.18466176  0.50267936 -0.61161406  1.45290789  0.44650832  0.14876862\n",
      " -0.56555523  0.24488473 -0.21257254]  energy_before :  50  energy_after :  150  reward :  -296.77865466583114\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "action : 1  next_temperatures :  [-0.738825   -0.04265666 -1.39139699  1.46928907 -0.65016891 -0.29267225\n",
      " -0.32079706 -0.81242401 -0.59206344]  energy_before :  150  energy_after :  310  reward :  -361.3717152357748\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "action : 1  next_temperatures :  [-1.27845962  1.45010645 -0.70737688  1.34643018 -1.23506343  1.83054566\n",
      " -1.15297484  1.95178186 -1.13419329]  energy_before :  310  energy_after :  40  reward :  73.0707960959752\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "action : 1  next_temperatures :  [-1.21826961  1.0052932  -0.55081227  0.73950724 -1.57902129  1.70456601\n",
      " -0.96206346  1.49799139 -1.7901704 ]  energy_before :  40  energy_after :  70  reward :  -229.15297918181804\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "action : 1  next_temperatures :  [-0.03314896  0.42058577 -0.72105728  1.31940122  0.69741478  0.06887909\n",
      "  0.41347746  0.0398728   0.54640924]  energy_before :  70  energy_after :  50  reward :  -175.24816588218957\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "action : 1  next_temperatures :  [-2.42622095  0.63587203 -1.47803954  0.48641792 -1.87811508  1.34711158\n",
      " -2.52851576  1.69839632 -2.28621922]  energy_before :  50  energy_after :  350  reward :  -504.4293126932996\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "action : 1  next_temperatures :  [ 0.03638089  0.76843643  0.02224458  0.87137579 -0.38264613  0.97019687\n",
      "  0.31557419  1.0150232   0.0042794 ]  energy_before :  350  energy_after :  140  reward :  15.620865208593642\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "action : 1  next_temperatures :  [ 0.72856606  2.45617183  0.81722795  0.2071187  -0.35772165  1.87663577\n",
      " -0.41870032  1.87499836  0.59429738]  energy_before :  140  energy_after :  70  reward :  -120.22140591246611\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "action : 1  next_temperatures :  [-0.01239378  4.05448385  0.33081365  0.33898724 -0.2829482   1.82030341\n",
      "  0.15077035  0.57658944 -1.07696847]  energy_before :  70  energy_after :  90  reward :  -212.1003625076775\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "action : 1  next_temperatures :  [-0.18466176 -0.45982614  0.05568556 -0.69548464 -0.81467049  0.58816104\n",
      "  0.07081602  0.15351237 -0.22612579]  energy_before :  90  energy_after :  40  reward :  -149.51259383803117\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "action : 1  next_temperatures :  [ 0.10591073  1.10665366  0.20464994  0.75670749  0.45592423  1.54427484\n",
      "  0.31557419  0.35468513 -0.3806328 ]  energy_before :  40  energy_after :  60  reward :  -213.53625257850285\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "action : 1  next_temperatures :  [-1.8596046  -0.56788812 -1.6604449  -0.05416122 -0.98581861 -0.29267225\n",
      " -1.69633798 -0.40009664 -1.00950342]  energy_before :  60  energy_after :  90  reward :  -236.5265277230888\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "action : 1  next_temperatures :  [-0.86958262 -0.30987968 -0.61161406 -0.67746534 -1.1303806  -0.59993967\n",
      " -0.90821667 -0.40700715 -1.0799803 ]  energy_before :  90  energy_after :  100  reward :  -214.5940660965249\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "action : 1  next_temperatures :  [-1.54827693  1.66874348 -0.83962076  1.55406171 -1.23506343  1.85819973\n",
      " -1.29982974  2.0669571  -1.19382757]  energy_before :  100  energy_after :  60  reward :  -156.96865642371944\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "action : 1  next_temperatures :  [0.31968906 1.13848587 0.5740208  1.01716834 0.21554145 0.83704765\n",
      " 0.19809027 1.42735058 0.10728407]  energy_before :  60  energy_after :  90  reward :  -222.16532190883774\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "action : 1  next_temperatures :  [-0.61429393 -1.22128612 -1.34579565 -0.24254485 -0.93596964 -0.69928947\n",
      " -0.59818965 -1.12877202 -0.59206344]  energy_before :  90  energy_after :  100  reward :  -215.3782047700143\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "action : 1  next_temperatures :  [0.74932124 1.41743656 0.3460141  1.86243753 1.41191661 0.90874338\n",
      " 1.09880034 1.1378768  1.57645596]  energy_before :  100  energy_after :  50  reward :  -137.49099749180303\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "action : 1  next_temperatures :  [ 0.0083614  -0.36935565 -0.56601272  0.31441547  0.07928761 -0.06529435\n",
      "  0.11976765 -0.40700715 -0.03186259]  energy_before :  50  energy_after :  40  reward :  -188.91770034385766\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "action : 1  next_temperatures :  [-0.18466176 -1.04788434 -0.74841808 -0.36540375 -0.08355234 -0.91642512\n",
      " -0.24410616 -0.97597286 -0.59206344]  energy_before :  40  energy_after :  100  reward :  -263.15848784601246\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "action : 1  next_temperatures :  [-1.672808    0.45995719 -0.93538358  0.21367117 -1.18521446  1.21601081\n",
      " -1.15297484  0.63648056 -0.97697563]  energy_before :  100  energy_after :  50  reward :  -151.39723678008065\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "action : 1  next_temperatures :  [1.44046866 0.83691757 0.6758638  1.40212621 1.37868396 0.35566202\n",
      " 1.29460687 0.86683105 1.90173387]  energy_before :  50  energy_after :  40  reward :  -177.84710598911778\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n",
      "action : 1  next_temperatures :  [ 0.83856851 -0.00914907  0.9342714  -0.23435426 -0.48732896  0.87494397\n",
      "  0.01696922  0.76086983  0.7036269 ]  energy_before :  40  energy_after :  80  reward :  -234.6015824650626\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "action : 1  next_temperatures :  [1.97387673 1.93680419 1.98766237 1.39311656 1.86055729 1.40405847\n",
      " 2.15825356 1.34201121 2.33001645]  energy_before :  80  energy_after :  40  reward :  -141.61364317509396\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "action : 1  next_temperatures :  [-1.65205282  0.21786485 -0.87306175 -0.05416122 -1.48430825  1.02857768\n",
      " -0.89189946  0.56967892 -1.19382757]  energy_before :  40  energy_after :  60  reward :  -222.3331896102461\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "action : 1  next_temperatures :  [ 0.0083614  -1.16432321  0.5740208  -1.7668142   0.06100966 -1.36810823\n",
      "  0.76662853 -1.17440335  0.27534432]  energy_before :  60  energy_after :  60  reward :  -201.78828428929347\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "action : 1  next_temperatures :  [-1.54827693  0.93995341 -0.93538358  0.92870994 -1.23506343  1.41983153\n",
      " -1.48421423  1.22080297 -1.35104523]  energy_before :  60  energy_after :  70  reward :  -210.04468554990814\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "action : 1  next_temperatures :  [ 0.195158   -0.71867227 -0.93538358  0.5331043   0.49469565 -0.51697747\n",
      " -0.27674059  0.12970949 -0.04993359]  energy_before :  70  energy_after :  100  reward :  -229.14504005940148\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "action : 1  next_temperatures :  [ 0.195158   -0.99762296 -0.09479886 -0.71759925  0.21554145 -1.54017799\n",
      "  0.41347746 -1.06580955  0.43256198]  energy_before :  100  energy_after :  80  reward :  -181.1592697258478\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "action : 1  next_temperatures :  [ 0.12666591  1.10665366  0.23505084  0.75670749  0.38447405  1.45226532\n",
      "  0.31557419  0.3078472  -0.3806328 ]  energy_before :  80  energy_after :  710  reward :  -823.695394145897\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n",
      "action : 1  next_temperatures :  [ 0.195158   -1.12327642 -0.61161406 -0.52348219  0.46478627 -0.62759374\n",
      "  0.56033236 -1.27312499  0.54640924]  energy_before :  710  energy_after :  80  reward :  429.6075944754337\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "action : 1  next_temperatures :  [-0.5167446  -0.84432573 -0.29240467 -0.72578984 -0.23808413 -1.275928\n",
      " -0.12499052 -0.9967044  -0.10956787]  energy_before :  80  energy_after :  50  reward :  -173.12453977728637\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "action : 1  next_temperatures :  [1.30971104 1.91083581 2.71532948 0.3203829  2.02339724 0.95790617\n",
      " 1.73027642 1.1071634  1.57645596]  energy_before :  50  energy_after :  100  reward :  -234.3485415837121\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "action : 1  next_temperatures :  [-1.19958995 -0.84432573 -0.80921987 -1.07143286 -1.2799275  -0.86462861\n",
      " -0.48723261 -0.73564052 -1.1016655 ]  energy_before :  100  energy_after :  50  reward :  -156.39366314304345\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "action : 1  next_temperatures :  [1.99463191 1.13848587 1.10299636 1.20555198 1.74091977 0.89747691\n",
      " 1.71395921 1.30680049 2.22701178]  energy_before :  50  energy_after :  40  reward :  -174.67216572949522\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "action : 1  next_temperatures :  [ 0.68705571 -0.24370219  0.11800739 -0.03204662  1.11282282 -0.42602631\n",
      "  0.9960019  -0.40009664  0.43256198]  energy_before :  40  energy_after :  50  reward :  -205.75542195354132\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "action : 1  next_temperatures :  [-1.2992148   0.45409336 -0.61161406  0.05804991 -0.59865831  2.01183344\n",
      " -0.8103134   0.13969134 -0.24871453]  energy_before :  50  energy_after :  50  reward :  -198.90484705737722\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "action : 1  next_temperatures :  [ 0.88007886 -0.24370219  0.30041276 -0.29356055  1.00813999 -0.6420792\n",
      "  1.15876609 -0.50893724  0.86084456]  energy_before :  50  energy_after :  70  reward :  -215.48003693187172\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "action : 1  next_temperatures :  [-1.49223795  1.23230712 -0.70737688  0.87956638 -1.37962543  1.46182475\n",
      " -0.48886433  0.69099685 -0.97697563]  energy_before :  70  energy_after :  40  reward :  -168.7803851225677\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "action : 1  next_temperatures :  [ 0.195158    0.27273353  0.16360874  0.37994021  0.39001283 -0.12213882\n",
      "  0.26172739  0.33932843  0.54640924]  energy_before :  40  energy_after :  100  reward :  -255.57322045913074\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n",
      "action : 1  next_temperatures :  [-0.30296627 -1.14589404 -0.33800601 -0.84045814 -0.2829482  -1.12229429\n",
      " -0.36974869 -0.88152916 -0.16378086]  energy_before :  100  energy_after :  300  reward :  -403.44762566155396\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n",
      "action : 1  next_temperatures :  [ 0.4172384   0.12739436  0.39161544  0.10801252  0.80874413 -0.88467415\n",
      "  0.26172739  0.28058906  0.64941392]  energy_before :  300  energy_after :  70  reward :  34.16006106826413\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "action : 1  next_temperatures :  [-0.55825495  0.78916925 -0.64505504  1.46928907 -0.33279717  0.26040912\n",
      " -0.61450686  0.86683105 -0.19630865]  energy_before :  70  energy_after :  90  reward :  -216.9612241767299\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "action : 1  next_temperatures :  [-0.61429393  0.21954023 -1.11778894  1.23831435  0.27702184 -0.06529435\n",
      " -0.36974869 -0.20583439  0.31406788]  energy_before :  90  energy_after :  40  reward :  -148.32401601015678\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "action : 1  next_temperatures :  [-0.30296627  0.57053223 -0.41704834  0.63384859 -0.58204199  0.62913003\n",
      "  0.42816295 -0.19047769 -0.59206344]  energy_before :  40  energy_after :  40  reward :  -197.822923929964\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "action : 1  next_temperatures :  [-1.672808    0.96257103 -0.91258291  0.8590899  -1.21844711  1.7783102\n",
      " -1.1040232   1.17473287 -1.29683224]  energy_before :  40  energy_after :  50  reward :  -209.42998946663303\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "action : 1  next_temperatures :  [-0.20541693  0.53786233  0.28217222  0.19155657 -0.86451946  0.78276374\n",
      " -0.47254712  0.86145621 -0.11559154]  energy_before :  50  energy_after :  60  reward :  -207.002263976509\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "action : 1  next_temperatures :  [-0.18466176 -0.49500911 -0.75981842  0.35680178  0.26040552 -0.32032631\n",
      " -0.45459819 -0.0061973   0.16149705]  energy_before :  60  energy_after :  60  reward :  -199.4419067379744\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "action : 1  next_temperatures :  [ 1.75179633 -0.88704791  2.14270693 -1.58744022  1.21252075 -1.64157624\n",
      "  2.02888139 -0.83545906  2.44386372]  energy_before :  60  energy_after :  140  reward :  -273.37175432381287\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "action : 1  next_temperatures :  [-0.28428661 -0.73710145 -0.74841808 -0.15490551 -0.43747999 -0.50775944\n",
      " -0.71730529 -0.66807104 -0.46737357]  energy_before :  140  energy_after :  70  reward :  -132.72270098899622\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "action : 1  next_temperatures :  [ 0.68705571  0.23629403 -0.18904163  1.22357128  1.05798895 -0.13903853\n",
      "  0.16871929  0.54664387  0.76326118]  energy_before :  70  energy_after :  420  reward :  -543.6445458507094\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "action : 1  next_temperatures :  [ 0.33836872 -1.13835483 -0.25136347 -0.60293094 -0.08355234 -1.28514603\n",
      "  0.05286708 -1.01973945 -0.53785045]  energy_before :  420  energy_after :  60  reward :  157.4722982913838\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "action : 1  next_temperatures :  [ 0.25742353 -0.39197328 -0.47937017  0.48641792  0.01116069 -0.3817798\n",
      " -0.03198241 -0.48993333  0.43256198]  energy_before :  60  energy_after :  80  reward :  -218.58747487202015\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "action : 1  next_temperatures :  [ 0.21591317 -0.29396358 -0.32280557  0.37912115  1.00813999 -0.89594062\n",
      "  0.50648556 -0.86079762  0.54640924]  energy_before :  80  energy_after :  50  reward :  -167.71743826124873\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "action : 1  next_temperatures :  [-0.9256216  -0.34171189 -0.47937017 -0.92318313 -1.76346246  0.08833936\n",
      " -1.54458791 -0.0061973  -0.7384385 ]  energy_before :  50  energy_after :  70  reward :  -224.63423359794632\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "action : 1  next_temperatures :  [-1.19958995  0.33430373 -0.82442032  0.625658   -0.85265066 -0.12938156\n",
      " -1.64249118  0.50748429 -0.6873234 ]  energy_before :  70  energy_after :  100  reward :  -231.86841104025928\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "action : 1  next_temperatures :  [-0.42749733 -1.69876926 -0.62833455 -1.59399269  0.21554145 -1.33430881\n",
      " -0.32079706 -1.72614762 -0.32099851]  energy_before :  100  energy_after :  110  reward :  -215.83530439892124\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "action : 1  next_temperatures :  [ 0.9423444   2.14538894  0.78682706  1.54873782  1.02641794  1.56424722\n",
      "  1.09880034 -0.16129996  1.02239925]  energy_before :  110  energy_after :  50  reward :  -128.02613699403665\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "action : 1  next_temperatures :  [-0.40674216  0.16090195 -0.43376883  0.61746741 -0.23808413 -0.25887283\n",
      " -0.52149876  0.16023093 -0.10956787]  energy_before :  50  energy_after :  50  reward :  -199.02993429462722\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "action : 1  next_temperatures :  [-0.98788713 -0.24370219 -0.74841808 -0.32690796 -1.2799275   0.26040912\n",
      " -0.56555523 -0.12137255 -1.19382757]  energy_before :  50  energy_after :  490  reward :  -643.207189093022\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "action : 1  next_temperatures :  [-1.18091029 -1.13081562 -0.53561182 -1.13777666 -1.32977646 -1.20320805\n",
      " -0.22778895 -0.98979389 -0.86312836]  energy_before :  490  energy_after :  90  reward :  193.4011898880911\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "action : 1  next_temperatures :  [ 0.4172384   1.28256851  0.70626469  0.73213571 -0.14515142  2.00590757\n",
      "  0.26172739  1.30526482  0.54640924]  energy_before :  90  energy_after :  50  reward :  -150.88763509484104\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "action : 1  next_temperatures :  [-0.67655947 -0.64579327 -0.23616302 -0.71104677 -0.43747999 -0.85292318\n",
      " -0.07603889 -0.57861827 -0.28485652]  energy_before :  50  energy_after :  60  reward :  -212.4994793744669\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "action : 1  next_temperatures :  [-0.86958262 -1.5002368  -1.32907516 -0.79131458  0.01116069 -1.24212859\n",
      " -0.56555523 -1.45740538 -0.48363747]  energy_before :  60  energy_after :  50  reward :  -196.22777512996856\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "action : 1  next_temperatures :  [ 0.58950637  0.61157903 -0.09479886  0.93608147  1.00813999  0.00537716\n",
      "  0.36452582 -0.09340141  0.66748491]  energy_before :  50  energy_after :  120  reward :  -264.00550552523777\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "action : 1  next_temperatures :  [ 0.43799358 -0.39197328  1.08931596 -0.96331703  0.01116069 -0.41250654\n",
      "  0.16871929 -0.38320427  0.05849238]  energy_before :  120  energy_after :  40  reward :  -118.38531922870521\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step\n",
      "action : 1  next_temperatures :  [1.87632739 2.34643447 3.09942306 0.99259656 1.44182598 2.17898692\n",
      " 2.32259119 1.33839141 2.27580346]  energy_before :  40  energy_after :  500  reward :  -640.127619543014\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "action : 1  next_temperatures :  [ 0.35704838  1.13094667  0.30041276  1.01716834 -0.22146781  1.50074529\n",
      "  0.75124373  1.46804583 -0.53785045]  energy_before :  500  energy_after :  130  reward :  177.76629273566206\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n",
      "action : 1  next_temperatures :  [-0.67655947 -0.5452705  -0.93538358 -0.15490551 -0.63189095  0.3218626\n",
      " -0.40238311 -0.27647521 -0.70591071]  energy_before :  130  energy_after :  50  reward :  -122.00691643444111\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "action : 1  next_temperatures :  [-0.05390414 -0.78544811 -0.12954274 -0.71759925 -0.72233122 -0.55736118\n",
      " -0.14334738 -0.96013626 -0.92276265]  energy_before :  50  energy_after :  60  reward :  -212.99243293165173\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "action : 1  next_temperatures :  [-0.69731464  1.45932104 -0.20576213  1.02453987 -1.03068267  1.89199914\n",
      " -0.0923561   1.60625612 -0.48363747]  energy_before :  60  energy_after :  490  reward :  -624.5276368266656\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "action : 1  next_temperatures :  [ 0.68705571 -0.81165583  0.44785709 -0.77657151  0.46478627 -0.73104044\n",
      "  0.97642125 -0.98426548  0.54640924]  energy_before :  490  energy_after :  60  reward :  231.8189963055555\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "action : 1  next_temperatures :  [ 1.65718506 -0.60323428  1.43117796 -1.11010948  1.29577499 -0.70241535\n",
      "  1.60694373 -0.17013505  0.96553898]  energy_before :  60  energy_after :  60  reward :  -193.6292734370366\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "action : 1  next_temperatures :  [ 0.64969639 -0.89458712  0.3460141  -0.69548464  0.31025448 -0.59993967\n",
      " -0.0466679   0.12279897  0.3295573 ]  energy_before :  60  energy_after :  110  reward :  -248.47835808925174\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "action : 1  next_temperatures :  [-1.36148033 -0.9038017  -1.6604449  -0.11968596 -1.18521446 -0.62759374\n",
      " -1.02570059 -1.10496913 -1.15407138]  energy_before :  110  energy_after :  140  reward :  -237.14296220614133\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "action : 1  next_temperatures :  [-0.49598942 -0.31909427  0.02224458 -0.80933389 -0.78143785 -0.05607633\n",
      "  0.16871929 -0.45307725 -0.75470239]  energy_before :  140  energy_after :  50  reward :  -111.4787475329149\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "action : 1  next_temperatures :  [-0.18466176 -0.06527428  0.0876065  -0.34902256 -0.50228365  1.0623771\n",
      " -0.36974869  0.68485417 -0.67880421]  energy_before :  50  energy_after :  100  reward :  -248.31495738332953\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "action : 1  next_temperatures :  [-0.42749733 -0.24370219 -0.79401942  0.64122012 -0.23808413 -0.56614025\n",
      " -0.48886433 -0.15285378 -0.16378086]  energy_before :  100  energy_after :  470  reward :  -570.433722181857\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n",
      "action : 1  next_temperatures :  [ 1.54424455  2.06078227  2.98633174 -0.21036752  2.70798969  1.08286159\n",
      "  1.78412322  1.26073039  1.59452695]  energy_before :  470  energy_after :  60  reward :  226.81122287465908\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "action : 1  next_temperatures :  [1.41763796 1.90162122 0.58922125 2.51522779 1.75587446 1.15455732\n",
      " 1.25870901 1.47572418 1.7878866 ]  energy_before :  60  energy_after :  60  reward :  -184.14354019775809\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "action : 1  next_temperatures :  [-0.61429393 -1.1735378  -0.74841808 -0.76919998 -1.23506343 -0.66139315\n",
      " -1.20682164 -0.81242401 -0.48363747]  energy_before :  60  energy_after :  70  reward :  -215.70478949979267\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "action : 1  next_temperatures :  [1.97387673 1.91083581 1.96160446 1.4047004  1.86055729 1.39729859\n",
      " 2.12678465 1.31923941 2.33001645]  energy_before :  70  energy_after :  80  reward :  -191.7150862096885\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "action : 1  next_temperatures :  [ 0.9423444   1.56822071  1.08931596  0.79684139  0.16569248  1.76362964\n",
      " -0.03198241  2.20439956  1.17407514]  energy_before :  80  energy_after :  20  reward :  -128.32746314399088\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "action : 1  next_temperatures :  [ 0.195158    0.49514016  0.07240605  0.80585104  0.46478627 -0.04685831\n",
      "  0.52443449  0.31629338  0.63315002]  energy_before :  20  energy_after :  50  reward :  -224.53963888576695\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "action : 1  next_temperatures :  [-0.738825   -1.2715475  -1.49323998 -0.16227704 -0.93596964 -0.68904722\n",
      " -0.6634585  -1.15794975 -0.68783971]  energy_before :  50  energy_after :  100  reward :  -255.80015434529867\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "action : 1  next_temperatures :  [ 0.5687512  -0.14066635  0.02224458  0.3881308   0.21554145  0.0483946\n",
      "  0.36452582 -0.12137255  0.63547343]  energy_before :  100  energy_after :  310  reward :  -406.0189770227316\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "action : 1  next_temperatures :  [ 0.31968906 -0.76893366  0.86130925 -1.20903482 -0.03370338 -0.87340768\n",
      "  0.49016835 -0.84390525 -0.26678553]  energy_before :  310  energy_after :  50  reward :  59.67539635559049\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "action : 1  next_temperatures :  [-0.18466176  1.42581345  0.25025128  1.10890298 -0.29956452  1.62928549\n",
      " -0.52149876  1.9725134  -0.53785045]  energy_before :  50  energy_after :  50  reward :  -193.1568088733831\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "action : 1  next_temperatures :  [-0.49598942  1.62685899 -0.58121317  0.73049759 -0.83128681  0.73257673\n",
      " -0.8103134   0.12279897 -0.81795088]  energy_before :  50  energy_after :  110  reward :  -258.32402139758403\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "action : 1  next_temperatures :  [ 0.74932124  0.00928011  0.43265665  0.15715608  0.29363816 -0.08475462\n",
      "  0.47385114 -0.0061973   0.85619773]  energy_before :  110  energy_after :  50  reward :  -135.11885081571592\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "action : 1  next_temperatures :  [ 0.63101673 -2.82965041  2.5804798  -4.81289572  0.50965034 -2.07175063\n",
      "  0.94705027 -2.32659456  0.87168715]  energy_before :  50  energy_after :  280  reward :  -434.5010070277089\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n",
      "action : 1  next_temperatures :  [-1.18091029 -0.50254832  0.11800739 -1.03867049 -1.09714796 -0.64807823\n",
      "  0.45753393 -0.72873    -0.97697563]  energy_before :  280  energy_after :  100  reward :  -23.597519600437266\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "action : 1  next_temperatures :  [-1.11864475  1.95188261 -0.59641361  1.15640842 -1.08053164  1.83054566\n",
      " -0.85926503  1.46804583 -0.86312836]  energy_before :  100  energy_after :  30  reward :  -126.11110088353303\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "action : 1  next_temperatures :  [ 0.61026155 -0.59301881  0.61962214 -0.67746534  0.31025448 -0.3817798\n",
      " -0.12499052  0.13815567  0.31148631]  energy_before :  30  energy_after :  680  reward :  -847.7874743109868\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "action : 1  next_temperatures :  [-0.24692729 -1.5245298  -0.15560065 -1.44000954 -0.73657378 -1.26466153\n",
      "  0.01696922 -1.27312499 -0.16378086]  energy_before :  680  energy_after :  50  reward :  425.2117607753015\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "action : 1  next_temperatures :  [ 2.37445166  0.62833282  2.18526818 -0.0484278   2.13971149 -0.01305889\n",
      "  2.30627398  0.56967892  2.17279879]  energy_before :  50  energy_after :  90  reward :  -225.68497084189693\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "action : 1  next_temperatures :  [ 0.12666591 -0.21605843  0.30041276 -0.4006233  -0.63189095  0.62913003\n",
      " -0.22778895  0.66181912  0.10728407]  energy_before :  90  energy_after :  50  reward :  -157.65104975408647\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "action : 1  next_temperatures :  [-0.61429393 -0.59301881 -1.14058961  0.0551832  -1.08053164 -0.35412573\n",
      " -0.71730529 -0.88152916 -0.75470239]  energy_before :  50  energy_after :  40  reward :  -194.080913377416\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "action : 1  next_temperatures :  [ 0.25742353 -0.69354158 -0.88978224  0.5027991   0.50965034 -0.53541351\n",
      " -0.27674059  0.12970949 -0.04993359]  energy_before :  40  energy_after :  60  reward :  -219.04582904316106\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "action : 1  next_temperatures :  [-0.98788713 -0.2512414  -0.97642479 -0.0705424  -1.00077329 -0.09499687\n",
      " -1.1040232  -0.61355476 -0.46918067]  energy_before :  60  energy_after :  50  reward :  -193.56862452059084\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "action : 1  next_temperatures :  [-0.11616967  1.07230838 -0.20576213  1.10808392 -0.48732896  0.60147596\n",
      "  0.54238343  0.0245161  -0.53785045]  energy_before :  50  energy_after :  70  reward :  -215.99834341405685\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n",
      "action : 1  next_temperatures :  [-0.82807226  1.20633874 -0.10999931  0.82059411 -1.11376428  1.95037995\n",
      " -0.53618425  1.704539   -0.9649283 ]  energy_before :  70  energy_after :  90  reward :  -215.87109660011535\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "action : 1  next_temperatures :  [-0.55825495  0.72047869 -0.66177553  1.38574502 -0.29956452  0.15901087\n",
      " -0.61450686  0.80002941 -0.16378086]  energy_before :  90  energy_after :  50  reward :  -157.23261873262626\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "action : 1  next_temperatures :  [-1.61054246 -1.39280309 -0.72105728 -1.66197461 -1.48430825 -1.19194157\n",
      " -0.97838068 -1.35758684 -1.29683224]  energy_before :  50  energy_after :  60  reward :  -219.6954270280358\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "action : 1  next_temperatures :  [ 0.83856851 -0.66924858  1.21243958 -1.75043302  0.46478627 -1.11102782\n",
      "  0.9960019  -1.11187965  0.76326118]  energy_before :  60  energy_after :  50  reward :  -188.36753162039312\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "action : 1  next_temperatures :  [ 0.31968906  0.86456133 -0.29240467  1.71500686  1.21252075  0.54002247\n",
      "  0.26172739  0.84609951  0.7036269 ]  energy_before :  50  energy_after :  340  reward :  -481.82915039954617\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "action : 1  next_temperatures :  [-1.42997242 -0.80411663 -1.47803954 -0.15490551 -1.18521446 -0.02150874\n",
      " -0.90821667 -0.56134198 -1.19382757]  energy_before :  340  energy_after :  40  reward :  94.26285648265434\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "action : 1  next_temperatures :  [ 1.44046866 -1.51699059  1.1622781  -1.7668142   0.66418213 -1.28514603\n",
      "  1.0498487  -1.37447921  1.19154376]  energy_before :  40  energy_after :  130  reward :  -288.43510866790814\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "action : 1  next_temperatures :  [-0.86958262 -1.1735378  -1.20443149 -0.68647499 -0.65016891 -0.98709662\n",
      " -0.61450686 -1.20632335 -0.70591071]  energy_before :  130  energy_after :  160  reward :  -236.09803335530728\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "action : 1  next_temperatures :  [-0.42749733 -0.52684132 -0.83962076 -0.02303696 -1.01572798 -0.3817798\n",
      " -0.45459819 -1.03663182 -0.46737357]  energy_before :  160  energy_after :  60  reward :  -103.1731077545769\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "action : 1  next_temperatures :  [ 0.25742353  1.14770046 -0.38360736  2.06720236  1.02475631  0.29420854\n",
      "  0.24541018  1.09027103  0.64941392]  energy_before :  60  energy_after :  30  reward :  -161.60722103844319\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "action : 1  next_temperatures :  [ 0.39648322  1.45764566  0.52841946  1.23995247 -0.13340131  1.78752822\n",
      "  0.44284844  1.51181242 -0.48363747]  energy_before :  30  energy_after :  60  reward :  -221.25234888038034\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "action : 1  next_temperatures :  [1.86476379 1.71038862 2.17006773 0.56364351 2.04547321 0.80485773\n",
      " 1.60775336 1.44365578 1.87701912]  energy_before :  60  energy_after :  350  reward :  -473.91237713894157\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "action : 1  next_temperatures :  [-0.42749733  1.29178309  0.02224458  1.22295699 -0.36602981  0.98043912\n",
      "  0.49016835  1.32062152 -0.29776438]  energy_before :  350  energy_after :  90  reward :  66.2369221256501\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "action : 1  next_temperatures :  [ 1.14989617 -1.69206775  0.88867006 -1.94864537  0.41493731 -1.21447452\n",
      "  1.09880034 -1.46585157  0.85361616]  energy_before :  90  energy_after :  60  reward :  -169.91511916886645\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "action : 1  next_temperatures :  [-1.74130008  1.13094667 -0.97642479  1.02453987 -1.1303806   1.76909217\n",
      " -2.13200752  1.83660661 -1.56789717]  energy_before :  60  energy_after :  150  reward :  -289.7868248376908\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "action : 1  next_temperatures :  [ 0.50648566  0.53786233 -0.06439797  0.86236613  1.37868396  0.36590427\n",
      "  1.09880034 -0.02923235  0.81747417]  energy_before :  150  energy_after :  60  reward :  -102.52605345549418\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "action : 1  next_temperatures :  [-1.80356562  0.88131512 -0.83962076  0.40287387 -1.46935356  1.1991111\n",
      " -1.05507157  0.80002941 -1.22996956]  energy_before :  60  energy_after :  90  reward :  -231.11425157115298\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "action : 1  next_temperatures :  [-2.54452546  0.73723249 -1.57380235  0.58900509 -1.87811508  1.36964452\n",
      " -2.57257223  1.67305777 -2.30248311]  energy_before :  90  energy_after :  60  reward :  -174.50255836302188\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "action : 1  next_temperatures :  [ 0.31968906 -1.09814572 -0.26504387 -0.94693585  0.57777726 -1.63133399\n",
      "  0.07081602 -1.29616004 -0.70591071]  energy_before :  60  energy_after :  50  reward :  -192.97524783918115\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "action : 1  next_temperatures :  [-1.09581406  0.68864648 -0.52041138  0.48641792 -1.23506343  1.5509323\n",
      " -0.68140743  0.79235106 -1.19382757]  energy_before :  50  energy_after :  30  reward :  -179.2081760985426\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "action : 1  next_temperatures :  [ 0.195158    0.47838636 -0.56601272  1.51597545  0.80874413 -0.12777206\n",
      "  0.65823563 -0.20314697  0.64941392]  energy_before :  30  energy_after :  70  reward :  -234.59101826627727\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "action : 1  next_temperatures :  [ 0.99838337 -1.29919126  1.34468346 -1.7004704   0.96327592 -1.32662713\n",
      "  1.48551825 -1.28080334  1.95594685]  energy_before :  70  energy_after :  20  reward :  -146.85928427120618\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "action : 1  next_temperatures :  [-0.11616967  0.0773424  -0.38360736  0.78783174  0.06100966 -0.37256178\n",
      " -0.0466679   0.06060434  0.25727332]  energy_before :  20  energy_after :  70  reward :  -247.6749452441647\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "action : 1  next_temperatures :  [-0.67655947 -0.76893366 -1.11778894 -0.09593324 -0.61527463 -0.49649297\n",
      " -1.0110151  -0.65117867 -0.59206344]  energy_before :  70  energy_after :  620  reward :  -754.0252401204302\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "action : 1  next_temperatures :  [-0.5167446  -0.66170937 -0.33800601 -1.09436652 -0.34941349 -0.55692223\n",
      " -0.17394215 -1.25239345 -0.86312836]  energy_before :  620  energy_after :  120  reward :  296.19337381275795\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "action : 1  next_temperatures :  [-0.11616967  1.55146691  0.21985039  1.00979681 -0.33279717  1.19347786\n",
      "  0.41347746  1.42197573 -0.50532266]  energy_before :  120  energy_after :  90  reward :  -163.14424433358656\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "action : 1  next_temperatures :  [-0.3652318   0.77074008  0.07240605  0.57651444 -0.78143785  1.71583249\n",
      " -0.63082407  1.35287059 -0.82999821]  energy_before :  90  energy_after :  70  reward :  -176.11912828508514\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "action : 1  next_temperatures :  [-1.18091029 -0.81919504 -1.29563417 -0.1712867  -1.23506343 -0.81502687\n",
      "  0.3318914  -1.22705489 -1.19382757]  energy_before :  70  energy_after :  130  reward :  -265.6061075581264\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "action : 1  next_temperatures :  [-1.49223795  0.45995719 -0.77881898  0.22268083 -1.00077329  1.34916003\n",
      " -1.0110151   0.52130532 -0.70591071]  energy_before :  130  energy_after :  60  reward :  -130.43565267154545\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "action : 1  next_temperatures :  [-0.738825    0.03273542 -0.97642479  0.3037677  -1.03068267 -0.35412573\n",
      " -0.90984839 -0.43848839 -1.13419329]  energy_before :  60  energy_after :  50  reward :  -193.2460851369643\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "action : 1  next_temperatures :  [ 0.195158   -0.29396358 -0.47937017  0.60927681  0.31025448 -0.07451237\n",
      " -0.03198241  0.10897794  0.22113133]  energy_before :  50  energy_after :  430  reward :  -577.4350299669459\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "action : 1  next_temperatures :  [-0.49598942  0.16090195 -1.20443149  1.59214797 -0.73657378 -0.32032631\n",
      " -0.0466679  -0.74562237 -0.53785045]  energy_before :  430  energy_after :  50  reward :  179.66558817913182\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "action : 1  next_temperatures :  [-0.55825495  0.78916925 -0.61161406  1.46928907 -0.33279717  0.26040912\n",
      " -0.61450686  0.87527724 -0.18004475]  energy_before :  50  energy_after :  260  reward :  -406.90307311333356\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "action : 1  next_temperatures :  [ 1.68330424 -0.44223466  1.21243958 -0.66845569  2.05496825 -0.32032631\n",
      "  1.88447407 -0.6770931   2.05895152]  energy_before :  260  energy_after :  60  reward :  8.786027893738265\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "action : 1  next_temperatures :  [-0.80731709 -1.12076335 -0.70737688 -1.15251973 -1.15388083 -0.72460245\n",
      " -0.53618425 -0.96599101 -1.13419329]  energy_before :  60  energy_after :  60  reward :  -206.30282886394437\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "action : 1  next_temperatures :  [ 1.19140653  0.11817977  0.30041276  0.77308867  1.04137263 -0.41250654\n",
      " -0.17394215  0.14506619  0.09102017]  energy_before :  60  energy_after :  140  reward :  -274.9259019728079\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "action : 1  next_temperatures :  [-0.80731709  1.45764566 -0.70737688  0.60927681 -1.14865856 -0.24965481\n",
      " -0.97838068 -0.27570737 -1.0799803 ]  energy_before :  140  energy_after :  80  reward :  -141.18015320322178\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "action : 1  next_temperatures :  [1.93236637 2.13617435 2.13085058 1.454546   2.25934901 1.54376273\n",
      " 1.97503459 1.49108088 2.38965073]  energy_before :  80  energy_after :  50  reward :  -150.68718475762918\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "action : 1  next_temperatures :  [ 1.37197657 -0.06527428  2.25671028 -1.47932439  1.05798895 -0.48071991\n",
      "  1.58831668 -0.19047769  0.43256198]  energy_before :  50  energy_after :  60  reward :  -203.50824180445562\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "action : 1  next_temperatures :  [-0.98788713  1.24906092 -0.52041138  1.07368343 -0.88113578  1.58473172\n",
      " -0.6634585   1.66614725 -1.13118146]  energy_before :  60  energy_after :  60  reward :  -196.61045092116953\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "action : 1  next_temperatures :  [-0.55825495 -0.43469545 -0.52041138 -0.4006233  -0.20485149 -0.79249392\n",
      "  0.18340478 -1.00668626 -0.93050736]  energy_before :  60  energy_after :  70  reward :  -212.66511933612958\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "action : 1  next_temperatures :  [ 0.1723273  -0.09040497 -0.00815632  0.03429719 -0.43747999  0.41404283\n",
      " -0.77727105  0.42513399 -0.75470239]  energy_before :  70  energy_after :  50  reward :  -179.02221340630268\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "action : 1  next_temperatures :  [-0.40674216 -0.6432802  -0.66177553 -0.26875475 -0.03702664 -0.21995229\n",
      " -0.56555523 -1.1372182  -0.48363747]  energy_before :  50  energy_after :  60  reward :  -212.42394246844273\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "action : 1  next_temperatures :  [1.93236637 1.91083581 1.25804092 2.28015777 1.86055729 1.18703988\n",
      " 1.94006914 1.52991139 2.33001645]  energy_before :  60  energy_after :  140  reward :  -261.7710049848055\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "action : 1  next_temperatures :  [-0.11616967 -0.19092774 -1.06762747  1.05894036  0.63094949 -0.32032631\n",
      "  0.07081602 -0.30565294  0.54640924]  energy_before :  140  energy_after :  80  reward :  -137.69358901154482\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "action : 1  next_temperatures :  [ 0.43799358 -0.11804873  0.16360874  0.35454937 -0.03370338 -0.29267225\n",
      " -0.22778895 -0.48993333  0.39641999]  energy_before :  80  energy_after :  120  reward :  -237.80957496398844\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "action : 1  next_temperatures :  [-0.55825495  0.86456133 -0.02335676  0.21367117 -0.65016891  0.90874338\n",
      " -0.58187244  1.1071634  -0.10956787]  energy_before :  120  energy_after :  50  reward :  -126.82908165332924\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n",
      "action : 1  next_temperatures :  [ 1.87632739 -2.05311202  0.98443287 -2.12064782  0.86357799 -1.79520995\n",
      "  1.68132478 -1.94881976  2.44386372]  energy_before :  50  energy_after :  30  reward :  -178.06826279785415\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "action : 1  next_temperatures :  [ 0.68705571 -0.85270263  0.11800739 -0.52921561  0.80874413 -0.57740673\n",
      "  0.80509053 -1.01359677 -0.05174069]  energy_before :  30  energy_after :  60  reward :  -228.60576466247906\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "action : 1  next_temperatures :  [ 0.88007886 -0.3249581  -0.20576213  0.34553972  0.55949931 -0.53541351\n",
      " -0.0923561   0.41611193  0.05849238]  energy_before :  60  energy_after :  40  reward :  -176.89876763343608\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "action : 1  next_temperatures :  [ 0.63101673 -0.19092774  1.03003421 -0.74217102  0.50965034 -0.35412573\n",
      "  1.22444286 -0.25190449  0.54640924]  energy_before :  40  energy_after :  60  reward :  -215.5975755923284\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "action : 1  next_temperatures :  [-0.11616967 -0.21605843  1.21129954 -0.68872741  0.06100966 -0.81502687\n",
      "  0.84704907 -0.44616674  0.3295573 ]  energy_before :  60  energy_after :  30  reward :  -167.83323352907829\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "action : 1  next_temperatures :  [-0.3652318  -0.96997919 -1.25003283 -0.09593324  0.01116069 -0.93486116\n",
      " -0.27674059 -1.38830024 -0.59206344]  energy_before :  30  energy_after :  40  reward :  -213.86198179937946\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "action : 1  next_temperatures :  [ 0.63101673 -0.10715877 -0.05071757  0.43727436  1.05798895 -0.55507863\n",
      "  0.82140774 -0.30565294  0.05849238]  energy_before :  40  energy_after :  390  reward :  -546.0124277286404\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "action : 1  next_temperatures :  [ 0.37572804 -0.26631982 -0.15560065  0.19155657 -0.08355234 -0.22814609\n",
      "  0.73492652 -0.40009664  0.10728407]  energy_before :  390  energy_after :  70  reward :  122.27577967219042\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "action : 1  next_temperatures :  [-0.80731709 -1.02191596 -0.70737688 -1.11975736 -1.18521446 -0.71977397\n",
      " -0.47254712 -0.79706731 -1.158047  ]  energy_before :  70  energy_after :  50  reward :  -185.98901714693352\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "action : 1  next_temperatures :  [-2.54452546  0.98183789 -1.55708186  0.69036368 -2.01270728  1.24366488\n",
      " -1.63106913  1.55250768 -2.27808727]  energy_before :  50  energy_after :  50  reward :  -203.55509687787483\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "action : 1  next_temperatures :  [2.12538953 2.04570386 1.34468346 2.31308396 2.15965108 1.61545846\n",
      " 2.12678465 1.53715098 2.44386372]  energy_before :  50  energy_after :  230  reward :  -360.2882303091977\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "action : 1  next_temperatures :  [ 0.50648566  0.16090195  1.07563555 -0.47188146  0.41493731 -0.17795907\n",
      "  0.60928399  0.2310637   0.7036269 ]  energy_before :  230  energy_after :  90  reward :  -54.947905458977544\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "action : 1  next_temperatures :  [ 0.39648322  0.0997506   0.33081365 -0.52184407  0.06100966 -0.67061118\n",
      "  0.65823563 -0.46689828  0.78133218]  energy_before :  90  energy_after :  70  reward :  -177.3317285944421\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n",
      "action : 1  next_temperatures :  [-1.11864475  1.31691379 -0.47937017  1.04255918 -0.93596964  1.48947882\n",
      " -0.90821667  1.60625612 -1.0799803 ]  energy_before :  70  energy_after :  70  reward :  -197.0669736274077\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "action : 1  next_temperatures :  [-0.67655947  0.20865027 -0.25136347 -0.23435426 -0.63189095  0.19076184\n",
      " -0.7336225   0.33932843 -0.3806328 ]  energy_before :  70  energy_after :  50  reward :  -180.16968291832472\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "action : 1  next_temperatures :  [-0.05390414 -0.41040245 -0.10999931 -0.2597451  -0.68672482 -0.29267225\n",
      "  0.18340478 -0.45998776 -0.18004475]  energy_before :  50  energy_after :  30  reward :  -180.27007579868823\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "action : 1  next_temperatures :  [ 1.89293153 -0.47657994  2.1518272  -1.62921224  1.25738481 -1.45721578\n",
      "  1.91349539 -1.48208579  2.33001645]  energy_before :  30  energy_after :  50  reward :  -213.49943837108316\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "action : 1  next_temperatures :  [-0.49598942 -0.6432802  -0.33800601 -0.35147974 -0.0503197  -1.06084081\n",
      "  0.22256608 -0.88152916  0.12535506]  energy_before :  50  energy_after :  70  reward :  -221.47352389234567\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "action : 1  next_temperatures :  [-0.67655947 -0.05019586 -0.61161406  0.26527191 -0.78143785 -0.1666926\n",
      " -0.85926503  0.06060434 -0.3806328 ]  energy_before :  70  energy_after :  50  reward :  -181.20052142186432\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "action : 1  next_temperatures :  [ 0.12666591  1.9443434   0.43265665  1.2956485   0.07928761  2.00261542\n",
      "  0.04389262  1.87000743 -0.04993359]  energy_before :  50  energy_after :  150  reward :  -290.25481605252037\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "action : 1  next_temperatures :  [ 1.12914099  0.29493231  1.89645969 -0.92093072  1.11282282 -0.15747458\n",
      "  1.34355851  0.09362124  0.97469182]  energy_before :  150  energy_after :  50  reward :  -92.23317790935371\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "action : 1  next_temperatures :  [ 2.74804486  0.34351831  2.71272369 -0.57262575  3.45501204 -0.5279513\n",
      "  2.32259119  0.62167232  2.75107063]  energy_before :  50  energy_after :  60  reward :  -194.14594401377155\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "action : 1  next_temperatures :  [-0.30296627 -0.06527428 -0.06439797  0.00317293 -0.20485149 -0.42377301\n",
      " -0.47254712 -0.03767853 -0.10956787]  energy_before :  60  energy_after :  40  reward :  -179.6778836137445\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "action : 1  next_temperatures :  [ 5.06485663e-01 -3.16581200e-01  2.50251283e-01 -1.62277043e-01\n",
      "  4.64786273e-01 -5.35413511e-01  9.47050270e-01  7.13213916e-04\n",
      "  2.21131335e-01]  energy_before :  40  energy_after :  80  reward :  -236.62385371657427\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "action : 1  next_temperatures :  [-0.30296627  0.16006426  1.42220574 -1.09436652 -0.13340131 -0.83448714\n",
      "  0.66704692 -0.86079762  0.05849238]  energy_before :  80  energy_after :  40  reward :  -158.91820954151888\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "action : 1  next_temperatures :  [-0.49598942 -0.26631982 -1.02202613  0.63384859 -0.08355234 -0.81502687\n",
      "  0.31557419 -0.6649997   0.16149705]  energy_before :  40  energy_after :  60  reward :  -220.23699444154346\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "action : 1  next_temperatures :  [ 0.12666591 -0.38443407  0.39161544 -0.66108415  0.11584352 -0.53541351\n",
      "  0.21277576 -0.35172303  0.27534432]  energy_before :  60  energy_after :  40  reward :  -178.81040982238926\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n",
      "action : 1  next_temperatures :  [-0.24692729  0.36194749  0.12940773 -0.12173361  0.11584352  1.17299337\n",
      " -1.0110151   0.45450368 -0.26678553]  energy_before :  40  energy_after :  280  reward :  -437.4117657424169\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "action : 1  next_temperatures :  [ 0.29893389  0.59398754  0.07240605  0.3881308  -0.43747999  0.60147596\n",
      " -0.61450686  1.02116588 -0.72488525]  energy_before :  280  energy_after :  70  reward :  13.199228022216005\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "action : 1  next_temperatures :  [ 0.37572804 -1.11406183 -0.20576213 -0.55460645 -0.08355234 -1.30358207\n",
      "  0.05286708 -1.10496913 -0.53785045]  energy_before :  70  energy_after :  80  reward :  -212.47578927359316\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "action : 1  next_temperatures :  [-0.42749733  1.44131071 -0.25136347  1.43488858 -0.2829482   1.13407283\n",
      " -0.36974869  1.46689408 -0.59206344]  energy_before :  80  energy_after :  70  reward :  -184.44645493009443\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "action : 1  next_temperatures :  [-1.74130008  0.48760095 -0.97642479  0.21367117 -1.20183079  1.24366488\n",
      " -1.17092377  0.65337293 -1.02576732]  energy_before :  70  energy_after :  390  reward :  -521.5179368152158\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "action : 1  next_temperatures :  [-1.02939749  0.30247152 -0.93538358  0.28738651 -1.08053164  0.47549632\n",
      " -0.71730529 -0.14440759 -0.75470239]  energy_before :  390  energy_after :  60  reward :  128.40362635244227\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "action : 1  next_temperatures :  [-0.24692729 -0.29396358 -0.93538358  0.7141164  -0.03370338 -0.40226429\n",
      " -0.52149876 -0.06839193 -0.03186259]  energy_before :  60  energy_after :  50  reward :  -189.81987899716276\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "action : 1  next_temperatures :  [ 0.31968906  0.99021479  0.47825799  0.72312605 -0.18214252  1.52327823\n",
      "  0.11976765  1.58322108 -0.26678553]  energy_before :  50  energy_after :  30  reward :  -172.71137319058388\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "action : 1  next_temperatures :  [-0.24692729 -0.71867227 -0.72105728 -0.15490551 -0.43747999 -0.50775944\n",
      " -0.71730529 -0.69724877 -0.43484578]  energy_before :  30  energy_after :  60  reward :  -232.63620162806825\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n",
      "action : 1  next_temperatures :  [-1.36148033 -0.49249604 -1.6604449   0.28984369 -1.18521446 -0.76381563\n",
      " -0.85926503 -1.03586399 -1.13419329]  energy_before :  60  energy_after :  40  reward :  -186.20292999208812\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "action : 1  next_temperatures :  [-0.05390414 -0.19092774 -0.56601272  0.5027991   0.01116069 -0.12777206\n",
      " -0.32079706 -0.12137255  0.05849238]  energy_before :  40  energy_after :  50  reward :  -208.80833408007385\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "action : 1  next_temperatures :  [-0.67655947 -1.78337593 -0.52041138 -1.76763326 -1.23506343 -1.83822739\n",
      " -0.17394215 -1.36756869 -0.50170846]  energy_before :  50  energy_after :  50  reward :  -207.86449016486588\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "action : 1  next_temperatures :  [-0.16183106  0.33597911 -0.29240467  0.1809088  -0.18823517 -0.54565576\n",
      " -0.0923561   0.00762373  0.3295573 ]  energy_before :  50  energy_after :  110  reward :  -258.4264138160538\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "action : 1  next_temperatures :  [-1.672808    1.44256725 -0.88978224  1.26288613 -1.2799275   1.67691195\n",
      " -1.29982974  1.53715098 -1.29683224]  energy_before :  110  energy_after :  110  reward :  -198.51966341867762\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "action : 1  next_temperatures :  [-0.11616967 -1.16432321 -1.16339028  0.04166872 -0.2829482  -1.22369254\n",
      " -0.22778895 -1.18943098  0.0042794 ]  energy_before :  110  energy_after :  90  reward :  -183.3217957243872\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "action : 1  next_temperatures :  [ 0.06440038 -0.14066635 -0.1571207   0.42662659  0.32853244 -0.44630596\n",
      "  0.45753393 -0.16974615  0.16149705]  energy_before :  90  energy_after :  50  reward :  -157.4752487749806\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "action : 1  next_temperatures :  [-0.3652318  -1.74232913 -0.03361706 -1.85465831 -0.90855271 -1.53556898\n",
      "  0.01696922 -1.70311257 -0.3752115 ]  energy_before :  50  energy_after :  90  reward :  -246.50131284613926\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "action : 1  next_temperatures :  [ 0.12666591  0.46917177 -0.43376883  1.42014551  0.63094949 -0.23838833\n",
      "  0.10345044  0.53128717  0.60062223]  energy_before :  90  energy_after :  70  reward :  -174.78986463379712\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "action : 1  next_temperatures :  [ 0.81781333  0.66100272  0.28369227  1.0663119   1.44514925 -0.22814609\n",
      "  0.31557419  0.52130532  1.0704681 ]  energy_before :  70  energy_after :  40  reward :  -162.04682901459773\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "action : 1  next_temperatures :  [-1.672808    0.25891165 -0.88978224  0.01832553 -1.49926294  1.08081314\n",
      " -0.90821667  0.61574902 -1.19382757]  energy_before :  40  energy_after :  60  reward :  -222.19009807580545\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "action : 1  next_temperatures :  [ 0.25742353  0.12194938 -0.33800601  0.8549946   0.27702184  0.11804188\n",
      " -0.17394215 -0.100641    0.22113133]  energy_before :  60  energy_after :  60  reward :  -196.76202660950372\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "action : 1  next_temperatures :  [-0.28428661  0.34351831  0.11800739 -0.11149537  0.11584352  1.15455732\n",
      " -1.02570059  0.45450368 -0.26678553]  energy_before :  60  energy_after :  50  reward :  -187.5018378662905\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "action : 1  next_temperatures :  [ 1.56499973 -0.91134091  1.66845298 -2.51952969  0.66418213 -1.6108495\n",
      "  0.97968469 -1.61174021  1.14275208]  energy_before :  50  energy_after :  80  reward :  -228.63338869937795\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "action : 1  next_temperatures :  [-0.61429393 -0.88704791 -1.13298939 -0.08856171 -1.08053164 -0.79249392\n",
      " -0.61450686 -0.96752668 -0.43484578]  energy_before :  80  energy_after :  130  reward :  -254.61279782319284\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "action : 1  next_temperatures :  [-0.67655947 -1.07050196 -0.52041138 -1.01491777 -1.18521446 -0.86901814\n",
      " -0.84784298 -0.42082818 -1.28707391]  energy_before :  130  energy_after :  60  reward :  -135.8923682561125\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "action : 1  next_temperatures :  [-0.55825495 -0.62820178 -1.10106845  0.26527191  0.46478627 -0.81502687\n",
      " -0.6634585  -0.46689828 -0.10956787]  energy_before :  60  energy_after :  40  reward :  -181.61241852203642\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "action : 1  next_temperatures :  [-1.92187013 -0.56034891 -1.67564535 -0.03941815 -0.98581861 -0.29267225\n",
      " -1.74528961 -0.39165045 -1.02576732]  energy_before :  40  energy_after :  20  reward :  -186.6384807733591\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "action : 1  next_temperatures :  [ 0.12666591 -0.45144925  0.07240605 -0.98788881  0.11584352 -0.90720709\n",
      "  0.85404217 -0.86909023  0.85180906]  energy_before :  20  energy_after :  50  reward :  -229.19486868106446\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "action : 1  next_temperatures :  [ 0.31968906 -0.37689486 -0.38360736  0.21367117  1.25738481 -0.59993967\n",
      "  0.65124254 -0.83545906  0.63315002]  energy_before :  50  energy_after :  40  reward :  -187.12076334015418\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "action : 1  next_temperatures :  [ 0.03638089  1.35335329  0.47825799  0.96884384 -0.19100455  1.63696718\n",
      " -0.47254712  2.04392205 -0.51676763]  energy_before :  40  energy_after :  80  reward :  -232.66259406087138\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "action : 1  next_temperatures :  [ 1.48197902  0.18351957  1.19571908  0.17353727  1.44514925 -0.01305889\n",
      "  1.34355851  0.57658944  2.02642373]  energy_before :  80  energy_after :  40  reward :  -149.58658302395241\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "action : 1  next_temperatures :  [ 0.63101673 -0.36935565  0.43265665 -0.34165103  0.41493731 -0.57459011\n",
      "  0.9029938   0.01453424  0.27534432]  energy_before :  40  energy_after :  60  reward :  -216.61411374367174\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "action : 1  next_temperatures :  [1.0834796  1.12173208 0.87225357 0.94640162 1.05798895 0.48676279\n",
      " 1.29460687 0.9820063  1.73367361]  energy_before :  60  energy_after :  60  reward :  -188.42109460043795\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n",
      "action : 1  next_temperatures :  [ 0.74932124  0.11064057  0.25025128  0.57487632  0.41493731  0.07912134\n",
      " -0.41870032  0.52130532  0.49219626]  energy_before :  60  energy_after :  50  reward :  -185.22605068668778\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n",
      "action : 1  next_temperatures :  [-0.22617211  0.34351831 -0.25136347 -0.61112154  0.24545083 -0.36334375\n",
      " -1.20682164 -0.89842153 -1.19382757]  energy_before :  50  energy_after :  80  reward :  -232.16210246337477\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "action : 1  next_temperatures :  [ 2.22501438 -1.8998148   3.12769589 -3.01751774  1.41191661 -0.93486116\n",
      "  1.61891145 -0.98029193  1.14275208]  energy_before :  80  energy_after :  50  reward :  -165.30619523694435\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "action : 1  next_temperatures :  [-0.61429393 -0.87196949 -1.19075109 -0.03941815 -1.08053164 -0.75357338\n",
      " -0.61450686 -0.95063431 -0.46737357]  energy_before :  50  energy_after :  50  reward :  -204.583052430004\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "action : 1  next_temperatures :  [-0.9256216  -0.35092648 -0.88978224 -0.11968596 -0.84790314 -0.51492902\n",
      "  0.16871929 -0.44463107 -0.70591071]  energy_before :  50  energy_after :  100  reward :  -252.63067091612217\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "action : 1  next_temperatures :  [-0.09541449 -1.33018578  0.07240605 -1.52846795 -0.93596964 -1.02704139\n",
      "  0.07081602 -1.24394726 -0.86312836]  energy_before :  100  energy_after :  50  reward :  -154.88093280464844\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "action : 1  next_temperatures :  [-0.49598942 -0.83594884 -0.97642479 -0.05661839 -0.48732896 -0.88467415\n",
      " -0.58187244 -0.92759926 -0.70591071]  energy_before :  50  energy_after :  60  reward :  -213.95236694881223\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "action : 1  next_temperatures :  [ 0.25742353  0.38707818 -0.56601272  1.35257312  0.7140311  -0.18000752\n",
      "  0.62560121 -0.19892388  0.68813748]  energy_before :  60  energy_after :  170  reward :  -304.9200995089932\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "action : 1  next_temperatures :  [ 0.77215194 -1.55636201  0.28369227 -1.80121469  0.66418213 -1.97137661\n",
      "  0.80509053 -1.56369568  0.87168715]  energy_before :  170  energy_after :  50  reward :  -81.49584496965932\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "action : 1  next_temperatures :  [-0.24692729 -1.75740755 -0.02335676 -1.82332929 -0.78143785 -1.59241345\n",
      "  0.11976765 -1.71079092 -0.16378086]  energy_before :  50  energy_after :  390  reward :  -545.979676318438\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "action : 1  next_temperatures :  [-1.23694927 -0.99071202 -1.29563417 -0.4006233  -0.98581861 -0.9778786\n",
      " -1.25577327 -0.65117867 -0.51977946]  energy_before :  390  energy_after :  60  reward :  123.68565264107423\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "action : 1  next_temperatures :  [-0.30296627 -1.02024058 -1.19075109  0.06869768 -0.43747999 -1.11102782\n",
      " -0.03198241 -1.32149859 -0.28485652]  energy_before :  60  energy_after :  110  reward :  -253.63210560226514\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n",
      "action : 1  next_temperatures :  [-2.67528308 -0.77814824 -1.80180906 -0.80933389 -2.23204273 -0.62759374\n",
      " -2.23480595 -0.60510857 -1.89317508]  energy_before :  110  energy_after :  50  reward :  -151.65730033825093\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n",
      "action : 1  next_temperatures :  [ 0.81781333  1.86141212  0.98443287  0.30540581  0.16569248  1.62365226\n",
      " -0.71730529  0.83611766 -0.06649867]  energy_before :  50  energy_after :  270  reward :  -412.1892774355188\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "action : 1  next_temperatures :  [ 0.02704106 -0.63741637  0.02224458 -0.60293094 -0.59865831 -0.43299104\n",
      " -0.36974869 -0.34481252 -0.14028856]  energy_before :  270  energy_after :  230  reward :  -161.07756079904073\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "action : 1  next_temperatures :  [-1.11864475 -0.47657994 -0.97642479 -0.13688621 -0.84790314 -0.11650559\n",
      " -1.15297484 -0.08374863 -0.53785045]  energy_before :  230  energy_after :  80  reward :  -53.44751833266369\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "action : 1  next_temperatures :  [-0.18466176 -0.8878856  -0.47937017 -0.41536637 -0.48732896 -1.24212859\n",
      " -0.12499052 -1.22705489 -0.59206344]  energy_before :  80  energy_after :  60  reward :  -183.64085028762509\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "action : 1  next_temperatures :  [ 1.87632739  0.16090195  1.45564673 -0.3342795   1.61131247 -0.25887283\n",
      "  1.68132478  0.35545297  2.61811974]  energy_before :  60  energy_after :  140  reward :  -268.8340663001311\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "action : 1  next_temperatures :  [ 0.5687512   1.13094667  0.72298518  0.65596319  0.06100966  1.83054566\n",
      " -0.22778895  2.04392205 -0.44026708]  energy_before :  140  energy_after :  40  reward :  -91.65393242663714\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "action : 1  next_temperatures :  [-1.11864475 -0.84432573 -1.70604624  0.24070013 -0.98581861 -0.53541351\n",
      " -0.82663061 -0.97597286 -0.59206344]  energy_before :  40  energy_after :  50  reward :  -215.3442156232892\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "action : 1  next_temperatures :  [0.74932124 1.26413933 0.74209432 1.19022387 1.11282282 0.30803557\n",
      " 1.52141611 0.90752631 1.19154376]  energy_before :  50  energy_after :  50  reward :  -189.01287667036775\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "action : 1  next_temperatures :  [ 0.81781333  0.42058577  0.61962214  0.68299215  0.41493731  0.07912134\n",
      " -0.27674059  0.66181912  0.97469182]  energy_before :  50  energy_after :  440  reward :  -583.605157606297\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n",
      "action : 1  next_temperatures :  [-2.67528308  0.53786233 -1.76836807  0.5511236  -2.2769068   0.44784225\n",
      " -2.67537066  0.63648056 -2.16424   ]  energy_before :  440  energy_after :  60  reward :  172.61314013181095\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "action : 1  next_temperatures :  [-0.63504911 -1.15510863 -1.02202613 -0.76919998 -0.63189095 -1.06084081\n",
      " -0.41870032 -1.20632335 -0.59206344]  energy_before :  60  energy_after :  40  reward :  -185.4912027209961\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "action : 1  next_temperatures :  [ 0.31968906  1.55146691  0.43265665  1.42014551 -0.2829482   2.22999331\n",
      " -0.79562791  2.44166057  0.227155  ]  energy_before :  40  energy_after :  100  reward :  -250.45580909713973\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "action : 1  next_temperatures :  [-0.49598942  0.0829968  -0.85634126  0.96147231 -0.2829482  -0.32032631\n",
      " -0.52149876  0.06060434 -0.16378086]  energy_before :  100  energy_after :  50  reward :  -149.535811350951\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "action : 1  next_temperatures :  [-0.30296627 -0.65249478 -0.97642479 -0.11149537 -0.23808413 -0.93486116\n",
      "  0.10997732 -0.84052677  0.05849238]  energy_before :  50  energy_after :  50  reward :  -201.88838356910406\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "action : 1  next_temperatures :  [-0.18466176  0.16090195 -0.29240467 -0.06317087 -1.03068267  0.14057482\n",
      "  0.01696922  0.06905053 -0.26678553]  energy_before :  50  energy_after :  70  reward :  -219.45020898176455\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "action : 1  next_temperatures :  [1.44046866 1.85135984 0.61962214 2.54799016 1.71101039 1.15455732\n",
      " 1.29460687 1.54406149 1.7878866 ]  energy_before :  70  energy_after :  30  reward :  -144.04843651221887\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "action : 1  next_temperatures :  [ 0.68705571  0.81429994  0.80202751  0.5109897  -0.08355234  1.49886754\n",
      "  0.01696922  1.39126233 -0.05987264]  energy_before :  30  energy_after :  50  reward :  -212.4219530220357\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "action : 1  next_temperatures :  [-0.30296627 -0.96997919 -1.06762747 -0.03204662 -0.08355234 -1.28514603\n",
      " -0.32079706 -1.07425574  0.0042794 ]  energy_before :  50  energy_after :  50  reward :  -203.13209131137538\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "action : 1  next_temperatures :  [-1.09581406 -0.61144799 -1.26523328 -0.07218052 -0.78143785  0.27167559\n",
      " -0.8103134  -0.36016922 -0.92276265]  energy_before :  50  energy_after :  40  reward :  -193.647683367081\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "action : 1  next_temperatures :  [ 0.43799358  0.16090195 -0.44896928  1.34643018  0.89681064 -0.14825656\n",
      "  0.07081602  0.43146863  0.68555591]  energy_before :  40  energy_after :  60  reward :  -214.5672489424733\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "action : 1  next_temperatures :  [ 0.61026155 -0.6022334  -0.56601272  0.43727436  0.50965034 -0.53541351\n",
      " -0.12499052  0.29940102  0.0042794 ]  energy_before :  60  energy_after :  110  reward :  -247.96778348579494\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "action : 1  next_temperatures :  [-0.30296627  1.08068528  0.07240605  0.47740827 -0.36602981  1.3358451\n",
      " -1.0110151   0.99045248 -0.28786836]  energy_before :  110  energy_after :  100  reward :  -186.01108234494072\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "action : 1  next_temperatures :  [-0.05390414 -0.41961704 -0.38360736  0.14241301 -0.13340131 -0.29267225\n",
      "  0.01696922 -0.30565294  0.0042794 ]  energy_before :  100  energy_after :  120  reward :  -219.4251933871118\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "action : 1  next_temperatures :  [ 0.12666591  0.41220887 -0.38360736  1.19654233  0.96327592  0.20202831\n",
      "  0.41347746  0.29095483  0.64941392]  energy_before :  120  energy_after :  270  reward :  -344.1290398147661\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "action : 1  next_temperatures :  [-0.9256216  -1.47259304 -1.39139699 -0.69548464 -0.08355234 -1.26466153\n",
      " -0.61450686 -1.41133529 -0.48363747]  energy_before :  270  energy_after :  70  reward :  -6.342789757676002\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "action : 1  next_temperatures :  [ 2.06312399 -1.1651609   2.27191073 -2.06249461  1.91871442 -0.87340768\n",
      "  1.97503459 -0.95908049  2.56674648]  energy_before :  70  energy_after :  50  reward :  -172.26461347303\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n",
      "action : 1  next_temperatures :  [-0.11616967 -1.03603701 -0.15560065 -0.9808683  -0.87005823 -0.61837572\n",
      "  0.20176164 -1.07214419 -0.87638043]  energy_before :  50  energy_after :  60  reward :  -213.52387256109654\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "action : 1  next_temperatures :  [-1.23694927 -0.18338853 -0.66177553 -0.20978248 -1.08053164  0.24094885\n",
      " -0.36974869 -0.73717619 -0.86312836]  energy_before :  60  energy_after :  200  reward :  -343.1015318451499\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "action : 1  next_temperatures :  [-0.61429393 -1.04788434  0.73818563 -1.66197461 -0.36602981 -1.42956172\n",
      " -0.14130773 -0.60510857 -0.45110968]  energy_before :  200  energy_after :  50  reward :  -53.57908476146031\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "action : 1  next_temperatures :  [-1.11864475 -1.14756942 -1.52516092 -0.14589586 -1.1303806  -0.92564314\n",
      " -0.55086974 -0.78938896 -0.92276265]  energy_before :  50  energy_after :  50  reward :  -206.25631604216457\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "action : 1  next_temperatures :  [ 0.23666835  1.66790579 -0.00815632  0.94427206  0.36508834 -0.24863058\n",
      " -0.24410616  0.91290115  0.14342606]  energy_before :  50  energy_after :  100  reward :  -244.2306313059453\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "action : 1  next_temperatures :  [ 0.31968906 -0.17584932  0.16360874 -0.66845569  0.01116069 -0.66139315\n",
      "  0.7022921  -0.51527188  0.60062223]  energy_before :  100  energy_after :  120  reward :  -218.22359722943523\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "action : 1  next_temperatures :  [-0.3652318   0.18603264 -0.02335676 -0.02303696 -0.53219302  0.92717943\n",
      " -0.56555523  0.65337293 -0.43484578]  energy_before :  120  energy_after :  60  reward :  -138.17763455615986\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "action : 1  next_temperatures :  [ 1.30971104  0.3116861   1.09205204  0.01414833  1.11282282 -0.22814609\n",
      "  1.34355851  0.06060434  1.03432611]  energy_before :  60  energy_after :  50  reward :  -181.9492368057017\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "action : 1  next_temperatures :  [-0.55825495  0.23629403 -0.15560065 -0.14589586 -0.63189095  0.97019687\n",
      "  0.38084303  0.43914698 -0.80891538]  energy_before :  50  energy_after :  50  reward :  -198.27407688718563\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "action : 1  next_temperatures :  [-0.55825495 -0.9448485  -0.97642479 -0.15490551 -0.10847682 -1.53556898\n",
      "  0.01696922 -0.92759926  0.16149705]  energy_before :  50  energy_after :  90  reward :  -243.02761254056446\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "action : 1  next_temperatures :  [ 2.5550217  -0.38443407  1.94206103 -0.57835917  2.23641848 -1.48794253\n",
      "  2.21979276  0.22415319  2.40772173]  energy_before :  90  energy_after :  50  reward :  -148.86556686776154\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "action : 1  next_temperatures :  [ 1.68330424 -1.12327642  1.64838839 -1.33336802  1.11282282 -1.76448321\n",
      "  1.97503459 -0.9967044   2.9961585 ]  energy_before :  50  energy_after :  50  reward :  -193.80212351410933\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "action : 1  next_temperatures :  [ 1.25367206 -1.8914379   1.54532936 -2.56293984  0.48721831 -1.38193527\n",
      "  1.29460687 -1.1656281   0.60062223]  energy_before :  50  energy_after :  50  reward :  -199.82049226860264\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "action : 1  next_temperatures :  [ 0.195158   -1.07050196 -0.80921987  0.01955412 -0.08355234 -1.17043285\n",
      "  0.07081602 -1.1065048   0.10728407]  energy_before :  50  energy_after :  50  reward :  -201.84739963217856\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "action : 1  next_temperatures :  [-0.18466176  0.28655541 -0.88978224  1.23176188  0.7140311   0.10677541\n",
      "  0.31557419 -0.100641    0.49219626]  energy_before :  50  energy_after :  30  reward :  -176.02819075771188\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "action : 1  next_temperatures :  [-1.11864475 -0.14988094 -0.74841808 -0.34165103 -0.16995721 -0.23838833\n",
      " -0.71730529 -0.76635392 -0.7384385 ]  energy_before :  30  energy_after :  430  reward :  -602.9890380601523\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "action : 1  next_temperatures :  [ 2.0174626  -1.01437675  2.09102541 -1.7266803   1.96025522 -0.86462861\n",
      "  1.97503459 -0.92759926  2.5143406 ]  energy_before :  430  energy_after :  60  reward :  178.02483350199282\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "action : 1  next_temperatures :  [-0.30296627  0.86456133 -0.25136347  1.03354953 -0.13340131  1.36964452\n",
      " -0.03198241  1.14555515 -0.59206344]  energy_before :  60  energy_after :  100  reward :  -234.89846637149725\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "action : 1  next_temperatures :  [ 1.19140653 -0.6432802   0.66066335 -0.39851715  1.00813999 -0.86111698\n",
      "  1.57199947 -0.76635392  1.82764279]  energy_before :  100  energy_after :  80  reward :  -174.4094161161422\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "action : 1  next_temperatures :  [-0.13900036  0.32676452  0.20464994 -0.10330477  0.11584352  1.18221139\n",
      " -0.99469789  0.44605749 -0.23064354]  energy_before :  80  energy_after :  60  reward :  -177.1921197011422\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "action : 1  next_temperatures :  [ 1.75179633  1.11586825  1.75314119  0.31230931  2.37566326 -0.33159279\n",
      "  1.80044043  0.76778034  1.75174461]  energy_before :  60  energy_after :  30  reward :  -156.70284906910098\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "action : 1  next_temperatures :  [-0.49598942  0.53786233 -0.07959842 -0.08119017 -0.41754041  1.73631698\n",
      "  0.39716025  0.13969134 -0.80891538]  energy_before :  30  energy_after :  40  reward :  -207.07220289376124\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "action : 1  next_temperatures :  [ 0.27817871  0.3854028   0.20464994  0.32014888  0.9931853  -0.1666926\n",
      "  0.11976765  0.61421335  0.54640924]  energy_before :  40  energy_after :  50  reward :  -204.704736723869\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n",
      "action : 1  next_temperatures :  [-0.61429393 -0.18338853 -0.29240467 -0.46450992 -0.03370338  0.10882386\n",
      "  0.75124373 -0.7748001  -0.94444784]  energy_before :  50  energy_after :  50  reward :  -200.4474807899866\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "action : 1  next_temperatures :  [ 0.22629076 -0.59427535  0.02224458 -0.51283442 -0.13340131 -1.03830786\n",
      " -0.22778895 -1.41133529  0.05849238]  energy_before :  50  energy_after :  130  reward :  -281.6109154513465\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "action : 1  next_temperatures :  [1.62103871 1.9200504  0.75642617 2.40301667 1.9901646  1.69534799\n",
      " 1.39251014 1.55788252 1.7878866 ]  energy_before :  130  energy_after :  140  reward :  -192.8756762119242\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "action : 1  next_temperatures :  [ 0.31968906  0.86456133 -0.29240467  1.73957864  1.21252075  0.54002247\n",
      "  0.21277576  0.84609951  0.7036269 ]  energy_before :  140  energy_after :  350  reward :  -401.8535302549232\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "action : 1  next_temperatures :  [ 0.68705571 -0.28307361  0.66913217 -0.29742183  1.16267178 -0.59993967\n",
      "  1.16243746 -0.53677126  1.63066894]  energy_before :  350  energy_after :  60  reward :  95.59475969594101\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "action : 1  next_temperatures :  [-0.61429393 -0.96997919 -1.29563417 -0.06317087 -0.2829482  -1.33430881\n",
      " -0.61450686 -1.22705489 -0.32099851]  energy_before :  60  energy_after :  40  reward :  -184.7228954548645\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "action : 1  next_temperatures :  [-0.61429393  0.20865027 -0.61161406  0.21367117 -1.03068267  0.72131026\n",
      " -0.78094242  0.33932843 -0.40171563]  energy_before :  40  energy_after :  50  reward :  -209.9562885840001\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "action : 1  next_temperatures :  [ 1.39480727 -0.13228946  3.69041644 -2.62092923  1.36206764 -0.64449345\n",
      "  1.39251014 -0.38320427  1.39574601]  energy_before :  50  energy_after :  110  reward :  -252.5453689079381\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "action : 1  next_temperatures :  [1.95312155 1.9200504  2.04390402 1.40376433 2.15965108 0.86388234\n",
      " 2.17084113 1.49108088 2.27580346]  energy_before :  110  energy_after :  40  reward :  -111.71790081391367\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "action : 1  next_temperatures :  [-0.96713196  0.11064057 -0.88978224  0.28001498 -0.73657378  0.07912134\n",
      " -0.17394215  0.09362124 -0.9558928 ]  energy_before :  40  energy_after :  60  reward :  -221.15992480857457\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "action : 1  next_temperatures :  [ 1.30971104  0.73807018  3.14411238 -1.49013597  1.92702258  0.0361039\n",
      "  1.83307485  0.52284099  1.03432611]  energy_before :  60  energy_after :  90  reward :  -218.94487395484197\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "action : 1  next_temperatures :  [-0.55825495  0.36948669 -0.25136347  0.36355902 -0.53219302  0.51953798\n",
      "  0.3318914   0.32397173 -0.50532266]  energy_before :  90  energy_after :  40  reward :  -147.93868727657429\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "action : 1  next_temperatures :  [-0.3652318   0.81429994 -0.40032785  0.97785349 -0.23808413  1.00092361\n",
      "  0.18340478  0.56123274 -0.21257254]  energy_before :  40  energy_after :  150  reward :  -305.67850175978623\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "action : 1  next_temperatures :  [ 0.39648322 -1.48180762  0.52841946 -1.72504218 -0.38264613 -1.42956172\n",
      "  0.50648556 -1.50405136 -0.59206344]  energy_before :  150  energy_after :  50  reward :  -103.68378419783289\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "action : 1  next_temperatures :  [ 0.12666591 -0.44223466 -0.50673098  0.5027991   0.31025448 -0.59993967\n",
      " -0.32079706 -0.0061973   0.687363  ]  energy_before :  50  energy_after :  60  reward :  -208.24881716191763\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "action : 1  next_temperatures :  [-0.738825   -0.05773507 -1.4324382   1.42014551 -0.68672482 -0.32032631\n",
      " -0.36974869 -0.79860298 -0.63181963]  energy_before :  60  energy_after :  40  reward :  -181.61607518508202\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "action : 1  next_temperatures :  [-0.80731709 -0.3165812  -1.02202613  0.14896549 -0.78143785 -0.88569837\n",
      " -1.25577327 -0.42927437 -0.86312836]  energy_before :  40  energy_after :  50  reward :  -214.2122711488516\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "action : 1  next_temperatures :  [-0.05390414  1.01283241 -0.25136347  1.46928907  0.41493731  0.75510967\n",
      "  0.07081602  1.04420093  0.10728407]  energy_before :  50  energy_after :  350  reward :  -493.4307981242405\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "action : 1  next_temperatures :  [ 0.63101673 -0.55280971  1.97246192 -1.94618819  0.50965034 -0.47396003\n",
      "  1.01395084 -0.45307725  0.64941392]  energy_before :  350  energy_after :  70  reward :  83.35045857800779\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "action : 1  next_temperatures :  [-1.05015267  1.26413933 -0.52041138  1.10071239 -0.88113578  1.58473172\n",
      " -0.76625693  1.68995014 -1.13419329]  energy_before :  70  energy_after :  100  reward :  -226.71261646280522\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "action : 1  next_temperatures :  [ 1.62103871 -0.49500911  1.07563555 -0.54559679  2.03835193 -0.29267225\n",
      "  1.85055758 -0.65117867  2.00473854]  energy_before :  100  energy_after :  60  reward :  -151.39413451899057\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "action : 1  next_temperatures :  [1.30971104 1.3236153  1.13187721 0.8369753  0.80874413 1.91248364\n",
      " 0.13608486 2.33493151 0.91234689]  energy_before :  60  energy_after :  90  reward :  -217.2932301230763\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "action : 1  next_temperatures :  [ 0.50648566 -0.44223466 -0.18904163 -0.41700448  1.02475631 -0.64807823\n",
      "  0.36452582 -1.36756869 -0.48363747]  energy_before :  90  energy_after :  40  reward :  -149.6517973757009\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "action : 1  next_temperatures :  [-0.30296627 -1.00516216 -0.38360736 -0.94120243 -0.48732896 -1.02704139\n",
      " -0.43664926 -0.83545906 -0.48363747]  energy_before :  40  energy_after :  70  reward :  -233.90305435417395\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "action : 1  next_temperatures :  [ 1.29103138 -2.08494423  1.34468346 -2.76524748  0.55949931 -1.42956172\n",
      "  1.24076008 -1.52651053  0.88795105]  energy_before :  70  energy_after :  60  reward :  -190.48233868619118\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "action : 1  next_temperatures :  [ 0.0083614   1.07314607 -0.17232114  1.53399476  0.41493731  0.78276374\n",
      "  0.07081602  1.09718154  0.10728407]  energy_before :  60  energy_after :  140  reward :  -273.08383624081625\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "action : 1  next_temperatures :  [-1.05015267 -0.41961704 -0.72105728 -1.04604202 -1.23506343 -0.81502687\n",
      " -0.41870032 -0.72873    -1.11870386]  energy_before :  140  energy_after :  80  reward :  -145.55309349083285\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "action : 1  next_temperatures :  [-0.05390414 -1.2715475  -0.83962076 -0.47188146  0.14907616 -1.45721578\n",
      "  0.11976765 -1.50347548  0.41449098]  energy_before :  80  energy_after :  50  reward :  -172.91431032698915\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "action : 1  next_temperatures :  [-0.47315873 -0.91301629 -0.33800601 -1.0222893  -0.88113578 -0.59993967\n",
      " -0.36974869 -0.89842153 -0.82698637]  energy_before :  50  energy_after :  100  reward :  -254.32270237694343\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "action : 1  next_temperatures :  [-0.94637678 -0.76893366 -1.3609961   0.01955412 -0.78143785 -0.49649297\n",
      " -1.1040232  -0.63044713 -0.70591071]  energy_before :  100  energy_after :  100  reward :  -204.77506426719424\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "action : 1  next_temperatures :  [ 0.68705571 -1.55636201 -0.23616302 -0.94857397 -0.33279717 -1.26466153\n",
      "  1.0498487  -1.39597859 -0.10956787]  energy_before :  100  energy_after :  40  reward :  -142.10719974122836\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "action : 1  next_temperatures :  [ 0.4172384  -1.02024058 -0.58121317 -0.11231443  0.02777701 -1.12229429\n",
      "  0.11976765 -0.92068874  0.16149705]  energy_before :  40  energy_after :  50  reward :  -211.0304710898141\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "action : 1  next_temperatures :  [ 0.195158    1.25660013  0.61962214  0.82796564 -0.13340131  1.64311253\n",
      " -0.32079706  2.1590973  -0.52580312]  energy_before :  50  energy_after :  100  reward :  -242.27844574776535\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "action : 1  next_temperatures :  [ 0.25742353 -0.36684258  0.47825799 -0.87485863 -0.15167926  0.69058351\n",
      "  0.49016835  0.05369383 -0.80891538]  energy_before :  100  energy_after :  90  reward :  -188.23216864389195\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "action : 1  next_temperatures :  [-0.9256216  -0.59553188 -0.66177553 -0.90680194 -1.18521446 -0.66139315\n",
      " -0.41870032 -0.68342774 -1.13419329]  energy_before :  90  energy_after :  90  reward :  -205.1726599301678\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "action : 1  next_temperatures :  [-0.3652318  -1.08725576 -0.36840691 -1.43018083 -0.93596964 -1.07927685\n",
      "  0.16871929 -1.36603302 -0.97697563]  energy_before :  90  energy_after :  100  reward :  -215.44061115933616\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "action : 1  next_temperatures :  [ 0.25742353  1.9770133   0.10280695  1.06795002  1.16267178  0.58099146\n",
      "  0.11976765 -0.03767853  0.3295573 ]  energy_before :  100  energy_after :  230  reward :  -322.4394965382518\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "action : 1  next_temperatures :  [-0.42749733 -0.76139445 -0.88978224 -0.15490551 -0.43747999 -0.44630596\n",
      " -0.85926503 -0.63044713 -0.53785045]  energy_before :  230  energy_after :  560  reward :  -533.144928095835\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "action : 1  next_temperatures :  [ 0.37572804 -0.48411915  0.72298518 -1.01327965  0.06100966 -0.66856273\n",
      "  0.07081602 -0.6408129   0.23662076]  energy_before :  560  energy_after :  70  reward :  290.6603852361101\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "action : 1  next_temperatures :  [-1.47148277  0.28655541 -0.97642479  0.24070013 -1.32977646  0.41404283\n",
      " -1.0110151  -0.18356718 -1.13419329]  energy_before :  70  energy_after :  70  reward :  -203.16516121666348\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "action : 1  next_temperatures :  [-0.49598942 -1.12327642 -0.03703716 -1.45475261 -0.45409631 -1.31382432\n",
      " -0.0466679  -0.97597286 -0.26678553]  energy_before :  70  energy_after :  50  reward :  -184.16840253936996\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "action : 1  next_temperatures :  [-2.05262775 -0.46736535 -1.39139699 -0.49645324 -1.82826611  0.01459518\n",
      " -2.27886242 -0.12137255 -1.75101658]  energy_before :  50  energy_after :  50  reward :  -208.37276581262765\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "action : 1  next_temperatures :  [-0.80731709 -0.29396358 -0.52041138 -0.29250747 -1.1303806   0.33312908\n",
      " -0.27674059 -0.17665666 -1.10407496]  energy_before :  50  energy_after :  60  reward :  -212.26892325166384\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "action : 1  next_temperatures :  [ 0.195158   -0.29396358 -0.43376883  0.28738651  0.06100966 -0.10523912\n",
      " -0.29142608  0.14660186  0.10728407]  energy_before :  60  energy_after :  70  reward :  -208.3269575121079\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "action : 1  next_temperatures :  [-1.11864475  0.61325441 -0.46416972  0.07443109 -0.71995746  0.77559417\n",
      " -1.04038608  0.80002941 -0.43484578]  energy_before :  70  energy_after :  50  reward :  -179.5146947185057\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "action : 1  next_temperatures :  [-2.02979705 -0.38443407 -1.32907516 -0.38342305 -1.87811508  0.00537716\n",
      " -2.23480595 -0.10755152 -1.83896209]  energy_before :  50  energy_after :  60  reward :  -218.18078681429643\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n",
      "action : 1  next_temperatures :  [-1.34072515 -1.75908293 -0.61161406 -2.15095301 -0.93472342 -1.7352928\n",
      " -0.76625693 -1.589473   -1.35104523]  energy_before :  60  energy_after :  90  reward :  -240.23916652273846\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n",
      "action : 1  next_temperatures :  [-0.42749733 -1.16432321 -0.53561182 -0.88304922 -1.18521446 -0.73329373\n",
      " -1.1040232  -0.73295309 -0.3806328 ]  energy_before :  90  energy_after :  140  reward :  -255.14659888815618\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "action : 1  next_temperatures :  [-0.71806982 -1.63342947 -0.06439797 -1.72749936 -0.95258596 -1.77574968\n",
      "  0.01696922 -1.5434029  -0.48363747]  energy_before :  140  energy_after :  40  reward :  -106.88180340423008\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "action : 1  next_temperatures :  [-0.22617211 -1.07887886 -0.69217643 -0.40799483 -1.03068267 -0.92564314\n",
      " -0.47254712 -1.01359677 -0.39870379]  energy_before :  40  energy_after :  100  reward :  -264.24639573356365\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "action : 1  next_temperatures :  [-0.55825495 -0.11804873  0.55882036 -0.59474035  0.02777701 -0.09499687\n",
      "  0.31557419 -1.0120611  -0.50170846]  energy_before :  100  energy_after :  50  reward :  -149.97763891533356\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "action : 1  next_temperatures :  [ 0.88007886 -0.5452705   0.80202751 -0.64634109 -0.18823517  0.75510967\n",
      "  0.38084303  0.34623895 -0.48363747]  energy_before :  50  energy_after :  240  reward :  -386.69918619669176\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "action : 1  next_temperatures :  [-2.2331978  -0.81919504 -1.39139699 -1.01491777 -2.07751094 -0.20049202\n",
      " -1.50053144 -0.61432259 -1.73595742]  energy_before :  240  energy_after :  300  reward :  -269.58752200379433\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "action : 1  next_temperatures :  [-0.55825495 -1.12327642 -0.58121317 -0.97150763 -1.08053164 -0.4628984\n",
      " -1.15297484 -0.58207352 -1.35104523]  energy_before :  300  energy_after :  210  reward :  -115.86377578899902\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "action : 1  next_temperatures :  [-0.32372145  1.24906092  0.07240605  0.91069063 -1.08053164  1.92272588\n",
      " -0.19352281  1.91953279 -0.28485652]  energy_before :  210  energy_after :  50  reward :  -33.80821613717936\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "action : 1  next_temperatures :  [-0.09749001  1.21555333  0.11800739  0.01955412 -0.39560686  0.97019687\n",
      " -1.23945606  1.62929117 -1.0799803 ]  energy_before :  50  energy_after :  160  reward :  -306.85993034573494\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "action : 1  next_temperatures :  [-0.96713196  0.28655541 -0.83962076  0.17353727 -1.08053164  0.45706027\n",
      " -0.69935636 -0.25958284 -0.7384385 ]  energy_before :  160  energy_after :  110  reward :  -151.6675091075851\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "action : 1  next_temperatures :  [ 2.10463435 -0.05019586  3.61107011 -2.11245722  1.91040625 -0.21155365\n",
      "  2.09415023 -0.25190449  1.90173387]  energy_before :  110  energy_after :  80  reward :  -159.0041164155476\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "action : 1  next_temperatures :  [ 0.06440038 -0.47741763  0.46331088 -0.73125023 -0.80636233  0.24658208\n",
      " -0.32744481  0.37308473 -0.16076903]  energy_before :  80  energy_after :  80  reward :  -199.35586595232573\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "action : 1  next_temperatures :  [ 0.04572072  0.38456511  0.3460141   0.01955412  0.16569248  1.21601081\n",
      " -0.96206346  0.45450368 -0.21257254]  energy_before :  80  energy_after :  270  reward :  -386.5425749926868\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "action : 1  next_temperatures :  [-0.55825495  0.16844116 -1.16339028  1.05156883  0.36508834  0.05863684\n",
      " -0.17394215 -0.0545709   0.31600406]  energy_before :  270  energy_after :  220  reward :  -147.99041906227689\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "action : 1  next_temperatures :  [-0.18466176 -0.39197328  0.34094728 -0.58245446 -0.86451946  0.29420854\n",
      " -0.33953163  0.33645616 -0.91914845]  energy_before :  220  energy_after :  50  reward :  -30.3106770498822\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "action : 1  next_temperatures :  [ 0.74932124  0.80592305  0.88867006  0.03061142  1.97520991 -0.07451237\n",
      "  0.36452582  0.66181912  0.7036269 ]  energy_before :  50  energy_after :  50  reward :  -191.8948048585864\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n",
      "action : 1  next_temperatures :  [ 0.14949661 -0.98673299  2.01502318 -2.50396757  0.16569248 -1.24212859\n",
      "  0.85404217 -1.0581312   0.0042794 ]  energy_before :  50  energy_after :  280  reward :  -430.6024265196414\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "action : 1  next_temperatures :  [ 0.66837605 -0.55280971  2.92704999 -2.30903145  0.66418213 -0.91642512\n",
      "  1.34355851 -0.74562237  0.03138589]  energy_before :  280  energy_after :  70  reward :  13.110663920718537\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "action : 1  next_temperatures :  [-0.23136091  1.29178309  0.0876065   1.07368343  0.06100966  1.74997331\n",
      " -0.41870032  1.69839632 -0.45653098]  energy_before :  70  energy_after :  270  reward :  -393.1441398908612\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "action : 1  next_temperatures :  [ 0.195158    0.72969328 -0.27872427  1.05156883  0.61433317  0.49802926\n",
      "  0.60928399  0.17577959  0.7036269 ]  energy_before :  270  energy_after :  140  reward :  -63.70125125406187\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "action : 1  next_temperatures :  [ 1.68330424 -0.44223466  1.25804092 -0.64634109  2.05496825 -0.32032631\n",
      "  1.88692165 -0.67766898  2.05895152]  energy_before :  140  energy_after :  50  reward :  -101.14438445892714\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "action : 1  next_temperatures :  [-0.67655947 -0.73710145 -0.22096257 -0.94120243 -0.70334114  0.92922788\n",
      " -1.69633798 -0.24422614 -0.47821617]  energy_before :  50  energy_after :  60  reward :  -212.76871946640946\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "action : 1  next_temperatures :  [-0.04500906 -0.36145744 -0.15560065 -0.49013478 -0.78143785 -0.33384608\n",
      "  0.06004666 -1.0427745  -0.86312836]  energy_before :  60  energy_after :  70  reward :  -212.01334206156508\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n",
      "action : 1  next_temperatures :  [-1.00864231 -0.52684132 -0.52041138 -0.6782844  -1.23506343 -0.36334375\n",
      "  0.31557419 -0.53600343 -0.86312836]  energy_before :  70  energy_after :  70  reward :  -203.4161441949146\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "action : 1  next_temperatures :  [ 0.0083614   0.47838636 -0.52041138  0.8549946   0.23049614  0.10677541\n",
      "  0.22909297  0.12970949  0.63315002]  energy_before :  70  energy_after :  50  reward :  -175.84944499936296\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "action : 1  next_temperatures :  [ 1.68330424 -0.46736535  1.1622781  -0.61931213  2.05496825 -0.32032631\n",
      "  1.87852994 -0.65117867  2.05895152]  energy_before :  50  energy_after :  100  reward :  -241.22015041262233\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "action : 1  next_temperatures :  [-0.30296627 -0.11804873 -0.79401942  0.74851689 -0.13340131 -0.35412573\n",
      "  0.11976765 -0.16974615 -0.16378086]  energy_before :  100  energy_after :  120  reward :  -219.16780392208415\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "action : 1  next_temperatures :  [ 2.24369404 -0.45982614  2.09102541 -0.86502992  1.5564786  -0.77200943\n",
      "  1.78412322 -0.59743022  1.61259795]  energy_before :  120  energy_after :  140  reward :  -211.4063764995638\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "action : 1  next_temperatures :  [ 0.02704106  0.45158029  0.10280695 -0.28349782 -0.61527463  0.55845852\n",
      " -0.20984002  0.11512062 -0.59206344]  energy_before :  140  energy_after :  30  reward :  -88.44566847173874\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "action : 1  next_temperatures :  [-0.7616557  -0.59553188 -0.97642479 -0.11968596 -1.06391532 -0.67061118\n",
      " -0.07603889 -1.17330645 -0.81072248]  energy_before :  30  energy_after :  100  reward :  -274.2478926288266\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "action : 1  next_temperatures :  [-0.42749733  0.03524849 -0.88978224  0.89430945 -0.23808413 -0.36334375\n",
      " -0.52149876 -0.07530245 -0.14570986]  energy_before :  100  energy_after :  100  reward :  -199.73166058969503\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "action : 1  next_temperatures :  [-1.40714172 -0.14988094 -1.13298939 -0.32690796 -0.81467049  0.3218626\n",
      " -1.34878137 -0.74562237 -1.0799803 ]  energy_before :  100  energy_after :  90  reward :  -194.6841119553971\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "action : 1  next_temperatures :  [-0.11616967 -0.17584932 -0.61161406  0.5027991   0.01116069 -0.10523912\n",
      " -0.36974869 -0.10755152  0.05849238]  energy_before :  90  energy_after :  420  reward :  -528.9137201992655\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "action : 1  next_temperatures :  [ 1.50273419  1.51712163  1.30364226  0.77308867  1.25738481  1.74860768\n",
      " -0.56555523  2.18213235  0.85662799]  energy_before :  420  energy_after :  60  reward :  172.5757843592853\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "action : 1  next_temperatures :  [ 0.46082427 -0.96997919 -0.22096257 -0.34902256 -0.23808413 -0.94612763\n",
      " -0.32079706 -1.02204296 -0.59206344]  energy_before :  60  energy_after :  60  reward :  -202.19825527818554\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "action : 1  next_temperatures :  [-0.80731709 -1.09563265 -0.83962076 -0.86502992 -1.08053164 -0.41250654\n",
      " -1.29982974 -0.58975187 -1.35104523]  energy_before :  60  energy_after :  80  reward :  -226.34126544509013\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n",
      "action : 1  next_temperatures :  [1.90972436 2.07014917 1.92809305 1.29453429 2.20587466 1.17411071\n",
      " 1.56891243 1.67762327 1.84556726]  energy_before :  80  energy_after :  50  reward :  -152.32541080714478\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "action : 1  next_temperatures :  [-0.80731709 -0.34171189 -0.80921987 -0.03204662 -0.48732896 -0.13903853\n",
      " -0.22778895 -0.65117867 -0.41935636]  energy_before :  50  energy_after :  180  reward :  -331.91498693447716\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "action : 1  next_temperatures :  [-0.738825    0.52948543 -0.15560065 -0.01402731 -0.73657378  0.56767654\n",
      " -0.90821667  0.50057378 -0.38665646]  energy_before :  180  energy_after :  90  reward :  -109.34216411966369\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "action : 1  next_temperatures :  [-1.672808    0.67189269 -0.69217643  0.16452762 -0.63521422  2.61919871\n",
      " -1.0110151   0.7140319  -1.29683224]  energy_before :  90  energy_after :  310  reward :  -419.13839507226936\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "action : 1  next_temperatures :  [-0.60628837 -0.87520058 -0.70737688 -0.52348219 -0.63189095 -0.12938156\n",
      " -0.76625693 -0.65841826 -0.77503226]  energy_before :  310  energy_after :  70  reward :  36.3266720228641\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "action : 1  next_temperatures :  [ 0.43799358 -2.00285064  2.92857004 -3.62525974  0.55949931 -1.66410918\n",
      "  0.94705027 -1.73382597  0.61688612]  energy_before :  70  energy_after :  130  reward :  -261.53604621964723\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "action : 1  next_temperatures :  [-1.05015267  1.04885307 -0.56601272  0.71591833 -1.18521446  1.73836543\n",
      " -0.56555523  1.02270155 -0.97697563]  energy_before :  130  energy_after :  50  reward :  -117.81807232368425\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "action : 1  next_temperatures :  [-0.86958262 -0.06527428 -0.74841808  0.26527191 -0.73657378 -0.10523912\n",
      " -0.96206346  0.02086888 -0.48363747]  energy_before :  50  energy_after :  50  reward :  -201.68464802186764\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "action : 1  next_temperatures :  [ 0.43799358  0.42058577 -0.18904163  0.90168098  1.16267178  0.26040912\n",
      "  0.9960019  -0.14440759  0.81747417]  energy_before :  50  energy_after :  230  reward :  -373.33663193077757\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "action : 1  next_temperatures :  [ 0.06440038  0.11817977 -0.03703716  0.28738651 -0.53219302  0.37614652\n",
      "  0.11976765 -0.13749708  0.77487825]  energy_before :  230  energy_after :  40  reward :  -6.9659681899716475\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "action : 1  next_temperatures :  [-0.61429393  0.00760473 -1.16339028  1.08269308  0.36508834  0.10677541\n",
      " -0.36974869 -0.23654779  0.28308903]  energy_before :  40  energy_after :  110  reward :  -268.5387301051324\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "action : 1  next_temperatures :  [0.50648566 1.30183537 0.70626469 0.54375207 1.39530028 0.62196045\n",
      " 0.60928399 0.26930188 0.7036269 ]  energy_before :  110  energy_after :  50  reward :  -131.34218868798405\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "action : 1  next_temperatures :  [-1.38431103  0.27734082 -0.97642479  0.24070013 -1.2799275   0.44784225\n",
      " -0.96206346 -0.16974615 -1.02576732]  energy_before :  50  energy_after :  50  reward :  -202.83235704239615\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "action : 1  next_temperatures :  [-0.3652318  -0.16831012 -0.02335676 -0.06317087 -0.18823517 -0.53541351\n",
      " -0.47254712 -0.19047769 -0.10956787]  energy_before :  50  energy_after :  70  reward :  -220.11631091440378\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "action : 1  next_temperatures :  [ 0.63101673 -0.16831012 -0.06439797  0.43727436  1.31820055 -0.32032631\n",
      "  1.08248312 -0.42082818  1.68488193]  energy_before :  70  energy_after :  110  reward :  -233.82000588794736\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "action : 1  next_temperatures :  [-0.24692729 -0.84432573 -0.50673098 -0.34165103 -0.2829482  -0.62759374\n",
      " -0.17394215 -0.42236385 -0.04993359]  energy_before :  110  energy_after :  240  reward :  -331.49641656015103\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "action : 1  next_temperatures :  [-1.80356562  1.56822071 -1.06762747  1.49386085 -1.2799275   1.76909217\n",
      " -1.50053144  1.85733816 -1.24804056]  energy_before :  240  energy_after :  90  reward :  -48.2111806926215\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "action : 1  next_temperatures :  [-1.80356562  1.16612963 -1.02202613  1.10071239 -1.18521446  1.85819973\n",
      " -2.13200752  1.88267671 -1.56789717]  energy_before :  90  energy_after :  200  reward :  -309.70299243881357\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "action : 1  next_temperatures :  [-0.47315873 -0.76893366 -0.90498269 -0.12787655 -0.43747999 -0.44630596\n",
      " -0.85926503 -0.63044713 -0.53785045]  energy_before :  200  energy_after :  30  reward :  -33.18630018468764\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "action : 1  next_temperatures :  [ 0.74932124 -0.75385524  0.80202751 -1.20903482  0.36508834 -0.87340768\n",
      "  0.9960019  -1.1372182   0.61282015]  energy_before :  30  energy_after :  50  reward :  -218.4482567972884\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "action : 1  next_temperatures :  [-3.04887628  1.36717517 -1.93405295  1.26288613 -2.43143859  1.18221139\n",
      " -2.80264491  1.21235679 -2.27808727]  energy_before :  50  energy_after :  40  reward :  -195.47047051343216\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "action : 1  next_temperatures :  [0.1723273  0.47671098 0.26697177 0.56586667 0.44816995 0.09755738\n",
      " 0.31557419 0.50594862 0.54640924]  energy_before :  40  energy_after :  100  reward :  -254.60446388543247\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "action : 1  next_temperatures :  [ 0.43799358  0.47838636  0.61962214  0.16452762 -0.2829482   1.15455732\n",
      " -0.36974869  0.46141419 -0.3806328 ]  energy_before :  100  energy_after :  50  reward :  -145.7168284760817\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "action : 1  next_temperatures :  [ 0.31968906 -0.28474899  2.48471699 -2.05430401  0.43155363 -0.47396003\n",
      "  0.94705027 -0.26802902  0.49219626]  energy_before :  50  energy_after :  140  reward :  -286.40583584454157\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "action : 1  next_temperatures :  [-0.61429393 -1.28076209 -1.39139699 -0.4006233  -0.38264613 -1.16531173\n",
      " -0.43664926 -1.12032583 -0.34087661]  energy_before :  140  energy_after :  260  reward :  -325.13288586879514\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "action : 1  next_temperatures :  [-0.30296627 -0.24370219 -1.08434796  0.93608147  0.59605521 -0.30189027\n",
      " -0.03198241 -0.33099149  0.49219626]  energy_before :  260  energy_after :  80  reward :  -18.271547650817382\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "action : 1  next_temperatures :  [ 0.14949661 -1.2715475  -0.90498269 -0.22616367 -0.36602981 -1.06084081\n",
      "  0.36452582 -1.38830024 -0.48363747]  energy_before :  80  energy_after :  340  reward :  -463.1874797457864\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "action : 1  next_temperatures :  [ 0.48365497 -1.2305007  -0.55081227 -0.48007205 -0.43747999 -1.1806751\n",
      "  0.82140774 -1.32149859 -0.32099851]  energy_before :  340  energy_after :  70  reward :  67.78302548290566\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "action : 1  next_temperatures :  [1.50273419 0.42728729 0.84762885 1.00078715 1.29061746 0.30445078\n",
      " 1.25870901 0.63110572 1.90173387]  energy_before :  70  energy_after :  40  reward :  -158.8349456820121\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "action : 1  next_temperatures :  [-1.8596046  -0.62066257 -1.25003283 -0.66845569 -1.57902129  0.35566202\n",
      " -2.18585432 -0.19047769 -1.62211015]  energy_before :  40  energy_after :  60  reward :  -227.6205571221758\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "action : 1  next_temperatures :  [-0.20541693  0.06037918 -0.22096257  0.01709694 -0.73657378  0.66292944\n",
      " -0.7336225   0.42225461 -0.92878631]  energy_before :  60  energy_after :  40  reward :  -179.66270192515213\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "action : 1  next_temperatures :  [ 0.0083614   0.51943316  0.17728914  0.47740827 -0.43747999  1.3358451\n",
      "  0.15240207  0.7140319  -0.10956787]  energy_before :  40  energy_after :  60  reward :  -215.1622768318284\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "action : 1  next_temperatures :  [ 2.06312399  0.0260339   3.75091422 -2.19190598  1.91040625 -0.20049202\n",
      "  2.07783302 -0.22963728  1.90173387]  energy_before :  60  energy_after :  100  reward :  -228.89199001464215\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "action : 1  next_temperatures :  [-0.55825495 -1.2305007   0.73970568 -2.1591436  -0.38264613 -1.30358207\n",
      "  0.16871929 -0.86079762 -0.48363747]  energy_before :  100  energy_after :  410  reward :  -514.070137586297\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "action : 1  next_temperatures :  [-0.61429393 -0.63574099 -1.19075109  0.28738651  0.46478627 -0.80376039\n",
      " -0.71730529 -0.51527188 -0.12763887]  energy_before :  410  energy_after :  80  reward :  128.14741033123448\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "action : 1  next_temperatures :  [1.44046866 0.00760473 0.49497848 0.5331043  1.61131247 0.19076184\n",
      " 1.45288382 0.09362124 0.61456271]  energy_before :  80  energy_after :  60  reward :  -171.56070175463523\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "action : 1  next_temperatures :  [ 0.27817871  1.10665366  0.66066335  0.70510675 -0.13340131  1.60180213\n",
      " -0.32079706  1.98095959 -0.48363747]  energy_before :  60  energy_after :  80  reward :  -212.6044716421111\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "action : 1  next_temperatures :  [-0.98788713 -0.51008753 -0.49305057 -0.67746534 -1.21013895 -0.39202205\n",
      "  0.39949128 -0.50309621 -0.86312836]  energy_before :  80  energy_after :  70  reward :  -193.23738486915755\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "action : 1  next_temperatures :  [ 0.37572804  0.6300082   0.6044217   0.1587942  -0.2829482   1.21601081\n",
      " -1.00938338  0.45220017 -0.3806328 ]  energy_before :  70  energy_after :  60  reward :  -186.2358012507411\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "action : 1  next_temperatures :  [0.43799358 0.7280179  0.84762885 0.28738651 0.16569248 0.52978023\n",
      " 0.21277576 0.9512929  0.05849238]  energy_before :  60  energy_after :  70  reward :  -203.7809394163449\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "action : 1  next_temperatures :  [-2.67528308  0.54623923 -1.78926869  0.54539019 -2.24699742  0.45706027\n",
      " -2.67537066  0.65337293 -2.16424   ]  energy_before :  70  energy_after :  380  reward :  -517.3490972295822\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "action : 1  next_temperatures :  [-1.18091029 -0.41961704 -1.06762747 -0.59719753 -1.08053164 -0.80376039\n",
      " -1.05507157 -1.26621448 -1.13419329]  energy_before :  380  energy_after :  60  reward :  113.39487631149373\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "action : 1  next_temperatures :  [ 0.31968906 -0.46736535 -0.61161406  0.54211395  0.44816995 -0.23838833\n",
      " -0.27674059 -0.100641    0.22113133]  energy_before :  60  energy_after :  70  reward :  -208.16364503339963\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "action : 1  next_temperatures :  [1.75179633 1.64109971 1.80069687 1.07368343 1.71101039 0.97019687\n",
      " 1.39251014 1.313711   1.94045743]  energy_before :  70  energy_after :  80  reward :  -194.40483781827723\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "action : 1  next_temperatures :  [-0.86958262  0.15168736 -0.38360736  0.11620312 -0.88113578 -0.01305889\n",
      " -0.40238311 -0.41391767 -0.80891538]  energy_before :  80  energy_after :  250  reward :  -371.5047103221401\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "action : 1  next_temperatures :  [1.99463191 1.87732822 2.80848651 0.00972541 3.22143403 0.89542846\n",
      " 1.78412322 1.35287059 1.68488193]  energy_before :  250  energy_after :  60  reward :  7.628910262646457\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "action : 1  next_temperatures :  [1.97387673 2.37994206 3.21433844 0.36812235 1.66116143 2.19838866\n",
      " 2.51839773 1.44270728 2.29387446]  energy_before :  60  energy_after :  100  reward :  -219.949190862336\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "action : 1  next_temperatures :  [ 2.06312399 -2.02546826  1.52252869 -2.39830892  0.52626666 -2.87167016\n",
      "  1.92608295 -1.52651053  2.355574  ]  energy_before :  100  energy_after :  100  reward :  -198.42838157170698\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n",
      "action : 1  next_temperatures :  [1.68330424 1.13848587 0.75642617 1.55406171 1.80572343 0.97019687\n",
      " 1.50346718 0.91520466 2.05895152]  energy_before :  100  energy_after :  80  reward :  -165.61417835683338\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "action : 1  next_temperatures :  [ 0.5687512  -0.71867227  0.16360874 -0.39161365  0.55949931 -0.47396003\n",
      "  0.94705027 -0.90686771  0.49219626]  energy_before :  80  energy_after :  50  reward :  -167.76000789234294\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "action : 1  next_temperatures :  [ 0.12666591 -0.41961704  0.77162661 -1.02966084  0.01116069 -0.75357338\n",
      "  0.56033236 -0.46689828  0.22113133]  energy_before :  50  energy_after :  80  reward :  -228.97883262407873\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "action : 1  next_temperatures :  [ 0.25742353 -0.60977261  0.20464994 -0.81834354  0.79212781 -1.33430881\n",
      " -0.61450686 -0.39165045 -0.3806328 ]  energy_before :  80  energy_after :  20  reward :  -140.8950137911922\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "action : 1  next_temperatures :  [-2.17093226  0.75398628 -1.4324382   0.90168098 -1.52917232  0.8472899\n",
      " -1.88724935  1.0303799  -1.55705457]  energy_before :  20  energy_after :  60  reward :  -243.0435096380347\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "action : 1  next_temperatures :  [-0.98788713 -0.36097876 -0.56601272 -0.48990076 -1.21844711 -0.34285926\n",
      "  0.26172739 -0.53369992 -0.86312836]  energy_before :  60  energy_after :  40  reward :  -183.1011866286271\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "action : 1  next_temperatures :  [-1.18091029  1.34141621 -0.52041138  0.98604409 -1.26497281  1.70456601\n",
      " -0.96206346  1.55788252 -1.31490324]  energy_before :  40  energy_after :  60  reward :  -217.65335233994037\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "action : 1  next_temperatures :  [ 0.31968906  0.21954023  0.1522084   0.32424418 -0.38264613  0.54002247\n",
      " -0.61450686  0.55355439 -0.7167533 ]  energy_before :  60  energy_after :  90  reward :  -227.6046475597935\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "action : 1  next_temperatures :  [-1.2992148  -0.84432573 -1.06762747 -0.41536637 -1.08053164 -0.95739411\n",
      " -1.22313885 -0.69033825 -0.67880421]  energy_before :  90  energy_after :  760  reward :  -876.2567414278553\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "action : 1  next_temperatures :  [-0.24692729 -0.41961704 -1.25003283  0.87956638  0.01116069 -0.78122745\n",
      "  0.45753393 -0.76635392  0.37834899]  energy_before :  760  energy_after :  50  reward :  510.26245146676047\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "action : 1  next_temperatures :  [-0.30296627 -1.18107701 -0.93538358 -0.54559679 -0.08355234 -1.01679914\n",
      " -0.47254712 -1.29616004 -0.21257254]  energy_before :  50  energy_after :  190  reward :  -344.04665484047325\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "action : 1  next_temperatures :  [-0.42749733 -0.65249478 -0.88978224 -0.04678968  0.16569248 -0.75357338\n",
      "  0.41347746 -0.93681328  0.20125324]  energy_before :  190  energy_after :  60  reward :  -70.92652751961637\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "action : 1  next_temperatures :  [1.56499973 1.08822449 1.11667676 1.00242527 2.25436411 0.16822889\n",
      " 1.89671197 0.75165581 1.51682167]  energy_before :  60  energy_after :  60  reward :  -186.6398912914056\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "action : 1  next_temperatures :  [ 0.52724084 -0.29396358 -0.06439797  0.21367117  0.11584352 -0.29267225\n",
      "  0.16871929  0.29095483  0.3295573 ]  energy_before :  60  energy_after :  110  reward :  -247.0050468384367\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "action : 1  next_temperatures :  [-0.42749733 -0.64722931 -0.20576213 -0.77472863 -1.03068267 -0.39055887\n",
      "  0.66924975 -0.62411249 -0.86312836]  energy_before :  110  energy_after :  50  reward :  -142.29445004434308\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "action : 1  next_temperatures :  [-2.2331978  -0.77814824 -1.39139699 -0.98788881 -2.07751094 -0.1666926\n",
      " -1.45157981 -0.48993333 -1.73595742]  energy_before :  50  energy_after :  50  reward :  -209.31230593484685\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "action : 1  next_temperatures :  [ 1.62103871 -0.21605843  1.10299636 -0.21879213  1.80572343 -0.71977397\n",
      "  1.78412322 -0.51527188  1.84752088]  energy_before :  50  energy_after :  50  reward :  -191.50849382465876\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "action : 1  next_temperatures :  [ 0.68705571  0.81429994  0.77162661  0.49460851 -0.08355234  1.52327823\n",
      " -0.03198241  1.32062152 -0.10956787]  energy_before :  50  energy_after :  240  reward :  -382.6136120991142\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "action : 1  next_temperatures :  [-0.09541449  0.20865027 -0.56601272  1.10071239 -0.58204199  0.06887909\n",
      " -0.12499052 -0.60510857 -0.3806328 ]  energy_before :  240  energy_after :  50  reward :  -8.975959344822513\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "action : 1  next_temperatures :  [-0.49598942 -0.6181495  -0.06439797 -0.71759925 -0.96920228  0.01459518\n",
      " -0.35343148  0.29095483 -0.97697563]  energy_before :  50  energy_after :  400  reward :  -551.890195524928\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "action : 1  next_temperatures :  [-0.49598942  0.18603264 -1.08434796  1.05156883  0.36508834  0.10677541\n",
      " -0.12499052 -0.04612472  0.3295573 ]  energy_before :  400  energy_after :  60  reward :  142.2875699077797\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n",
      "action : 1  next_temperatures :  [-0.9256216  -0.69354158 -1.70604624  0.60026716 -0.98581861 -0.59993967\n",
      " -0.61450686 -1.02204296 -0.80891538]  energy_before :  60  energy_after :  110  reward :  -254.75616573585864\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "action : 1  next_temperatures :  [-1.11864475  1.60842981 -1.11778894  0.59289563 -1.08053164 -0.77200943\n",
      " -1.0110151  -0.91377823 -1.13419329]  energy_before :  110  energy_after :  40  reward :  -132.9466359363736\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n",
      "action : 1  next_temperatures :  [-0.24692729  0.36194749 -0.73473768  1.17442773  0.44816995  0.2225128\n",
      " -0.12499052 -0.02923235  0.43256198]  energy_before :  40  energy_after :  150  reward :  -306.49626789532977\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "action : 1  next_temperatures :  [ 0.9423444  -0.6022334   1.07563555 -1.03703237  0.26040552 -0.3817798\n",
      "  0.60928399 -0.51527188  0.87168715]  energy_before :  150  energy_after :  290  reward :  -336.7769608383601\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "action : 1  next_temperatures :  [-1.2992148   1.45094414 -0.70737688  1.0994838  -0.98581861  1.43109801\n",
      " -1.13665763  1.60625612 -1.14081932]  energy_before :  290  energy_after :  50  reward :  42.31789484919946\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "action : 1  next_temperatures :  [ 1.87632739 -2.11091262  1.07563555 -2.10590475  0.86357799 -1.82900937\n",
      "  1.68132478 -1.99719336  2.4980767 ]  energy_before :  50  energy_after :  140  reward :  -288.0480776751392\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "action : 1  next_temperatures :  [-0.98788713 -1.2715475  -0.97642479 -1.08617593 -0.83128681 -0.81502687\n",
      " -0.96206346 -1.25239345 -1.0799803 ]  energy_before :  140  energy_after :  50  reward :  -117.26278624346105\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "action : 1  next_temperatures :  [-0.67655947  0.91482271 -0.22096257  0.74851689 -0.83128681  1.57346525\n",
      " -0.52149876  1.49108088 -1.02576732]  energy_before :  50  energy_after :  50  reward :  -196.5481891977372\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "action : 1  next_temperatures :  [ 0.06440038 -0.41961704 -0.44896928 -0.09593324 -0.08355234 -0.59993967\n",
      "  0.47152011 -0.7772133   0.37834899]  energy_before :  50  energy_after :  40  reward :  -189.510955384261\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "action : 1  next_temperatures :  [ 0.39648322 -0.96997919 -0.10999931 -0.39161365 -0.22146781 -1.02704139\n",
      " -0.22778895 -1.1372182  -0.59206344]  energy_before :  40  energy_after :  60  reward :  -222.28068872273113\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "action : 1  next_temperatures :  [ 0.0083614   0.99021479 -0.02335676  0.99423468 -0.08355234  1.46182475\n",
      "  0.45753393  1.19162524 -0.53785045]  energy_before :  60  energy_after :  290  reward :  -423.54096476974485\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "action : 1  next_temperatures :  [-0.96713196  1.94518109 -0.35320646  0.97785349 -1.18521446  1.73836543\n",
      " -0.90821667  1.68995014 -1.35104523]  energy_before :  290  energy_after :  50  reward :  43.58653537391859\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "action : 1  next_temperatures :  [-0.42749733  0.85534674  0.11800739  0.31441547 -0.30122615  2.62636829\n",
      " -0.20657658  1.30603265 -1.07395664]  energy_before :  50  energy_after :  80  reward :  -224.7890861603292\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "action : 1  next_temperatures :  [ 0.12666591 -1.2715475  -0.85634126 -0.3342795   0.41493731 -1.3957623\n",
      "  0.45753393 -1.53664595  0.64941392]  energy_before :  80  energy_after :  60  reward :  -181.74602543984722\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "action : 1  next_temperatures :  [ 0.43799358  0.88717895 -0.22096257  1.68060637  1.25738481  0.54002247\n",
      "  0.26172739  0.86683105  0.76326118]  energy_before :  60  energy_after :  100  reward :  -231.52595675748444\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n",
      "action : 1  next_temperatures :  [-0.9256216   0.61325441 -0.52041138  0.43727436 -0.70334114  1.59394974\n",
      " -1.48421423  1.08336051 -1.0799803 ]  energy_before :  100  energy_after :  590  reward :  -688.9857296251025\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n",
      "action : 1  next_temperatures :  [-0.11616967  0.22540406 -0.47937017  0.91970028 -0.58204199 -0.12213882\n",
      " -0.10867331 -0.63044713 -0.28485652]  energy_before :  590  energy_after :  270  reward :  120.82140673110337\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n",
      "action : 1  next_temperatures :  [ 0.50648566 -0.28474899 -0.1404002   0.01955412  1.36206764 -0.78122745\n",
      "  0.7022921  -0.8041314   0.7036269 ]  energy_before :  270  energy_after :  80  reward :  -6.716481616957111\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "action : 1  next_temperatures :  [-0.49598942 -0.87196949 -1.20443149 -0.07443293 -0.18823517 -0.88185753\n",
      " -0.0466679  -0.9967044   0.0042794 ]  energy_before :  80  energy_after :  70  reward :  -192.75600895477794\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "action : 1  next_temperatures :  [-0.24692729  0.29493231 -0.3410461   0.96802478  0.11584352 -0.25119114\n",
      " -0.19352281  0.04678331  0.86394244]  energy_before :  70  energy_after :  130  reward :  -256.74316097968085\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "action : 1  next_temperatures :  [-1.49223795  0.97178562 -0.88978224  0.92870994 -1.23506343  1.48026079\n",
      " -1.43363087  1.23769534 -1.34502156]  energy_before :  130  energy_after :  60  reward :  -129.7772843694744\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "action : 1  next_temperatures :  [ 0.10591073 -0.79657742  0.02224458 -0.92318313 -0.73657378 -0.23838833\n",
      " -0.17394215 -0.73717619 -0.53785045]  energy_before :  60  energy_after :  120  reward :  -262.0155361443491\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "action : 1  next_temperatures :  [1.50273419 1.14770046 0.98443287 1.16284389 2.20950004 0.28294206\n",
      " 1.78412322 0.7140319  1.51682167]  energy_before :  120  energy_after :  70  reward :  -136.69486969710903\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "action : 1  next_temperatures :  [-0.18466176 -0.25878061  0.69258429 -0.38997553 -0.16995721 -0.53541351\n",
      " -0.17394215  0.0398728   0.16149705]  energy_before :  70  energy_after :  70  reward :  -198.8187766300788\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "action : 1  next_temperatures :  [-0.18466176 -0.79657742 -0.82442032 -0.06317087 -0.38264613 -0.84268094\n",
      " -0.45459819 -0.92759926 -0.65169772]  energy_before :  70  energy_after :  390  reward :  -523.128052595318\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "action : 1  next_temperatures :  [-0.98788713 -1.23971529 -1.4324382  -0.50628195 -0.22562189 -1.54171433\n",
      " -0.6634585  -1.34856478 -0.53785045]  energy_before :  390  energy_after :  80  reward :  103.51646749109003\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "action : 1  next_temperatures :  [ 0.14949661  0.43733956 -0.56601272  1.24650494  1.02475631  0.07912134\n",
      "  0.7022921  -0.25190449  0.64941392]  energy_before :  80  energy_after :  110  reward :  -224.52899243143614\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "action : 1  next_temperatures :  [-0.16509259 -0.7305196  -0.47937017 -0.37359434 -0.33279717 -0.68904722\n",
      " -0.76503314 -0.2434583  -0.80891538]  energy_before :  110  energy_after :  390  reward :  -482.58782790799313\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "action : 1  next_temperatures :  [2.06312399 0.9810002  1.34468346 1.24814306 2.15965108 0.35566202\n",
      " 2.21979276 0.84609951 2.11858581]  energy_before :  390  energy_after :  100  reward :  105.33674189492112\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "action : 1  next_temperatures :  [-1.49223795  0.43733956 -0.66177553  0.21367117 -2.1273599   1.39729859\n",
      " -2.43061249  2.0669571  -2.24495711]  energy_before :  100  energy_after :  50  reward :  -152.84167656188947\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "action : 1  next_temperatures :  [ 1.93236637 -0.36935565  1.53164896 -0.57999728  1.61131247 -0.34285926\n",
      "  1.68132478 -0.37475808  1.63066894]  energy_before :  50  energy_after :  60  reward :  -201.27964875387133\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "action : 1  next_temperatures :  [-0.32372145 -1.12327642 -0.58881339 -0.61931213 -0.53219302 -1.35684176\n",
      " -0.03198241 -1.33531962 -0.59206344]  energy_before :  60  energy_after :  130  reward :  -274.50352364198943\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "action : 1  next_temperatures :  [ 1.06064891 -0.06527428  0.25025128  0.5331043   1.25738481 -0.44630596\n",
      "  1.14775197 -0.08374863  0.05849238]  energy_before :  130  energy_after :  40  reward :  -104.28769521504188\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "action : 1  next_temperatures :  [ 1.24962884  0.32705825  0.99837977  0.48035475  1.35378106 -0.0320137\n",
      "  1.28653303  0.21517849  0.92611136]  energy_before :  40  energy_after :  40  reward :  -191.19498812997446\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "action : 1  next_temperatures :  [ 0.37572804  1.16612963  0.30041276  1.01716834 -0.18823517  1.5509323\n",
      "  0.75124373  1.46804583 -0.53010574]  energy_before :  40  energy_after :  60  reward :  -212.08868026740706\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "action : 1  next_temperatures :  [-0.61429393 -0.79657742 -0.08719864 -0.96454562 -0.43747999 -0.9778786\n",
      " -0.04399782 -0.69159471 -0.26678553]  energy_before :  60  energy_after :  50  reward :  -192.88035226452263\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "action : 1  next_temperatures :  [ 0.0083614   0.18603264 -0.18904163  0.13422242 -0.63189095  0.35566202\n",
      " -0.06135339 -0.19047769 -0.0282484 ]  energy_before :  50  energy_after :  60  reward :  -208.4167335904533\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "action : 1  next_temperatures :  [ 0.88007886 -1.08725576  0.25025128 -0.69548464  0.80874413 -0.65012668\n",
      "  0.9029938  -1.09114811  0.10728407]  energy_before :  60  energy_after :  50  reward :  -188.57466304854108\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n",
      "action : 1  next_temperatures :  [ 1.37197657  0.25891165  1.31536832 -0.24371494  1.16267178 -0.32032631\n",
      "  1.39251014  0.10897794  1.19231824]  energy_before :  50  energy_after :  60  reward :  -201.76130661086262\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "action : 1  next_temperatures :  [-1.05015267 -0.84432573 -1.6467645   0.19155657 -0.98581861 -0.52619549\n",
      " -0.8103134  -0.97597286 -0.55592145]  energy_before :  60  energy_after :  60  reward :  -205.2039081272639\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "action : 1  next_temperatures :  [ 1.12914099 -0.6432802   0.54144842 -0.32690796  1.21252075 -0.29267225\n",
      "  1.29460687 -0.53600343  0.81747417]  energy_before :  60  energy_after :  70  reward :  -204.80367263116216\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "action : 1  next_temperatures :  [ 0.25742353 -0.9038017  -0.20576213 -0.34165103 -0.2829482  -1.02704139\n",
      " -0.20984002 -1.15794975 -0.59206344]  energy_before :  70  energy_after :  40  reward :  -172.4636341246777\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "action : 1  next_temperatures :  [ 0.31968906  1.06560687  0.66066335  0.66497284 -0.10016866  1.57346525\n",
      " -0.41870032  1.95178186 -0.48363747]  energy_before :  40  energy_after :  110  reward :  -262.7663272277272\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "action : 1  next_temperatures :  [1.99463191 3.24276249 1.61829151 3.04843539 2.00511929 2.0763596\n",
      " 1.68132478 2.64974384 1.87462737]  energy_before :  110  energy_after :  50  reward :  -117.80870381910233\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "action : 1  next_temperatures :  [-0.55825495 -1.28830129 -0.02335676 -1.68408921 -0.38264613 -1.30358207\n",
      " -0.07603889 -1.11187965 -0.48363747]  energy_before :  50  energy_after :  40  reward :  -194.91178642919618\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "action : 1  next_temperatures :  [-1.36148033  0.93995341 -0.72105728  0.80585104 -1.1303806   1.73836543\n",
      " -2.08305589  1.69839632 -1.56789717]  energy_before :  40  energy_after :  90  reward :  -249.68130506984224\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "action : 1  next_temperatures :  [ 1.19140653 -1.29919126  0.70626469 -1.25162591  0.66418213 -1.12229429\n",
      "  0.9960019  -1.22014438  0.64941392]  energy_before :  90  energy_after :  60  reward :  -168.68598666540223\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "action : 1  next_temperatures :  [-0.80731709  0.68864648 -0.25136347  0.16452762 -0.68672482  0.78276374\n",
      " -0.85926503  0.9359362  -0.26678553]  energy_before :  60  energy_after :  80  reward :  -218.2995818915433\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "action : 1  next_temperatures :  [-0.16183106 -0.56788812  1.07563555 -1.08617593 -0.20485149 -0.83448714\n",
      "  0.45753393 -0.76635392 -0.32099851]  energy_before :  80  energy_after :  80  reward :  -200.40941668300385\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "action : 1  next_temperatures :  [-2.05262775  0.71126411 -1.29563417  0.8549946  -1.57902129  0.93639745\n",
      " -1.78934608  1.0150232  -1.4648925 ]  energy_before :  80  energy_after :  50  reward :  -172.6638424270277\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "action : 1  next_temperatures :  [-0.42749733  1.07314607 -0.33800601  1.1326557  -0.38264613  1.00092361\n",
      " -0.22778895  1.09027103 -0.59206344]  energy_before :  50  energy_after :  70  reward :  -215.67100545454682\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "action : 1  next_temperatures :  [-1.8596046  -0.41040245 -1.11778894 -0.48826264 -1.77841715  0.26040912\n",
      " -1.60577745 -0.21581625 -1.7901704 ]  energy_before :  70  energy_after :  50  reward :  -187.00583076753452\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "action : 1  next_temperatures :  [ 0.31968906 -0.13312715  0.70626469 -0.48007205  0.11584352 -0.25887283\n",
      "  0.36452582 -0.16974615  0.37834899]  energy_before :  50  energy_after :  60  reward :  -207.15714608640192\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "action : 1  next_temperatures :  [-0.3652318  -0.5452705  -0.93538358  0.26527191  0.46478627 -0.84268094\n",
      " -0.56555523 -0.35172303 -0.04993359]  energy_before :  60  energy_after :  400  reward :  -540.9257204851492\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "action : 1  next_temperatures :  [-0.98788713 -0.52767901 -0.30912517 -0.92318313 -1.1303806  -0.90720709\n",
      " -0.14130773 -0.88997534 -0.92276265]  energy_before :  400  energy_after :  50  reward :  145.2604921403667\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "action : 1  next_temperatures :  [-0.77796334 -0.50039426 -0.59858511 -0.44976686 -0.88113578 -0.44630596\n",
      " -0.87325121 -0.65841826 -0.86312836]  energy_before :  50  energy_after :  60  reward :  -214.04894912985077\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "action : 1  next_temperatures :  [-0.738825   -0.84432573 -1.20443149 -0.15490551 -1.08053164 -0.60685319\n",
      "  0.31557419 -0.74562237 -0.80891538]  energy_before :  60  energy_after :  270  reward :  -413.8688361218861\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "action : 1  next_temperatures :  [ 0.06440038 -0.23448761 -0.10999931 -0.02303696  0.75889517 -0.89594062\n",
      " -0.36974869 -0.41391767  0.10728407]  energy_before :  270  energy_after :  50  reward :  20.88344875116283\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "action : 1  next_temperatures :  [ 0.31968906 -0.36935565 -0.35320646  0.21367117  1.25738481 -0.61837572\n",
      "  0.65823563 -0.83545906  0.63315002]  energy_before :  50  energy_after :  50  reward :  -197.09426619346462\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "action : 1  next_temperatures :  [-0.30296627  0.74644708  0.16360874  0.56750479 -0.86451946  1.63389451\n",
      " -0.76625693  1.37590564 -0.86312836]  energy_before :  50  energy_after :  120  reward :  -266.3095102759177\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "action : 1  next_temperatures :  [-1.36148033  0.18603264 -1.20443149  0.34717784 -1.03068267  0.42735775\n",
      " -1.15297484  0.14583402 -0.93179814]  energy_before :  120  energy_after :  70  reward :  -152.5749652241706\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "action : 1  next_temperatures :  [2.06312399 0.95503182 1.35988391 1.19654233 2.15965108 0.35083353\n",
      " 2.21979276 0.84609951 2.11858581]  energy_before :  70  energy_after :  30  reward :  -144.73045526361196\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "action : 1  next_temperatures :  [-2.36395542 -1.16432321 -1.6330841  -0.8814111  -2.02766197 -0.56614025\n",
      " -2.03410425 -0.69724877 -1.60705099]  energy_before :  30  energy_after :  180  reward :  -360.9749800651871\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "action : 1  next_temperatures :  [-0.98788713 -1.14589404 -1.20443149 -0.70654194 -0.78143785 -1.01679914\n",
      " -0.50354982 -1.0427745  -0.80891538]  energy_before :  180  energy_after :  50  reward :  -76.19823130462396\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "action : 1  next_temperatures :  [-1.51091761 -1.31510737 -0.59641361 -1.69309887 -1.09714796 -0.74230691\n",
      " -0.90821667 -1.41978147 -1.31490324]  energy_before :  50  energy_after :  60  reward :  -218.59789369963494\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n",
      "action : 1  next_temperatures :  [-0.49598942  0.18603264 -1.11778894  1.05894036  0.36508834  0.10677541\n",
      " -0.12499052 -0.04612472  0.3295573 ]  energy_before :  60  energy_after :  50  reward :  -187.73849954188788\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "action : 1  next_temperatures :  [0.77215194 1.42330038 0.43265665 1.5995195  1.29061746 0.63117848\n",
      " 0.31557419 0.50748429 0.7036269 ]  energy_before :  50  energy_after :  20  reward :  -160.32389021875014\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "action : 1  next_temperatures :  [-0.67655947  0.56299302 -0.20576213  0.04166872 -0.63189095  0.54002247\n",
      " -0.8103134   0.45450368 -0.3806328 ]  energy_before :  20  energy_after :  60  reward :  -239.10597084636933\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "action : 1  next_temperatures :  [ 0.06440038  0.57053223 -0.53561182  1.42751705  0.36508834  0.11804188\n",
      "  0.41347746  0.24488473  0.64941392]  energy_before :  60  energy_after :  370  reward :  -504.68225584206124\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "action : 1  next_temperatures :  [ 1.46122384 -0.5285167   1.92686058 -1.39823752  1.41191661 -0.36103925\n",
      "  1.60463389 -0.10601585  0.43256198]  energy_before :  370  energy_after :  50  reward :  126.44338757648373\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "action : 1  next_temperatures :  [ 0.31968906 -0.16831012 -0.02335676  0.26527191  0.46478627 -0.44630596\n",
      "  0.75124373 -0.021554    0.16149705]  energy_before :  50  energy_after :  50  reward :  -196.69703880733258\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "action : 1  next_temperatures :  [ 0.5687512   0.43733956  1.94206103 -0.92318313  0.46478627  0.01459518\n",
      "  1.39251014 -0.07530245  0.87168715]  energy_before :  50  energy_after :  70  reward :  -213.306755039762\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "action : 1  next_temperatures :  [-0.32372145  1.13848587 -0.29240467  1.04993071 -0.16995721  1.34711158\n",
      " -0.03198241  1.14555515 -0.61194153]  energy_before :  70  energy_after :  40  reward :  -164.74892397278214\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "action : 1  next_temperatures :  [-0.71806982 -0.9532254  -0.58121317 -1.03129896 -0.43747999 -1.26466153\n",
      " -0.45459819 -0.76635392 -0.65169772]  energy_before :  40  energy_after :  60  reward :  -224.85859869350807\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "action : 1  next_temperatures :  [-0.59561427 -0.6432802  -1.16339028  0.26527191  0.43155363 -0.78122745\n",
      " -0.68140743 -0.47457663 -0.12763887]  energy_before :  60  energy_after :  50  reward :  -191.77030959345848\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "action : 1  next_temperatures :  [-0.07465931  0.3116861  -0.66177553  1.27926732 -0.68672482 -0.10523912\n",
      "  0.01696922 -0.40009664 -0.41677479]  energy_before :  50  energy_after :  40  reward :  -188.73734756781832\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "action : 1  next_temperatures :  [-1.96338049 -0.9448485  -1.14818984 -1.08617593 -2.07751094 -0.40226429\n",
      " -1.20682164 -0.88997534 -1.49199899]  energy_before :  40  energy_after :  70  reward :  -239.21116595139637\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "action : 1  next_temperatures :  [-0.42749733  0.41220887 -0.07959842  0.27264344 -0.73657378  1.59497397\n",
      " -1.20682164  1.00734485 -0.83602187]  energy_before :  70  energy_after :  90  reward :  -217.99934190691354\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "action : 1  next_temperatures :  [ 0.06440038  0.62833282 -0.56601272  1.51597545  0.38170466  0.14979285\n",
      "  0.41347746  0.29095483  0.7036269 ]  energy_before :  90  energy_after :  50  reward :  -154.41774736876127\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "action : 1  next_temperatures :  [ 0.37572804 -0.40286324  0.70626469 -0.91581159  0.06100966 -0.58662475\n",
      "  0.07081602 -0.65117867  0.27534432]  energy_before :  50  energy_after :  80  reward :  -229.06731552655532\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "action : 1  next_temperatures :  [-0.30296627 -0.01501289 -0.00815632 -0.299879   -0.51723834  1.07159512\n",
      " -0.47254712  0.67717582 -0.70591071]  energy_before :  80  energy_after :  50  reward :  -168.57293971101134\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "action : 1  next_temperatures :  [-0.42749733 -0.56034891 -1.11778894  0.36355902 -0.15167926 -0.81502687\n",
      "  0.16871929 -0.86672091  0.14342606]  energy_before :  50  energy_after :  70  reward :  -221.26335786619825\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "action : 1  next_temperatures :  [-0.86958262 -0.92977009 -0.88978224 -0.69548464 -0.42181317 -0.99631465\n",
      " -1.15297484 -0.65117867 -1.29683224]  energy_before :  70  energy_after :  60  reward :  -195.90373316299187\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "action : 1  next_temperatures :  [ 1.43157358 -0.08825091  1.19159325 -0.22967392  1.32788549 -0.33130015\n",
      "  1.42957352  0.04316352  0.94371298]  energy_before :  60  energy_after :  50  reward :  -182.28172264205577\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "action : 1  next_temperatures :  [ 1.99463191 -1.9081917   1.46780708 -2.28036438  0.66418213 -2.58693568\n",
      "  1.95871738 -1.48965445  2.33001645]  energy_before :  50  energy_after :  70  reward :  -217.8497912651006\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "action : 2  next_temperatures :  [-0.27845962 -0.69876926  0.32302402 -0.7004704  -0.52917232 -0.75526519\n",
      "  0.85869227 -0.29616004 -0.02576732]  energy_before :  70  energy_after :  20  reward :  -159.10234786462723\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "action : 1  next_temperatures :  [-0.67655947 -0.9448485  -0.36840691 -0.56279704 -0.40092408 -1.46745803\n",
      " -0.41870032 -0.82778071 -0.43484578]  energy_before :  20  energy_after :  100  reward :  -284.1023208516989\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "action : 1  next_temperatures :  [ 0.14949661 -0.41961704 -0.29240467 -0.24254485 -0.08355234 -0.59993967\n",
      "  0.549563   -0.77648934  0.43256198]  energy_before :  100  energy_after :  30  reward :  -129.28292633093022\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "action : 1  next_temperatures :  [0.5687512  0.25891165 0.16360874 0.64859166 0.55949931 0.16822889\n",
      " 0.85404217 0.15504804 0.64941392]  energy_before :  30  energy_after :  70  reward :  -233.97390444153257\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "action : 1  next_temperatures :  [-0.67655947 -0.67092396 -0.74841808 -0.47188146 -0.63189095 -0.10523912\n",
      " -0.71730529 -0.53600343 -0.82698637]  energy_before :  70  energy_after :  60  reward :  -193.3852081286867\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "action : 1  next_temperatures :  [-0.11616967  0.3770259   0.72450523  0.07606921  0.26040552 -0.28140577\n",
      "  1.14775197  0.35314946  0.43256198]  energy_before :  60  energy_after :  60  reward :  -195.02610617474727\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "action : 1  next_temperatures :  [ 0.92158922 -0.14988094  0.54361991 -0.52348219  1.78910711 -1.24212859\n",
      "  0.9029938  -0.86079762  0.64941392]  energy_before :  60  energy_after :  60  reward :  -195.9695653898515\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "action : 1  next_temperatures :  [-0.47315873 -0.71867227 -0.58121317 -0.61931213 -0.68672482 -0.13058868\n",
      " -0.61450686 -0.63044713 -0.79084438]  energy_before :  60  energy_after :  240  reward :  -383.24546816116924\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "action : 1  next_temperatures :  [-0.11616967  0.12739436  1.33100306 -0.73561855  0.06100966 -0.25887283\n",
      "  0.26172739 -0.09910533  0.83590658]  energy_before :  240  energy_after :  50  reward :  -6.592725324188706\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "action : 1  next_temperatures :  [ 0.0083614   1.08822449 -0.15560065  1.54300441  0.41493731  0.76432769\n",
      "  0.07081602  1.1225201   0.10728407]  energy_before :  50  energy_after :  60  reward :  -203.03612517330296\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "action : 1  next_temperatures :  [-1.71846939 -0.67092396 -1.08434796 -0.71759925 -1.54578864  0.30342656\n",
      " -2.13200752 -0.19047769 -1.56789717]  energy_before :  60  energy_after :  60  reward :  -207.32408502001903\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "action : 1  next_temperatures :  [-0.98788713 -0.09040497 -0.83962076  0.19155657 -0.73657378 -0.07451237\n",
      " -1.0110151  -0.0545709  -0.53785045]  energy_before :  60  energy_after :  60  reward :  -202.14087890718434\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "action : 1  next_temperatures :  [-1.65205282 -0.62066257 -1.52364088 -0.08856171 -0.98581861 -0.41250654\n",
      " -1.59353955 -0.42082818 -0.86312836]  energy_before :  60  energy_after :  40  reward :  -186.16073921549875\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "action : 1  next_temperatures :  [-1.47148277  0.11817977 -0.70737688 -0.16227704 -1.48430825  0.8472899\n",
      " -0.84294782  0.25333092 -1.19382757]  energy_before :  40  energy_after :  70  reward :  -232.64341974925424\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "action : 1  next_temperatures :  [-0.28428661 -1.12327642 -0.97642479 -0.52348219  0.11584352 -0.91642512\n",
      " -0.22778895 -1.09114811  0.0042794 ]  energy_before :  70  energy_after :  150  reward :  -283.02270926353856\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n",
      "action : 1  next_temperatures :  [0.37572804 0.97178562 0.66066335 0.6995781  0.21554145 0.7005697\n",
      " 0.21277576 1.37590564 0.10728407]  energy_before :  150  energy_after :  50  reward :  -92.68016828043633\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n",
      "action : 1  next_temperatures :  [ 0.81781333 -1.32180888  1.25804092 -1.86592038  0.41493731 -1.14994836\n",
      "  0.9960019  -1.17177078  0.76326118]  energy_before :  50  energy_after :  50  reward :  -199.25939375506996\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "action : 1  next_temperatures :  [-0.49598942  0.06791839 -0.29240467  0.14241301 -0.58204199  0.10677541\n",
      "  0.21767092  0.28404432 -0.68783971]  energy_before :  50  energy_after :  30  reward :  -179.23945375050403\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "action : 1  next_temperatures :  [ 0.43799358 -0.2755344   0.43265665 -0.4006233   0.21554145 -0.29267225\n",
      "  0.29762526 -0.28492139  0.39641999]  energy_before :  30  energy_after :  50  reward :  -217.4735144257433\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "action : 1  next_temperatures :  [-0.30296627  0.93995341  1.48604762 -0.31052678 -0.20485149  0.42735775\n",
      "  0.03491815  0.86683105 -0.10956787]  energy_before :  50  energy_after :  50  reward :  -195.1728044209664\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "action : 1  next_temperatures :  [-2.05262775 -0.36935565 -1.32907516 -0.4006233  -1.87811508  0.01459518\n",
      " -2.23480595 -0.12137255 -1.83625144]  energy_before :  50  energy_after :  50  reward :  -208.2076316970983\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "action : 1  next_temperatures :  [ 1.99463191  0.27734082  4.00932182 -2.09607604  1.91040625 -0.18021237\n",
      "  2.07783302 -0.11446203  1.88366287]  energy_before :  50  energy_after :  50  reward :  -188.23755374460026\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "action : 1  next_temperatures :  [ 0.12666591  0.58561065 -0.44896928  1.2555146   0.61433317 -0.01305889\n",
      "  0.50648556  0.12970949  0.63315002]  energy_before :  50  energy_after :  40  reward :  -184.6105587763066\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "action : 1  next_temperatures :  [-0.16183106 -1.23133839 -0.56601272 -1.18446304 -0.93596964 -0.59993967\n",
      " -0.61450686 -0.94295596 -0.24871453]  energy_before :  40  energy_after :  80  reward :  -244.48573187731498\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "action : 1  next_temperatures :  [ 0.195158   -1.55049818 -0.06439797 -1.28275016 -0.73657378 -0.9778786\n",
      " -0.24410616 -1.40365694  0.31148631]  energy_before :  80  energy_after :  60  reward :  -183.7532174840499\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "action : 1  next_temperatures :  [ 0.50648566 -0.03344207  1.11667676 -0.66108415  0.41493731 -0.25887283\n",
      "  0.60928399  0.12279897  0.7036269 ]  energy_before :  60  energy_after :  90  reward :  -225.47958945320855\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "action : 1  next_temperatures :  [-0.40674216 -1.84117652 -0.47937017 -1.75207113  0.33767141 -1.2590283\n",
      " -0.27674059 -1.72614762 -0.26678553]  energy_before :  90  energy_after :  90  reward :  -205.67039060139194\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "action : 1  next_temperatures :  [-0.18466176 -1.2715475  -0.97642479 -0.37359434  0.18230881 -1.35684176\n",
      "  0.09039667 -1.45740538  0.37834899]  energy_before :  90  energy_after :  40  reward :  -152.96942105795378\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n",
      "action : 1  next_temperatures :  [ 0.43799358  0.44571646  0.43265665 -0.34165103  0.06100966 -0.66139315\n",
      "  0.60928399 -0.48734189  0.92047884]  energy_before :  40  energy_after :  60  reward :  -216.58324689450004\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "action : 1  next_temperatures :  [-0.30296627 -0.09961956  0.00704413 -0.2114206  -0.79805417  0.92717943\n",
      " -0.8103134   0.85992054 -0.3806328 ]  energy_before :  60  energy_after :  120  reward :  -258.8088626938313\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "action : 1  next_temperatures :  [-2.17093226 -0.2755344  -1.4324382  -0.18602976 -1.96618158  0.05863684\n",
      " -2.35228988  0.00416847 -1.91124607]  energy_before :  120  energy_after :  90  reward :  -178.2318468387675\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "action : 1  next_temperatures :  [1.12914099 1.53387543 0.61962214 1.70599721 1.36206764 0.49802926\n",
      " 0.56033236 1.30680049 0.88388508]  energy_before :  90  energy_after :  50  reward :  -148.40024940131244\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "action : 1  next_temperatures :  [-1.18091029 -0.28474899 -0.66177553 -0.31626019 -1.14865856  0.11804188\n",
      " -0.53618425 -0.75253289 -0.79084438]  energy_before :  50  energy_after :  100  reward :  -253.55387319596335\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "action : 1  next_temperatures :  [-1.19958995  1.45764566 -0.61161406  1.2555146  -1.18521446  1.83054566\n",
      " -1.05507157  1.88267671 -1.11612229]  energy_before :  100  energy_after :  60  reward :  -156.7412297054055\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "action : 1  next_temperatures :  [-0.24692729 -0.49500911 -0.79401942  0.33653007  0.26040552 -0.29267225\n",
      " -0.47254712 -0.02923235  0.10728407]  energy_before :  60  energy_after :  70  reward :  -209.6261878925166\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "action : 1  next_temperatures :  [ 0.68705571 -0.62820178  0.20464994 -0.72578984  0.19892513 -1.06084081\n",
      " -0.33711427 -0.63812548  0.3458212 ]  energy_before :  70  energy_after :  100  reward :  -229.95362019263504\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "action : 1  next_temperatures :  [2.24369404 1.49115325 1.71405433 1.21374257 1.80572343 0.90874338\n",
      " 1.63726831 1.40508336 2.63360916]  energy_before :  100  energy_after :  50  reward :  -132.94692816175927\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n",
      "action : 1  next_temperatures :  [-0.55825495  0.83691757 -0.38360736  1.05156883 -0.18823517  0.91980501\n",
      " -0.61450686  1.28146193 -0.85228577]  energy_before :  50  energy_after :  40  reward :  -186.50713675967728\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "action : 1  next_temperatures :  [-0.42749733  1.04801538 -0.00815632  0.36355902 -0.33279717  1.64157619\n",
      "  0.16708756  1.25842689 -0.22461987]  energy_before :  40  energy_after :  80  reward :  -234.5144056428084\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "action : 1  next_temperatures :  [-0.18466176  0.26812624 -0.05375766  0.83779436  0.21554145 -0.35412573\n",
      "  0.9029938   0.15504804  0.37834899]  energy_before :  80  energy_after :  110  reward :  -225.83469226975552\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "action : 1  next_temperatures :  [-0.5167446  -1.73311454 -0.55081227 -1.63658377 -1.03068267 -1.3957623\n",
      " -0.71730529 -1.46738724 -1.19382757]  energy_before :  110  energy_after :  40  reward :  -138.2422202640936\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "action : 1  next_temperatures :  [-1.05015267 -0.01501289 -0.85634126  0.14241301 -0.79805417 -0.14825656\n",
      " -1.05507157 -0.07530245 -0.59206344]  energy_before :  40  energy_after :  60  reward :  -222.44784198502396\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "action : 1  next_temperatures :  [-1.18091029 -1.2305007  -0.58121317 -1.3564655  -1.08053164 -1.08849487\n",
      " -0.79562791 -1.26621448 -1.18530839]  energy_before :  60  energy_after :  90  reward :  -237.76526693552256\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "action : 1  next_temperatures :  [ 0.50648566 -1.39720096 -0.23616302 -0.86502992  0.61433317 -0.6798292\n",
      "  0.80509053 -1.41133529  0.64941392]  energy_before :  90  energy_after :  90  reward :  -200.01423510719604\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "action : 1  next_temperatures :  [-1.11864475 -0.43553314 -1.47803954  0.19155657 -0.76648316 -0.52619549\n",
      " -1.20682164 -0.52064673 -0.70591071]  energy_before :  90  energy_after :  60  reward :  -174.56671857705945\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "action : 1  next_temperatures :  [-1.11864475 -1.22128612 -1.6604449  -0.04678968 -1.09714796 -0.85292318\n",
      " -0.71730529 -0.7748001  -0.92276265]  energy_before :  60  energy_after :  60  reward :  -206.4121046339341\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "action : 1  next_temperatures :  [ 0.37572804 -0.3165812   0.43265665 -0.3342795   0.27702184 -0.41250654\n",
      "  0.18340478  0.25333092  0.3295573 ]  energy_before :  60  energy_after :  60  reward :  -197.2116677098658\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "action : 1  next_temperatures :  [ 1.30971104 -1.40641555  0.9342714  -1.51372488  0.66418213 -1.1806751\n",
      "  1.0498487  -1.32149859  0.92047884]  energy_before :  60  energy_after :  50  reward :  -188.54382201233986\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "action : 1  next_temperatures :  [ 0.31968906  0.50435474  0.30041276  0.28165309  1.16267178 -0.38485247\n",
      "  0.11976765  0.51439481  0.64941392]  energy_before :  50  energy_after :  50  reward :  -194.5324946616612\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n",
      "action : 1  next_temperatures :  [-0.42749733 -0.55029664 -0.38360736 -0.59474035 -0.04741184 -0.72899199\n",
      " -1.04038608 -0.88152916 -1.24804056]  energy_before :  50  energy_after :  60  reward :  -213.90250130199223\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n",
      "action : 1  next_temperatures :  [ 1.56499973 -0.56034891  0.98443287 -0.44976686  1.19590442 -0.42377301\n",
      "  1.43656661 -0.51527188  0.87168715]  energy_before :  60  energy_after :  100  reward :  -233.8955698761953\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "action : 1  next_temperatures :  [ 0.31968906  0.13325819 -0.29240467  0.8549946   0.27702184  0.14057482\n",
      " -0.17394215 -0.100641    0.24281653]  energy_before :  100  energy_after :  90  reward :  -186.59863278558834\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "action : 1  next_temperatures :  [-0.47315873 -0.6432802  -0.93538358  0.04166872  0.16569248 -0.71977397\n",
      "  0.38410648 -0.90686771  0.16149705]  energy_before :  90  energy_after :  60  reward :  -170.92549944971685\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "action : 1  next_temperatures :  [1.93236637 1.69387417 1.03003421 2.26085138 1.93034584 1.30819104\n",
      " 2.07783302 1.16628669 2.29387446]  energy_before :  60  energy_after :  90  reward :  -212.3063428279375\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "action : 1  next_temperatures :  [ 0.12666591  0.6300082  -0.02335676  1.36281136  0.52626666 -0.20049202\n",
      "  0.21277576  0.55432222  0.60062223]  energy_before :  90  energy_after :  70  reward :  -174.2103764322124\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "action : 1  next_temperatures :  [ 0.12666591  1.01283241  0.11800739  0.95082454 -0.13340131  1.46182475\n",
      "  0.7022921   1.42197573 -0.53785045]  energy_before :  70  energy_after :  100  reward :  -222.87682892420372\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "action : 1  next_temperatures :  [-0.11616967  0.33430373 -0.70737688  1.3329157  -0.70334114 -0.13903853\n",
      "  0.03491815 -0.40700715 -0.43484578]  energy_before :  100  energy_after :  190  reward :  -288.8056415728797\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "action : 1  next_temperatures :  [ 0.5687512   0.25891165  0.66066335 -0.1450768   1.07626691 -0.6798292\n",
      "  0.75124373  0.06398281  0.60062223]  energy_before :  190  energy_after :  50  reward :  -54.84446411635909\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "action : 1  next_temperatures :  [ 1.19140653  0.20111106  1.25804092 -0.1450768   0.77551149  1.16377535\n",
      "  0.36452582  0.89908012  1.07287756]  energy_before :  50  energy_after :  60  reward :  -201.21874795348765\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "action : 1  next_temperatures :  [ 1.68330424 -0.29396358  1.61829151 -0.79131458  1.46176557 -0.42377301\n",
      "  1.63726831  0.32397173  1.95594685]  energy_before :  60  energy_after :  230  reward :  -360.82850295419496\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "action : 1  next_temperatures :  [-0.24692729 -0.01501289  0.03896507 -0.31789831 -0.51723834  1.07159512\n",
      " -0.41870032  0.66949747 -0.70591071]  energy_before :  230  energy_after :  120  reward :  -88.4416302020665\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "action : 1  next_temperatures :  [-0.61429393 -0.87196949 -0.56601272 -0.66845569 -0.84374906 -0.99631465\n",
      " -0.90821667 -0.51527188 -1.13419329]  energy_before :  120  energy_after :  90  reward :  -175.11847737502285\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "action : 1  next_temperatures :  [ 0.9423444  -1.40641555  0.95433599 -1.642481    0.79450157 -1.62928554\n",
      "  1.34355851 -1.28157118  1.95594685]  energy_before :  90  energy_after :  50  reward :  -157.96906595712548\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "action : 1  next_temperatures :  [ 0.50648566  0.57053223  0.91907095 -0.03778003  0.11584352  0.39560679\n",
      "  0.31557419  0.79235106  0.05849238]  energy_before :  50  energy_after :  60  reward :  -204.36382325226265\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "action : 1  next_temperatures :  [-0.42749733  0.10142598 -0.35320646 -0.16964858  0.19892513  0.92922788\n",
      " -0.71730529 -0.06148142 -0.65169772]  energy_before :  60  energy_after :  80  reward :  -219.15125782192138\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "action : 1  next_temperatures :  [-0.26560695 -0.77898593 -0.26504387 -0.78394305 -0.71995746 -0.5886732\n",
      " -0.32079706 -0.47457663 -0.86312836]  energy_before :  80  energy_after :  90  reward :  -213.06071250510016\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "action : 1  next_temperatures :  [1.83047732 2.56207104 1.70953527 2.01704789 2.34672065 1.65121322\n",
      " 1.50717163 1.95014243 1.77035285]  energy_before :  90  energy_after :  40  reward :  -130.6552677114053\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "action : 1  next_temperatures :  [1.85594958 2.4039533  1.77978599 1.78481137 2.30144873 1.49785884\n",
      " 1.52701688 1.86254698 1.79452891]  energy_before :  40  energy_after :  100  reward :  -241.19209942075017\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "action : 1  next_temperatures :  [-0.11616967 -0.39197328 -0.52041138  0.321787   -0.03370338 -0.59993967\n",
      " -0.27674059 -0.21581625 -0.04993359]  energy_before :  100  energy_after :  150  reward :  -249.88290079019362\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "action : 1  next_temperatures :  [-0.11616967 -1.26400829 -0.88978224 -0.4227379   0.16569248 -1.3957623\n",
      "  0.11976765 -1.48274394  0.37834899]  energy_before :  150  energy_after :  50  reward :  -102.9073952091907\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "action : 1  next_temperatures :  [-1.05015267 -0.20768153 -0.70737688 -0.43911909 -0.10016866 -0.28140577\n",
      " -0.6634585  -0.74562237 -0.70591071]  energy_before :  50  energy_after :  60  reward :  -212.90089617073968\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "action : 1  next_temperatures :  [ 1.19140653  0.15084967  1.30364226 -0.19503942  0.75889517  1.15455732\n",
      "  0.36452582  0.86683105  1.29274134]  energy_before :  60  energy_after :  130  reward :  -261.1115902545484\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "action : 1  next_temperatures :  [-0.30296627  0.18603264 -1.02202613  1.22357128  0.66418213  0.0483946\n",
      "  0.22909297 -0.16974615  0.43256198]  energy_before :  130  energy_after :  50  reward :  -116.71090294679263\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "action : 1  next_temperatures :  [ 0.12666591  0.91230964 -0.27872427  1.4848512  -0.08355234  0.00742561\n",
      "  0.18340478  0.09362124  0.10728407]  energy_before :  50  energy_after :  140  reward :  -285.4467141665966\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "action : 1  next_temperatures :  [-1.23694927 -0.99762296 -1.26523328 -0.41536637 -0.98581861 -1.01679914\n",
      " -1.22313885 -0.65117867 -0.48363747]  energy_before :  140  energy_after :  100  reward :  -166.27574460032082\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n",
      "action : 1  next_temperatures :  [-0.05390414  1.022047   -0.23616302  1.50123238  0.41493731  0.76432769\n",
      "  0.07081602  1.06800381  0.10728407]  energy_before :  100  energy_after :  50  reward :  -143.34141887105372\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "action : 1  next_temperatures :  [ 0.64969639 -1.95007619  0.16360874 -1.8896731  -0.29956452 -1.7142962\n",
      "  0.75124373 -1.28080334 -0.43484578]  energy_before :  50  energy_after :  90  reward :  -244.00471026643714\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "action : 1  next_temperatures :  [ 0.21591317  1.27419161  0.6044217   0.72312605  0.06100966  1.34147834\n",
      " -0.22778895  1.52179428 -0.56796878]  energy_before :  90  energy_after :  100  reward :  -203.0538229178887\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "action : 1  next_temperatures :  [ 0.68705571  0.84613215  0.9342714   0.49460851  0.07014863  1.24929811\n",
      " -0.17394215  1.69839632 -0.48363747]  energy_before :  100  energy_after :  60  reward :  -152.67766878428824\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "action : 1  next_temperatures :  [ 1.06064891  0.17765574  1.71405433 -0.81834354  1.00813999 -0.10523912\n",
      "  1.29460687  0.00762373  0.84845302]  energy_before :  60  energy_after :  60  reward :  -192.8124000678511\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "action : 1  next_temperatures :  [ 0.0083614  -1.13835483  0.52841946 -1.72504218  0.06100966 -1.36810823\n",
      "  0.80509053 -1.1549881   0.27534432]  energy_before :  60  energy_after :  70  reward :  -211.70826797048204\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "action : 1  next_temperatures :  [-0.24692729 -0.86275491 -0.10999931 -0.81834354 -0.73657378 -0.84268094\n",
      " -0.20984002 -1.15103923  0.58977963]  energy_before :  70  energy_after :  50  reward :  -182.38837938014404\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "action : 1  next_temperatures :  [-1.34072515  1.17450653 -0.70737688  0.92870994 -1.18521446  1.654379\n",
      " -1.29982974  1.07645    -1.29683224]  energy_before :  50  energy_after :  440  reward :  -588.9959330092984\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "action : 1  next_temperatures :  [-0.80731709 -0.84432573 -1.37619654  0.06869768 -1.03068267 -0.71977397\n",
      " -0.6634585  -0.95063431 -0.48363747]  energy_before :  440  energy_after :  30  reward :  205.19267140433396\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "action : 1  next_temperatures :  [-1.2992148  -0.78568745 -1.17707069 -0.48007205 -0.93596964 -0.62759374\n",
      " -0.22778895 -0.73564052 -0.78723018]  energy_before :  30  energy_after :  40  reward :  -215.05626801854675\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "action : 1  next_temperatures :  [-1.2992148  -0.76893366 -1.39139699 -0.13688621 -1.08053164 -0.14825656\n",
      " -0.6634585  -0.51527188 -1.0980513 ]  energy_before :  40  energy_after :  50  reward :  -215.10200152067802\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "action : 1  next_temperatures :  [-0.86958262 -0.56788812 -1.11778894 -0.14589586 -0.68672482  0.35566202\n",
      " -0.6634585  -0.33099149 -0.80891538]  energy_before :  50  energy_after :  60  reward :  -212.83558370239012\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "action : 1  next_temperatures :  [-0.49598942 -0.35092648 -0.49305057 -0.3342795  -0.08355234 -0.77200943\n",
      "  0.29762526 -0.98288338 -0.92276265]  energy_before :  60  energy_after :  40  reward :  -182.1378285032024\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "action : 1  next_temperatures :  [ 0.16091195  1.2666524   0.43265665 -0.21879213  0.07928761  1.8489817\n",
      " -1.05507157  1.4826347  -1.35104523]  energy_before :  40  energy_after :  290  reward :  -445.35378391945545\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "action : 1  next_temperatures :  [-1.2992148  -1.60746108 -1.25003283 -1.30977912 -1.2799275  -1.04957433\n",
      " -1.1040232  -1.34223014 -1.02576732]  energy_before :  290  energy_after :  150  reward :  -69.26801032286426\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "action : 1  next_temperatures :  [ 0.0083614  -1.2305007  -0.70737688 -0.57999728  0.16569248 -1.499209\n",
      "  0.16871929 -1.52651053  0.43256198]  energy_before :  150  energy_after :  240  reward :  -292.76825924785174\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "action : 1  next_temperatures :  [0.83856851 1.70895258 1.1049507  1.29588252 1.14605546 0.72131026\n",
      " 1.44880452 1.2774308  1.24575675]  energy_before :  240  energy_after :  60  reward :  -7.212287905722235\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "action : 1  next_temperatures :  [-0.98788713  0.97178562 -0.47937017  0.65719178 -1.23506343  1.48947882\n",
      " -0.47254712  0.82076096 -1.13419329]  energy_before :  60  energy_after :  60  reward :  -198.36984397553903\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "action : 1  next_temperatures :  [ 0.195158   -0.14066635  0.3460141  -0.49645324 -0.43747999  1.00092361\n",
      " -0.14130773  0.57658944 -0.59206344]  energy_before :  60  energy_after :  40  reward :  -177.68928560700206\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "action : 1  next_temperatures :  [-0.55825495  0.25137244 -0.15560065 -0.11149537 -0.63189095  0.9384459\n",
      "  0.45753393  0.37004183 -0.80891538]  energy_before :  40  energy_after :  110  reward :  -268.2487632019303\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "action : 1  next_temperatures :  [-0.96713196 -1.47259304 -1.41875779 -0.69548464 -0.08355234 -1.24212859\n",
      " -0.61450686 -1.41133529 -0.51977946]  energy_before :  110  energy_after :  100  reward :  -196.4252699631203\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "action : 1  next_temperatures :  [ 0.12666591 -1.2715475  -0.88978224 -0.34902256  0.41493731 -1.37732625\n",
      "  0.45753393 -1.52651053  0.64941392]  energy_before :  100  energy_after :  100  reward :  -201.7656380234732\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "action : 1  next_temperatures :  [-0.738825    1.37471438 -0.18904163  0.88611885 -0.70167951  3.35561631\n",
      " -1.1040232   1.68995014 -1.89317508]  energy_before :  100  energy_after :  110  reward :  -205.32034474450182\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "action : 1  next_temperatures :  [ 0.50648566  0.62079362  0.64698295  0.04166872  0.16569248  1.27746429\n",
      " -0.85926503  0.39921956 -0.16378086]  energy_before :  110  energy_after :  140  reward :  -225.3647386050295\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "action : 1  next_temperatures :  [ 1.56499973 -0.5452705   1.03003421 -0.47188146  1.21252075 -0.41250654\n",
      "  1.43656661 -0.51527188  0.87168715]  energy_before :  140  energy_after :  80  reward :  -133.82912192714517\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "action : 1  next_temperatures :  [ 0.37572804 -0.26631982  1.21243958 -0.96331703 -0.003794   -0.39202205\n",
      "  0.19809027 -0.24422614  0.05849238]  energy_before :  80  energy_after :  70  reward :  -188.02492876640548\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "action : 1  next_temperatures :  [ 9.42344395e-01 -2.84748990e-01  9.50991888e-01 -3.91613646e-01\n",
      " -5.17238335e-01  7.94030212e-01  6.52008481e-04  8.92169608e-01\n",
      "  7.48352613e-01]  energy_before :  70  energy_after :  50  reward :  -174.86506024670783\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "action : 1  next_temperatures :  [-0.11616967 -0.82757194 -0.70737688 -0.08119017  0.16569248 -1.01679914\n",
      "  0.53879364 -1.19112022  0.22113133]  energy_before :  50  energy_after :  40  reward :  -191.01461055799484\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "action : 1  next_temperatures :  [-1.49223795  1.64109971 -0.83962076  1.54300441 -1.23506343  1.85819973\n",
      " -1.29982974  2.04392205 -1.19382757]  energy_before :  40  energy_after :  50  reward :  -206.97435355458845\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "action : 1  next_temperatures :  [ 0.81781333  0.81429994  0.43265665  0.56013325  1.92702258  1.41983153\n",
      "  0.96336748 -0.34481252  1.08853909]  energy_before :  50  energy_after :  40  reward :  -180.3211486615185\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "action : 1  next_temperatures :  [-0.55825495  1.01283241 -0.06439797  0.52573276 -0.13340131  2.05485088\n",
      " -0.22778895  1.52716912 -0.16378086]  energy_before :  40  energy_after :  100  reward :  -254.027038861465\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "action : 1  next_temperatures :  [ 0.12666591 -0.87196949 -0.70737688 -0.078733    0.36508834 -0.91642512\n",
      "  0.54238343 -1.22014438  0.51930275]  energy_before :  100  energy_after :  50  reward :  -150.24120843017147\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "action : 1  next_temperatures :  [ 1.75179633  1.08822449  1.48604762  0.63827151  2.25436411 -0.22814609\n",
      "  1.88202648  0.96127475  1.64873994]  energy_before :  50  energy_after :  50  reward :  -186.5174008524574\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "action : 1  next_temperatures :  [ 0.58950637  0.19357185 -0.33800601  1.25920036  1.00813999 -0.13903853\n",
      "  0.15240207  0.50057378  0.74338309]  energy_before :  50  energy_after :  40  reward :  -184.03026703209264\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "action : 1  next_temperatures :  [ 2.12538953 -1.2715475   2.39807444 -2.38110867  1.96025522 -0.74005362\n",
      "  1.97503459 -0.9967044   2.66071566]  energy_before :  40  energy_after :  70  reward :  -222.2699447653822\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "action : 1  next_temperatures :  [-1.49223795  1.14016125 -0.70737688  0.87956638 -1.37962543  1.46182475\n",
      " -0.45459819  0.77699436 -0.94083364]  energy_before :  70  energy_after :  60  reward :  -188.71612534369794\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "action : 1  next_temperatures :  [0.99838337 1.33953141 0.49497848 1.6879779  1.27400114 0.4253093\n",
      " 0.50648556 1.26073039 0.90421494]  energy_before :  60  energy_after :  110  reward :  -239.10838749732662\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "action : 1  next_temperatures :  [ 0.9423444   0.3116861   0.25025128  0.87956638  1.08540589 -0.22814609\n",
      "  1.0498487   0.01453424  0.92047884]  energy_before :  110  energy_after :  30  reward :  -112.77403025556384\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "action : 1  next_temperatures :  [-1.18091029  1.80109845 -0.56601272  1.1326557  -1.08053164  1.85819973\n",
      " -0.8103134   1.62698767 -0.75470239]  energy_before :  30  energy_after :  710  reward :  -875.9735288850584\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "action : 1  next_temperatures :  [ 0.27817871  0.57974682 -0.02335676  1.00897775  0.84530004 -0.34285926\n",
      "  0.16871929  0.70558571  0.76326118]  energy_before :  710  energy_after :  60  reward :  455.98355347275634\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "action : 1  next_temperatures :  [ 0.0083614  -0.92809471  0.23505084 -1.05505167  1.71101039 -0.20766159\n",
      " -0.41870032 -0.30565294  0.25727332]  energy_before :  60  energy_after :  50  reward :  -188.70346528170916\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "action : 1  next_temperatures :  [ 0.25742353 -0.58464192 -0.25136347 -0.31789831 -0.48732896 -0.33159279\n",
      "  0.31557419 -0.7594434  -0.97697563]  energy_before :  50  energy_after :  60  reward :  -211.1362467473531\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "action : 1  next_temperatures :  [ 0.02704106  1.55984381  0.23505084  1.41113586  0.29363816  1.82030341\n",
      " -0.19189109  2.49617685  0.01933856]  energy_before :  60  energy_after :  80  reward :  -210.32936254485364\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "action : 1  next_temperatures :  [ 0.25742353 -0.77982362 -0.25136347 -0.44976686 -0.53219302 -0.45552398\n",
      "  0.36452582 -0.83776257 -0.70410361]  energy_before :  80  energy_after :  60  reward :  -181.38858777350973\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "action : 1  next_temperatures :  [-0.88826228 -0.47657994 -1.05242702 -0.14589586 -1.09714796 -0.71977397\n",
      "  0.01696922 -1.15103923 -1.19382757]  energy_before :  60  energy_after :  50  reward :  -194.70798460804144\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "action : 1  next_temperatures :  [-0.34447662 -1.07050196 -0.43376883 -0.86502992 -0.33279717 -1.36810823\n",
      "  0.10181872 -0.63044713 -0.21257254]  energy_before :  50  energy_after :  50  reward :  -203.15588368332362\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "action : 1  next_temperatures :  [ 0.1723273  -0.39197328 -0.88978224  0.5511236   0.09756556 -0.45552398\n",
      "  0.60928399 -0.46689828  0.51930275]  energy_before :  50  energy_after :  20  reward :  -168.25457456080716\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n",
      "action : 1  next_temperatures :  [0.8489461  2.69093438 2.13966684 0.93690053 1.75587446 1.7660195\n",
      " 1.40719563 1.67305777 1.57645596]  energy_before :  20  energy_after :  90  reward :  -253.20494884037205\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n",
      "action : 1  next_temperatures :  [-0.3652318  -0.3165812  -0.83962076  0.60927681 -0.23808413 -0.56614025\n",
      " -0.47254712 -0.19047769 -0.16378086]  energy_before :  90  energy_after :  90  reward :  -200.5431870110043\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "action : 1  next_temperatures :  [-1.2992148  -0.81919504 -1.16339028 -0.49645324 -0.68672482 -0.71977397\n",
      " -1.39773301 -0.47457663 -1.35104523]  energy_before :  90  energy_after :  50  reward :  -166.4081070074169\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "action : 1  next_temperatures :  [ 0.74932124  0.0829968   0.16360874  0.59846523  1.11282282 -0.62759374\n",
      "  0.9960019  -0.28492139  1.63066894]  energy_before :  50  energy_after :  40  reward :  -183.57862945678906\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "action : 1  next_temperatures :  [ 0.06440038  0.71126411  0.11800739  0.81322258 -0.33279717  0.90874338\n",
      "  0.26172739  0.78467271  0.15375234]  energy_before :  40  energy_after :  70  reward :  -224.51700688293647\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "action : 1  next_temperatures :  [-1.42997242 -0.89458712 -1.57380235 -0.12787655 -1.23506343 -0.81502687\n",
      " -0.17557387 -0.7748001  -1.19382757]  energy_before :  70  energy_after :  110  reward :  -246.22053028460192\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "action : 1  next_temperatures :  [ 0.0083614   0.87963974  0.02224458  1.00979681 -0.2829482   1.01935966\n",
      "  0.29762526  0.85147435  0.57676852]  energy_before :  110  energy_after :  80  reward :  -163.61767788976337\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "action : 1  next_temperatures :  [-0.61429393 -0.51762674 -0.50673098 -0.63733143 -0.31285758 -0.75357338\n",
      " -0.99469789 -0.69033825 -1.24804056]  energy_before :  80  energy_after :  30  reward :  -154.2754907393791\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "action : 1  next_temperatures :  [ 0.68705571  0.45409336  0.30041276  0.46839861  0.26040552  0.0483946\n",
      " -0.07603889 -0.61355476  0.27534432]  energy_before :  30  energy_after :  120  reward :  -286.1954887721311\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "action : 1  next_temperatures :  [-0.24692729  1.30015999  0.11800739  0.5511236   0.20169451  1.33960059\n",
      " -0.22778895  1.10985082 -0.59206344]  energy_before :  120  energy_after :  120  reward :  -194.44634276118225\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "action : 1  next_temperatures :  [-0.40674216 -0.69354158 -0.38360736 -0.82571507 -0.88113578 -0.71977397\n",
      " -0.47254712 -0.88152916  0.05849238]  energy_before :  120  energy_after :  40  reward :  -123.20609981231098\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "action : 1  next_temperatures :  [ 0.195158    0.83105374 -0.29240467  0.5027991  -0.53219302  0.48881124\n",
      "  0.26172739 -0.85235143 -0.97697563]  energy_before :  40  energy_after :  90  reward :  -248.37437529265256\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "action : 1  next_temperatures :  [-0.30296627 -0.41961704 -0.83962076  0.62483894 -0.16995721 -0.71977397\n",
      " -0.61450686 -0.31409912 -0.04993359]  energy_before :  90  energy_after :  80  reward :  -190.80563588261202\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "action : 1  next_temperatures :  [ 0.81781333  0.20278644  0.02224458  0.95082454  0.86357799 -0.35412573\n",
      "  0.94705027  0.17577959  0.81747417]  energy_before :  80  energy_after :  50  reward :  -163.55657483186397\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "action : 1  next_temperatures :  [ 0.81781333  0.83943064  0.3460141   1.15804654  1.53986228 -0.14825656\n",
      "  0.3318914   0.50057378  1.17527987]  energy_before :  50  energy_after :  60  reward :  -201.4393446253507\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "action : 1  next_temperatures :  [ 0.14949661  0.90560813  0.40529584  0.76407902 -0.08355234  1.75884993\n",
      " -0.87558224  1.30680049 -0.26076186]  energy_before :  60  energy_after :  60  reward :  -193.92976644280998\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "action : 2  next_temperatures :  [ 0.57250267 -0.69311486  0.66199399 -0.5776115  -0.03068267 -0.48794253\n",
      "  1.01696922 -0.34223014  0.02302437]  energy_before :  60  energy_after :  50  reward :  -196.85709146357817\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "action : 1  next_temperatures :  [-0.20541693  0.86456133  0.3460141   0.24070013 -0.58204199  0.93639745\n",
      " -0.8103134   1.38281615  0.85000196]  energy_before :  50  energy_after :  70  reward :  -214.97728120208623\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "action : 1  next_temperatures :  [ 0.31968906 -0.49500911 -0.26504387  0.12603183  0.31025448 -0.36795276\n",
      " -0.17394215  0.13815567  0.27534432]  energy_before :  70  energy_after :  70  reward :  -198.13247253513754\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "action : 1  next_temperatures :  [ 0.43799358 -0.62066257  0.70626469 -0.81834354 -0.53219302  0.10677541\n",
      " -0.30629287  0.43718473  0.3295573 ]  energy_before :  70  energy_after :  90  reward :  -218.2597162928292\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "action : 1  next_temperatures :  [ 1.87632739 -0.34171189  1.34468346 -0.46450992  1.66116143 -0.22814609\n",
      "  1.68132478 -0.40009664  1.57645596]  energy_before :  90  energy_after :  50  reward :  -151.2945115115431\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "action : 1  next_temperatures :  [ 0.14949661 -1.39720096 -0.29240467 -0.97150763 -0.33279717 -1.28514603\n",
      "  0.31394247 -1.28080334 -0.32099851]  energy_before :  50  energy_after :  80  reward :  -233.41741923407528\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "action : 1  next_temperatures :  [-1.49223795 -0.62066257 -1.25003283 -0.25073545 -0.88113578 -0.56614025\n",
      " -1.50053144 -0.28492139 -1.40525821]  energy_before :  80  energy_after :  390  reward :  -516.2516558833078\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "action : 1  next_temperatures :  [ 1.81406186  0.03357311  1.61829151 -0.63733143  1.49167495 -0.47396003\n",
      "  1.71395921  0.22261752  2.17279879]  energy_before :  390  energy_after :  120  reward :  79.95568548399532\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "action : 1  next_temperatures :  [-0.72325862 -0.80223182 -0.61161406 -0.63733143 -0.88113578 -0.99631465\n",
      " -0.90821667 -0.61355476 -1.13419329]  energy_before :  120  energy_after :  130  reward :  -215.30785107427727\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "action : 1  next_temperatures :  [-1.56903211 -0.47657994 -1.29563417 -0.03941815 -0.83128681 -0.47396003\n",
      " -1.54458791 -0.12137255 -1.40525821]  energy_before :  130  energy_after :  260  reward :  -335.75712988021746\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "action : 1  next_temperatures :  [ 1.09489495 -0.95992692  1.03915448 -1.12155929  1.0799225  -0.94961\n",
      "  1.34355851 -1.02204296  1.95594685]  energy_before :  260  energy_after :  30  reward :  34.46033812541722\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "action : 1  next_temperatures :  [2.06312399 1.25911319 1.30364226 1.62327222 2.10980211 0.44608643\n",
      " 2.09415023 1.19008957 2.46193471]  energy_before :  30  energy_after :  60  reward :  -213.44878527323624\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "action : 1  next_temperatures :  [0.88007886 2.9478957  2.17006773 0.97785349 1.82400138 1.84078791\n",
      " 1.43656661 1.83660661 1.59814115]  energy_before :  60  energy_after :  60  reward :  -182.48800054125928\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "action : 1  next_temperatures :  [-0.71806982  1.08236066 -0.06439797  0.14978455 -0.73657378  0.60147596\n",
      " -0.90821667  0.76854818 -0.43484578]  energy_before :  60  energy_after :  30  reward :  -168.2599346757737\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "action : 1  next_temperatures :  [ 0.63101673 -0.34171189  0.13320784  0.16452762 -0.13340131 -0.22814609\n",
      " -0.14130773  0.33165008  0.16149705]  energy_before :  30  energy_after :  40  reward :  -207.42266769402354\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "action : 1  next_temperatures :  [1.33046622 1.39230586 1.1622781  0.8369753  0.80874413 1.89199914\n",
      " 0.16871929 2.30421811 0.95421136]  energy_before :  40  energy_after :  50  reward :  -197.15008249208984\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "action : 1  next_temperatures :  [-2.05262775 -0.44223466 -1.39139699 -0.48007205 -1.82826611  0.01459518\n",
      " -2.27886242 -0.12137255 -1.77812307]  energy_before :  50  energy_after :  70  reward :  -228.35836042708615\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "action : 1  next_temperatures :  [-0.67655947 -0.2998274  -0.43376883 -0.53986338 -0.08355234 -0.09704532\n",
      " -0.84294782 -0.56825249 -1.0799803 ]  energy_before :  70  energy_after :  90  reward :  -222.62179735886826\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "action : 1  next_temperatures :  [-1.05015267 -0.56788812 -0.38360736 -0.67746534 -1.74850777  0.10677541\n",
      " -0.53618425 -0.36016922 -1.40525821]  energy_before :  90  energy_after :  50  reward :  -164.62245752182972\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "action : 1  next_temperatures :  [-0.49598942  0.84613215  0.27001186  0.91232875 -0.33279717  0.28294206\n",
      " -0.39422451  1.06378072 -0.16378086]  energy_before :  50  energy_after :  70  reward :  -216.01159639693392\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "action : 1  next_temperatures :  [-0.49598942  0.51021857 -0.59641361  1.11627452 -0.33279717 -0.04685831\n",
      " -0.56555523  0.56200057 -0.16378086]  energy_before :  70  energy_after :  30  reward :  -158.01290093172608\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "action : 1  next_temperatures :  [ 0.25742353  1.14770046  0.66066335  0.76407902 -0.18214252  1.61375142\n",
      " -0.27674059  2.1130272  -0.48363747]  energy_before :  30  energy_after :  190  reward :  -352.38587559023995\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "action : 1  next_temperatures :  [ 0.37572804 -1.64013098  1.68365343 -2.53017746  0.55949931 -1.30665475\n",
      "  0.76919267 -1.66472082  0.64941392]  energy_before :  190  energy_after :  60  reward :  -71.10419665566019\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "action : 1  next_temperatures :  [1.12914099 1.04047617 0.97010102 0.8578028  1.04552671 0.43939239\n",
      " 1.29460687 0.96818527 1.777044  ]  energy_before :  60  energy_after :  90  reward :  -218.47772375655987\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "action : 1  next_temperatures :  [-1.11864475 -0.84432573 -1.72124669  0.26527191 -0.98581861 -0.53541351\n",
      " -0.84294782 -0.97597286 -0.59206344]  energy_before :  90  energy_after :  110  reward :  -225.3511615028181\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "action : 1  next_temperatures :  [ 1.81406186 -0.46736535  1.61829151 -0.97150763  1.96025522 -0.47396003\n",
      "  1.94240017 -0.70569495  2.22701178]  energy_before :  110  energy_after :  180  reward :  -261.0565074280938\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "action : 1  next_temperatures :  [-0.45032803  1.21555333 -0.10999931  0.8369753  -0.33279717  1.4515825\n",
      "  0.13608486  1.09718154 -0.26678553]  energy_before :  180  energy_after :  60  reward :  -74.42253250322716\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "action : 1  next_temperatures :  [-0.61429393 -1.07050196 -1.6604449   0.20629964 -0.48732896 -1.30358207\n",
      " -0.61450686 -1.37447921 -0.26678553]  energy_before :  60  energy_after :  80  reward :  -225.18562378424775\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "action : 1  next_temperatures :  [-1.31996998 -0.89458712 -1.80180906  0.09081228 -0.98581861 -0.53541351\n",
      " -0.56555523 -0.87461865 -1.0799803 ]  energy_before :  80  energy_after :  60  reward :  -185.96694016444906\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "action : 1  next_temperatures :  [ 0.23666835  0.64592431  0.58922125  0.01136353  0.80874413  0.79403021\n",
      "  0.22909297  0.72247808 -0.3806328 ]  energy_before :  60  energy_after :  50  reward :  -184.34310996869513\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "action : 1  next_temperatures :  [ 0.63101673 -0.16831012 -0.06439797  0.4295518   1.30723378 -0.35412573\n",
      "  1.09880034 -0.42082818  1.70114582]  energy_before :  50  energy_after :  60  reward :  -203.83991352910363\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "action : 1  next_temperatures :  [-0.24692729 -0.65417016 -1.02202613  0.27182438 -0.13340131 -0.7627914\n",
      " -0.17394215 -0.69724877 -0.18004475]  energy_before :  60  energy_after :  40  reward :  -181.59872758341146\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "action : 1  next_temperatures :  [ 1.19140653  1.32759433  1.17899859  0.46839861  1.36206764  1.8694662\n",
      " -0.41870032  2.58063869  1.08853909]  energy_before :  40  energy_after :  60  reward :  -207.35159063438627\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "action : 1  next_temperatures :  [-1.88035977 -0.55280971 -1.6604449  -0.05416122 -0.98581861 -0.29267225\n",
      " -1.72081379 -0.40009664 -1.02576732]  energy_before :  60  energy_after :  50  reward :  -196.57294419812922\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "action : 1  next_temperatures :  [ 0.54799602 -0.19092774  0.54361991 -0.299879   -0.48732896  1.3358451\n",
      " -1.25577327  0.86683105 -0.70591071]  energy_before :  50  energy_after :  50  reward :  -197.645527591681\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "action : 1  next_temperatures :  [ 0.04572072  0.47838636 -0.02335676  0.76407902  0.84530004 -0.24965481\n",
      " -0.27674059  0.38539853  0.22113133]  energy_before :  50  energy_after :  60  reward :  -205.80973615332317\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "action : 1  next_temperatures :  [ 0.74932124  0.76152549  0.35741443  0.9772392   1.00813999 -0.06529435\n",
      "  0.69739694  0.40267482  1.08853909]  energy_before :  60  energy_after :  120  reward :  -252.02304314716804\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "action : 1  next_temperatures :  [ 1.48197902 -0.16831012  1.75965567 -1.08765023  1.21252075 -0.30189027\n",
      "  1.39251014 -0.06839193  1.19154376]  energy_before :  120  energy_after :  50  reward :  -122.58803321792874\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "action : 1  next_temperatures :  [2.20633472 1.26413933 1.57269017 0.97785349 1.80572343 0.8472899\n",
      " 1.63726831 1.42197573 2.60108137]  energy_before :  50  energy_after :  40  reward :  -173.66564354050524\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "action : 1  next_temperatures :  [0.79498263 1.28256851 0.7746667  1.28106925 1.11282282 0.35566202\n",
      " 1.48551825 0.89216961 1.19154376]  energy_before :  40  energy_after :  60  reward :  -208.82899645578652\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "action : 1  next_temperatures :  [1.54424455 1.13848587 1.03003421 1.10071239 2.25436411 0.23275505\n",
      " 1.88202648 0.73783478 1.51682167]  energy_before :  60  energy_after :  60  reward :  -186.56272087774636\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "action : 1  next_temperatures :  [-0.55825495 -1.29919126  0.10280695 -1.72504218 -0.38264613 -1.30358207\n",
      " -0.03198241 -1.08270192 -0.50170846]  energy_before :  60  energy_after :  120  reward :  -264.7823024462331\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "action : 1  next_temperatures :  [-0.03314896  1.6670681  -0.33800601  0.32915853 -0.65183054  0.2511911\n",
      "  0.31557419 -0.92145658 -0.97697563]  energy_before :  120  energy_after :  30  reward :  -108.35842580834205\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "action : 1  next_temperatures :  [-0.49598942 -0.43553314 -0.47937017 -0.35147974 -0.36602981 -0.54667998\n",
      " -0.52149876 -0.83545906 -0.75470239]  energy_before :  30  energy_after :  100  reward :  -272.786742478803\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "action : 1  next_temperatures :  [ 2.43671719  0.61325441  2.3524731  -0.35721316  2.15965108 -0.16116179\n",
      "  2.37154283  0.60730284  2.22701178]  energy_before :  100  energy_after :  90  reward :  -175.75042173036414\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "action : 1  next_temperatures :  [ 0.25742353  0.57807144  0.16360874  0.74851689  0.66418213 -0.31110829\n",
      "  0.16871929  0.56967892  0.54640924]  energy_before :  90  energy_after :  50  reward :  -154.6144981093107\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "action : 1  next_temperatures :  [-0.3652318  -0.67092396 -1.06762747 -0.01402731 -0.58204199 -0.40226429\n",
      " -0.22778895 -1.20632335 -0.80891538]  energy_before :  50  energy_after :  400  reward :  -553.3451445022263\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "action : 1  next_temperatures :  [ 0.0083614  -1.02024058 -0.87306175 -0.52348219  0.16569248 -0.99631465\n",
      " -0.07603889 -1.46585157 -0.55592145]  energy_before :  400  energy_after :  60  reward :  136.66314281333007\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "action : 1  next_temperatures :  [ 0.50648566  0.25891165  1.13187721 -0.5636161   0.50965034 -0.04685831\n",
      "  1.14775197 -0.11446203  0.87168715]  energy_before :  60  energy_after :  90  reward :  -224.29857245036624\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "action : 1  next_temperatures :  [ 1.06064891 -0.9532254   0.46305754 -0.61931213  0.21554145 -0.95739411\n",
      " -0.40238311 -0.100641   -0.21257254]  energy_before :  90  energy_after :  30  reward :  -139.50628039857713\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "action : 1  next_temperatures :  [ 1.06064891 -0.63574099  0.61962214 -0.34902256  1.25738481 -0.29267225\n",
      "  1.24076008 -0.51527188  0.81747417]  energy_before :  30  energy_after :  40  reward :  -204.79681756893424\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "action : 1  next_temperatures :  [ 1.83481704 -0.36014107  1.28844181 -0.44976686  1.69439407 -0.22814609\n",
      "  1.66663929 -0.40009664  1.57645596]  energy_before :  40  energy_after :  50  reward :  -201.37740247465882\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "action : 1  next_temperatures :  [-1.23694927  1.15607736 -0.47937017  0.88611885 -1.37962543  1.41983153\n",
      " -2.03410425  1.55788252 -1.60705099]  energy_before :  50  energy_after :  40  reward :  -189.71718984169786\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "action : 1  next_temperatures :  [-0.86958262 -0.84432573 -0.66177553 -0.98051728 -1.15231415 -0.68904722\n",
      " -0.47254712 -0.69033825 -1.13419329]  energy_before :  40  energy_after :  60  reward :  -225.49464120229493\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "action : 1  next_temperatures :  [-0.05390414 -0.9448485  -0.74841808 -0.11968596  0.16569248 -0.90720709\n",
      "  0.56033236 -1.17209985  0.27534432]  energy_before :  60  energy_after :  20  reward :  -160.94479446060996\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "action : 1  next_temperatures :  [ 0.06440038  0.08550987 -0.08719864  0.10432676 -0.61527463  0.33312908\n",
      " -0.03198241 -0.21581625  0.05849238]  energy_before :  20  energy_after :  110  reward :  -288.3044134688856\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n",
      "action : 1  next_temperatures :  [-1.05015267 -0.26631982 -0.80921987 -0.34902256 -1.22260119  0.36334371\n",
      " -0.6634585  -0.1290509  -1.19985124]  energy_before :  110  energy_after :  70  reward :  -163.32633302413163\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "action : 1  next_temperatures :  [ 0.12666591  0.71126411 -0.38360736  1.05894036  0.61433317  0.47549632\n",
      "  0.56033236  0.15504804  0.7036269 ]  energy_before :  70  energy_after :  50  reward :  -173.97790018785548\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "action : 1  next_temperatures :  [ 0.14949661  0.0754576  -0.30760512  0.5027991   0.31025448 -0.10523912\n",
      "  0.34820861  0.27022329  0.27534432]  energy_before :  50  energy_after :  60  reward :  -206.48106023102366\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "action : 1  next_temperatures :  [ 0.0083614  -1.16432321  0.02224458 -1.25162591 -0.58204199 -0.70953172\n",
      "  0.10345044 -0.74562237 -0.86312836]  energy_before :  60  energy_after :  100  reward :  -243.18221714429754\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "action : 1  next_temperatures :  [ 1.06064891 -0.93730929  0.49497848 -0.63733143  0.23049614 -0.96866058\n",
      " -0.40238311 -0.06839193 -0.21257254]  energy_before :  100  energy_after :  50  reward :  -149.44052537370675\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "action : 1  next_temperatures :  [ 1.19140653 -2.66378784  1.98766237 -3.49421025  0.41493731 -1.9918611\n",
      "  0.91767929 -1.98951501  0.76326118]  energy_before :  50  energy_after :  120  reward :  -272.8644275324553\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "action : 1  next_temperatures :  [-0.11616967  0.60487751 -0.18904163  0.39550234 -0.50976099  0.33876231\n",
      "  0.16871929 -0.19047769 -0.65169772]  energy_before :  120  energy_after :  100  reward :  -178.14928626337604\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "action : 1  next_temperatures :  [ 1.93236637 -0.78568745  1.81589732 -1.26636897  1.91040625 -0.79088443\n",
      "  1.97503459 -0.86079762  2.38965073]  energy_before :  100  energy_after :  90  reward :  -181.68038320138623\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "action : 1  next_temperatures :  [ 1.19140653 -0.30904199  1.07563555 -0.32690796 -0.53219302  1.29794879\n",
      " -1.15297484  1.00734485 -0.57399244]  energy_before :  90  energy_after :  40  reward :  -146.32277453870418\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "action : 1  next_temperatures :  [ 0.195158   -0.82757194 -0.43376883 -0.18602976  0.31025448 -0.68904722\n",
      " -0.63082407 -0.22963728 -0.26678553]  energy_before :  40  energy_after :  40  reward :  -200.75825215426113\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "action : 1  next_temperatures :  [-0.55825495  0.69618569 -0.61161406  1.35462077 -0.2829482   0.14979285\n",
      " -0.61450686  0.75165581 -0.21257254]  energy_before :  40  energy_after :  80  reward :  -237.32764150347114\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "action : 1  next_temperatures :  [-0.9256216   1.55146691 -0.33800601  1.02453987 -0.98581861  1.92272588\n",
      " -0.45459819  1.71375302 -0.59206344]  energy_before :  80  energy_after :  40  reward :  -155.08362215630717\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "action : 1  next_temperatures :  [-0.11616967 -0.77814824 -0.76361853  0.01136353  0.29363816 -0.63886021\n",
      " -0.76625693 -0.33099149 -0.28485652]  energy_before :  40  energy_after :  40  reward :  -201.37389990858952\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "action : 1  next_temperatures :  [-1.13939993 -0.36014107 -0.72105728 -0.31789831 -1.18521446 -0.47396003\n",
      " -0.47254712 -0.65117867 -1.13419329]  energy_before :  40  energy_after :  60  reward :  -224.45559015520627\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "action : 1  next_temperatures :  [-0.738825   -0.98380107 -1.28043373 -0.2114206  -0.43747999 -1.45721578\n",
      " -0.20984002 -0.89842153 -0.24871453]  energy_before :  60  energy_after :  70  reward :  -214.46615226067806\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "action : 1  next_temperatures :  [-0.3652318  -0.83594884 -0.29240467 -0.84045814 -0.83128681 -0.69928947\n",
      " -0.41870032 -0.91377823  0.13981186]  energy_before :  70  energy_after :  90  reward :  -223.0572864312751\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "action : 1  next_temperatures :  [-1.36148033 -0.56788812 -0.6298546  -0.32445078 -1.18521446 -0.69928947\n",
      " -0.15762494 -0.67651722 -0.86312836]  energy_before :  90  energy_after :  260  reward :  -374.465448297878\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "action : 1  next_temperatures :  [-0.18466176 -1.22128612 -1.11778894  0.02692565 -0.33279717 -0.96866058\n",
      "  0.11976765 -1.28848169 -0.59206344]  energy_before :  260  energy_after :  50  reward :  6.440953616757014\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "action : 1  next_temperatures :  [ 0.50648566  0.0427877   0.41897624 -0.30888866  0.19892513 -0.10523912\n",
      " -0.03198241 -0.79169247  0.28308903]  energy_before :  50  energy_after :  90  reward :  -237.78753889433935\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "action : 1  next_temperatures :  [-0.11616967 -0.59301881 -0.76361853 -0.12787655 -0.58204199 -0.41250654\n",
      " -0.12499052 -1.22705489 -0.70591071]  energy_before :  90  energy_after :  80  reward :  -192.65318821513384\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "action : 1  next_temperatures :  [ 1.50273419 -0.56788812  0.9342714  -0.4227379   1.12943914 -0.44630596\n",
      "  1.43656661 -0.51527188  0.81747417]  energy_before :  80  energy_after :  380  reward :  -494.13171835110836\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "action : 1  next_temperatures :  [1.93236637 1.76675318 1.1622781  2.20644244 2.18101492 1.2906329\n",
      " 2.02888139 1.46804583 2.38965073]  energy_before :  380  energy_after :  90  reward :  108.42606585095501\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "action : 1  next_temperatures :  [-0.61429393  0.0754576  -1.29563417  1.56511901 -0.68672482 -0.29267225\n",
      " -0.22778895 -0.79169247 -0.55592145]  energy_before :  90  energy_after :  390  reward :  -500.82415143185176\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n",
      "action : 1  next_temperatures :  [ 0.43799358  1.47356177  0.75642617  0.73213571  0.44816995  2.81072874\n",
      " -0.61450686  2.30345027  0.57351574]  energy_before :  390  energy_after :  60  reward :  140.9214750568953\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "action : 1  next_temperatures :  [-2.02979705 -0.20014233 -1.52364088 -0.26056416 -1.77841715 -0.10523912\n",
      " -1.74528961 -0.12137255 -1.47392799]  energy_before :  60  energy_after :  110  reward :  -257.2383908311166\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "action : 1  next_temperatures :  [-1.46110518 -0.01501289 -1.02202613  0.01955412 -1.57902129  0.10677541\n",
      " -1.28514425 -0.33099149 -1.67632314]  energy_before :  110  energy_after :  40  reward :  -135.2432948460385\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "action : 1  next_temperatures :  [ 0.0083614  -1.72641303 -0.31520534 -1.62921224  0.29363816 -0.66036893\n",
      " -0.52149876 -1.70311257 -1.35104523]  energy_before :  40  energy_after :  100  reward :  -265.60485653870967\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "action : 1  next_temperatures :  [1.87632739 1.89240664 1.20527365 2.35036286 1.97307352 1.14577825\n",
      " 1.94566361 1.47725985 2.33001645]  energy_before :  100  energy_after :  90  reward :  -171.8038377808232\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "action : 1  next_temperatures :  [0.88007886 1.07691568 0.99963332 0.60927681 0.07928761 1.61033734\n",
      " 0.10345044 1.90340826 0.21781832]  energy_before :  90  energy_after :  80  reward :  -180.5197933679269\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "action : 1  next_temperatures :  [ 1.50273419 -1.18861622  2.44367578 -2.53591088  0.86357799 -0.90720709\n",
      "  1.63726831 -0.92759926  0.25727332]  energy_before :  80  energy_after :  380  reward :  -496.85480384493076\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "action : 1  next_temperatures :  [ 0.9423444  -1.43992314  0.92124244 -1.64184916  0.75889517 -1.69749891\n",
      "  1.34355851 -1.28848169  1.95594685]  energy_before :  380  energy_after :  50  reward :  131.85423446822176\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "action : 1  next_temperatures :  [-0.18466176 -1.30505509  0.07240605 -1.5374776  -0.93596964 -1.01167802\n",
      "  0.07081602 -1.22705489 -0.86312836]  energy_before :  50  energy_after :  50  reward :  -204.92180328855204\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "action : 1  next_temperatures :  [ 0.195158   -1.02024058 -0.25136347 -0.76019033 -0.13340131 -1.14994836\n",
      " -0.32079706 -1.38830024 -0.10956787]  energy_before :  50  energy_after :  60  reward :  -212.93865120811705\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "action : 1  next_temperatures :  [ 0.10591073  1.88654281  0.54361991  0.943453   -0.18823517  1.62194522\n",
      " -0.47254712  2.08077813 -0.53182679]  energy_before :  60  energy_after :  50  reward :  -182.0103592746142\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "action : 1  next_temperatures :  [ 0.12666591 -1.21290922  0.39161544 -1.38349445  1.29061746 -0.92769159\n",
      " -0.36974869 -0.37475808  0.05849238]  energy_before :  50  energy_after :  60  reward :  -210.4012108449674\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "action : 1  next_temperatures :  [ 0.81781333  0.42477422  0.49497848  0.56750479  0.36508834  0.07912134\n",
      " -0.32079706  0.59041047  0.78133218]  energy_before :  60  energy_after :  30  reward :  -164.19977391675752\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "action : 1  next_temperatures :  [ 0.10591073 -0.45061156 -0.43376883  0.40287387  0.31025448 -0.59993967\n",
      " -0.32079706 -0.02923235  0.60062223]  energy_before :  30  energy_after :  80  reward :  -248.4146881502942\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "action : 1  next_temperatures :  [-0.09541449  1.30853689 -0.25136347  1.77971254  0.16569248  0.68238971\n",
      "  0.01696922  1.14555515  0.27534432]  energy_before :  80  energy_after :  110  reward :  -222.97257764070508\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "action : 1  next_temperatures :  [ 0.50648566  0.0017409   0.21985039  0.28001498 -0.08355234 -0.22814609\n",
      " -0.0923561   0.53819769  0.22113133]  energy_before :  110  energy_after :  50  reward :  -136.6366335722313\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "action : 1  next_temperatures :  [ 0.34370577 -0.81596395  0.02224458 -0.76919998 -0.73657378 -0.3817798\n",
      " -0.47254712 -0.83907886 -0.24355139]  energy_before :  50  energy_after :  80  reward :  -231.89274453613962\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "action : 1  next_temperatures :  [ 1.06064891  0.16090195  1.71405433 -0.83308661  1.00813999 -0.12777206\n",
      "  1.29460687 -0.0061973   0.87168715]  energy_before :  80  energy_after :  70  reward :  -182.85701676732182\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "action : 1  next_temperatures :  [ 1.12914099 -0.30150278  0.5740208  -0.20404907  0.66418213 -0.21892806\n",
      "  0.16871929 -0.02923235  0.37834899]  energy_before :  70  energy_after :  190  reward :  -315.839300058136\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "action : 1  next_temperatures :  [2.43671719 2.52234932 2.26973924 1.60969924 1.96025522 1.99603111\n",
      " 2.31280086 1.16628669 2.4980767 ]  energy_before :  190  energy_after :  60  reward :  -49.228044431018105\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "action : 1  next_temperatures :  [-0.55825495  0.0829968  -0.53561182 -0.00501766 -1.03068267  0.26040912\n",
      " -0.32079706 -0.18356718 -0.48363747]  energy_before :  60  energy_after :  70  reward :  -210.77416289112915\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "action : 1  next_temperatures :  [ 0.0083614  -0.01501289 -0.70737688  0.96884384  0.11584352 -0.29267225\n",
      " -0.12499052  0.20111814  0.16149705]  energy_before :  70  energy_after :  50  reward :  -177.68438858535052\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "action : 1  next_temperatures :  [ 0.06440038 -0.89458712 -0.59641361 -0.16964858 -0.23808413 -0.84268094\n",
      " -0.40238311 -0.96752668 -0.65169772]  energy_before :  50  energy_after :  440  reward :  -592.6986215091924\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "action : 1  next_temperatures :  [-0.30296627  1.08989987  0.12940773  0.31994412 -0.43747999  1.25493135\n",
      " -1.0110151   0.52130532 -0.3806328 ]  energy_before :  440  energy_after :  30  reward :  213.1833942267292\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "action : 1  next_temperatures :  [ 0.5687512   0.72969328  0.43265665  0.80585104  0.01116069  1.00092361\n",
      "  0.27967632  1.73678807 -0.17772134]  energy_before :  30  energy_after :  70  reward :  -232.61222047736348\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "action : 1  next_temperatures :  [-1.23694927 -1.2305007  -0.96274438 -1.07880439 -1.32977646 -0.93486116\n",
      " -1.07138878 -0.72873    -1.08772501]  energy_before :  70  energy_after :  60  reward :  -197.66148017033626\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "action : 1  next_temperatures :  [ 0.12666591  0.71126411  0.07240605  0.77882209  0.75889517 -0.35412573\n",
      " -0.26042337  0.33932843  0.16149705]  energy_before :  60  energy_after :  80  reward :  -215.6656702969082\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "action : 1  next_temperatures :  [ 0.63101673  1.13848587  0.84762885  0.77145055  0.01116069  1.83054566\n",
      " -0.22778895  1.96560289 -0.43484578]  energy_before :  80  energy_after :  90  reward :  -201.46674349295094\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "action : 1  next_temperatures :  [-0.67655947 -0.5285167  -0.32280557 -0.56197798 -0.43747999 -0.79249392\n",
      " -0.07603889 -0.42214447 -0.32099851]  energy_before :  90  energy_after :  50  reward :  -162.13901550053436\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "action : 1  next_temperatures :  [-1.34072515  0.25891165 -0.93538358  0.28738651 -1.23506343  0.44784225\n",
      " -0.87558224 -0.23040511 -0.97697563]  energy_before :  50  energy_after :  70  reward :  -222.59999474371938\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "action : 1  next_temperatures :  [-0.07465931 -0.28307361 -0.10999931 -0.59474035  1.00813999 -0.61837572\n",
      " -0.59818965 -0.25190449 -0.43484578]  energy_before :  70  energy_after :  60  reward :  -189.9576482319521\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "action : 1  next_temperatures :  [-0.738825   -1.72389996 -0.26504387 -2.10344757 -1.18521446 -1.66410918\n",
      " -0.22778895 -1.41133529 -0.53785045]  energy_before :  60  energy_after :  150  reward :  -297.8575147370153\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "action : 1  next_temperatures :  [-1.672808    0.15168736 -0.77881898 -0.45713839 -1.14865856  1.18425984\n",
      " -2.26417693 -0.36707973 -1.26370208]  energy_before :  150  energy_after :  40  reward :  -94.6164354699396\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "action : 1  next_temperatures :  [ 0.0083614  -0.10883414  0.20464994 -0.4227379  -0.45409631  1.02857768\n",
      " -0.27674059  0.63648056 -0.65169772]  energy_before :  40  energy_after :  40  reward :  -198.0360370809971\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "action : 1  next_temperatures :  [ 0.02704106 -1.24892988 -0.61161406 -0.73398043 -0.48732896 -1.37732625\n",
      " -0.14130773 -0.63044713  0.0042794 ]  energy_before :  40  energy_after :  60  reward :  -223.1996139825656\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "action : 1  next_temperatures :  [-1.05015267 -1.29919126 -1.06762747 -1.07143286 -0.83128681 -0.81502687\n",
      " -0.96206346 -1.25239345 -1.10321444]  energy_before :  60  energy_after :  200  reward :  -347.45238928878894\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "action : 1  next_temperatures :  [-0.18466176 -1.09563265 -0.83962076 -0.36540375 -1.1303806  -0.90720709\n",
      " -0.48886433 -0.89688586 -0.39870379]  energy_before :  200  energy_after :  20  reward :  -24.307360606198813\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "action : 1  next_temperatures :  [-0.67655947 -0.14066635 -0.88978224  0.11784124 -0.58204199  0.41404283\n",
      " -0.41870032 -0.12137255 -0.53785045]  energy_before :  20  energy_after :  100  reward :  -280.83508930887865\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "action : 1  next_temperatures :  [1.99463191 1.94518109 2.04173253 1.37100196 1.86055729 1.42687308\n",
      " 2.145666   1.35287059 2.33001645]  energy_before :  100  energy_after :  270  reward :  -351.53146911622997\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "action : 1  next_temperatures :  [1.68613449 3.4580716  1.31144789 3.33305481 2.60326155 2.52022136\n",
      " 1.39471517 2.4465166  1.63335517]  energy_before :  270  energy_after :  60  reward :  32.386778641549\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "action : 1  next_temperatures :  [ 0.81781333  0.23629403 -0.00815632  0.96884384  0.93835144 -0.27577254\n",
      "  0.94705027  0.17577959  0.81747417]  energy_before :  60  energy_after :  30  reward :  -163.3823221912808\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "action : 1  next_temperatures :  [-0.42749733 -0.69354158 -1.20443149  0.04166872 -0.70334114 -0.45552398\n",
      " -0.27674059 -1.20632335 -0.80891538]  energy_before :  30  energy_after :  70  reward :  -243.73464611791468\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "action : 1  next_temperatures :  [ 1.68330424  1.83628142  2.8671168  -0.12085604  2.82098068  1.15250887\n",
      "  1.78412322  1.22924916  1.66681093]  energy_before :  70  energy_after :  50  reward :  -163.0804807217142\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "action : 1  next_temperatures :  [-1.2992148  -0.35176417 -0.83962076 -0.21961119 -1.23506343 -0.53541351\n",
      " -0.32079706 -0.58975187 -1.13419329]  energy_before :  50  energy_after :  220  reward :  -374.52543008379837\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "action : 1  next_temperatures :  [-0.55825495 -0.89458712 -1.34579565  0.18254692 -0.78143785 -0.53541351\n",
      " -0.36974869 -1.20632335 -0.86312836]  energy_before :  220  energy_after :  100  reward :  -84.37214256432077\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "action : 1  next_temperatures :  [-0.30296627  0.671055   -0.38360736  0.71575452 -0.54880935  0.62913003\n",
      "  0.45753393 -0.19047769 -0.59206344]  energy_before :  100  energy_after :  720  reward :  -817.5444506250062\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "action : 1  next_temperatures :  [-2.2331978  -0.15909553 -1.47803954 -0.10330477 -1.9827979   0.10677541\n",
      " -2.41266356  0.07749671 -1.94738806]  energy_before :  720  energy_after :  50  reward :  461.8677849578249\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "action : 1  next_temperatures :  [-2.11489328 -0.41961704 -1.39139699 -0.46450992 -1.86149876 -0.01305889\n",
      " -2.27886242 -0.14440759 -1.7901704 ]  energy_before :  50  energy_after :  170  reward :  -328.47841530112686\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "action : 1  next_temperatures :  [-0.11616967 -0.98577563 -0.15560065 -0.9808683  -0.88113578 -0.56614025\n",
      "  0.26172739 -1.07666893 -0.88016673]  energy_before :  170  energy_after :  60  reward :  -93.38079855603905\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "action : 1  next_temperatures :  [-0.67655947  0.72047869 -0.70737688  1.00242527 -0.2829482   1.03165035\n",
      " -0.27674059  0.60730284 -0.35507525]  energy_before :  60  energy_after :  40  reward :  -176.93684321879388\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "action : 1  next_temperatures :  [-0.3652318  -1.02024058 -0.93538358 -0.29435035 -0.03370338 -0.81502687\n",
      " -0.32079706 -1.02204296 -0.65169772]  energy_before :  40  energy_after :  40  reward :  -203.45847429460468\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "action : 1  next_temperatures :  [-0.11616967 -0.36014107 -0.29240467 -0.12787655 -0.68672482 -0.32032631\n",
      " -0.22289379  0.20726082 -0.51977946]  energy_before :  40  energy_after :  80  reward :  -240.43905551832884\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "action : 1  next_temperatures :  [ 1.01913855  1.28256851  1.11667676  0.48641792  0.97823061  1.82030341\n",
      " -0.55454111  2.57891107  0.953609  ]  energy_before :  80  energy_after :  40  reward :  -148.31868528774763\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "action : 1  next_temperatures :  [ 0.31968906 -0.3249581  -0.02335676  0.05231649 -0.2829482  -0.82424489\n",
      "  0.07081602 -0.44524533  0.45244007]  energy_before :  40  energy_after :  50  reward :  -209.0054916400254\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "action : 1  next_temperatures :  [ 1.48197902 -1.37458334  0.41624016 -1.01491777  0.86357799 -1.24212859\n",
      "  1.53936504 -1.46585157  2.22701178]  energy_before :  50  energy_after :  90  reward :  -236.56930726980764\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "action : 1  next_temperatures :  [-0.30296627 -0.42715624 -0.88978224  0.64122012 -0.13340131 -0.71977397\n",
      " -0.61450686 -0.30565294 -0.0946593 ]  energy_before :  90  energy_after :  110  reward :  -220.84667899967846\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "action : 1  next_temperatures :  [2.24369404 2.14371356 1.57269017 2.13026992 2.10980211 1.67691195\n",
      " 2.17084113 1.58322108 2.44386372]  energy_before :  110  energy_after :  120  reward :  -189.92499233846738\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "action : 1  next_temperatures :  [1.81406186 1.53303774 1.84629821 0.90168098 1.71101039 0.87494397\n",
      " 1.52141611 1.50490191 1.95594685]  energy_before :  120  energy_after :  100  reward :  -164.33670197322917\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "action : 1  next_temperatures :  [-0.18466176  1.18037036 -0.33800601  1.02576846 -0.53219302  0.60147596\n",
      "  0.52443449 -0.04612472 -0.55953565]  energy_before :  100  energy_after :  60  reward :  -156.3284718838368\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "action : 1  next_temperatures :  [ 0.83856851 -0.02338979  0.30041276 -0.30151712  0.66418213 -1.91888509\n",
      "  0.80509053 -1.50347548  0.87168715]  energy_before :  60  energy_after :  40  reward :  -178.267326405174\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n",
      "action : 1  next_temperatures :  [0.77215194 0.7037249  0.43539273 1.03977438 1.05798895 0.02586165\n",
      " 1.09880034 0.66181912 1.19154376]  energy_before :  40  energy_after :  120  reward :  -271.0129422335965\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "action : 1  next_temperatures :  [-0.61429393 -0.79657742 -0.6572154  -0.08692359 -0.25303882 -1.22164409\n",
      " -0.22778895 -0.98979389 -0.04993359]  energy_before :  120  energy_after :  40  reward :  -122.89720968645992\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "action : 1  next_temperatures :  [1.50273419 0.81429994 0.73970568 1.37837349 1.37868396 0.35566202\n",
      " 1.29460687 0.77699436 1.90173387]  energy_before :  40  energy_after :  60  reward :  -207.85720561196936\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "action : 1  next_temperatures :  [-0.738825    1.022047   -0.25136347  0.80585104 -1.1303806   1.27746429\n",
      " -0.71730529  1.6166219  -1.02576732]  energy_before :  60  energy_after :  160  reward :  -297.14165744966476\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "action : 1  next_temperatures :  [-0.738825   -0.01501289 -0.74841808  0.26527191 -0.43747999  0.47549632\n",
      " -1.05507157  0.47523522 -0.90951058]  energy_before :  160  energy_after :  80  reward :  -120.68831467603175\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "action : 1  next_temperatures :  [ 0.06440038 -0.09040497 -0.10999931  0.09081228 -0.43747999  0.41404283\n",
      " -0.8103134   0.45450368 -0.75470239]  energy_before :  80  energy_after :  600  reward :  -719.179140899482\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "action : 1  next_temperatures :  [-0.38598698 -0.92977009 -0.88978224 -0.17702011 -1.08053164 -0.81502687\n",
      " -0.56555523 -0.97597286 -0.39870379]  energy_before :  600  energy_after :  40  reward :  355.7816501978375\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "action : 1  next_temperatures :  [-1.42997242  0.99021479 -0.83962076  0.95082454 -1.26497281  1.48947882\n",
      " -1.41568194  1.23769534 -1.29683224]  energy_before :  40  energy_after :  140  reward :  -299.578866689914\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "action : 1  next_temperatures :  [ 0.88007886  0.0829968   0.26279165  0.51928267  1.25738481  0.01459518\n",
      "  1.09880034 -0.100641    0.83296359]  energy_before :  140  energy_after :  70  reward :  -123.15174708860005\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "action : 1  next_temperatures :  [-0.30296627  1.2750293   0.05568556  0.60026716 -0.2829482   1.43109801\n",
      " -1.0110151   1.11407391 -0.26678553]  energy_before :  70  energy_after :  200  reward :  -325.3875611570781\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "action : 1  next_temperatures :  [ 0.88007886 -0.93730929  0.07240605 -0.52348219  0.14907616 -0.96866058\n",
      " -0.22778895 -0.13749708  0.60062223]  energy_before :  200  energy_after :  60  reward :  -59.092554790772766\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "action : 1  next_temperatures :  [ 0.12666591  0.55461613 -0.29240467  1.32841087  0.75889517  0.26040912\n",
      "  0.60928399  0.38539853  0.51026725]  energy_before :  60  energy_after :  50  reward :  -183.75845770044688\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "action : 1  next_temperatures :  [-0.13900036  0.47838636  0.11800739  0.21367117 -0.68672482  1.67691195\n",
      " -1.12034042  0.96127475 -0.70591071]  energy_before :  50  energy_after :  60  reward :  -207.20372467501923\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "action : 1  next_temperatures :  [ 0.88007886  0.0829968   0.29324683  0.5109897   1.25738481  0.01459518\n",
      "  1.09880034 -0.12137255  0.87168715]  energy_before :  60  energy_after :  90  reward :  -223.11159286611775\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "action : 1  next_temperatures :  [1.12914099 1.01283241 1.07563555 0.65596319 1.05798895 0.41404283\n",
      " 1.31092408 0.89216961 1.84752088]  energy_before :  90  energy_after :  110  reward :  -208.60378148899102\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "action : 1  next_temperatures :  [-2.05262775  0.83691757 -1.20443149  0.51836123 -1.43445929  1.10129764\n",
      " -1.05507157  0.66949747 -1.29683224]  energy_before :  110  energy_after :  700  reward :  -791.9173484397593\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "action : 1  next_temperatures :  [-0.30296627 -0.75385524 -0.74841808 -0.20404907  0.11584352 -0.81502687\n",
      "  0.50648556 -1.03500017  0.27534432]  energy_before :  700  energy_after :  60  reward :  439.038357699296\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "action : 1  next_temperatures :  [-0.67655947 -1.24892988 -1.02202613 -0.84045814 -0.83128681 -0.29267225\n",
      " -0.90821667 -0.95063431 -0.59206344]  energy_before :  60  energy_after :  50  reward :  -195.36284708294698\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "action : 1  next_temperatures :  [-0.30296627  1.16612963 -0.29240467  1.14166535 -0.18823517  1.28770654\n",
      " -0.07603889  1.1225201  -0.63181963]  energy_before :  50  energy_after :  40  reward :  -184.77344299612915\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "action : 1  next_temperatures :  [0.0083614  0.53786233 0.41897624 0.05067837 0.16569248 0.07912134\n",
      " 0.16871929 0.56123274 0.23920233]  energy_before :  40  energy_after :  50  reward :  -205.77015347814512\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "action : 1  next_temperatures :  [-0.42749733 -1.24892988 -0.06439797 -1.4629432  -0.48732896 -1.43877974\n",
      " -0.07603889 -1.0427745  -0.26678553]  energy_before :  50  energy_after :  50  reward :  -204.5154759958255\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "action : 1  next_temperatures :  [ 2.1461447  -0.83594884  2.75832503 -2.1673342   1.96025522 -0.46605886\n",
      "  2.02888139 -0.68342774  2.42579272]  energy_before :  50  energy_after :  40  reward :  -180.83337057523534\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "action : 1  next_temperatures :  [-0.11616967 -0.9448485  -0.77121875 -0.19053459  0.31025448 -1.3957623\n",
      "  0.34494517 -1.20954826  0.45244007]  energy_before :  40  energy_after :  590  reward :  -751.520442347984\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "action : 1  next_temperatures :  [-1.42997242 -0.69354158 -1.20443149 -0.31789831 -0.83128681 -0.62759374\n",
      " -1.45157981 -0.34481252 -1.38357302]  energy_before :  590  energy_after :  100  reward :  283.71531030244546\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "action : 1  next_temperatures :  [ 0.06440038  1.07314607  0.30041276  0.8549946  -0.05862786  1.68459363\n",
      " -0.17394215  1.56632871 -0.36738073]  energy_before :  100  energy_after :  30  reward :  -123.05607460020278\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "action : 1  next_temperatures :  [-0.61429393 -0.74631603 -0.18904163 -0.94120243 -0.76814479  0.64244495\n",
      " -1.7289724  -0.27647521 -0.45382033]  energy_before :  30  energy_after :  120  reward :  -293.0758218136989\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "action : 1  next_temperatures :  [-0.738825    0.57807144 -0.17232114  0.26527191 -0.88113578  1.27439162\n",
      "  0.23398813  0.83074281 -1.13419329]  energy_before :  120  energy_after :  60  reward :  -137.7440093009721\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "action : 1  next_temperatures :  [ 0.63101673 -0.71029538  1.25804092 -1.74142336  0.31025448 -1.03830786\n",
      "  0.80509053 -0.78171061  0.3458212 ]  energy_before :  60  energy_after :  50  reward :  -188.92151335805082\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "action : 1  next_temperatures :  [-0.738825    0.27650313 -0.29240467 -0.33264138 -0.33279717  0.55845852\n",
      " -0.8103134  -0.02923235 -0.64507169]  energy_before :  50  energy_after :  100  reward :  -250.3463240005521\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "action : 1  next_temperatures :  [ 0.0083614   0.14414816  0.33081365 -0.15490551  0.11584352 -0.18922555\n",
      "  0.26172739  0.23029587  0.27534432]  energy_before :  100  energy_after :  40  reward :  -136.9775967532833\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "action : 1  next_temperatures :  [ 1.66254906  0.01681932  0.8324284   0.22268083  1.46176557 -0.05607633\n",
      "  1.73027642  0.42302244  1.23491415]  energy_before :  40  energy_after :  50  reward :  -200.4716201399408\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "action : 1  next_temperatures :  [ 0.99838337  0.58561065  1.14707765  0.625658    0.79212781 -0.05607633\n",
      "  1.14775197  0.29095483  0.81747417]  energy_before :  50  energy_after :  120  reward :  -261.6510378770979\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "action : 1  next_temperatures :  [-0.32372145 -0.99762296 -0.15560065 -1.20903482 -0.88113578 -0.62759374\n",
      " -0.22778895 -0.98979389 -0.80891538]  energy_before :  120  energy_after :  60  reward :  -144.22120761113501\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "action : 1  next_temperatures :  [ 0.10591073  1.79439694  0.43265665  1.17442773  0.06100966  1.94116193\n",
      "  0.19809027  2.12070555 -0.04993359]  energy_before :  60  energy_after :  60  reward :  -190.22157414373942\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "action : 1  next_temperatures :  [1.92953612 1.9471687  1.9827325  1.11390588 2.17066317 1.05483508\n",
      " 1.58434763 1.60949348 1.86437086]  energy_before :  60  energy_after :  40  reward :  -162.74294658107974\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "action : 1  next_temperatures :  [ 0.43799358 -0.41961704  0.77162661 -0.92318313  1.37702233 -0.41250654\n",
      "  1.09880034 -0.89166458  0.47231816]  energy_before :  40  energy_after :  40  reward :  -196.48921026687498\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "action : 1  next_temperatures :  [ 0.61026155 -1.42484472 -0.12519976 -0.94120243  0.61433317 -0.68904722\n",
      "  0.85404217 -1.41133529  0.7036269 ]  energy_before :  40  energy_after :  160  reward :  -319.8093656350919\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n",
      "action : 1  next_temperatures :  [ 0.195158   -0.41961704  0.75642617 -1.03703237  0.01116069 -0.75357338\n",
      "  0.56033236 -0.46689828  0.22113133]  energy_before :  160  energy_after :  40  reward :  -78.93291251821711\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "action : 1  next_temperatures :  [-0.18466176 -0.71867227 -0.93538358  0.37174962 -0.03370338 -0.68904722\n",
      " -0.56555523 -0.53600343 -0.21257254]  energy_before :  40  energy_after :  50  reward :  -211.5038497888487\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "action : 1  next_temperatures :  [ 1.47524032 -0.18792511  1.23796448 -0.4000808   1.32167056 -0.4031289\n",
      "  1.46390324  0.00187992  0.94793736]  energy_before :  50  energy_after :  50  reward :  -192.5425389249552\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "action : 1  next_temperatures :  [-2.07338293 -0.38443407 -1.29563417 -0.4006233  -1.77841715  0.3218626\n",
      " -1.74528961 -0.21581625 -1.84197392]  energy_before :  50  energy_after :  60  reward :  -217.41370879268896\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "action : 1  next_temperatures :  [-0.67655947  0.34268062 -0.49305057 -0.22862085 -0.08355234  0.2429973\n",
      " -1.27045876 -0.82010236 -1.19382757]  energy_before :  60  energy_after :  350  reward :  -492.180494001116\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "action : 1  next_temperatures :  [-0.30296627  1.73324559 -0.20576213  1.63146281 -0.01874869  1.03984415\n",
      " -0.27674059  1.30680049 -0.6039903 ]  energy_before :  350  energy_after :  50  reward :  106.30314507633278\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "action : 1  next_temperatures :  [-1.18091029  1.52633622 -0.61161406  1.08269308 -1.08053164  1.79674624\n",
      " -0.85926503  1.36822729 -0.92276265]  energy_before :  50  energy_after :  50  reward :  -196.8810808317824\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "action : 1  next_temperatures :  [ 1.67901843 -0.65307138  1.45436357 -1.19531292  1.29266752 -0.73832973\n",
      "  1.62410859 -0.19077685  0.96765118]  energy_before :  50  energy_after :  50  reward :  -193.75968157848627\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "action : 1  next_temperatures :  [ 0.90083404 -0.66003399  0.13320784 -0.44976686  0.19892513 -0.93486116\n",
      " -0.27674059 -0.0545709   0.49219626]  energy_before :  50  energy_after :  50  reward :  -198.6508102321706\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "action : 1  next_temperatures :  [-1.54827693  0.71880331 -0.83962076  0.321787   -1.43445929  1.3358451\n",
      " -0.71730529  0.83611766 -1.0799803 ]  energy_before :  50  energy_after :  60  reward :  -210.40708950730436\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "action : 1  next_temperatures :  [1.70028575 3.37022841 1.35047607 3.20403452 2.57811048 2.43502448\n",
      " 1.40574031 2.39785247 1.64678632]  energy_before :  60  energy_after :  50  reward :  -167.91146119697606\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "action : 1  next_temperatures :  [-0.18466176  0.72215407  0.11800739  0.321787    1.19590442  1.51201176\n",
      "  0.31557419  0.79235106 -0.40773929]  energy_before :  50  energy_after :  90  reward :  -233.61461114136728\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "action : 1  next_temperatures :  [ 0.9423444  -0.25878061  0.9342714  -0.54559679 -0.53219302  0.80529668\n",
      "  0.41347746  0.93823971  0.83554516]  energy_before :  90  energy_after :  80  reward :  -184.4673956240325\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "action : 1  next_temperatures :  [ 0.12666591  0.25891165  0.07240605  0.51836123  0.29363816 -0.22814609\n",
      "  0.31557419  0.36005998  0.49219626]  energy_before :  80  energy_after :  50  reward :  -165.79033265734543\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "action : 1  next_temperatures :  [ 0.74932124  0.18603264  0.3156132   0.54211395  0.39832099  0.07912134\n",
      " -0.36974869  0.53819769  0.56448024]  energy_before :  50  energy_after :  110  reward :  -254.99654739857604\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "action : 1  next_temperatures :  [ 0.21591317 -0.71867227  0.25025128 -1.47277191 -0.23808413  0.42735775\n",
      "  0.45753393 -0.09065915 -0.80891538]  energy_before :  110  energy_after :  40  reward :  -129.97804670712284\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "action : 1  next_temperatures :  [-0.49598942  0.59482523 -0.07959842 -0.05416122 -0.33279717  0.51953798\n",
      " -0.43664926  0.28404432 -0.32099851]  energy_before :  40  energy_after :  50  reward :  -208.32178646106854\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "action : 1  next_temperatures :  [-1.42997242  0.27734082 -0.94906398  0.26527191 -1.2799275   0.44784225\n",
      " -0.96206346 -0.15285378 -1.0799803 ]  energy_before :  50  energy_after :  40  reward :  -192.86340646568732\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "action : 1  next_temperatures :  [-0.98788713 -0.10045725 -0.73473768  0.16452762 -0.88113578 -0.1666926\n",
      "  0.27967632 -0.47534446 -0.92276265]  energy_before :  40  energy_after :  40  reward :  -201.82481361321996\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "action : 1  next_temperatures :  [-0.49598942 -0.34338727  0.04732532 -0.60702624 -0.88113578  0.19076184\n",
      " -0.35312931  0.29524902 -1.01492472]  energy_before :  40  energy_after :  60  reward :  -221.16225657076475\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "action : 1  next_temperatures :  [2.37445166 1.80863766 2.5804798  0.46676049 2.68971174 0.4457938\n",
      " 1.88202648 1.50490191 1.95594685]  energy_before :  60  energy_after :  40  reward :  -162.29128960219708\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "action : 1  next_temperatures :  [0.81781333 0.99021479 0.9342714  0.5331043  0.06100966 1.58097623\n",
      " 0.11976765 1.85733816 0.15246155]  energy_before :  40  energy_after :  360  reward :  -510.9530429399881\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "action : 1  next_temperatures :  [-1.05015267  0.20865027 -0.97642479  0.37994021 -0.98581861  0.56767654\n",
      " -1.04038608  0.31629338 -0.75470239]  energy_before :  360  energy_after :  50  reward :  108.66507587111283\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "action : 1  next_temperatures :  [-1.54827693 -0.6432802  -1.47803954 -0.10330477 -1.03068267 -0.52619549\n",
      " -1.54458791 -0.40700715 -0.80891538]  energy_before :  50  energy_after :  60  reward :  -216.09029004317662\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "action : 1  next_temperatures :  [ 0.88007886  1.15607736  0.25025128  0.86973767  0.31025448 -0.56614025\n",
      "  0.9029938  -0.58668053  0.81747417]  energy_before :  60  energy_after :  60  reward :  -193.96595316770896\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n",
      "action : 1  next_temperatures :  [ 0.25742353 -0.05857276  0.11800739  0.15715608 -0.03370338 -0.35412573\n",
      " -0.17394215 -0.16821048  0.41449098]  energy_before :  60  energy_after :  80  reward :  -217.84147651200527\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "action : 1  next_temperatures :  [ 0.25742353  1.22476792 -0.17232114  1.32103934  0.31025448  0.31264458\n",
      "  0.21277576  0.29095483  0.68555591]  energy_before :  80  energy_after :  50  reward :  -163.55690480260762\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "action : 1  next_temperatures :  [-0.47315873 -0.19092774 -1.02202613  0.90168098  0.06100966 -0.10523912\n",
      " -0.22778895 -0.14440759  0.10728407]  energy_before :  50  energy_after :  50  reward :  -199.0935735505863\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "action : 1  next_temperatures :  [ 1.44046866 -0.35176417  1.66845298 -1.31862496  1.16267178 -0.39304627\n",
      "  1.39251014 -0.100641    1.20238636]  energy_before :  50  energy_after :  50  reward :  -193.29758646755334\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "action : 1  next_temperatures :  [-0.3652318   0.93995341  1.31732266 -0.13688621 -0.23808413  0.36590427\n",
      " -0.0466679   0.92211517 -0.16378086]  energy_before :  50  energy_after :  80  reward :  -225.40535539759446\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "action : 1  next_temperatures :  [-1.54827693 -0.16831012 -1.14818984 -0.02303696 -1.62887025  0.10677541\n",
      " -1.45157981 -0.39165045 -1.77209941]  energy_before :  80  energy_after :  50  reward :  -176.02523836409256\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "action : 1  next_temperatures :  [-0.49598942 -0.99762296 -0.93538358 -0.22616367 -1.1303806  -0.53541351\n",
      "  0.16871929 -0.92068874 -0.59206344]  energy_before :  50  energy_after :  80  reward :  -233.66498663535256\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "action : 1  next_temperatures :  [-0.9256216  -0.77898593 -1.75164758  0.49378945 -0.93596964 -0.53541351\n",
      " -0.56555523 -1.07502357 -0.86312836]  energy_before :  80  energy_after :  610  reward :  -734.9375559773797\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "action : 1  next_temperatures :  [1.75689078 3.01885564 1.50658877 2.68795338 2.47750621 2.09423697\n",
      " 1.44984088 2.20319593 1.7005109 ]  energy_before :  610  energy_after :  70  reward :  360.8955794489243\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "action : 1  next_temperatures :  [2.30595957 0.61325441 1.89645969 0.35454937 2.20950004 0.10677541\n",
      " 2.51839773 0.73092426 2.1547278 ]  energy_before :  70  energy_after :  50  reward :  -165.10945172075176\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "action : 1  next_temperatures :  [ 0.5687512   0.93995341  0.66066335  0.56013325 -0.13340131  1.50825627\n",
      "  0.07081602  1.55788252 -0.1990193 ]  energy_before :  50  energy_after :  110  reward :  -252.46596458799866\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "action : 1  next_temperatures :  [-0.3652318   0.88717895  0.07240605  0.48641792 -0.15167926  2.04563285\n",
      " -0.10867331  1.47572418 -0.04993359]  energy_before :  110  energy_after :  90  reward :  -173.7081580002088\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "action : 1  next_temperatures :  [-0.55825495 -0.96997919 -0.97642479 -0.17702011 -1.18521446 -0.50775944\n",
      "  0.11976765 -0.86079762 -0.65169772]  energy_before :  90  energy_after :  80  reward :  -193.7673806398814\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "action : 1  next_temperatures :  [ 0.12666591  0.57053223 -0.51015108  1.25920036  0.61433317 -0.01305889\n",
      "  0.50648556  0.12970949  0.60062223]  energy_before :  80  energy_after :  40  reward :  -154.71566101470427\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "action : 1  next_temperatures :  [1.68330424 1.12340746 0.75642617 1.54300441 1.80572343 0.99068136\n",
      " 1.50346718 0.91520466 2.05895152]  energy_before :  40  energy_after :  230  reward :  -375.6198295776039\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "action : 1  next_temperatures :  [1.68330424 1.96779871 0.80202751 2.45216023 2.00511929 1.73836543\n",
      " 1.42188112 1.62007715 1.84752088]  energy_before :  230  energy_after :  60  reward :  -12.461745440289263\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "action : 1  next_temperatures :  [1.19140653 1.19879953 1.03003421 0.82796564 0.61433317 1.67691195\n",
      " 0.07081602 2.25738017 0.68856774]  energy_before :  60  energy_after :  90  reward :  -218.44378504020975\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "action : 1  next_temperatures :  [-0.28428661 -0.16831012 -0.53561182  0.37174962 -0.003794   -0.50775944\n",
      " -0.22778895  0.0398728   0.43256198]  energy_before :  90  energy_after :  70  reward :  -178.88336655086752\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "action : 1  next_temperatures :  [-0.3652318   0.07713298  1.57269017 -1.60218328  0.06100966 -1.31382432\n",
      " -0.07603889 -0.67651722 -0.16378086]  energy_before :  70  energy_after :  30  reward :  -160.4867435695673\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "action : 1  next_temperatures :  [ 0.88007886 -0.51762674  1.1622781  -1.01491777  0.23049614 -0.33159279\n",
      "  0.60928399 -0.46689828  0.76326118]  energy_before :  30  energy_after :  70  reward :  -236.6856372927867\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "action : 1  next_temperatures :  [-0.05390414  0.695348    0.16360874  0.36355902  0.68079845  0.59020949\n",
      " -0.03198241 -0.16129996  0.22113133]  energy_before :  70  energy_after :  580  reward :  -705.5325314761175\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "action : 1  next_temperatures :  [-1.05015267 -0.11804873 -0.88978224  0.16452762 -0.73657378 -0.04685831\n",
      " -1.0110151  -0.07530245 -0.53785045]  energy_before :  580  energy_after :  60  reward :  317.6989438908108\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "action : 1  next_temperatures :  [ 1.75179633 -0.92223088  1.03003421 -0.79131458  0.97449194 -2.12014525\n",
      "  1.92608295 -0.7110698   2.29129289]  energy_before :  60  energy_after :  70  reward :  -204.57106219354378\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "action : 1  next_temperatures :  [ 1.62103871 -1.40809093  3.7569944  -2.97525429  1.36206764 -0.74230691\n",
      "  1.39251014 -0.65117867  1.19154376]  energy_before :  70  energy_after :  240  reward :  -364.452676141834\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "action : 1  next_temperatures :  [ 1.81406186 -0.34171189  1.21243958 -0.36540375  1.71101039 -0.1666926\n",
      "  1.6519538  -0.39165045  1.51682167]  energy_before :  240  energy_after :  60  reward :  -11.35917138816103\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "action : 1  next_temperatures :  [ 0.195158    0.7280179   0.21985039  0.44464589 -0.06582826  2.22811556\n",
      "  0.31557419  0.45450368 -0.32099851]  energy_before :  60  energy_after :  80  reward :  -213.8009611662884\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "action : 1  next_temperatures :  [ 0.31968906 -0.37689486  0.11800739 -0.22616367  0.16569248 -0.3817798\n",
      "  0.21277576 -0.49837951  0.3620851 ]  energy_before :  80  energy_after :  50  reward :  -168.3049680470593\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "action : 1  next_temperatures :  [-0.16183106 -1.60829877  0.00704413 -1.69391792 -0.73657378 -1.60163147\n",
      "  0.11976765 -1.64168577 -0.04993359]  energy_before :  50  energy_after :  60  reward :  -215.36706059346153\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "action : 1  next_temperatures :  [-0.30296627  1.39146817  0.20464994  1.01716834 -0.73657378  1.81927919\n",
      "  0.16545584  1.38281615 -0.80891538]  energy_before :  60  energy_after :  40  reward :  -173.86761779238537\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "action : 1  next_temperatures :  [ 0.31968906 -0.6181495   0.58922125 -1.29339793  0.01116069 -0.81195419\n",
      "  0.60928399 -0.53600343  0.72531209]  energy_before :  40  energy_after :  80  reward :  -239.00483795897443\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "action : 1  next_temperatures :  [-0.49598942  0.99021479 -0.02335676  0.73213571 -0.93596964  1.32662708\n",
      " -0.43664926  1.51181242 -0.97697563]  energy_before :  80  energy_after :  50  reward :  -166.3081507114803\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "action : 1  next_temperatures :  [-1.07298336  0.23629403 -1.02202613  0.38198786 -1.00077329  0.48881124\n",
      " -1.05507157  0.29940102 -0.75470239]  energy_before :  50  energy_after :  50  reward :  -201.49906261028957\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "action : 1  next_temperatures :  [-0.738825   -1.24892988 -1.57380235 -0.15490551 -0.98581861 -0.66139315\n",
      " -0.6634585  -1.0427745  -0.75470239]  energy_before :  50  energy_after :  50  reward :  -205.8246098910678\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "action : 1  next_temperatures :  [-0.11616967  0.36948669 -0.52041138  1.26288613 -0.54880935 -0.03559183\n",
      " -0.17394215 -0.66384795 -0.28485652]  energy_before :  50  energy_after :  110  reward :  -258.7112560286305\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "action : 1  next_temperatures :  [-1.49223795  1.64109971 -0.83962076  1.51597545 -1.23506343  1.85819973\n",
      " -1.25577327  2.0669571  -1.19382757]  energy_before :  110  energy_after :  90  reward :  -176.93429099158715\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "action : 1  next_temperatures :  [-1.2992148  -0.82840963 -1.23483239 -0.58736882 -0.93596964 -0.64090866\n",
      " -0.5867676  -0.66653537 -0.75470239]  energy_before :  90  energy_after :  40  reward :  -155.5347092961029\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "action : 1  next_temperatures :  [ 1.06064891 -0.62066257  0.74209432 -0.71759925  1.00813999 -0.99631465\n",
      "  1.14775197 -0.92759926  1.60898375]  energy_before :  40  energy_after :  250  reward :  -405.6945567914484\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "action : 1  next_temperatures :  [-0.69731464  0.56969454 -0.49305057 -0.11231443 -0.08355234  0.45603605\n",
      " -1.27045876 -0.7748001  -1.19382757]  energy_before :  250  energy_after :  60  reward :  -11.59958782985467\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "action : 1  next_temperatures :  [ 0.25742353  0.38456511  0.39161544  0.25708132 -0.33279717  1.26619782\n",
      "  0.42979467  0.69099685  0.19131419]  energy_before :  60  energy_after :  40  reward :  -174.46380824033474\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "action : 1  next_temperatures :  [ 1.0834796  -0.59301881  1.09615616 -0.91417348  1.00813999 -0.3612953\n",
      "  0.31557419  0.01453424  0.3295573 ]  energy_before :  40  energy_after :  40  reward :  -196.02104610583723\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "action : 1  next_temperatures :  [ 1.19140653 -1.22128612 -0.02335676 -0.49645324  0.96327592 -0.84268094\n",
      "  1.39251014 -1.1809848   2.05895152]  energy_before :  40  energy_after :  60  reward :  -216.15861773123265\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "action : 1  next_temperatures :  [-0.86958262 -0.49500911 -0.94906398 -0.18602976 -0.63189095  0.28294206\n",
      " -1.05507157  0.01453424 -0.47821617]  energy_before :  60  energy_after :  90  reward :  -232.36738786713312\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "action : 1  next_temperatures :  [ 1.83481704 -2.06819044  0.97726695 -2.10309655  0.86357799 -1.7849677\n",
      "  1.68132478 -1.91810636  2.43302112]  energy_before :  90  energy_after :  100  reward :  -208.08435317387259\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "action : 1  next_temperatures :  [ 0.37572804 -0.29396358 -0.25136347  0.33653007  0.21554145 -0.20049202\n",
      "  0.07081602  0.17577959  0.27534432]  energy_before :  100  energy_after :  60  reward :  -157.29607958011763\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "action : 1  next_temperatures :  [-0.30296627 -1.12327642 -1.02202613 -0.41536637 -1.08053164 -0.88467415\n",
      " -0.52149876 -0.95063431 -0.51977946]  energy_before :  60  energy_after :  60  reward :  -204.8207534882885\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "action : 1  next_temperatures :  [-0.40674216  0.21786485 -0.41704834 -0.44976686 -0.2829482  -1.29436405\n",
      " -0.17394215 -1.15276686 -0.10956787]  energy_before :  60  energy_after :  40  reward :  -182.06928163681386\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "action : 1  next_temperatures :  [-0.18466176 -0.6181495   0.00704413 -0.62832178  1.04137263  0.56767654\n",
      " -0.40646242 -0.04823627 -0.21257254]  energy_before :  40  energy_after :  60  reward :  -218.48231095981546\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "action : 1  next_temperatures :  [-0.59561427 -1.9165686  -0.61161406 -1.69391792 -1.08053164 -1.3957623\n",
      " -0.17394215 -1.37447921 -0.97697563]  energy_before :  60  energy_after :  50  reward :  -197.8194057850113\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "action : 1  next_temperatures :  [-0.24692729  1.16612963  0.25025128  0.66497284 -0.36602981  1.41983153\n",
      " -0.90821667  0.43914698 -0.32099851]  energy_before :  50  energy_after :  110  reward :  -255.90184000462807\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "action : 1  next_temperatures :  [-1.36148033 -0.67092396 -1.3609961  -0.20404907 -0.98581861 -1.0065569\n",
      " -1.05507157 -0.82010236 -1.0799803 ]  energy_before :  110  energy_after :  40  reward :  -136.54497918828844\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "action : 1  next_temperatures :  [ 1.81406186  0.00760473  1.07563555  0.04166872  1.46176557 -0.1666926\n",
      "  1.58831668  0.20802865  1.48584283]  energy_before :  40  energy_after :  40  reward :  -190.48376801150036\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "action : 1  next_temperatures :  [ 2.29039319 -1.84955342  3.10163798 -2.87359733  1.41191661 -0.93486116\n",
      "  1.65073001 -0.98201956  1.14275208]  energy_before :  40  energy_after :  50  reward :  -205.04260159951892\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "action : 1  next_temperatures :  [-2.11489328 -0.53438053 -1.57380235 -0.53822526 -1.82826611 -0.20049202\n",
      " -1.83829772 -0.42927437 -1.61006282]  energy_before :  50  energy_after :  50  reward :  -208.6676944614482\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "action : 1  next_temperatures :  [ 0.21591317 -0.26799519  0.47825799 -0.7446282  -0.18823517  0.61069398\n",
      "  0.45753393  0.09976392 -0.80891538]  energy_before :  50  energy_after :  50  reward :  -198.14761094546358\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "action : 1  next_temperatures :  [ 1.0834796  -0.29396358  0.98443287 -0.32690796 -0.53219302  1.27746429\n",
      " -1.15297484  1.00734485 -0.59206344]  energy_before :  50  energy_after :  60  reward :  -206.54538121930432\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "action : 1  next_temperatures :  [-2.40546577  0.06791839 -1.61940369  0.16452762 -2.07751094  0.23275505\n",
      " -2.52851576  0.27022329 -2.02870754]  energy_before :  60  energy_after :  50  reward :  -197.92417935756995\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "action : 1  next_temperatures :  [1.58367939 1.70141338 1.66845298 1.34643018 1.67777775 1.02857768\n",
      " 1.34355851 1.43579676 1.90173387]  energy_before :  50  energy_after :  40  reward :  -174.31257950836726\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "action : 1  next_temperatures :  [1.1063103  0.32676452 0.39161544 0.80585104 1.16267178 0.10677541\n",
      " 1.17712295 0.16886907 0.79578897]  energy_before :  40  energy_after :  60  reward :  -211.95823051629034\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "action : 1  next_temperatures :  [ 0.12666591 -1.32180888 -0.46796984 -0.79254317  0.31025448 -0.81502687\n",
      "  0.65823563 -1.36756869  0.3295573 ]  energy_before :  60  energy_after :  100  reward :  -241.3402041249327\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "action : 1  next_temperatures :  [ 0.63101673 -0.6181495   0.3460141  -0.82571507  0.16569248 -1.02704139\n",
      " -0.27674059 -0.85235143 -0.30292752]  energy_before :  100  energy_after :  70  reward :  -170.76020219150388\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "action : 1  next_temperatures :  [ 0.12666591  0.68864648 -0.43376883  1.07368343  0.55949931  0.42249268\n",
      "  0.54238343  0.13815567  0.7036269 ]  energy_before :  70  energy_after :  50  reward :  -174.1786150122724\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "action : 1  next_temperatures :  [-0.11616967  1.19879953  0.25025128  0.97785349 -0.83128681  1.98417937\n",
      " -1.46381772  1.80723693 -0.53785045]  energy_before :  50  energy_after :  130  reward :  -274.73080404422\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "action : 1  next_temperatures :  [1.12914099 1.01283241 1.12970571 0.60927681 1.05798895 0.4253093\n",
      " 1.34355851 0.89216961 1.84752088]  energy_before :  130  energy_after :  50  reward :  -108.5524968124036\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "action : 1  next_temperatures :  [ 0.74932124 -0.01501289  0.05568556  0.57487632  0.49469565  0.09755738\n",
      " -0.41870032  0.50057378  0.43256198]  energy_before :  50  energy_after :  60  reward :  -205.5284413064442\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "action : 1  next_temperatures :  [1.97387673 1.81115073 1.93636086 1.47236054 1.91040625 1.27746429\n",
      " 2.12678465 1.23769534 2.29387446]  energy_before :  60  energy_after :  150  reward :  -271.96002613340204\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "action : 1  next_temperatures :  [-0.03314896  1.35796058  0.33081365  0.83861341  0.06710231  1.29248626\n",
      " -0.27674059  1.24537369 -0.59206344]  energy_before :  150  energy_after :  90  reward :  -133.76960307553344\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "action : 1  next_temperatures :  [-1.16015511 -0.36935565 -0.56601272 -0.5636161  -1.03068267 -0.68904722\n",
      " -0.27674059 -0.74562237 -0.85538365]  energy_before :  90  energy_after :  150  reward :  -264.2566160825388\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "action : 1  next_temperatures :  [-0.55825495 -1.2715475  -1.3609961  -0.4227379  -0.38264613 -1.1806751\n",
      " -0.41870032 -1.11187965 -0.32099851]  energy_before :  150  energy_after :  50  reward :  -105.02843616848543\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "action : 1  next_temperatures :  [-1.21826961 -1.2547937  -1.16339028 -1.01491777 -0.93596964 -0.82219644\n",
      " -1.05507157 -1.23550108 -1.19382757]  energy_before :  50  energy_after :  50  reward :  -207.89393766401156\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "action : 1  next_temperatures :  [-0.3652318   1.36717517  0.07240605  0.8549946   0.01116069  1.89199914\n",
      " -0.71730529  1.74216291 -0.53785045]  energy_before :  50  energy_after :  100  reward :  -243.68048897574022\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "action : 1  next_temperatures :  [ 1.19140653 -1.48934683  0.95576917 -2.14767677  0.92339675 -1.54939601\n",
      "  1.11511755 -1.61174021  1.68488193]  energy_before :  100  energy_after :  60  reward :  -158.92758790419848\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "action : 1  next_temperatures :  [-0.24692729  0.41220887 -1.02202613  1.6879779   0.36508834 -0.22814609\n",
      "  0.16871929 -0.21581625  0.43256198]  energy_before :  60  energy_after :  100  reward :  -236.64635936938495\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "action : 1  next_temperatures :  [ 0.81781333  0.71126411  0.9038705   0.47740827 -0.2829482   1.73836543\n",
      " -0.8103134   1.19162524 -0.09300279]  energy_before :  100  energy_after :  90  reward :  -183.34591751541737\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "action : 1  next_temperatures :  [ 0.9423444   0.06791839  0.23505084  0.14978455  1.67777775 -0.30189027\n",
      " -0.17394215 -0.05994575  0.05849238]  energy_before :  90  energy_after :  40  reward :  -145.40440987011357\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "action : 1  next_temperatures :  [ 0.25742353 -0.67092396  0.00704413 -0.57262575 -0.43747999 -0.34285926\n",
      " -0.71730529  0.0552295   0.59158673]  energy_before :  40  energy_after :  70  reward :  -229.82991036165575\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "action : 1  next_temperatures :  [-0.30296627  0.87210054  0.10280695  0.34553972 -0.38264613  1.22318038\n",
      " -0.99469789  0.84609951 -0.32099851]  energy_before :  70  energy_after :  350  reward :  -476.6115817051179\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "action : 1  next_temperatures :  [ 1.37197657  0.13325819  1.53164896 -0.59031743  1.17264157 -0.34736585\n",
      "  1.39251014 -0.0061973   1.3311422 ]  energy_before :  350  energy_after :  40  reward :  117.98929706207582\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "action : 1  next_temperatures :  [ 0.195158    0.09221139 -0.38360736  0.89430945  0.31025448  0.14057482\n",
      " -0.22778895 -0.100641    0.22113133]  energy_before :  40  energy_after :  40  reward :  -196.85839783298024\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "action : 1  next_temperatures :  [-0.90694194  0.16927885 -0.80921987  0.21367117 -0.78143785  0.10677541\n",
      " -0.41870032 -0.04458905 -0.96794013]  energy_before :  40  energy_after :  60  reward :  -221.4391037404263\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "action : 1  next_temperatures :  [-0.67655947  0.61325441 -0.36840691  0.60927681 -0.83128681  1.76909217\n",
      " -1.57722233  1.86578434 -1.02576732]  energy_before :  60  energy_after :  70  reward :  -207.62183510697656\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "action : 1  next_temperatures :  [-0.11616967 -0.44223466 -0.74841808  0.14978455  0.03608517 -0.47396003\n",
      "  0.36452582 -0.83545906  0.27534432]  energy_before :  70  energy_after :  160  reward :  -289.7905016344392\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "action : 1  next_temperatures :  [ 0.12666591 -1.38212254 -0.29240467 -1.05505167 -0.18823517 -1.42956172\n",
      "  0.22909297 -1.51883218 -0.43484578]  energy_before :  160  energy_after :  60  reward :  -103.94529486025183\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "action : 1  next_temperatures :  [ 0.195158    0.39545508  0.25025128  0.45938896  0.54288298 -0.29267225\n",
      " -0.30611157  0.40613008  0.16149705]  energy_before :  60  energy_after :  60  reward :  -196.1880203828579\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "action : 1  next_temperatures :  [-1.05015267 -0.41710397 -0.59641361 -1.17791057 -1.08053164 -0.79088443\n",
      " -0.61450686 -1.27312499 -0.86312836]  energy_before :  60  energy_after :  50  reward :  -195.86375709769356\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "action : 1  next_temperatures :  [1.97198989 1.68363912 2.09981702 0.72684503 2.09520996 0.79924445\n",
      " 1.61742306 1.46350108 1.9046643 ]  energy_before :  50  energy_after :  60  reward :  -193.63766609665444\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n",
      "action : 1  next_temperatures :  [0.77215194 1.12340746 0.43265665 1.3218584  1.59303451 0.43452733\n",
      " 0.34820861 0.61574902 0.95662083]  energy_before :  60  energy_after :  20  reward :  -150.40178526107596\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "action : 1  next_temperatures :  [-1.61054246 -0.41040245 -1.29563417  0.01955412 -0.83128681 -0.41250654\n",
      " -1.54458791 -0.07530245 -1.40525821]  energy_before :  20  energy_after :  60  reward :  -245.56596689449856\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "action : 1  next_temperatures :  [2.37445166 1.72738176 2.85408785 0.14241301 2.95723452 0.78481219\n",
      " 1.83307485 1.55788252 1.7698156 ]  energy_before :  60  energy_after :  130  reward :  -251.99884604193753\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "action : 1  next_temperatures :  [-0.01239378  0.61157903  0.20464994  0.56750479  0.06100966 -0.06631858\n",
      "  0.07081602  0.48444924  0.22113133]  energy_before :  130  energy_after :  100  reward :  -165.85757234663197\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "action : 1  next_temperatures :  [ 0.74932124 -0.92223088  1.08931596 -1.48833404  2.32249103 -0.40226429\n",
      "  1.0498487  -1.07304914  0.60062223]  energy_before :  100  energy_after :  30  reward :  -126.0742791933827\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "action : 1  next_temperatures :  [-0.98788713 -0.2755344  -1.06762747  0.03429719 -0.83128681 -0.12213882\n",
      " -0.6634585  -0.58975187 -0.61194153]  energy_before :  30  energy_after :  40  reward :  -213.11532935861695\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "action : 1  next_temperatures :  [-0.55825495 -1.26400829  0.64850299 -2.12801935 -0.38264613 -1.30358207\n",
      "  0.16871929 -0.89688586 -0.48363747]  energy_before :  40  energy_after :  50  reward :  -214.1998118476655\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "action : 1  next_temperatures :  [-0.24692729 -1.02024058 -0.82442032 -0.34902256 -0.08355234 -0.84268094\n",
      " -0.27674059 -0.97597286 -0.61194153]  energy_before :  50  energy_after :  220  reward :  -373.2314990021904\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "action : 1  next_temperatures :  [ 0.195158    1.09743908 -0.29240467  2.02543033  1.37868396  0.39560679\n",
      "  0.60928399  0.72247808  0.45244007]  energy_before :  220  energy_after :  90  reward :  -61.41588437599205\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "action : 1  next_temperatures :  [-1.0190199   0.21116333 -0.97642479  0.37174962 -1.03068267  0.54002247\n",
      " -1.04038608  0.31629338 -0.74928109]  energy_before :  90  energy_after :  50  reward :  -161.37656572415142\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "action : 1  next_temperatures :  [-1.74130008 -0.01501289 -1.34579565  0.07606921 -1.46769193  0.20202831\n",
      " -1.29982974 -0.16974615 -1.43507535]  energy_before :  50  energy_after :  230  reward :  -385.19635428272625\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "action : 1  next_temperatures :  [ 0.88007886 -1.38212254  0.39161544 -1.26800709  0.24545083 -1.33430881\n",
      "  0.26172739 -1.00515059  0.88614395]  energy_before :  230  energy_after :  40  reward :  -10.324572570266525\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "action : 1  next_temperatures :  [ 0.58950637 -0.84432573  0.11800739 -0.42519508 -0.13340131 -0.85292318\n",
      "  0.59296678 -0.41545334 -0.04993359]  energy_before :  40  energy_after :  40  reward :  -199.42075167509532\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "action : 1  next_temperatures :  [1.06064891 0.25891165 0.29324683 0.80901027 1.14605546 0.07912134\n",
      " 1.14775197 0.17577959 0.81747417]  energy_before :  40  energy_after :  80  reward :  -232.21199981572826\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "action : 1  next_temperatures :  [-0.49598942 -1.01270137 -0.02335676 -1.308141   -0.40092408 -1.1806751\n",
      " -0.03198241 -0.95908049 -0.26678553]  energy_before :  80  energy_after :  50  reward :  -173.6796361721688\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "action : 1  next_temperatures :  [-0.55825495  0.18603264 -0.15560065 -0.05416122 -0.68672482  0.78276374\n",
      " -0.6634585   0.66181912 -0.48363747]  energy_before :  50  energy_after :  60  reward :  -208.97122210161461\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "action : 1  next_temperatures :  [-0.11616967 -0.45898845 -1.11778894  0.64859166  0.06100966 -0.65012668\n",
      "  0.69599832 -0.74858402  0.43256198]  energy_before :  60  energy_after :  60  reward :  -199.2534961617449\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "action : 1  next_temperatures :  [-0.42749733  1.99544247 -0.10999931  1.7887222  -0.38264613  2.30066482\n",
      " -0.26042337  2.32034264 -0.26678553]  energy_before :  60  energy_after :  50  reward :  -181.0421795501435\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "action : 1  next_temperatures :  [-1.2992148  -0.92223088 -1.11778894 -0.52921561 -1.08053164 -0.9778786\n",
      " -1.25577327 -0.67651722 -0.65169772]  energy_before :  50  energy_after :  70  reward :  -226.5108486862645\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "action : 1  next_temperatures :  [1.50273419 0.81429994 0.75642617 1.37100196 1.36206764 0.3218626\n",
      " 1.29460687 0.75165581 1.90173387]  energy_before :  70  energy_after :  340  reward :  -457.9236109461049\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "action : 1  next_temperatures :  [ 0.81781333  1.01534548  0.70626469  0.34553972  0.06100966  1.12383058\n",
      " -0.96206346  2.37255542 -0.97697563]  energy_before :  340  energy_after :  70  reward :  76.50331978271308\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step\n",
      "action : 1  next_temperatures :  [-1.42997242 -0.84432573 -1.52364088 -0.11149537 -1.23506343 -0.78122745\n",
      " -1.05507157 -0.82778071 -1.19382757]  energy_before :  70  energy_after :  50  reward :  -187.0024051301579\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n",
      "action : 1  next_temperatures :  [ 1.1063103  -0.28307361  1.42741733 -0.55331935  1.29061746 -0.41250654\n",
      "  1.29460687 -0.42082818  0.81747417]  energy_before :  50  energy_after :  20  reward :  -163.73330156120542\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "action : 1  next_temperatures :  [-0.738825    0.73890787 -0.41704834  0.73213571 -0.88113578  1.58473172\n",
      " -1.39773301  1.42197573 -0.59206344]  energy_before :  20  energy_after :  60  reward :  -237.54905454005728\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "action : 1  next_temperatures :  [ 0.5687512  -1.1735378   1.53164896 -2.29838368  0.31025448 -1.17043285\n",
      "  0.85404217 -1.24394726  0.60062223]  energy_before :  60  energy_after :  60  reward :  -200.02098256838227\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "action : 1  next_temperatures :  [-0.05390414 -0.24370219  0.02224458 -0.25073545 -0.53219302  0.07912134\n",
      " -0.50518155 -0.16129996 -0.70591071]  energy_before :  60  energy_after :  240  reward :  -380.35156109923435\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "action : 1  next_temperatures :  [-1.40714172  0.46917177 -0.66177553  0.21367117 -0.79805417  1.59394974\n",
      " -0.90821667  0.44682533 -0.53785045]  energy_before :  240  energy_after :  50  reward :  -9.58942053422652\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "action : 1  next_temperatures :  [ 0.83856851  0.98853941  0.52841946  0.69937333  1.59303451  1.17401759\n",
      "  0.9960019  -0.30565294  1.19154376]  energy_before :  50  energy_after :  30  reward :  -170.2961544496311\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "action : 1  next_temperatures :  [-0.24692729 -0.28474899 -0.61161406  0.5027991   0.11584352 -0.90720709\n",
      "  0.52187036 -0.48993333  0.29341531]  energy_before :  30  energy_after :  70  reward :  -239.1065024621616\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "action : 1  next_temperatures :  [-0.738825   -0.51762674 -0.88978224 -0.25073545 -0.58204199  0.26040912\n",
      " -1.0110151   0.01453424 -0.3806328 ]  energy_before :  70  energy_after :  110  reward :  -242.09571594747348\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "action : 1  next_temperatures :  [-1.23694927 -1.14003021 -0.85634126 -1.30076946 -1.08053164 -1.13151231\n",
      " -0.9261656  -1.32149859 -1.16827002]  energy_before :  110  energy_after :  60  reward :  -158.1620683632472\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "action : 1  next_temperatures :  [ 0.37572804 -0.47657994 -0.17232114  0.11784124  0.26040552 -0.464742\n",
      " -0.12499052  0.18422577  0.27534432]  energy_before :  60  energy_after :  40  reward :  -178.02508871907395\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "action : 1  next_temperatures :  [2.06312399 2.01052089 3.21433844 0.04166872 1.79860215 1.75548462\n",
      " 2.56734936 1.21235679 2.33001645]  energy_before :  40  energy_after :  80  reward :  -221.0065385975232\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "action : 1  next_temperatures :  [-2.21244262  1.38392897 -1.13298939  0.98604409 -2.37660473  1.43109801\n",
      " -2.67537066  2.12684823 -2.27808727]  energy_before :  80  energy_after :  50  reward :  -172.74757537650788\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "action : 1  next_temperatures :  [ 0.39648322 -0.29396358 -0.22096257  0.28738651  0.21554145 -0.22814609\n",
      "  0.11976765  0.22415319  0.27534432]  energy_before :  50  energy_after :  50  reward :  -197.22439589738372\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "action : 1  next_temperatures :  [-0.5167446  -0.46736535  0.32321343 -1.27722151 -0.31618084 -0.90720709\n",
      "  0.01696922 -0.9967044  -0.80891538]  energy_before :  50  energy_after :  50  reward :  -202.95015653217433\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "action : 1  next_temperatures :  [ 0.195158    3.21846949  0.55882036  1.36281136 -0.09352213  2.28468691\n",
      " -0.17394215  1.50490191  0.37834899]  energy_before :  50  energy_after :  160  reward :  -298.76426727118826\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "action : 1  next_temperatures :  [ 1.75179633 -0.6432802   0.69323574 -0.16122397  0.96327592 -2.22538435\n",
      "  1.97503459 -0.33691479  2.27580346]  energy_before :  160  energy_after :  50  reward :  -83.70765726256005\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "action : 1  next_temperatures :  [-1.23694927 -0.99762296 -1.19075109 -0.50546289 -1.03068267 -1.06084081\n",
      " -1.22313885 -0.61355476 -0.59206344]  energy_before :  50  energy_after :  70  reward :  -226.45106672172483\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "action : 1  next_temperatures :  [-0.24692729  1.38979279  0.16360874  0.87956638  0.06100966  1.8694662\n",
      " -0.64714128  1.78823301 -0.51375579]  energy_before :  70  energy_after :  80  reward :  -203.25614759194644\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "action : 1  next_temperatures :  [ 0.9423444  -0.51762674  0.10280695  0.01955412  0.46478627 -0.20049202\n",
      " -0.03198241 -0.07530245  0.3295573 ]  energy_before :  80  energy_after :  60  reward :  -176.96635457668566\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "action : 1  next_temperatures :  [-0.42749733 -1.2715475  -0.83962076 -0.94857397 -0.83128681 -0.464742\n",
      " -0.76625693 -0.92759926 -0.43484578]  energy_before :  60  energy_after :  100  reward :  -244.91197034987286\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "action : 1  next_temperatures :  [ 1.06064891 -0.87196949  0.52841946 -0.66108415  0.29363816 -1.02704139\n",
      " -0.32079706  0.11512062 -0.26678553]  energy_before :  100  energy_after :  50  reward :  -149.1498504703412\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "action : 1  next_temperatures :  [ 0.12666591 -0.40118786  0.80202751 -1.01491777 -0.003794   -0.7627914\n",
      "  0.56033236 -0.46689828  0.16149705]  energy_before :  50  energy_after :  50  reward :  -198.99906648422885\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "action : 1  next_temperatures :  [ 0.29893389  0.10142598 -0.66177553  1.17442773  0.86357799 -0.12777206\n",
      "  0.25193706 -0.21581625  0.60062223]  energy_before :  50  energy_after :  70  reward :  -215.71443896682328\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "action : 1  next_temperatures :  [1.37197657 1.31691379 0.9342714  1.44226011 1.72596508 0.09755738\n",
      " 1.6519538  0.82920714 1.51682167]  energy_before :  70  energy_after :  220  reward :  -337.1130730435202\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "action : 1  next_temperatures :  [-0.11616967  0.40299428 -0.49305057  1.27025766  0.34681039  0.14057482\n",
      " -0.56555523  0.2310637  -0.18004475]  energy_before :  220  energy_after :  40  reward :  -16.963119360571255\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "action : 1  next_temperatures :  [-1.2992148   1.21387795 -0.70737688  0.92870994 -1.21844711  1.654379\n",
      " -1.27045876  1.15169783 -1.29683224]  energy_before :  40  energy_after :  30  reward :  -188.84366507245977\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "action : 1  next_temperatures :  [-0.11616967 -0.39197328 -0.70737688  0.3881308   0.01116069 -0.04685831\n",
      " -0.03198241 -0.44616674 -0.04993359]  energy_before :  30  energy_after :  70  reward :  -239.39116937073024\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "action : 1  next_temperatures :  [-1.8596046  -0.62066257 -1.25003283 -0.66845569 -1.57902129  0.35566202\n",
      " -2.20217153 -0.19047769 -1.62211015]  energy_before :  70  energy_after :  100  reward :  -237.63687433358163\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "action : 1  next_temperatures :  [-0.59561427  0.03524849 -1.20443149  1.17442773  0.36508834  0.14057482\n",
      " -0.32079706 -0.23654779  0.3295573 ]  energy_before :  100  energy_after :  70  reward :  -168.31249392599662\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "action : 1  next_temperatures :  [ 1.75179633  1.13848587  1.71405433  0.40392695  2.22445473 -0.373586\n",
      "  1.83307485  0.75165581  1.73367361]  energy_before :  70  energy_after :  60  reward :  -176.8224635251944\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "action : 1  next_temperatures :  [ 0.33836872  1.50790705 -0.01423649  0.07361203 -0.68672482  0.07707289\n",
      "  0.45753393 -0.46689828 -0.35430078]  energy_before :  60  energy_after :  50  reward :  -187.06766574611578\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "action : 1  next_temperatures :  [1.81406186 1.12717706 0.88867006 1.46027942 1.86055729 1.15455732\n",
      " 1.63726831 1.08336051 2.11858581]  energy_before :  50  energy_after :  60  reward :  -194.8554823591348\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "action : 1  next_temperatures :  [-0.61429393 -1.26400829 -0.94906398 -0.87403957 -0.83128681 -0.35412573\n",
      " -0.85926503 -0.94295596 -0.53785045]  energy_before :  60  energy_after :  50  reward :  -195.22688976683924\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "action : 1  next_temperatures :  [-2.48225993 -1.04788434 -1.6604449  -0.96331703 -2.02766197 -0.54565576\n",
      " -2.08305589 -0.74562237 -1.67632314]  energy_before :  50  energy_after :  30  reward :  -191.23222532819022\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "action : 1  next_temperatures :  [-1.672808   -0.05773507 -1.29563417 -0.07218052 -1.37962543  0.29420854\n",
      " -1.25577327 -0.21581625 -1.44700221]  energy_before :  30  energy_after :  60  reward :  -235.10236638194246\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "action : 1  next_temperatures :  [-0.738825   -1.02024058 -1.58520269  0.28185786 -0.93596964 -0.62759374\n",
      " -0.47254712 -1.15794975 -0.95890464]  energy_before :  60  energy_after :  50  reward :  -195.2153752920636\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "action : 1  next_temperatures :  [ 1.19140653  0.48676326  1.80252093  0.03822867  1.21252075 -0.07451237\n",
      "  1.29460687  0.45450368  0.92047884]  energy_before :  50  energy_after :  110  reward :  -250.67348285322507\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "action : 1  next_temperatures :  [-0.3652318  -1.01700949 -0.56601272 -0.69548464 -0.65539118 -0.23692516\n",
      " -0.6634585  -0.78535783 -0.70591071]  energy_before :  110  energy_after :  90  reward :  -183.69078202404344\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "action : 1  next_temperatures :  [-0.18466176 -0.09040497  0.10660706 -0.19729183 -0.84790314  0.90874338\n",
      " -0.71730529  0.86683105 -0.32099851]  energy_before :  90  energy_after :  50  reward :  -158.4763840005515\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "action : 1  next_temperatures :  [ 0.12666591  0.66351579  0.3460141   0.3881308   0.11584352  1.44987546\n",
      " -0.12499052  0.7140319  -0.26678553]  energy_before :  50  energy_after :  40  reward :  -184.58769857056285\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "action : 1  next_temperatures :  [ 0.27817871  0.3527329   1.07563555 -0.4006233   0.41493731 -0.13903853\n",
      "  1.19180844  0.01453424  0.47231816]  energy_before :  40  energy_after :  90  reward :  -244.7395165134755\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "action : 1  next_temperatures :  [-0.20541693  1.19796184  0.25025128  0.66497284 -0.38264613  1.40856506\n",
      " -0.90821667  0.43914698 -0.32099851]  energy_before :  90  energy_after :  90  reward :  -195.85638023305722\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "action : 1  next_temperatures :  [-1.11864475 -1.04788434 -1.06762747 -0.75118068 -0.63189095 -0.99631465\n",
      " -1.28514425 -0.58207352 -1.32006638]  energy_before :  90  energy_after :  70  reward :  -186.80082699255615\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "action : 1  next_temperatures :  [-1.05015267 -0.46736535 -0.83962076 -0.26711663 -0.83128681 -0.55692223\n",
      " -0.48886433 -0.75253289 -0.70591071]  energy_before :  70  energy_after :  60  reward :  -193.95977238729176\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "action : 1  next_temperatures :  [ 0.25742353 -1.2715475  -0.74841808 -0.4006233   0.47974096 -1.41829524\n",
      "  0.50648556 -1.57258063  0.68555591]  energy_before :  60  energy_after :  30  reward :  -171.4822587919344\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "action : 1  next_temperatures :  [ 0.5687512   0.38456511  0.05568556  0.79684139  0.26040552  0.10677541\n",
      " -0.12499052 -0.14440759  0.3295573 ]  energy_before :  30  energy_after :  50  reward :  -215.76681662767604\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "action : 1  next_temperatures :  [-2.05262775  0.87963974 -1.20443149  0.54211395 -1.37962543  1.15455732\n",
      " -1.04038608  0.68485417 -1.29683224]  energy_before :  50  energy_after :  60  reward :  -211.71273780581785\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "action : 1  next_temperatures :  [ 0.33836872  0.80508536  0.64698295 -0.00501766  0.80874413  0.8554837\n",
      "  0.21277576  0.73783478 -0.3806328 ]  energy_before :  60  energy_after :  70  reward :  -203.9803750625787\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "action : 1  next_temperatures :  [-0.24692729 -1.26023869 -1.02202613 -0.32690796  0.21554145 -1.30358207\n",
      "  0.07081602 -1.42147071  0.3458212 ]  energy_before :  70  energy_after :  50  reward :  -182.94897417889467\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "action : 1  next_temperatures :  [-1.23694927  1.21387795 -0.66177553  1.04255918 -0.93596964  1.44134025\n",
      " -1.1040232   1.62698767 -1.13419329]  energy_before :  50  energy_after :  90  reward :  -237.74814588246826\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "action : 1  next_temperatures :  [-1.49223795  1.37555207 -0.74841808  0.64859166 -1.43445929  1.2651736\n",
      " -0.56555523  0.63110572 -1.02576732]  energy_before :  90  energy_after :  40  reward :  -149.34601482579197\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "action : 1  next_temperatures :  [-0.67655947  0.57053223 -0.15560065  0.01955412 -0.63189095  0.56767654\n",
      " -0.8103134   0.43914698 -0.3806328 ]  energy_before :  40  energy_after :  60  reward :  -219.0580873958008\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "action : 1  next_temperatures :  [ 0.06440038  0.3116861   0.25025128  0.04166872 -0.38264613  1.00783713\n",
      " -0.32079706  0.70558571 -0.26678553]  energy_before :  60  energy_after :  20  reward :  -156.58879939182992\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "action : 1  next_temperatures :  [ 0.31968906 -0.39197328  0.16360874 -0.2114206   0.16569248 -0.3817798\n",
      "  0.21277576 -0.46689828  0.37834899]  energy_before :  20  energy_after :  110  reward :  -288.2119569251154\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "action : 1  next_temperatures :  [-0.98788713  0.0829968  -0.88978224  0.26527191 -0.68672482  0.12930835\n",
      " -0.12499052  0.12279897 -0.92276265]  energy_before :  110  energy_after :  110  reward :  -201.0117713170586\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "action : 1  next_temperatures :  [-0.49598942 -0.3855111  -0.33800601 -0.56490319  0.01116069 -0.22024492\n",
      " -0.83129267 -0.67651722 -0.84763894]  energy_before :  110  energy_after :  110  reward :  -202.3489427898884\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "action : 1  next_temperatures :  [ 0.0083614   0.79754615  0.26697177  0.59125751 -0.75152847  1.78752822\n",
      " -1.59353955  1.74216291 -0.26678553]  energy_before :  110  energy_after :  50  reward :  -135.41802558440602\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "action : 1  next_temperatures :  [-1.14977752  4.30620961 -0.62833455  2.27196718 -0.98581861  1.60214354\n",
      " -1.15297484  1.62007715 -1.13419329]  energy_before :  50  energy_after :  310  reward :  -453.25070131727944\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "action : 1  next_temperatures :  [-0.9256216   0.55377844 -0.92018313  0.63384859 -0.43747999 -0.02432536\n",
      " -1.15297484  0.07749671 -0.65169772]  energy_before :  310  energy_after :  110  reward :  -0.8471589080941158\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "action : 1  next_temperatures :  [ 5.06485663e-01  4.02156594e-01  6.60663351e-01 -1.03303126e-04\n",
      "  1.14605546e+00 -6.61393155e-01  7.51243733e-01  1.07186329e-01\n",
      "  6.00622229e-01]  energy_before :  110  energy_after :  50  reward :  -134.48708309911646\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "action : 1  next_temperatures :  [ 0.12666591 -0.43469545 -0.26504387 -0.14589586  0.06100966 -0.53541351\n",
      "  0.11976765 -0.34481252  0.27534432]  energy_before :  50  energy_after :  130  reward :  -279.14307367075503\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "action : 1  next_temperatures :  [1.3512214  0.00760473 0.40529584 0.56750479 1.5564786  0.17949536\n",
      " 1.39251014 0.0398728  0.41784702]  energy_before :  130  energy_after :  350  reward :  -412.0821693169006\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "action : 1  next_temperatures :  [-0.57693461 -0.82170811 -1.06762747 -0.10453336 -0.13340131 -0.82219644\n",
      " -0.43664926 -1.06580955  0.46870397]  energy_before :  350  energy_after :  20  reward :  127.43984385407765\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "action : 1  next_temperatures :  [-1.54827693  0.16927885 -0.83962076 -0.10330477 -1.48430825  1.00092361\n",
      " -0.85926503  0.45450368 -1.19382757]  energy_before :  20  energy_after :  60  reward :  -242.40389719076632\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "action : 1  next_temperatures :  [-0.67655947  1.49282863 -0.15560065  1.00242527 -1.03068267  1.92272588\n",
      "  0.03491815  1.58322108 -0.43484578]  energy_before :  60  energy_after :  80  reward :  -214.26156955657012\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "action : 1  next_temperatures :  [-0.30296627 -0.11804873 -0.43376883  0.14978455 -0.41920204  0.45706027\n",
      " -0.9261656   0.50057378 -0.80891538]  energy_before :  80  energy_after :  50  reward :  -169.90164825234476\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "action : 1  next_temperatures :  [-0.18466176  0.06791839 -0.38360736  0.82223223  0.43155363 -0.03354338\n",
      " -0.36974869  0.37695235  0.3295573 ]  energy_before :  50  energy_after :  30  reward :  -176.94334728650148\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "action : 1  next_temperatures :  [-0.26560695  1.38225359  0.16360874  0.87956638 -0.03370338  1.79674624\n",
      " -0.6634585   1.78823301 -0.52279129]  energy_before :  30  energy_after :  50  reward :  -213.47515215881538\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "action : 1  next_temperatures :  [ 0.46082427 -0.43469545 -0.06439797  0.07606921 -0.13340131 -0.32032631\n",
      "  0.94705027 -0.27647521  0.18137515]  energy_before :  50  energy_after :  50  reward :  -197.56397735030276\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "action : 1  next_temperatures :  [-0.07465931 -1.92662087 -0.10999931 -1.99778892 -0.93596964 -1.30358207\n",
      " -0.43828098 -1.89583915 -1.19382757]  energy_before :  50  energy_after :  60  reward :  -217.87656782924125\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "action : 1  next_temperatures :  [ 0.5687512   0.50435474  0.39161544  0.17353727  0.26040552 -0.20971004\n",
      "  0.31557419 -0.15976429  0.3295573 ]  energy_before :  60  energy_after :  130  reward :  -265.825678679254\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "action : 1  next_temperatures :  [-0.55825495  0.75398628 -0.66177553  1.44226011 -0.33279717  0.17949536\n",
      " -0.61450686  0.84609951 -0.16378086]  energy_before :  130  energy_after :  60  reward :  -127.10927410226108\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "action : 1  next_temperatures :  [-0.86958262  0.56299302 -0.47937017  0.4102454  -0.68672482  1.5509323\n",
      " -1.45157981  1.07645    -1.02877915]  energy_before :  60  energy_after :  250  reward :  -388.91541583663764\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "action : 1  next_temperatures :  [-0.45032803 -0.5452705  -0.66177553 -0.34902256 -0.7116493   0.13903849\n",
      " -0.8103134   0.06905053 -0.16378086]  energy_before :  250  energy_after :  60  reward :  -11.484051168392767\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "action : 1  next_temperatures :  [-1.672808   -1.33018578 -0.92018313 -1.39987564 -1.48430825 -1.21447452\n",
      " -1.13665763 -1.36756869 -1.26430445]  energy_before :  60  energy_after :  70  reward :  -219.79036609301158\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "action : 1  next_temperatures :  [ 0.06440038 -0.44223466 -0.38360736  0.00317293  0.11584352 -0.41250654\n",
      "  0.07081602 -0.25958284  0.27534432]  energy_before :  70  energy_after :  60  reward :  -188.96835422824216\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "action : 1  next_temperatures :  [ 1.75179633  1.08822449  1.39028481  0.73705006  2.20950004 -0.1666926\n",
      "  1.88202648  0.96127475  1.63066894]  energy_before :  60  energy_after :  70  reward :  -196.51586669585237\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "action : 1  next_temperatures :  [-0.80731709  0.93995341 -0.33800601  0.82796564 -0.93596964  1.51201176\n",
      " -0.75401902  1.55788252 -1.0799803 ]  energy_before :  70  energy_after :  270  reward :  -397.07747873199577\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "action : 1  next_temperatures :  [1.21216171 0.57974682 0.70626469 0.68931061 1.11282282 0.20202831\n",
      " 1.29460687 0.29095483 0.80392092]  energy_before :  270  energy_after :  50  reward :  28.89181757176877\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "action : 1  next_temperatures :  [-0.61429393 -0.26631982 -0.29240467 -0.54559679 -0.80992297 -0.33964027\n",
      " -0.89423049 -0.62320754 -0.84763894]  energy_before :  50  energy_after :  60  reward :  -213.23325541908753\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "action : 1  next_temperatures :  [-0.11616967 -0.71029538 -0.88978224  0.29639616 -0.03370338 -0.68904722\n",
      " -0.56555523 -0.53600343 -0.16378086]  energy_before :  60  energy_after :  110  reward :  -251.40794123281944\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "action : 1  next_temperatures :  [-1.23694927 -0.96997919 -1.20443149 -0.81834354 -1.16328092 -0.48747979\n",
      " -1.25577327 -0.73717619 -1.40525821]  energy_before :  110  energy_after :  400  reward :  -497.27867187127947\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "action : 1  next_temperatures :  [-0.9256216   0.05200228 -0.88978224  0.19892811 -0.63189095  0.14057482\n",
      "  0.05286708  0.13969134 -0.92276265]  energy_before :  400  energy_after :  60  reward :  139.21400620012187\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n",
      "action : 1  next_temperatures :  [ 0.21591317  2.15460352  0.3460141   1.50123238 -0.18823517  2.12654661\n",
      "  0.50648556  1.36054894 -0.53785045]  energy_before :  60  energy_after :  50  reward :  -180.51474133238918\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "action : 1  next_temperatures :  [ 0.06440038  0.51189395  0.03896507  0.74769783  0.75889517 -0.35412573\n",
      " -0.27674059  0.34623895  0.20125324]  energy_before :  50  energy_after :  30  reward :  -175.96152173168545\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "action : 1  next_temperatures :  [-0.61429393 -1.63342947 -0.66177553 -1.50635335 -1.08053164 -1.23291056\n",
      " -0.76625693 -1.40365694 -1.24804056]  energy_before :  30  energy_after :  50  reward :  -228.1472489026927\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "action : 1  next_temperatures :  [ 1.93236637 -0.61144799  1.91166014 -1.43018083  1.16267178 -0.75357338\n",
      "  1.48551825 -0.69724877  0.95662083]  energy_before :  50  energy_after :  40  reward :  -184.04361360362233\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "action : 1  next_temperatures :  [-0.05390414 -1.28997667 -0.44896928 -1.26800709 -0.93596964 -0.67061118\n",
      " -0.52149876 -0.95063431 -0.16378086]  energy_before :  40  energy_after :  60  reward :  -224.30335191708764\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "action : 1  next_temperatures :  [ 0.9423444   0.0829968   0.39161544  0.37338774  1.21252075  0.0483946\n",
      "  1.14775197 -0.16974615  0.85000196]  energy_before :  60  energy_after :  100  reward :  -233.12073250188044\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "action : 1  next_temperatures :  [-2.36395542 -0.49500911 -1.57380235 -0.67746534 -2.02766197 -0.10523912\n",
      " -1.99004778 -0.59743022 -1.82811949]  energy_before :  100  energy_after :  60  reward :  -169.6587308103591\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "action : 1  next_temperatures :  [ 0.0083614   1.04885307  0.3460141   0.90168098  0.01116069  1.73836543\n",
      " -0.90821667  1.37590564 -0.26678553]  energy_before :  60  energy_after :  90  reward :  -223.74466089071097\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "action : 1  next_temperatures :  [2.37445166 2.35397368 2.08863677 1.71500686 1.97948268 1.95037995\n",
      " 2.38916541 1.71682436 2.71131444]  energy_before :  90  energy_after :  80  reward :  -168.72076418865413\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "action : 1  next_temperatures :  [-0.65580429  2.16214273 -0.09479886  1.68224449 -0.84790314  2.01183344\n",
      " -1.15297484  1.65232622 -1.13419329]  energy_before :  80  energy_after :  90  reward :  -204.37712753463654\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "action : 1  next_temperatures :  [ 0.61026155 -0.17584932  0.61962214 -0.299879   -0.48732896  1.34711158\n",
      " -1.25577327  0.88372342 -0.70591071]  energy_before :  90  energy_after :  60  reward :  -167.4640225669983\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "action : 1  next_temperatures :  [-0.7616557  -0.21605843  0.05568556 -0.53822526 -0.83128681 -0.25887283\n",
      "  0.16871929 -0.53600343 -0.70591071]  energy_before :  60  energy_after :  50  reward :  -191.62360831506246\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "action : 1  next_temperatures :  [ 0.74932124 -0.14066635  0.00270115  0.33653007  1.30723378 -0.47396003\n",
      "  1.14775197 -0.46689828  1.73367361]  energy_before :  50  energy_after :  90  reward :  -233.80431284134363\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "action : 1  next_temperatures :  [-0.55825495 -1.68369085 -0.52041138 -1.60218328 -1.06059205 -1.22000533\n",
      " -0.76625693 -1.1809848  -1.02576732]  energy_before :  90  energy_after :  50  reward :  -167.61814689224303\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "action : 1  next_temperatures :  [-0.42749733  0.14414816 -0.52041138  0.19155657 -0.65016891  0.33517753\n",
      "  0.38084303 -0.01464349 -0.63465936]  energy_before :  50  energy_after :  90  reward :  -239.19565517503761\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "action : 1  next_temperatures :  [-0.69731464  0.21786485 -0.70737688  0.19155657 -1.03068267  0.75510967\n",
      " -0.85926503  0.33932843 -0.48966113]  energy_before :  90  energy_after :  60  reward :  -170.28044083149365\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "action : 1  next_temperatures :  [-2.05262775  0.86456133 -1.20443149  0.5331043  -1.39790338  1.12383058\n",
      " -1.05507157  0.68485417 -1.29683224]  energy_before :  60  energy_after :  50  reward :  -191.80051605982047\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "action : 1  next_temperatures :  [ 0.50648566 -0.69354158  0.02224458 -0.09593324  0.26040552 -0.66139315\n",
      " -0.07603889  0.06060434  0.27534432]  energy_before :  50  energy_after :  50  reward :  -198.40182244268533\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "action : 1  next_temperatures :  [ 0.33836872  0.00760473 -0.15560065  0.31441547  0.26040552 -0.22814609\n",
      "  0.21277576  0.02298043  0.27534432]  energy_before :  50  energy_after :  60  reward :  -206.9518517984282\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "action : 1  next_temperatures :  [-0.3652318   0.26812624  0.10280695  0.42089317  0.01116069 -0.25887283\n",
      "  0.07081602  0.00071321  0.54640924]  energy_before :  60  energy_after :  40  reward :  -177.20317910397037\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "action : 1  next_temperatures :  [-2.11489328 -0.09208035 -1.3609961  -0.4006233  -1.82826611  0.23275505\n",
      " -1.78934608 -0.23654779 -1.89317508]  energy_before :  40  energy_after :  60  reward :  -227.48317303723798\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "action : 1  next_temperatures :  [1.50273419 1.84214525 0.66066335 2.35387311 2.00511929 1.61545846\n",
      " 1.34355851 1.49108088 1.82764279]  energy_before :  60  energy_after :  60  reward :  -183.35772417207005\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "action : 1  next_temperatures :  [-1.63129764 -1.40641555 -0.80921987 -1.56123032 -1.52917232 -1.25339506\n",
      " -1.02570059 -1.37447921 -1.29683224]  energy_before :  60  energy_after :  60  reward :  -209.88774279869972\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "action : 1  next_temperatures :  [-0.98788713 -0.98757068 -1.42027784 -0.25237357 -1.03068267 -0.79249392\n",
      " -0.52149876 -1.1218615  -0.92276265]  energy_before :  60  energy_after :  100  reward :  -246.03740871909545\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "action : 1  next_temperatures :  [ 0.25742353  0.28655541  0.40529584  0.01955412 -0.38264613  1.02857768\n",
      " -0.10867331  0.63648056 -0.16378086]  energy_before :  100  energy_after :  80  reward :  -176.02121314911346\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "action : 1  next_temperatures :  [1.30971104 1.9770133  2.82672704 0.21514548 2.24107105 1.18425984\n",
      " 1.73027642 1.16091185 1.61259795]  energy_before :  80  energy_after :  100  reward :  -203.74228603160634\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "action : 2  next_temperatures :  [ 0.0743784   0.57284376  0.70759533 -0.5554969  -0.2799275  -0.07005883\n",
      "  0.9843348  -0.19787717  0.07723735]  energy_before :  100  energy_after :  110  reward :  -215.686970764417\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "action : 1  next_temperatures :  [-0.11616967  0.03524849 -0.66177553  0.92870994  0.16569248 -0.25887283\n",
      " -0.03198241  0.12970949  0.18137515]  energy_before :  110  energy_after :  280  reward :  -367.6280649026621\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "action : 1  next_temperatures :  [-1.09581406 -0.72872455 -0.93538358 -0.97969822 -1.06391532 -1.33635726\n",
      " -0.76625693 -1.38830024 -1.0799803 ]  energy_before :  280  energy_after :  90  reward :  -17.37443045468956\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "action : 1  next_temperatures :  [-0.11616967  0.00760473 -0.77881898  0.98604409  0.26040552  0.00537716\n",
      " -0.29142608 -0.15285378  0.16149705]  energy_before :  90  energy_after :  60  reward :  -167.91833995932038\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "action : 1  next_temperatures :  [-1.61054246 -1.39133713 -1.47803954 -1.05341356 -1.2799275  -0.81502687\n",
      " -1.25577327 -1.22705489 -1.19382757]  energy_before :  60  energy_after :  60  reward :  -209.30494278911078\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "action : 1  next_temperatures :  [-0.24692729  0.3770259  -0.97642479  1.52662322  0.31025448 -0.20049202\n",
      "  0.27967632 -0.07683812  0.43256198]  energy_before :  60  energy_after :  280  reward :  -416.57454030554425\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "action : 1  next_temperatures :  [-0.18466176  0.28655541 -0.83962076  1.56511901 -0.73657378 -0.20049202\n",
      "  0.13608486 -0.41391767 -0.43484578]  energy_before :  280  energy_after :  40  reward :  41.17764751500667\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "action : 1  next_temperatures :  [ 0.31968906 -1.11406183 -0.18904163 -0.75118068 -0.68672482 -0.87340768\n",
      " -0.07603889 -1.09114811 -0.65169772]  energy_before :  40  energy_after :  70  reward :  -233.11361228233577\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "action : 1  next_temperatures :  [-0.82599675  1.23984633 -0.20462209 -0.0117749  -0.10016866  2.36314253\n",
      " -0.9261656   0.78390488 -1.35104523]  energy_before :  70  energy_after :  20  reward :  -147.03287949122745\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "action : 1  next_temperatures :  [ 0.06440038 -0.47657994 -0.06439797 -0.31626019 -0.43747999 -0.41250654\n",
      "  0.50648556 -0.56134198 -0.04993359]  energy_before :  20  energy_after :  50  reward :  -229.74761426215187\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "action : 1  next_temperatures :  [-1.80356562  0.86288595 -0.80921987  0.32096794 -1.28325076  1.72607473\n",
      " -1.02570059  0.75395931 -1.26430445]  energy_before :  50  energy_after :  100  reward :  -250.5221533534517\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "action : 1  next_temperatures :  [-0.42749733 -0.99762296 -1.29563417 -0.08119017  0.01116069 -0.93486116\n",
      " -0.27674059 -1.38830024 -0.59206344]  energy_before :  100  energy_after :  100  reward :  -203.98274936743258\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "action : 1  next_temperatures :  [-0.18466176 -0.76893366 -0.88978224  0.04166872 -0.01874869 -0.55589801\n",
      " -0.07603889 -0.65117867 -0.26678553]  energy_before :  100  energy_after :  90  reward :  -191.37035870853927\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "action : 1  next_temperatures :  [-0.67655947 -1.2715475  -1.39139699 -0.18602976 -0.93596964 -0.68904722\n",
      " -0.61450686 -1.1372182  -0.65169772]  energy_before :  90  energy_after :  40  reward :  -155.55397336884218\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "action : 1  next_temperatures :  [-0.67655947 -1.24892988 -1.47803954 -0.15490551 -0.98581861 -0.68904722\n",
      " -0.6634585  -1.0427745  -0.75470239]  energy_before :  40  energy_after :  50  reward :  -215.69423561023973\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "action : 1  next_temperatures :  [-0.67655947  0.71817505 -0.38360736  0.70510675 -0.88113578  1.60521621\n",
      " -1.34878137  1.40508336 -0.58905161]  energy_before :  50  energy_after :  50  reward :  -197.4455542088184\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "action : 1  next_temperatures :  [-1.05015267  1.18288343 -0.46416972  0.97785349 -1.2799275   1.50074529\n",
      " -0.90821667  1.71375302 -1.0799803 ]  energy_before :  50  energy_after :  50  reward :  -197.4072116265423\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "action : 1  next_temperatures :  [-0.18466176  0.20111106  0.72298518 -0.26711663  0.01116069 -0.25887283\n",
      "  0.21277576 -0.0061973   0.47231816]  energy_before :  50  energy_after :  40  reward :  -187.0964976629545\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "action : 1  next_temperatures :  [-0.738825   -0.84432573 -0.61161406 -1.09436652 -1.0947742  -0.83960826\n",
      " -1.20682164 -0.69110609 -1.29683224]  energy_before :  40  energy_after :  320  reward :  -486.41827374251466\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "action : 1  next_temperatures :  [-0.24692729 -0.13312715 -0.10999931 -0.15326739 -0.58204199  0.09960583\n",
      " -0.0466679  -0.03767853 -0.70591071]  energy_before :  320  energy_after :  40  reward :  80.08398556051907\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "action : 1  next_temperatures :  [-0.40674216  0.49597784  1.61829151 -1.56286844  0.06100966 -1.42956172\n",
      " -0.10867331 -0.69033825 -0.16378086]  energy_before :  40  energy_after :  50  reward :  -210.18668571842815\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "action : 1  next_temperatures :  [-0.61429393 -1.1735378  -1.6467645   0.35454937 -0.36602981 -1.23291056\n",
      " -0.58187244 -1.35067632 -0.21257254]  energy_before :  50  energy_after :  30  reward :  -184.82410854012403\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n",
      "action : 1  next_temperatures :  [ 0.0083614  -0.01501289 -0.70737688  0.95082454  0.11584352 -0.29267225\n",
      " -0.12499052  0.17577959  0.16149705]  energy_before :  30  energy_after :  40  reward :  -207.72774644365657\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n",
      "action : 1  next_temperatures :  [ 0.195158   -0.91301629 -0.52041138 -0.20404907 -0.23808413 -0.84268094\n",
      " -0.36974869 -0.97597286 -0.65169772]  energy_before :  40  energy_after :  40  reward :  -202.520503081113\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "action : 1  next_temperatures :  [-1.61054246  0.87210054 -0.72105728  0.54948548 -2.23204273  1.39729859\n",
      " -2.52851576  2.24893399 -2.24827013]  energy_before :  40  energy_after :  90  reward :  -252.2726097578549\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n",
      "action : 1  next_temperatures :  [ 2.68577932 -0.38443407  2.17006773 -0.97232669  3.17087294 -1.44097451\n",
      "  2.27363956  0.15504804  3.36277381]  energy_before :  90  energy_after :  40  reward :  -136.97955385591615\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "action : 1  next_temperatures :  [ 0.74932124  0.03524849  1.25804092 -0.22800655  0.91342696 -0.66139315\n",
      "  0.96336748 -0.04612472 -0.04993359]  energy_before :  40  energy_after :  60  reward :  -215.0660529286155\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "action : 1  next_temperatures :  [-0.11616967 -0.09040497  0.14840829 -0.22616367 -0.84790314  0.8472899\n",
      " -0.71730529  0.88372342 -0.32099851]  energy_before :  60  energy_after :  60  reward :  -198.4395236407428\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "action : 1  next_temperatures :  [-0.49598942 -0.84432573 -0.29240467 -0.79131458 -0.25303882 -1.275928\n",
      " -0.10867331 -0.98979389 -0.16378086]  energy_before :  60  energy_after :  70  reward :  -213.21524929141697\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "action : 1  next_temperatures :  [ 0.50648566 -1.67615164  0.30041276 -1.86592038  0.49469565 -1.03830786\n",
      "  1.01754062 -1.44082015  0.72350499]  energy_before :  70  energy_after :  150  reward :  -280.97856033813093\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "action : 1  next_temperatures :  [-0.34447662 -0.29396358 -0.46416972 -0.299879   -0.53219302 -0.35412573\n",
      "  0.15240207 -0.69033825 -0.21257254]  energy_before :  150  energy_after :  90  reward :  -141.0393164087548\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "action : 1  next_temperatures :  [ 0.02704106  1.08822449  0.37641499  0.56013325 -0.324489    1.87270958\n",
      "  0.31557419  1.56632871  0.18468816]  energy_before :  90  energy_after :  50  reward :  -152.3333745783448\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "action : 1  next_temperatures :  [-0.18466176 -1.19615542 -1.25003283  0.02692565 -0.33279717 -1.24212859\n",
      " -0.29142608 -1.22705489 -0.04993359]  energy_before :  50  energy_after :  90  reward :  -243.74726466883192\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "action : 1  next_temperatures :  [ 0.5687512  -0.52684132  1.30364226 -1.26063556  0.16569248 -0.1666926\n",
      "  0.52443449 -0.5221824   0.49219626]  energy_before :  90  energy_after :  80  reward :  -187.42163518843927\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "action : 1  next_temperatures :  [-0.67655947 -0.04265666 -0.66177553  0.26527191 -0.78143785 -0.1666926\n",
      " -0.85926503  0.06060434 -0.41677479]  energy_before :  80  energy_after :  70  reward :  -191.27928567914614\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "action : 1  next_temperatures :  [-0.11616967 -0.09040497 -0.70737688  0.8549946  -0.08355234 -0.39202205\n",
      " -0.12662224 -0.36707973  0.22113133]  energy_before :  70  energy_after :  70  reward :  -198.80710194139493\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "action : 1  next_temperatures :  [-2.48225993 -1.00516216 -1.70604624 -0.96331703 -2.1273599  -0.59993967\n",
      " -2.11569031 -0.72873    -1.73595742]  energy_before :  70  energy_after :  50  reward :  -191.4644626709225\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "action : 1  next_temperatures :  [-0.49598942 -0.9448485  -0.10999931 -1.20903482 -0.89941373 -0.7627914\n",
      "  0.45753393 -1.16946727 -1.02576732]  energy_before :  50  energy_after :  100  reward :  -254.15977785467805\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n",
      "action : 1  next_temperatures :  [ 0.88007886  1.08822449  1.03003421  0.69773522 -0.23808413  1.69534799\n",
      " -0.76625693  1.32753203 -0.26678553]  energy_before :  100  energy_after :  100  reward :  -192.55217378721636\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "action : 1  next_temperatures :  [ 0.77215194  0.19440954  0.80202751  0.00317293 -0.26799351  1.11256411\n",
      " -0.8103134   1.56786438 -0.0137916 ]  energy_before :  100  energy_after :  50  reward :  -144.63990810472555\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n",
      "action : 1  next_temperatures :  [0.63101673 1.36717517 0.66066335 1.0663119  0.50965034 1.92272588\n",
      " 0.31557419 2.31803914 0.3295573 ]  energy_before :  50  energy_after :  50  reward :  -188.87928599479002\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "action : 1  next_temperatures :  [-0.30296627 -0.09040497 -0.82442032  0.82796564 -0.13340131 -0.29267225\n",
      " -0.19189109 -0.41545334 -0.16378086]  energy_before :  50  energy_after :  60  reward :  -209.5870247446642\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "action : 1  next_temperatures :  [ 0.25742353 -1.13835483 -0.25136347 -0.79131458  0.11584352 -1.67537566\n",
      "  0.36452582 -1.34729785  0.56448024]  energy_before :  60  energy_after :  60  reward :  -201.90143327410073\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "action : 1  next_temperatures :  [ 0.10591073 -1.03113054 -0.18904163 -0.98788881 -0.36602981 -1.34557529\n",
      " -0.27674059 -0.94295596 -0.04993359]  energy_before :  60  energy_after :  70  reward :  -213.08338548646736\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "action : 1  next_temperatures :  [-2.67528308  0.48760095 -1.75164758  0.54211395 -2.23204273  0.43657578\n",
      " -2.67537066  0.61574902 -2.15068675]  energy_before :  70  energy_after :  80  reward :  -217.4029911146127\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "action : 1  next_temperatures :  [ 0.74932124 -0.37521948  0.66066335 -0.73398043  0.34681039 -0.60915769\n",
      "  0.60928399 -0.76312901  0.63315002]  energy_before :  80  energy_after :  110  reward :  -227.4822576173144\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "action : 1  next_temperatures :  [ 1.66254906  0.84613215  2.30231162 -0.89065477  1.86055729 -0.58662475\n",
      "  1.86570927  0.35314946  1.30539103]  energy_before :  110  energy_after :  50  reward :  -129.28147962507649\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "action : 1  next_temperatures :  [ 0.63101673 -0.22527302  0.80202751 -0.31789831  0.16569248 -0.24863058\n",
      "  0.16871929  0.11588846  0.22113133]  energy_before :  50  energy_after :  60  reward :  -206.68732610937082\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "action : 1  next_temperatures :  [ 1.75179633 -0.14066635  1.61829151 -0.63733143  1.46176557 -0.4852265\n",
      "  1.73027642  0.33932843  2.12633052]  energy_before :  60  energy_after :  150  reward :  -280.2354355123095\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "action : 1  next_temperatures :  [ 0.63101673  0.53786233  1.21243958 -0.2114206   0.21554145  0.48676279\n",
      "  0.36452582  0.68485417  0.0042794 ]  energy_before :  150  energy_after :  60  reward :  -104.0741383430678\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "action : 1  next_temperatures :  [ 0.12666591 -0.9532254  -0.70737688 -0.19503942  0.34681039 -0.94817608\n",
      "  0.50648556 -1.25239345  0.49219626]  energy_before :  60  energy_after :  140  reward :  -280.58405310149004\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "action : 1  next_temperatures :  [-0.18466176  0.48592557  0.49497848 -0.26875475 -0.0503197  -0.39202205\n",
      " -0.12499052 -0.22272676  0.22113133]  energy_before :  140  energy_after :  70  reward :  -128.0414401489342\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "action : 1  next_temperatures :  [ 0.0083614  -0.45898845 -0.10999931 -0.31789831 -0.68672482 -0.24863058\n",
      "  0.08713323 -0.5528958  -0.16378086]  energy_before :  70  energy_after :  30  reward :  -160.44342349850334\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "action : 1  next_temperatures :  [ 0.99838337 -0.9448485   0.28217222 -0.59474035  0.16569248 -0.90720709\n",
      " -0.47254712 -0.16974615 -0.21257254]  energy_before :  30  energy_after :  90  reward :  -259.8554136824507\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "action : 1  next_temperatures :  [ 0.195158   -1.2715475  -0.83962076 -0.28513594 -0.33279717 -1.08849487\n",
      "  0.41347746 -1.41133529 -0.43484578]  energy_before :  90  energy_after :  50  reward :  -163.0551418553296\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "action : 1  next_temperatures :  [ 0.50648566 -0.72788686  0.70626469 -1.33189372  1.46176557 -1.09976135\n",
      "  0.80509053 -1.01359677  0.60062223]  energy_before :  50  energy_after :  110  reward :  -258.0929100126067\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "action : 1  next_temperatures :  [-0.3652318  -1.12914024 -0.26504387 -1.24998779 -0.73657378 -1.21447452\n",
      " -0.56555523 -1.62709691 -0.92276265]  energy_before :  110  energy_after :  50  reward :  -146.0758667854638\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "action : 1  next_temperatures :  [-1.16015511 -0.5452705  -0.41704834 -0.64634109 -1.77841715  0.11804188\n",
      " -0.6634585  -0.23654779 -1.4450144 ]  energy_before :  50  energy_after :  60  reward :  -214.77421098631316\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n",
      "action : 1  next_temperatures :  [-1.05015267  0.95503182 -0.59641361  0.69036368 -1.15779753  1.73836543\n",
      " -0.61450686  0.94438239 -0.97697563]  energy_before :  60  energy_after :  50  reward :  -188.06770298799202\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "action : 1  next_temperatures :  [-0.3652318  -0.16831012 -0.97642479  0.8549946   0.06100966 -0.11650559\n",
      " -0.17394215 -0.100641    0.10728407]  energy_before :  50  energy_after :  50  reward :  -198.8777671240848\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "action : 1  next_temperatures :  [ 0.73375486 -0.47427629 -0.40032785  0.43727436  0.54288298 -0.53541351\n",
      " -0.10867331  0.35468513  0.05849238]  energy_before :  50  energy_after :  50  reward :  -197.3916012422111\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "action : 1  next_temperatures :  [ 0.12666591 -0.18338853  0.3460141  -0.44976686 -0.63189095  0.528756\n",
      " -0.29142608  0.59808882  0.3620851 ]  energy_before :  50  energy_after :  70  reward :  -217.59486249399097\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "action : 1  next_temperatures :  [ 0.21591317  0.49514016  0.0876065   0.82796564  0.50965034 -0.01305889\n",
      "  0.56033236  0.31629338  0.60062223]  energy_before :  70  energy_after :  220  reward :  -344.3995351008849\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "action : 1  next_temperatures :  [-0.18466176 -0.91469167 -0.15560065 -0.93734115 -0.90463601 -0.51961119\n",
      "  0.34354655 -1.04606522 -0.88549122]  energy_before :  220  energy_after :  40  reward :  -23.20455231462472\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "action : 1  next_temperatures :  [-0.55825495 -0.3165812  -0.64505504 -0.12050502 -0.48732896 -0.24863058\n",
      " -0.06135339 -0.69724877 -0.32099851]  energy_before :  40  energy_after :  20  reward :  -181.4559564319147\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "action : 1  next_temperatures :  [ 0.9423444  -1.12327642  0.33081365 -0.76919998  0.80874413 -0.6798292\n",
      "  0.9029938  -1.1372182   0.22113133]  energy_before :  20  energy_after :  50  reward :  -228.50349648894291\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "action : 1  next_temperatures :  [ 2.24369404 -0.14988094  1.33100306  0.11784124  1.80572343 -1.4532652\n",
      "  2.15982701  0.12970949  2.38965073]  energy_before :  50  energy_after :  60  reward :  -199.42569715524797\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "action : 1  next_temperatures :  [ 1.62103871 -1.40641555  2.3524731  -2.5113391   0.86357799 -1.1929658\n",
      "  1.58831668 -0.92759926  0.27534432]  energy_before :  60  energy_after :  100  reward :  -237.33756891038342\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "action : 1  next_temperatures :  [ 2.1461447  -0.88704791  2.71272369 -2.20992528  1.96025522 -0.47396003\n",
      "  2.02888139 -0.72028382  2.44386372]  energy_before :  100  energy_after :  50  reward :  -140.99934831904446\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "action : 1  next_temperatures :  [-0.42749733  0.83105374  0.07240605  0.28001498 -0.003794    2.10503789\n",
      "  0.54075171  0.82920714 -1.0799803 ]  energy_before :  50  energy_after :  60  reward :  -204.85280012914586\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "action : 1  next_temperatures :  [ 1.62103871 -0.53605591  1.80069687 -1.43263801  1.41191661 -0.44630596\n",
      "  1.76617428  0.13969134  0.54640924]  energy_before :  60  energy_after :  30  reward :  -163.12907282337753\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "action : 1  next_temperatures :  [ 0.5687512  -0.3165812  -0.02335676  0.19892811  0.11584352 -0.32032631\n",
      "  0.13608486  0.26024143  0.3295573 ]  energy_before :  30  energy_after :  50  reward :  -217.05085785597348\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n",
      "action : 1  next_temperatures :  [-2.17093226 -0.16831012 -1.4324382  -0.36622281 -1.87811508  0.20202831\n",
      " -1.83829772 -0.33790201 -1.90823424]  energy_before :  50  energy_after :  80  reward :  -237.89842411277098\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "action : 1  next_temperatures :  [ 0.68705571  1.35879827  0.84762885  0.82796564 -0.18823517  2.20950881\n",
      " -0.48886433  2.62670879  0.04975807]  energy_before :  80  energy_after :  50  reward :  -160.0696753536098\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "action : 1  next_temperatures :  [-0.24692729 -0.21605843 -1.16339028  1.00242527  0.55949931 -0.3817798\n",
      "  0.01696922 -0.30565294  0.49219626]  energy_before :  50  energy_after :  50  reward :  -198.2427186809122\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "action : 1  next_temperatures :  [-0.55825495 -0.74631603 -0.43376883 -0.82571507 -0.58204199 -0.68904722\n",
      " -0.90821667 -0.86079762 -1.0799803 ]  energy_before :  50  energy_after :  90  reward :  -244.6841386896361\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "action : 1  next_temperatures :  [2.30595957 2.24674939 1.7655187  2.04075844 2.05496825 1.76909217\n",
      " 2.21979276 1.62698767 2.44386372]  energy_before :  90  energy_after :  180  reward :  -269.52630932742136\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "action : 1  next_temperatures :  [-0.49598942  0.10142598 -0.8647015   0.97785349 -0.26799351 -0.35412573\n",
      " -0.52149876  0.05369383 -0.16378086]  energy_before :  180  energy_after :  50  reward :  -69.53511647859062\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "action : 1  next_temperatures :  [-0.80731709  1.53387543 -0.29240467  1.02453987 -1.03068267  1.92272588\n",
      " -0.30611157  1.66614725 -0.53785045]  energy_before :  50  energy_after :  50  reward :  -194.82707801437084\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "action : 1  next_temperatures :  [-1.05015267 -1.5814927  -0.92018313 -1.3564655  -1.26710919 -0.90720709\n",
      " -1.07138878 -1.17330645 -1.24804056]  energy_before :  50  energy_after :  60  reward :  -218.5753460669216\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "action : 1  next_temperatures :  [ 1.19140653  0.18603264  0.79551303  0.1518907   1.14130794 -0.04685831\n",
      "  1.29460687 -0.0545709   0.92047884]  energy_before :  60  energy_after :  50  reward :  -182.4201926567683\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "action : 1  next_temperatures :  [-0.55825495 -0.62066257 -0.47937017 -0.2777644  -0.13340131 -1.36810823\n",
      "  0.21277576 -0.57378091  0.20125324]  energy_before :  50  energy_after :  100  reward :  -251.59731354975963\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "action : 1  next_temperatures :  [-2.67528308  0.46917177 -1.75164758  0.5331043  -2.23204273  0.41404283\n",
      " -2.67537066  0.61574902 -2.13171221]  energy_before :  100  energy_after :  320  reward :  -427.4339883408061\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "action : 1  next_temperatures :  [-0.16183106 -0.30150278 -0.1404002  -0.59474035  0.94499797 -0.57740673\n",
      " -0.56555523 -0.20583439 -0.43484578]  energy_before :  320  energy_after :  30  reward :  89.96288144190979\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "action : 1  next_temperatures :  [1.97387673 1.91083581 1.98766237 1.42014551 1.86055729 1.37517533\n",
      " 2.12678465 1.31272379 2.33001645]  energy_before :  30  energy_after :  630  reward :  -781.7022220651684\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "action : 1  next_temperatures :  [ 1.12914099 -1.19615542  0.59682147 -1.08617593  0.7140311  -1.01679914\n",
      "  0.94705027 -1.1809848   0.54640924]  energy_before :  630  energy_after :  50  reward :  381.45333779003306\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "action : 1  next_temperatures :  [ 0.06440038 -0.29396358 -0.61161406  0.65596319  0.31025448 -0.04685831\n",
      " -0.07603889  0.08594289  0.18137515]  energy_before :  50  energy_after :  90  reward :  -237.73053873581665\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "action : 1  next_temperatures :  [-0.61429393  1.13094667 -0.35320646  1.27025766 -0.43747999  0.81656316\n",
      " -0.17394215  1.52025861 -0.81975798]  energy_before :  90  energy_after :  40  reward :  -145.66065442262308\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "action : 1  next_temperatures :  [ 0.54799602 -1.95845308  2.38287399 -3.61051667  0.19892513 -2.08199288\n",
      "  1.09880034 -1.6048297   0.54640924]  energy_before :  40  energy_after :  40  reward :  -202.48078761726927\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "action : 1  next_temperatures :  [-0.49598942  1.18288343 -0.27188407  1.1989995  -0.21980618  1.36759607\n",
      " -0.27674059  1.15937618 -0.63181963]  energy_before :  40  energy_after :  50  reward :  -204.98738470290044\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "action : 1  next_temperatures :  [ 0.12666591 -0.49500911 -0.32660568  0.02508277 -0.33279717 -0.7896773\n",
      "  0.21277576 -0.25036882  0.27534432]  energy_before :  50  energy_after :  50  reward :  -199.55458932492343\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "action : 1  next_temperatures :  [ 0.31968906  0.45995719  1.80069687 -0.73398043  0.41493731 -0.04685831\n",
      "  1.29460687  0.02298043  0.76326118]  energy_before :  50  energy_after :  50  reward :  -193.7047098217806\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "action : 1  next_temperatures :  [ 0.99838337  0.22707944  1.71405433 -0.79131458  1.05798895 -0.04685831\n",
      "  1.29460687  0.01453424  0.84070831]  energy_before :  50  energy_after :  50  reward :  -192.6908173717477\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "action : 1  next_temperatures :  [-1.27845962  1.6503143  -0.43376883  1.23995247 -1.18521446  1.70456601\n",
      " -2.18585432  1.99785196 -0.75470239]  energy_before :  50  energy_after :  100  reward :  -247.24531488896673\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n",
      "action : 1  next_temperatures :  [ 1.99463191 -0.24370219  0.88867006  0.21367117  1.36206764 -1.76448321\n",
      "  2.07783302 -0.08543787  2.33001645]  energy_before :  100  energy_after :  80  reward :  -171.2267330283561\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "action : 1  next_temperatures :  [1.99463191 1.74413555 1.1622781  2.16897047 2.05496825 1.18221139\n",
      " 1.92608295 1.30680049 2.38965073]  energy_before :  80  energy_after :  70  reward :  -172.0702701497094\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "action : 1  next_temperatures :  [ 0.5687512  -0.78736283  0.10280695 -0.31052678  0.26040552 -0.68904722\n",
      " -0.03198241  0.0398728   0.3295573 ]  energy_before :  70  energy_after :  80  reward :  -208.5175254828644\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "action : 1  next_temperatures :  [-0.11616967  0.28655541  0.16360874  0.04166872 -0.43747999  1.00092361\n",
      " -0.41870032  0.66181912 -0.32099851]  energy_before :  80  energy_after :  90  reward :  -207.13877290250528\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "action : 1  next_temperatures :  [-0.3652318  -0.71867227 -1.03722657 -0.10330477 -0.18823517 -0.88467415\n",
      "  0.03850794 -0.90686771  0.05849238]  energy_before :  90  energy_after :  90  reward :  -202.1072121356877\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "action : 1  next_temperatures :  [-1.4507276   0.93995341 -0.76361853  0.82059411 -1.18521446  1.70456601\n",
      " -2.08305589  1.72143137 -1.56789717]  energy_before :  90  energy_after :  100  reward :  -209.86396874736658\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "action : 1  next_temperatures :  [-0.61429393  0.84780753 -0.12519976  0.58224786 -0.88113578  1.52327823\n",
      " -0.47254712  1.09948505 -0.74928109]  energy_before :  100  energy_after :  50  reward :  -146.78963901661768\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "action : 1  next_temperatures :  [-0.24692729 -0.42715624 -0.52041138 -0.25073545 -0.38264613 -0.81502687\n",
      " -0.66672194 -0.79783515 -1.17394948]  energy_before :  50  energy_after :  140  reward :  -293.2814099194816\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "action : 1  next_temperatures :  [2.37445166 1.33953141 2.62608114 0.14241301 2.95723452 0.27167559\n",
      " 1.88202648 1.41352955 1.86559188]  energy_before :  140  energy_after :  40  reward :  -83.1274647590489\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "action : 1  next_temperatures :  [-1.74130008 -0.67092396 -1.60420325 -0.12787655 -1.43445929 -0.4852265\n",
      " -1.29982974 -0.59743022 -1.15587848]  energy_before :  40  energy_after :  40  reward :  -207.11712807494007\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "action : 1  next_temperatures :  [ 1.1063103   0.0260339   3.00305223 -1.90523522  0.99916718 -0.52435188\n",
      "  1.53936504 -0.19047769  0.16149705]  energy_before :  40  energy_after :  100  reward :  -253.78463909685738\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "action : 1  next_temperatures :  [-0.57693461  0.16760347 -0.52041138  0.22349988 -0.10016866 -0.08680307\n",
      " -0.52149876 -0.78324628 -0.75470239]  energy_before :  100  energy_after :  50  reward :  -150.9526618079551\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "action : 1  next_temperatures :  [ 0.48365497 -1.1735378   1.635012   -2.36636561  0.26040552 -1.1806751\n",
      "  0.85404217 -1.27312499  0.74338309]  energy_before :  50  energy_after :  290  reward :  -440.01720575992465\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "action : 1  next_temperatures :  [ 0.14949661  0.17765574  0.47825799 -0.12787655 -0.22146781  1.30614259\n",
      " -0.50518155  0.96127475 -1.02576732]  energy_before :  290  energy_after :  570  reward :  -476.80746554716427\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "action : 1  next_temperatures :  [ 1.48197902  2.59020219  1.30364226  0.81404164  1.00813999  1.7783102\n",
      " -0.56555523  2.12684823  0.65242575]  energy_before :  570  energy_after :  220  reward :  163.19003403154923\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "action : 1  next_temperatures :  [1.74840002 3.07156155 1.48317186 2.76536555 2.49259685 2.1453551\n",
      " 1.4432258  2.23239441 1.69245221]  energy_before :  220  energy_after :  60  reward :  -18.925476647960636\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "action : 1  next_temperatures :  [0.43799358 0.62079362 0.75642617 0.14241301 1.46176557 0.24094885\n",
      " 0.43991134 0.22415319 0.7036269 ]  energy_before :  60  energy_after :  70  reward :  -202.9719677798218\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "action : 1  next_temperatures :  [-1.2992148   0.23629403 -0.97642479  0.28738651 -1.25001812  0.44784225\n",
      " -0.85926503 -0.22963728 -0.97697563]  energy_before :  70  energy_after :  60  reward :  -192.6200128610611\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "action : 1  next_temperatures :  [ 0.50648566  0.45241798  0.5740208   0.12603183  1.29061746 -0.75357338\n",
      "  0.73220699  0.22632872  0.56448024]  energy_before :  60  energy_after :  90  reward :  -224.280983705026\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "action : 1  next_temperatures :  [0.12666591 0.52864774 0.25025128 0.64122012 0.46478627 0.14979285\n",
      " 0.3318914  0.59194614 0.54640924]  energy_before :  90  energy_after :  70  reward :  -174.36838903810073\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "action : 1  next_temperatures :  [ 0.81781333 -1.09730803  1.21243958 -1.83233895  0.43155363 -1.13151231\n",
      "  0.9960019  -1.13215049  0.76326118]  energy_before :  70  energy_after :  80  reward :  -208.97224016423078\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "action : 1  next_temperatures :  [ 0.9423444   0.46917177  1.47084717 -0.16063892  0.89681064  0.20202831\n",
      "  1.20812565  0.37541668  0.81747417]  energy_before :  80  energy_after :  50  reward :  -161.77842014179922\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "action : 1  next_temperatures :  [-0.86958262  0.86456133 -0.20576213  0.65596319 -1.18521446  1.48947882\n",
      " -2.03410425  1.66614725 -1.56789717]  energy_before :  50  energy_after :  60  reward :  -209.18641004250526\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "action : 1  next_temperatures :  [-0.45032803  1.76005166  0.11800739  0.65842037 -0.63189095  1.12383058\n",
      " -0.84702712  1.53599923  0.39732354]  energy_before :  60  energy_after :  120  reward :  -254.33561334510725\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "action : 1  next_temperatures :  [-1.672808   -0.62066257 -1.61940369 -0.03204662 -1.34639278 -0.34081081\n",
      " -1.25577327 -0.52909291 -1.24804056]  energy_before :  120  energy_after :  60  reward :  -146.66503121132786\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "action : 1  next_temperatures :  [ 0.43799358 -0.62066257  0.70626469 -0.81534032 -0.53219302  0.10677541\n",
      " -0.30780372  0.43260616  0.3295573 ]  energy_before :  60  energy_after :  50  reward :  -188.26280249977737\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "action : 1  next_temperatures :  [1.93236637 1.79439694 1.25804092 2.09762456 2.15965108 1.32201807\n",
      " 2.03867171 1.48647387 2.44386372]  energy_before :  50  energy_after :  50  reward :  -181.4668927681561\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "action : 1  next_temperatures :  [ 0.31968906 -0.65249478 -0.55081227  0.36355902  0.55949931 -0.13903853\n",
      " -0.27674059 -0.100641    0.22113133]  energy_before :  50  energy_after :  50  reward :  -198.25584844807554\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "action : 1  next_temperatures :  [-0.5167446  -0.82757194 -0.32280557 -0.74217102 -0.23808413 -1.275928\n",
      " -0.12499052 -0.9967044  -0.16378086]  energy_before :  50  energy_after :  60  reward :  -213.20878104727285\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "action : 1  next_temperatures :  [-0.3652318  -0.20851922  0.44785709 -0.90680194 -0.18823517 -0.18000752\n",
      "  0.27967632 -0.59051971 -0.53785045]  energy_before :  60  energy_after :  70  reward :  -210.2496324030542\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "action : 1  next_temperatures :  [-0.61429393 -0.63574099 -0.38360736 -1.05505167 -0.469051   -0.22814609\n",
      " -0.17394215 -1.1809848  -0.86312836]  energy_before :  70  energy_after :  40  reward :  -173.6039463552815\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "action : 1  next_temperatures :  [0.83856851 1.33953141 0.46305754 1.71500686 1.34378969 0.92717943\n",
      " 1.14775197 1.1225201  1.59194538]  energy_before :  40  energy_after :  80  reward :  -227.5106491185437\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "action : 1  next_temperatures :  [-1.2992148  -1.77416134 -0.59641361 -2.07969485 -1.01572798 -1.7849677\n",
      " -0.74993972 -1.59791918 -1.35104523]  energy_before :  80  energy_after :  80  reward :  -210.24908441838096\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "action : 1  next_temperatures :  [ 0.31968906  1.0630938  -0.06439797  1.41113586  0.80874413  0.33312908\n",
      "  0.21277576  0.25333092  0.9107205 ]  energy_before :  80  energy_after :  90  reward :  -202.7517788649366\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "action : 1  next_temperatures :  [ 0.195158   -1.38212254 -0.38360736 -0.90680194  0.21554145 -0.91642512\n",
      "  0.7022921  -1.38830024  0.37834899]  energy_before :  90  energy_after :  90  reward :  -201.4859166606358\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "action : 1  next_temperatures :  [ 1.68330424 -0.19092774  0.98443287  0.06869768  1.71101039 -0.07451237\n",
      "  1.58831668 -0.28492139  1.46260869]  energy_before :  90  energy_after :  300  reward :  -401.05199095548664\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n",
      "action : 1  next_temperatures :  [-0.24692729  0.74644708  0.07240605  0.37994021 -0.0503197   0.67317169\n",
      " -0.41870032  0.89984796  0.16149705]  energy_before :  300  energy_after :  90  reward :  14.217362729134123\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "action : 1  next_temperatures :  [-1.05015267 -1.32180888 -1.80180906 -0.09593324 -1.08053164 -0.68904722\n",
      " -0.8103134  -1.1372182  -0.86312836]  energy_before :  90  energy_after :  100  reward :  -216.84994267372608\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "action : 1  next_temperatures :  [-0.05390414 -0.26799519  0.05568556 -0.34165103 -0.23808413 -0.51697747\n",
      "  0.08550151 -0.4607556  -0.94444784]  energy_before :  100  energy_after :  90  reward :  -190.6826283274138\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "action : 1  next_temperatures :  [-0.61429393 -1.14756942 -1.25003283 -0.35721316 -0.08355234 -1.01679914\n",
      " -0.58187244 -1.23550108 -0.32099851]  energy_before :  90  energy_after :  40  reward :  -154.607832855215\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "action : 1  next_temperatures :  [-0.42749733  1.24738554 -0.02335676  0.77882209 -0.2829482   1.37886254\n",
      " -0.3860659   1.63696952 -0.40020971]  energy_before :  40  energy_after :  120  reward :  -274.47803821677644\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "action : 1  next_temperatures :  [-0.98788713  0.74456227 -0.93538358  0.49378945 -0.32033492 -0.01536339\n",
      " -1.15297484  0.0705862  -0.59206344]  energy_before :  120  energy_after :  80  reward :  -160.69506938738527\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "action : 1  next_temperatures :  [-0.13900036  0.10142598 -0.70737688  1.11709357  0.06100966 -0.44630596\n",
      " -0.41870032  0.27022329  0.10728407]  energy_before :  80  energy_after :  60  reward :  -178.0543469584712\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "action : 1  next_temperatures :  [ 0.99838337  0.25891165  0.61962214  0.30599086  1.07626691 -0.02637381\n",
      "  1.09880034  0.36005998  1.46260869]  energy_before :  60  energy_after :  80  reward :  -211.84572987547898\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "action : 1  next_temperatures :  [-0.24692729 -0.39197328 -0.76361853  0.51836123 -0.08355234 -0.51492902\n",
      " -0.52149876  0.0398728   0.0042794 ]  energy_before :  80  energy_after :  30  reward :  -149.95998578436817\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "action : 1  next_temperatures :  [-0.18466176  0.63587203  0.10280695  0.60927681 -0.40092408  1.32662708\n",
      " -0.22778895  0.86683105 -0.26678553]  energy_before :  30  energy_after :  670  reward :  -835.5387463941343\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "action : 1  next_temperatures :  [ 0.50648566  0.16006426  0.39161544 -0.2597451   0.16569248 -0.14825656\n",
      " -0.03198241 -0.79169247  0.27534432]  energy_before :  670  energy_after :  30  reward :  442.2675256271124\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "action : 1  next_temperatures :  [-0.18466176 -0.65249478 -0.82442032 -0.12787655 -0.58204199 -0.43503949\n",
      " -0.12499052 -1.22705489 -0.70591071]  energy_before :  30  energy_after :  50  reward :  -222.86449100522117\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "action : 1  next_temperatures :  [-0.62467152 -0.74547834 -0.74841808 -0.35323487 -0.68672482 -0.22024492\n",
      " -0.77727105 -0.63563001 -0.67493186]  energy_before :  50  energy_after :  270  reward :  -423.4666054742558\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "action : 1  next_temperatures :  [ 0.43799358  0.3116861  -0.17232114  1.05894036  0.86357799  0.07912134\n",
      "  0.50648556  0.2771338   0.74338309]  energy_before :  270  energy_after :  70  reward :  6.106000683860685\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "action : 1  next_temperatures :  [-0.61429393 -1.32180888  0.39161544 -1.94618819 -0.38264613 -1.33430881\n",
      "  0.07081602 -1.0581312  -0.48363747]  energy_before :  70  energy_after :  50  reward :  -184.67858316298896\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "action : 1  next_temperatures :  [ 1.06064891 -1.09563265  0.02224458 -0.4586127   1.00813999 -0.72943094\n",
      "  1.29460687 -1.09114811  2.00473854]  energy_before :  50  energy_after :  50  reward :  -195.98444551060192\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "action : 1  next_temperatures :  [-0.88826228 -0.98003147 -0.66177553 -1.20903482 -1.18521446 -1.06084081\n",
      " -1.20682164 -0.83545906 -1.27592152]  energy_before :  50  energy_after :  40  reward :  -197.30336159668803\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "action : 1  next_temperatures :  [2.12538953 0.83691757 1.48604762 0.95983419 2.25436411 0.29420854\n",
      " 2.28995677 0.79235106 2.11858581]  energy_before :  40  energy_after :  60  reward :  -204.84234481164762\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "action : 1  next_temperatures :  [ 0.5687512  -0.61144799  1.27324136 -1.43263801  2.20950004  0.10984808\n",
      "  1.22117942 -0.96076973  0.52833825]  energy_before :  60  energy_after :  40  reward :  -175.0939973701037\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "action : 1  next_temperatures :  [-1.42997242  0.21954023 -0.97642479  0.01955412 -0.98457238  1.17529787\n",
      " -1.64249118 -0.58207352 -1.28237545]  energy_before :  40  energy_after :  50  reward :  -213.48351751036438\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "action : 1  next_temperatures :  [-0.42749733  1.348746   -0.29240467  1.36281136 -0.33279717  1.07159512\n",
      " -0.36974869  1.36054894 -0.59206344]  energy_before :  50  energy_after :  60  reward :  -204.8708098878022\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "action : 1  next_temperatures :  [-1.2992148   0.36027211 -0.56601272  0.09982193 -1.3314381   1.82030341\n",
      " -0.6634585   0.30707936 -0.23064354]  energy_before :  60  energy_after :  60  reward :  -199.50329083480153\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "action : 1  next_temperatures :  [2.12538953 1.94518109 1.39028481 2.08358354 2.0769018  1.81702589\n",
      " 2.21979276 1.44777499 2.38965073]  energy_before :  60  energy_after :  50  reward :  -170.5044148720389\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "action : 1  next_temperatures :  [ 0.31968906  1.34078794  0.61962214  0.50198004 -0.22146781  1.41795379\n",
      "  0.73492652  0.73092426 -0.26678553]  energy_before :  50  energy_after :  160  reward :  -302.82236956852296\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "action : 1  next_temperatures :  [ 0.35704838 -0.29396358  2.44367578 -2.08706639  0.46478627 -0.47396003\n",
      "  0.94705027 -0.30565294  0.54640924]  energy_before :  160  energy_after :  50  reward :  -86.40167297543667\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "action : 1  next_temperatures :  [-0.24692729 -0.69354158 -0.93538358 -0.10330477 -0.58204199 -0.41250654\n",
      " -0.17394215 -1.20632335 -0.7221746 ]  energy_before :  50  energy_after :  90  reward :  -243.07614586065336\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "action : 1  next_temperatures :  [-1.23694927 -0.46736535  0.11800739 -0.89779229 -1.11376428 -0.68904722\n",
      "  0.26335911 -0.62891146 -0.95890464]  energy_before :  90  energy_after :  30  reward :  -143.61136799962102\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "action : 1  next_temperatures :  [-0.98788713  1.13094667 -0.38360736  0.90168098 -1.2799275   1.46182475\n",
      " -0.85926503  1.70607467 -1.0799803 ]  energy_before :  30  energy_after :  70  reward :  -237.39014025840527\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "action : 1  next_temperatures :  [-1.49223795  1.56822071 -0.79401942  1.44226011 -1.18521446  1.8489817\n",
      " -1.25577327  2.0185835  -1.16401043]  energy_before :  70  energy_after :  40  reward :  -167.01320951320886\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "action : 1  next_temperatures :  [1.75179633 3.38516975 1.48604762 3.0664547  2.80270273 2.06509312\n",
      " 1.43656661 2.44166057 1.68488193]  energy_before :  40  energy_after :  30  reward :  -167.87962665499458\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "action : 1  next_temperatures :  [-0.52712219 -0.76893366 -0.97642479 -0.11149537 -0.48732896 -0.41250654\n",
      " -0.90821667 -0.63044713 -0.53785045]  energy_before :  30  energy_after :  70  reward :  -243.36032574400247\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "action : 1  next_temperatures :  [ 0.9423444   0.57974682  0.73970568 -0.26056416  2.52188689 -0.45347553\n",
      "  0.94705027 -0.94405286  0.64941392]  energy_before :  70  energy_after :  70  reward :  -193.27794458973065\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "action : 1  next_temperatures :  [-0.98788713 -0.2428645  -0.83962076 -0.49645324 -0.93596964 -0.99631465\n",
      " -0.85926503 -0.86770813 -1.13419329]  energy_before :  70  energy_after :  120  reward :  -255.3602763747546\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "action : 1  next_temperatures :  [-0.55825495  0.96257103 -0.15560065  0.54211395 -0.45409631  1.31638483\n",
      "  0.03491815  0.69176468 -0.3806328 ]  energy_before :  120  energy_after :  50  reward :  -126.00083206960252\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "action : 1  next_temperatures :  [ 0.4172384   1.20801412  0.75642617  0.18254692  0.39001283 -0.18359231\n",
      "  0.60928399 -0.19771728  0.7036269 ]  energy_before :  50  energy_after :  60  reward :  -204.11416026306966\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "action : 1  next_temperatures :  [-0.30296627  0.28655541  0.3460141   0.19728999  0.01116069 -0.25887283\n",
      "  0.11976765  0.00762373  0.49219626]  energy_before :  60  energy_after :  100  reward :  -237.10123126863746\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "action : 1  next_temperatures :  [-0.11616967  0.09221139 -0.15560065  0.01955412 -0.68672482  0.54002247\n",
      " -0.76625693  0.25486659 -0.93480998]  energy_before :  100  energy_after :  40  reward :  -139.75290746607402\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "action : 1  next_temperatures :  [-0.53749978  0.02519621 -0.38360736 -0.2114206  -0.16206446  1.03933204\n",
      " -0.76625693 -0.04612472 -0.65169772]  energy_before :  40  energy_after :  60  reward :  -219.69414330966774\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "action : 1  next_temperatures :  [-0.24692729 -1.24892988 -0.66177553 -1.07880439 -0.96089412 -0.53541351\n",
      " -0.6634585  -0.92759926 -0.32099851]  energy_before :  60  energy_after :  80  reward :  -224.64480099538508\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "action : 1  next_temperatures :  [-0.24692729 -1.06296275 -0.52041138 -0.72988513  0.06100966 -1.59241345\n",
      "  0.03491815 -1.01436461 -0.59206344]  energy_before :  80  energy_after :  560  reward :  -683.6631002449865\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "action : 1  next_temperatures :  [-0.32372145 -1.38966175 -0.20576213 -1.40560905 -1.03068267 -1.24212859\n",
      " -0.32079706 -1.03586399 -1.19382757]  energy_before :  560  energy_after :  250  reward :  103.85194574721663\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "action : 1  next_temperatures :  [-1.52959727  1.33953141 -0.64505504  1.04255918 -1.52917232  1.39729859\n",
      " -2.03410425  1.53715098 -1.62211015]  energy_before :  250  energy_after :  50  reward :  -0.04349888748839703\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "action : 1  next_temperatures :  [-1.80356562  0.04362539 -1.40507739  0.13422242 -1.51421763  0.21227056\n",
      " -1.36509859 -0.1290509  -1.51910548]  energy_before :  50  energy_after :  40  reward :  -195.34599723974236\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "action : 1  next_temperatures :  [ 0.10591073 -0.40118786 -0.88978224  0.57487632  0.07928761 -0.464742\n",
      "  0.60928399 -0.46689828  0.49219626]  energy_before :  40  energy_after :  40  reward :  -198.36105546604122\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "action : 1  next_temperatures :  [-1.49223795 -0.6432802  -1.44763864 -0.11149537 -1.08053164 -0.56614025\n",
      " -1.54458791 -0.42716282 -0.75470239]  energy_before :  40  energy_after :  240  reward :  -406.0677771753333\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "action : 1  next_temperatures :  [ 0.08515556  2.93951881  0.83090836  1.1326557   0.41493731 -0.32237476\n",
      "  0.58131163 -0.02265091  0.92047884]  energy_before :  240  energy_after :  330  reward :  -281.44005947112566\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "action : 1  next_temperatures :  [ 0.58950637 -0.80244125  2.38287399 -2.06085649  0.74394048 -1.07927685\n",
      "  1.14775197 -0.74562237  0.0042794 ]  energy_before :  330  energy_after :  70  reward :  62.180155248406635\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "action : 1  next_temperatures :  [-0.30296627 -1.19615542 -0.99162523 -0.54559679 -0.08355234 -1.02704139\n",
      " -0.47254712 -1.29616004 -0.21257254]  energy_before :  70  energy_after :  60  reward :  -194.1282171569786\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "action : 1  next_temperatures :  [-0.34447662 -1.19615542 -0.25136347 -1.20903482 -0.73657378 -1.21447452\n",
      " -0.56555523 -1.62709691 -0.8048494 ]  energy_before :  60  energy_after :  50  reward :  -195.94958017751517\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "action : 1  next_temperatures :  [-0.30296627 -1.02024058 -1.06762747 -0.10330477 -0.03370338 -1.22369254\n",
      " -0.27674059 -1.10496913  0.0042794 ]  energy_before :  50  energy_after :  450  reward :  -603.1289653322043\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "action : 1  next_temperatures :  [ 0.74932124 -0.24370219  0.1964417  -0.17702011  1.08148918 -0.51566061\n",
      "  1.0498487  -0.47457663  0.62850319]  energy_before :  450  energy_after :  60  reward :  194.29464448140766\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "action : 1  next_temperatures :  [-2.05262775  1.47439946 -1.20443149  0.96884384 -1.34639278  1.63389451\n",
      " -0.94411453  1.04420093 -2.27808727]  energy_before :  60  energy_after :  60  reward :  -200.70431509092742\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "action : 1  next_temperatures :  [-2.29546333  0.61325441 -1.39139699  0.45201743 -1.96618158  1.3358451\n",
      " -2.52851576  1.69839632 -2.27808727]  energy_before :  60  energy_after :  130  reward :  -274.3601316683541\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "action : 1  next_temperatures :  [-0.42749733  0.05200228 -0.83962076  0.92870994 -0.33279717 -0.33159279\n",
      " -0.56555523  0.08594289 -0.18004475]  energy_before :  130  energy_after :  50  reward :  -119.61045291440792\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "action : 1  next_temperatures :  [ 0.9423444  -0.38066446  1.1622781  -1.11074771  0.41493731 -0.90720709\n",
      "  0.80509053 -0.48993333  0.3295573 ]  energy_before :  50  energy_after :  220  reward :  -367.23434495487356\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "action : 1  next_temperatures :  [ 0.37572804 -0.19930464  0.73970568 -0.75118068  0.11584352 -0.41250654\n",
      "  0.07081602 -0.67651722  0.27534432]  energy_before :  220  energy_after :  80  reward :  -58.46207150427318\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "action : 1  next_temperatures :  [-1.98413566 -0.37689486 -1.34579565 -0.46450992 -1.68370411  0.13852637\n",
      " -2.24949144 -0.13749708 -1.73595742]  energy_before :  80  energy_after :  120  reward :  -247.83945977977172\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "action : 1  next_temperatures :  [ 0.81781333 -1.34693958  1.25804092 -1.89704463  0.41493731 -1.14994836\n",
      "  0.9960019  -1.19112022  0.76326118]  energy_before :  120  energy_after :  40  reward :  -119.33499814146526\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "action : 1  next_temperatures :  [-1.36148033 -0.16663474 -1.6604449   0.59289563 -1.1303806  -0.66139315\n",
      " -0.85926503 -1.02050729 -1.13419329]  energy_before :  40  energy_after :  110  reward :  -275.40140371005896\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "action : 1  next_temperatures :  [-0.61429393  1.07691568 -0.25136347  0.5109897  -0.48732896  0.98897432\n",
      " -0.19189109  0.67717582 -0.53785045]  energy_before :  110  energy_after :  50  reward :  -136.8286723829928\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n",
      "action : 1  next_temperatures :  [ 0.25742353 -0.18338853  1.21243958 -0.94120243  0.01116069 -0.39202205\n",
      "  0.16871929 -0.12137255  0.05849238]  energy_before :  50  energy_after :  30  reward :  -177.92975009131027\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "action : 1  next_temperatures :  [ 0.63101673  1.77680545  0.84762885  0.96884384 -0.26799351  2.44508051\n",
      " -0.47254712  2.47237396 -0.86312836]  energy_before :  30  energy_after :  150  reward :  -310.46191965338096\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "action : 1  next_temperatures :  [-0.49598942  0.13325819 -1.21963194  1.58313831 -0.73657378 -0.30189027\n",
      " -0.12499052 -0.76635392 -0.53785045]  energy_before :  150  energy_after :  60  reward :  -110.4668837946952\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "action : 1  next_temperatures :  [ 0.50648566 -0.29396358 -0.09479886  0.23169048  0.11584352 -0.29267225\n",
      "  0.15240207  0.27022329  0.29341531]  energy_before :  60  energy_after :  210  reward :  -347.111374350975\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "action : 1  next_temperatures :  [-0.30296627 -0.72788686 -0.79401942 -0.17702011  0.13245984 -0.78122745\n",
      "  0.50648556 -0.9967044   0.27534432]  energy_before :  210  energy_after :  100  reward :  -90.86553479587099\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "action : 1  next_temperatures :  [ 1.81406186 -0.46736535  1.57269017 -0.9559455   2.00511929 -0.44630596\n",
      "  1.95055877 -0.686883    2.22701178]  energy_before :  100  energy_after :  50  reward :  -140.987057943459\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "action : 1  next_temperatures :  [-0.57693461 -1.31426968 -0.25136347 -1.40560905 -1.06391532 -1.19194157\n",
      " -0.41870032 -1.12877202 -1.19382757]  energy_before :  50  energy_after :  40  reward :  -196.54533361528348\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "action : 1  next_temperatures :  [-0.53490538 -0.58705027 -0.25649362 -0.71790639 -1.03068267 -0.41250654\n",
      "  0.65823563 -0.56002569 -0.88549122]  energy_before :  40  energy_after :  50  reward :  -212.32682616019642\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "action : 1  next_temperatures :  [-0.13329269 -0.17333625  1.01483377 -0.62176931 -0.13340131 -0.50775944\n",
      " -0.07603889  0.0398728   0.10728407]  energy_before :  50  energy_after :  40  reward :  -188.48360725754054\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "action : 1  next_temperatures :  [ 0.50648566 -0.63574099 -0.43376883  0.33653007  0.52626666 -0.11650559\n",
      " -0.20984002 -0.09219482  0.23920233]  energy_before :  40  energy_after :  100  reward :  -257.8795655214227\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "action : 1  next_temperatures :  [-0.738825   -0.04265666 -0.67697598  0.28001498 -0.76648316 -0.13903853\n",
      " -0.85926503  0.06060434 -0.43484578]  energy_before :  100  energy_after :  400  reward :  -501.31747082926404\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "action : 1  next_temperatures :  [-0.22617211 -1.2715475   0.07240605 -1.5554969  -0.98581861 -0.99631465\n",
      "  0.07081602 -1.19787717 -0.88300646]  energy_before :  400  energy_after :  30  reward :  165.0269886815101\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "action : 1  next_temperatures :  [ 0.03638089  0.18477611  0.3156132  -0.00501766 -0.78143785  0.87494397\n",
      " -0.07603889  0.82076096  0.16149705]  energy_before :  30  energy_after :  70  reward :  -236.46852221841647\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "action : 1  next_temperatures :  [ 0.08515556  0.0670807   0.14840829 -0.30888866 -0.56542567  0.32391105\n",
      "  0.27967632 -0.17588883 -0.35081566]  energy_before :  70  energy_after :  90  reward :  -218.49678688942566\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "action : 1  next_temperatures :  [-0.78448639 -0.6432802  -0.79401942 -0.4227379  -0.63189095 -0.07451237\n",
      " -0.76625693 -0.48993333 -0.86312836]  energy_before :  90  energy_after :  90  reward :  -203.47024585857702\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "action : 1  next_temperatures :  [-0.24692729 -0.92223088 -0.17232114 -0.91417348 -0.78143785 -0.75357338\n",
      " -0.30611157 -0.98288338  0.3295573 ]  energy_before :  90  energy_after :  60  reward :  -172.7501016543698\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "action : 1  next_temperatures :  [-0.05390414 -1.13835483 -0.29240467 -0.89205888 -0.53219302 -1.08849487\n",
      " -0.40238311 -0.92759926 -0.3607547 ]  energy_before :  60  energy_after :  50  reward :  -193.68814748946932\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "action : 1  next_temperatures :  [ 0.27817871 -1.64264405  0.37185486 -1.82414835 -0.75152847 -1.14994836\n",
      " -0.03198241 -1.47429775 -0.75470239]  energy_before :  50  energy_after :  50  reward :  -204.9792182287011\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "action : 1  next_temperatures :  [-0.24692729 -2.09415882 -0.23616302 -2.14276242 -1.03068267 -1.52174194\n",
      " -0.55086974 -1.83364452 -1.19382757]  energy_before :  50  energy_after :  50  reward :  -208.85077798783004\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "action : 1  next_temperatures :  [-0.18466176 -0.49500911 -0.80921987  0.19155657  0.06100966 -0.464742\n",
      "  0.31557419 -0.83545906  0.27534432]  energy_before :  50  energy_after :  60  reward :  -209.9456070671855\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "action : 1  next_temperatures :  [-1.18091029 -0.87196949 -1.61940369  0.05067837 -0.98581861 -0.56614025\n",
      " -0.36974869 -0.79169247 -1.02576732]  energy_before :  60  energy_after :  380  reward :  -525.3607724372464\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "action : 1  next_temperatures :  [-0.18466176 -0.26631982 -0.83962076  0.93444335  0.31025448 -0.67061118\n",
      " -0.36974869  0.20111814 -0.10956787]  energy_before :  380  energy_after :  70  reward :  111.0052858972895\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "action : 1  next_temperatures :  [-2.67528308 -0.73542607 -1.75164758 -0.73398043 -2.23204273 -0.62759374\n",
      " -2.27886242 -0.60510857 -1.89317508]  energy_before :  70  energy_after :  60  reward :  -201.53311970239298\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "action : 1  next_temperatures :  [-0.34447662 -1.76662213 -0.15560065 -2.21893493 -0.34941349 -1.48077295\n",
      " -0.17394215 -1.57258063 -0.20037462]  energy_before :  60  energy_after :  150  reward :  -296.2627181853961\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "action : 1  next_temperatures :  [ 0.43799358 -1.40641555 -0.29240467 -0.81834354  0.66418213 -0.6798292\n",
      "  0.75124373 -1.43667384  0.64941392]  energy_before :  150  energy_after :  90  reward :  -140.1308334413234\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "action : 1  next_temperatures :  [-0.98788713 -1.07050196 -1.29563417 -0.36540375  0.02943865 -0.54565576\n",
      " -0.6634585  -1.15794975 -0.53785045]  energy_before :  90  energy_after :  160  reward :  -274.594902826206\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "action : 2  next_temperatures :  [ 0.40438573 -0.5814927   0.61639264 -0.48833404 -0.18521446 -0.3957623\n",
      "  0.92396111 -0.32149859  0.07723735]  energy_before :  160  energy_after :  50  reward :  -96.95032526336044\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "action : 1  next_temperatures :  [-0.61429393 -0.79657742 -0.95362412  0.02569706 -0.32033492 -1.1806751\n",
      " -0.22778895 -1.02204296 -0.04993359]  energy_before :  50  energy_after :  50  reward :  -203.1395739303921\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "action : 1  next_temperatures :  [-0.13900036  0.32676452 -0.82442032  1.53399476 -0.73657378 -0.17795907\n",
      "  0.11976765 -0.40009664 -0.43484578]  energy_before :  50  energy_after :  110  reward :  -258.7323690304752\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "action : 1  next_temperatures :  [ 0.74932124 -0.81919504  0.61962214 -1.04604202  0.41493731 -0.81502687\n",
      "  0.9960019  -1.05198852  0.56448024]  energy_before :  110  energy_after :  50  reward :  -138.38788961561684\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "action : 1  next_temperatures :  [ 1.12914099 -0.49500911  0.9342714  -1.01491777  1.11282282 -1.13414604\n",
      "  1.24076008 -0.97597286  2.09473209]  energy_before :  50  energy_after :  40  reward :  -185.1083184033596\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "action : 1  next_temperatures :  [ 0.37572804 -0.07532656  0.73970568 -0.7266089   0.11584352 -0.39202205\n",
      "  0.07081602 -0.68342774  0.27534432]  energy_before :  40  energy_after :  60  reward :  -218.29994766413893\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "action : 1  next_temperatures :  [ 0.12666591 -0.24370219 -0.22096257  0.28001498  0.46478627 -0.3817798\n",
      "  0.60928399 -0.23654779  0.16149705]  energy_before :  60  energy_after :  40  reward :  -177.4407441497456\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "action : 1  next_temperatures :  [ 2.30595957 -0.28474899  2.75832503 -1.36547515  2.10980211 -0.45420712\n",
      "  2.30627398 -0.0061973   2.11858581]  energy_before :  40  energy_after :  50  reward :  -198.51168205446172\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "action : 1  next_temperatures :  [ 1.06064891 -0.39197328  1.92686058 -1.3744848   1.29061746 -0.36231953\n",
      "  1.37619293 -0.42927437 -0.12041047]  energy_before :  50  energy_after :  380  reward :  -525.024142561345\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "action : 1  next_temperatures :  [-0.63504911 -0.40118786 -0.33800601 -0.49645324 -0.79805417  0.08731514\n",
      " -0.27674059 -0.46689828 -0.84505737]  energy_before :  380  energy_after :  80  reward :  97.82986850727602\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "action : 1  next_temperatures :  [ 0.5687512  -0.71867227 -0.27872427 -0.05416122  0.01116069 -0.78122745\n",
      " -0.36974869 -0.42082818  0.3458212 ]  energy_before :  80  energy_after :  50  reward :  -169.69762899500535\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "action : 1  next_temperatures :  [-0.11616967 -2.05897585 -0.12519976 -2.08706639 -0.89941373 -1.48794253\n",
      " -0.48886433 -1.86512575 -1.19382757]  energy_before :  50  energy_after :  50  reward :  -208.3225855770312\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "action : 1  next_temperatures :  [ 1.06064891 -1.33940037  1.43328036 -1.82438237  0.96327592 -1.275928\n",
      "  1.45288382 -1.38138972  1.95594685]  energy_before :  50  energy_after :  60  reward :  -206.95506460306453\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "action : 1  next_temperatures :  [ 2.12538953 -0.21605843  3.3253017  -2.09607604  1.91040625 -0.25887283\n",
      "  2.07783302 -0.34481252  1.95594685]  energy_before :  60  energy_after :  260  reward :  -389.5209424632458\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "action : 1  next_temperatures :  [-2.2331978   0.78916925 -1.47803954  0.92870994 -1.54578864  0.87494397\n",
      " -1.90519828  1.07645    -1.56789717]  energy_before :  260  energy_after :  140  reward :  -83.06084827151713\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "action : 1  next_temperatures :  [-1.11864475 -0.50254832  0.11800739 -1.12876701 -1.08053164 -0.62759374\n",
      "  0.53340896 -0.74562237 -0.97697563]  energy_before :  140  energy_after :  20  reward :  -83.52926710927662\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "action : 1  next_temperatures :  [ 0.58950637  0.6383851   0.39161544  0.51651835  0.84530004 -0.60915769\n",
      "  0.26172739  0.41611193  0.60062223]  energy_before :  20  energy_after :  590  reward :  -764.3493708444842\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "action : 1  next_temperatures :  [ 0.81781333  1.49282863  0.75642617  1.10890298 -0.18823517  2.25764738\n",
      " -0.53618425  2.61979828  0.71115648]  energy_before :  590  energy_after :  60  reward :  341.0401538313197\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "action : 1  next_temperatures :  [-1.11864475 -0.59301881 -0.33800601 -0.79131458 -1.62887025  0.08833936\n",
      " -0.6634585  -0.42236385 -1.22695773]  energy_before :  60  energy_after :  40  reward :  -184.69429512864178\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "action : 1  next_temperatures :  [ 0.12666591 -0.19930464  0.30041276 -0.4006233  -0.63189095  0.62913003\n",
      " -0.22778895  0.66181912  0.16149705]  energy_before :  40  energy_after :  70  reward :  -227.5800829744592\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "action : 1  next_temperatures :  [-0.22617211 -0.30150278 -0.25136347 -0.32690796 -0.18823517  0.09755738\n",
      " -0.71730529 -0.17665666 -0.65169772]  energy_before :  70  energy_after :  70  reward :  -200.7422837853932\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "action : 1  next_temperatures :  [-0.98788713  1.27335392 -0.52041138  0.80585104 -1.18521446  1.70456601\n",
      " -0.47254712  1.16628669 -0.92276265]  energy_before :  70  energy_after :  60  reward :  -187.13876507813686\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "action : 1  next_temperatures :  [-1.18091029  1.41743656 -0.56601272  1.17442773 -1.18521446  1.76909217\n",
      " -1.0110151   1.78823301 -1.0799803 ]  energy_before :  60  energy_after :  60  reward :  -196.8739434068763\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "action : 1  next_temperatures :  [-0.42749733  0.05975091  0.19096954  0.01054447 -0.06693602 -0.37256178\n",
      " -0.22778895 -0.06839193  0.22113133]  energy_before :  60  energy_after :  40  reward :  -178.68077975694536\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step\n",
      "action : 1  next_temperatures :  [1.54424455 0.03524849 0.63330255 0.4102454  1.5564786  0.11804188\n",
      " 1.57199947 0.16886907 0.93596826]  energy_before :  40  energy_after :  50  reward :  -201.0256017269767\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "action : 1  next_temperatures :  [ 1.12914099 -0.29396358  1.03003421 -0.34902256 -0.53219302  1.27746429\n",
      " -1.15297484  1.00734485 -0.59206344]  energy_before :  50  energy_after :  50  reward :  -196.4762330883854\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "action : 1  next_temperatures :  [-1.40714172 -0.26631982 -0.93538358 -0.26875475 -1.68370411 -0.12777206\n",
      " -1.3814158  -0.18356718 -1.19382757]  energy_before :  50  energy_after :  370  reward :  -525.4478865911315\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "action : 1  next_temperatures :  [-2.05262775 -0.36935565 -1.29563417 -0.4006233  -1.87811508  0.01459518\n",
      " -2.23480595 -0.1290509  -1.801013  ]  energy_before :  370  energy_after :  40  reward :  121.85336937676084\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "action : 1  next_temperatures :  [-1.36148033  0.25891165 -0.93538358  0.26527191 -1.23506343  0.44784225\n",
      " -0.89189946 -0.20737006 -0.99323953]  energy_before :  40  energy_after :  40  reward :  -202.6524105803409\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "action : 1  next_temperatures :  [ 0.5687512   0.93995341  0.84762885  0.56013325  0.05547088  1.30819104\n",
      " -0.19189109  1.64388004 -0.52279129]  energy_before :  40  energy_after :  40  reward :  -192.79067371610472\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "action : 1  next_temperatures :  [ 0.25742353 -1.29919126 -0.33800601 -0.84045814 -0.43747999 -1.47770028\n",
      " -0.26042337 -0.66807104  0.23920233]  energy_before :  40  energy_after :  50  reward :  -212.82470423943855\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "action : 1  next_temperatures :  [-0.05390414 -1.04788434 -0.66177553 -0.38710882 -0.08355234 -0.96866058\n",
      " -0.19189109 -0.95063431 -0.59206344]  energy_before :  50  energy_after :  50  reward :  -202.93747458183103\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "action : 1  next_temperatures :  [-2.32970937  0.99021479 -1.46283909  1.02453987 -1.62887025  0.88621044\n",
      " -1.95741336  1.27455142 -1.62211015]  energy_before :  50  energy_after :  60  reward :  -212.8254257032096\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "action : 1  next_temperatures :  [0.9423444  1.19879953 0.57972097 1.44901735 1.25738481 0.8268054\n",
      " 1.19180844 1.0303799  1.63066894]  energy_before :  60  energy_after :  310  reward :  -437.89307024325984\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "action : 1  next_temperatures :  [1.93236637 1.80947535 1.07563555 2.20496813 2.15965108 1.32662708\n",
      " 2.01811203 1.19162524 2.38965073]  energy_before :  310  energy_after :  110  reward :  18.108111568325654\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "action : 1  next_temperatures :  [-0.55825495 -0.46736535  0.3156132  -1.35892267 -0.2829482  -0.90720709\n",
      " -0.0156652  -1.01359677 -0.80891538]  energy_before :  110  energy_after :  60  reward :  -153.09726242451364\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "action : 1  next_temperatures :  [1.93236637 1.79439694 1.30364226 2.00003949 2.1297417  0.78276374\n",
      " 2.07783302 1.59089943 2.24327567]  energy_before :  60  energy_after :  40  reward :  -162.14504138228892\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "action : 1  next_temperatures :  [-2.11489328  0.71126411 -1.39139699  0.82796564 -1.61225393  0.91796141\n",
      " -1.83829772  1.0303799  -1.51910548]  energy_before :  40  energy_after :  60  reward :  -222.98837634133452\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "action : 1  next_temperatures :  [2.41596201 2.03648927 2.07430492 1.54300441 1.96025522 1.79674624\n",
      " 2.25210084 1.28146193 2.4980767 ]  energy_before :  60  energy_after :  60  reward :  -180.14159845654157\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "action : 1  next_temperatures :  [-2.54452546  0.80592305 -1.57380235  0.60927681 -1.89639303  1.34916003\n",
      " -2.54320125  1.74984126 -2.30790441]  energy_before :  60  energy_after :  80  reward :  -224.3516253573636\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "action : 1  next_temperatures :  [ 0.99838337  0.42896267  0.45089718  0.91789835  1.02475631 -0.20971004\n",
      "  1.08248312  0.15504804  1.14275208]  energy_before :  80  energy_after :  390  reward :  -502.0085289068046\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "action : 1  next_temperatures :  [-0.30296627 -0.58547961 -1.05242702  0.36355902 -0.13340131 -0.81502687\n",
      " -0.19189109 -0.72028382 -0.21257254]  energy_before :  390  energy_after :  300  reward :  -111.6504894923591\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "action : 1  next_temperatures :  [-0.98788713  0.91482271 -0.43376883  0.57487632 -1.23506343  1.52327823\n",
      " -0.53618425  0.80693993 -1.13419329]  energy_before :  300  energy_after :  80  reward :  21.492820267003424\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "action : 1  next_temperatures :  [-0.49598942  0.21954023 -0.50673098 -0.44730968 -0.83128681 -0.76074296\n",
      " -0.76625693  0.0398728  -1.16401043]  energy_before :  80  energy_after :  70  reward :  -192.71291417251317\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "action : 1  next_temperatures :  [ 0.06440038  0.7037249   0.11800739  0.80585104 -0.33279717  0.90874338\n",
      "  0.26172739  0.78313704  0.10728407]  energy_before :  70  energy_after :  40  reward :  -164.57992156691458\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "action : 1  next_temperatures :  [ 0.25742353 -1.2715475  -0.73473768 -0.4227379   0.50965034 -1.3957623\n",
      "  0.48690491 -1.58271605  0.7036269 ]  energy_before :  40  energy_after :  130  reward :  -291.4498957474832\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "action : 1  next_temperatures :  [0.81781333 1.29178309 0.47825799 1.6658633  1.30723378 0.90874338\n",
      " 1.14775197 1.1225201  1.57645596]  energy_before :  130  energy_after :  60  reward :  -117.68357709926934\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "action : 1  next_temperatures :  [ 0.99838337  0.13493357  0.79917742 -0.36315134  0.20183298  1.92887123\n",
      " -0.03198241  0.37541668 -0.3806328 ]  energy_before :  60  energy_after :  90  reward :  -224.3371512871893\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "action : 1  next_temperatures :  [ 0.99838337 -0.42715624  0.81722795 -0.58736882 -0.03370338  0.89747691\n",
      "  0.11976765  0.3232039  -0.43484578]  energy_before :  90  energy_after :  150  reward :  -256.327014428526\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "action : 1  next_temperatures :  [ 0.68705571 -1.43238393 -0.03703716 -0.98788881  0.61433317 -0.71209228\n",
      "  0.9029938  -1.41133529  0.7036269 ]  energy_before :  150  energy_after :  50  reward :  -99.67272789518242\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "action : 1  next_temperatures :  [1.7662953  1.83413933 2.17006773 0.60506451 2.02332603 0.90845075\n",
      " 1.59004438 1.48430587 1.84592638]  energy_before :  50  energy_after :  80  reward :  -213.7723797195208\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "action : 1  next_temperatures :  [ 1.12914099 -0.5452705   1.94206103 -1.5776115   1.36206764 -0.32032631\n",
      "  1.48551825 -0.28492139 -0.16378086]  energy_before :  80  energy_after :  50  reward :  -164.97312265529806\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "action : 1  next_temperatures :  [-0.98788713 -0.09040497 -0.85634126  0.18254692 -0.73657378 -0.07451237\n",
      " -1.0110151  -0.06839193 -0.53785045]  energy_before :  50  energy_after :  120  reward :  -272.1804300804438\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "action : 1  next_temperatures :  [-0.61429393 -1.28076209 -1.36859632 -0.41720925 -0.38264613 -1.1806751\n",
      " -0.41870032 -1.12877202 -0.34087661]  energy_before :  120  energy_after :  50  reward :  -135.13253177235245\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "action : 1  next_temperatures :  [ 0.43799358 -0.21605843  0.49497848 -0.299879   -0.48732896  1.31740906\n",
      " -1.28514425  0.82920714 -0.75470239]  energy_before :  50  energy_after :  50  reward :  -197.96352478163692\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "action : 1  next_temperatures :  [ 0.50648566  0.22707944  0.98443287 -0.35721316  0.46478627 -0.11650559\n",
      "  0.60928399  0.3078472   0.76326118]  energy_before :  50  energy_after :  60  reward :  -204.6105421207188\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "action : 1  next_temperatures :  [-0.42749733 -0.6432802  -0.59641361 -0.59474035 -0.2829482  -1.04957433\n",
      " -1.33246416 -0.92759926 -1.19382757]  energy_before :  60  energy_after :  70  reward :  -215.04834502264146\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "action : 1  next_temperatures :  [ 1.25367206 -0.08286576  0.95099189 -0.42437602  0.80874413  0.00742561\n",
      "  0.36452582  0.17577959  0.37834899]  energy_before :  70  energy_after :  40  reward :  -164.5677536962788\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "action : 1  next_temperatures :  [-2.606791    0.36948669 -1.75164758  0.43727436 -2.23204273  0.35566202\n",
      " -2.62152386  0.52763996 -2.11544831]  energy_before :  40  energy_after :  70  reward :  -237.637390450155\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "action : 1  next_temperatures :  [ 1.25367206  0.00760473  0.30041276  0.60927681  1.52324596  0.23275505\n",
      "  1.34355851 -0.0061973   0.16149705]  energy_before :  70  energy_after :  60  reward :  -182.57417437206772\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "action : 1  next_temperatures :  [-0.30296627 -0.06527428 -0.02335676 -0.08119017 -0.23808413 -0.47396003\n",
      " -0.41870032 -0.0545709  -0.08968978]  energy_before :  60  energy_after :  50  reward :  -189.74779264732916\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "action : 1  next_temperatures :  [1.89274285 2.175561   1.88125924 1.44935863 2.23605595 1.27634696\n",
      " 1.55568226 1.73602023 1.82944989]  energy_before :  50  energy_after :  60  reward :  -191.96752300091498\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "action : 1  next_temperatures :  [-0.90694194 -1.5002368  -1.34579565 -0.76919998  0.01116069 -1.24212859\n",
      " -0.56555523 -1.43667384 -0.48363747]  energy_before :  60  energy_after :  120  reward :  -266.23900879653166\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "action : 1  next_temperatures :  [-0.3652318  -1.22128612 -0.38360736 -0.94120243 -0.2829482  -1.30358207\n",
      " -0.47254712 -0.88152916 -0.21257254]  energy_before :  120  energy_after :  50  reward :  -134.0645068038468\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "action : 1  next_temperatures :  [-0.42749733  0.21786485 -0.52041138  0.78783174 -0.2829482  -0.20049202\n",
      " -0.52149876  0.24488473 -0.10956787]  energy_before :  50  energy_after :  40  reward :  -188.81183423758603\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "action : 1  next_temperatures :  [-1.74130008  1.48361404 -0.92018313  1.23995247 -1.32977646  1.58473172\n",
      " -2.14995645  1.94410351 -1.56789717]  energy_before :  40  energy_after :  50  reward :  -209.4567115620988\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "action : 1  next_temperatures :  [ 0.12666591 -0.46736535 -0.55081227  0.51836123  0.26040552 -0.56614025\n",
      " -0.27674059  0.0398728   0.16149705]  energy_before :  50  energy_after :  80  reward :  -228.75425595663893\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "action : 1  next_temperatures :  [-1.00864231 -1.12914024 -1.03722657 -0.83390567 -0.10016866 -0.62861796\n",
      " -1.1040232  -0.69033825 -0.75470239]  energy_before :  80  energy_after :  240  reward :  -365.28676527122985\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "action : 1  next_temperatures :  [-0.5167446  -1.15510863 -0.66177553 -0.81834354 -1.19233575 -0.68904722\n",
      " -1.15297484 -0.76635392 -0.43484578]  energy_before :  240  energy_after :  60  reward :  -25.387529802404146\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "action : 1  next_temperatures :  [-0.3652318   0.25891165 -0.97642479  1.02453987  0.41493731  0.10677541\n",
      " -0.03198241  0.03142661  0.37834899]  energy_before :  60  energy_after :  60  reward :  -197.1586991610865\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "action : 1  next_temperatures :  [-0.55825495 -1.56473891 -0.33800601 -1.98714115 -1.21844711 -1.51866927\n",
      " -0.03198241 -1.25239345 -0.92276265]  energy_before :  60  energy_after :  40  reward :  -187.39239591376491\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "action : 1  next_temperatures :  [-0.18466176 -0.86012217 -0.11651379 -0.90785502 -0.93596964 -0.52005014\n",
      "  0.37540396 -1.01871567 -0.88963249]  energy_before :  40  energy_after :  70  reward :  -233.05811670886743\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "action : 1  next_temperatures :  [-0.67655947  0.80592305 -0.25136347  0.64859166 -0.93596964  1.48947882\n",
      " -0.24247444  1.05111145 -0.65470955]  energy_before :  70  energy_after :  150  reward :  -276.76597160320796\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "action : 1  next_temperatures :  [ 0.3617183  -1.04599954 -0.15560065 -0.76919998 -0.68672482 -0.86316543\n",
      " -0.03198241 -1.07502357 -0.65169772]  energy_before :  150  energy_after :  470  reward :  -522.9176758249922\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "action : 1  next_temperatures :  [ 0.5687512  -1.1735378   1.53164896 -2.27463096  0.31025448 -1.14994836\n",
      "  0.85404217 -1.22705489  0.60062223]  energy_before :  470  energy_after :  50  reward :  220.0401470153442\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "action : 1  next_temperatures :  [-0.05390414 -0.3249581  -0.56601272  0.40287387  0.11584352 -0.31110829\n",
      "  0.00065201 -0.15976429  0.22113133]  energy_before :  50  energy_after :  80  reward :  -228.67524680439004\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "action : 1  next_temperatures :  [ 0.88007886 -0.37689486  0.39161544 -0.4006233   0.92339675 -0.7892164\n",
      "  1.16243746 -0.49914735  0.94371298]  energy_before :  80  energy_after :  70  reward :  -185.76464042200942\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "action : 1  next_temperatures :  [-0.34447662 -1.54128359 -0.25136347 -1.4711338  -1.01145522 -1.26056463\n",
      " -0.96206346 -1.0427745  -1.11250809]  energy_before :  70  energy_after :  40  reward :  -176.9976233904518\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "action : 1  next_temperatures :  [ 1.37197657  0.11064057  1.61829151 -0.74287307  1.14130794 -0.35412573\n",
      "  1.39251014 -0.18356718  0.69355877]  energy_before :  40  energy_after :  50  reward :  -202.95228047828937\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "action : 1  next_temperatures :  [-0.42749733  0.04781384 -0.88978224  0.90168098 -0.13340131 -0.29267225\n",
      " -0.48886433 -0.03767853 -0.14570986]  energy_before :  50  energy_after :  470  reward :  -619.4661110400476\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "action : 1  next_temperatures :  [-0.61429393 -0.79657742  0.04048511 -0.65289356 -0.18823517 -1.275928\n",
      " -0.14130773 -0.91377823 -0.04993359]  energy_before :  470  energy_after :  50  reward :  217.40753748114898\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "action : 1  next_temperatures :  [-0.738825    0.93995341 -0.32280557  0.79520327 -0.88113578  1.5509323\n",
      " -0.68140743  1.55097201 -1.04383831]  energy_before :  50  energy_after :  50  reward :  -196.83095110252967\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "action : 1  next_temperatures :  [-0.61429393 -0.96997919 -1.29563417 -0.00501766 -0.33279717 -1.3752778\n",
      " -0.61450686 -1.03240873 -0.32099851]  energy_before :  50  energy_after :  40  reward :  -194.56091403629603\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "action : 1  next_temperatures :  [ 0.25742353  0.33430373 -0.29240467  1.12528417  0.96327592  0.16822889\n",
      "  0.45753393  0.27022329  0.66748491]  energy_before :  40  energy_after :  50  reward :  -204.04864631245056\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "action : 1  next_temperatures :  [-0.18466176  0.66184041  0.28369227  0.21367117 -0.22146781  1.81723074\n",
      "  0.34820861  0.6526051  -1.0799803 ]  energy_before :  50  energy_after :  100  reward :  -245.50886157064252\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "action : 1  next_temperatures :  [-0.3652318  -0.71867227 -1.06762747 -0.10330477 -0.15167926 -0.88467415\n",
      "  0.01696922 -0.90686771  0.05849238]  energy_before :  100  energy_after :  120  reward :  -222.12259584109017\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n",
      "action : 1  next_temperatures :  [-0.80731709 -0.69354158 -1.34579565  0.29639616  0.36508834 -0.81502687\n",
      " -0.8103134  -0.58207352 -0.21257254]  energy_before :  120  energy_after :  20  reward :  -102.60515614541623\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "action : 1  next_temperatures :  [-0.42749733  0.78916925 -0.43376883  0.98604409 -0.2829482   1.00092361\n",
      "  0.11976765  0.56200057 -0.23425774]  energy_before :  20  energy_after :  370  reward :  -545.9205669272875\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "action : 1  next_temperatures :  [ 0.25742353  0.51021857  0.52841946  0.14978455 -0.63189095  1.5509323\n",
      " -0.84294782  0.65337293 -0.14360158]  energy_before :  370  energy_after :  40  reward :  134.03171098966953\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "action : 1  next_temperatures :  [ 0.72856606 -0.22527302  0.16360874 -0.11968596  1.11282282 -0.46605886\n",
      "  0.9960019  -0.44616674  0.5154304 ]  energy_before :  40  energy_after :  90  reward :  -245.74075466150202\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "action : 1  next_temperatures :  [-1.18091029  1.44256725 -0.52041138  1.12528417 -1.23506343  1.68612997\n",
      " -0.96206346  1.78823301 -1.0799803 ]  energy_before :  90  energy_after :  40  reward :  -146.9362144668449\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "action : 1  next_temperatures :  [-0.24692729 -0.51762674 -0.88978224  0.19155657  0.04439334 -0.44630596\n",
      "  0.31557419 -0.86079762  0.22113133]  energy_before :  40  energy_after :  140  reward :  -300.188784407018\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "action : 1  next_temperatures :  [-0.86958262  1.56822071 -0.29240467  1.05156883 -1.00077329  1.92272588\n",
      " -0.36974869  1.67305777 -0.53785045]  energy_before :  140  energy_after :  30  reward :  -84.85478654248385\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "action : 1  next_temperatures :  [-0.30296627 -0.21605843 -0.33800601  0.19155657 -0.13340131 -0.50775944\n",
      " -0.07603889  0.2617771   0.37834899]  energy_before :  30  energy_after :  90  reward :  -258.742547682926\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "action : 1  next_temperatures :  [-0.86958262 -1.02024058 -1.6604449   0.33653007 -0.84790314 -0.56614025\n",
      " -0.52149876 -1.1372182  -0.97697563]  energy_before :  90  energy_after :  50  reward :  -165.26347401187607\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "action : 1  next_temperatures :  [-1.61054246  1.81952763 -0.88978224  1.6658633  -1.23506343  1.89199914\n",
      " -1.34878137  2.20286389 -1.21189857]  energy_before :  50  energy_after :  120  reward :  -266.7158141093623\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "action : 1  next_temperatures :  [-0.49598942  0.83691757 -0.38360736  1.00979681 -0.23808413  0.89425792\n",
      " -0.56555523  1.28146193 -0.84763894]  energy_before :  120  energy_after :  60  reward :  -136.50844084551102\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n",
      "action : 1  next_temperatures :  [-0.67655947 -0.84432573 -0.25136347 -0.97150763 -1.2799275   0.3218626\n",
      " -1.88724935 -0.25958284 -0.98239693]  energy_before :  60  energy_after :  40  reward :  -184.83105030898284\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "action : 1  next_temperatures :  [ 0.9423444   0.71126411  1.04523466  0.41188352 -0.23808413  1.67691195\n",
      " -0.8103134   1.20544627  0.11330773]  energy_before :  40  energy_after :  60  reward :  -212.94200489719674\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "action : 1  next_temperatures :  [ 1.58367939 -0.56034891  1.08931596 -0.53085373  1.21252075 -0.42377301\n",
      "  1.43656661 -0.53600343  0.87168715]  energy_before :  60  energy_after :  40  reward :  -173.85720922478188\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "action : 1  next_temperatures :  [-0.86958262 -1.5982465  -0.79401942 -1.40560905 -1.23506343 -0.87340768\n",
      " -0.9261656  -1.29616004 -1.19382757]  energy_before :  40  energy_after :  30  reward :  -198.19208191142252\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "action : 1  next_temperatures :  [ 0.0083614  -0.38443407 -1.02202613  0.70510675  0.06100966 -0.56614025\n",
      "  0.88900762 -0.54324301  0.43256198]  energy_before :  30  energy_after :  90  reward :  -258.4197960640756\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "action : 1  next_temperatures :  [ 0.14949661 -1.19615542 -0.47937017 -0.71759925  0.06100966 -1.6108495\n",
      "  0.26172739 -1.56665733  0.49219626]  energy_before :  90  energy_after :  50  reward :  -162.6062017521871\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "action : 1  next_temperatures :  [ 0.50648566 -0.2101946   2.87688852 -2.7226564   0.46478627 -0.87340768\n",
      "  0.97968469 -0.83008422  0.64941392]  energy_before :  50  energy_after :  70  reward :  -217.15908383475923\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "action : 1  next_temperatures :  [ 0.27817871 -0.41961704 -0.43376883  0.24070013  1.25738481 -0.57740673\n",
      "  0.60928399 -0.83545906  0.60062223]  energy_before :  70  energy_after :  50  reward :  -177.28008178050456\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "action : 1  next_temperatures :  [ 0.63101673 -0.85123667  0.16360874 -0.43911909 -0.13340131 -0.87340768\n",
      "  0.56033236 -0.45998776 -0.04993359]  energy_before :  50  energy_after :  70  reward :  -219.45212827280852\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n",
      "action : 1  next_temperatures :  [-2.54452546  0.84613215 -1.61940369  0.61746741 -1.93294894  1.28770654\n",
      " -2.29517964  1.83430311 -2.30519376]  energy_before :  70  energy_after :  50  reward :  -184.11164228173928\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n",
      "action : 1  next_temperatures :  [-0.78448639 -1.78505131 -0.79401942 -1.84790107 -1.18521446 -1.36810823\n",
      " -0.85926503 -1.70311257  0.16691835]  energy_before :  50  energy_after :  50  reward :  -208.1602401451063\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "action : 1  next_temperatures :  [-0.80731709 -1.09563265 -0.80921987 -0.88304922 -1.08053164 -0.41250654\n",
      " -1.27045876 -0.58975187 -1.35104523]  energy_before :  50  energy_after :  50  reward :  -206.29951287511557\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "action : 1  next_temperatures :  [ 2.74804486  0.6383851   2.92704999 -0.57262575  3.4058752  -0.30847457\n",
      "  2.3617525   0.71157482  2.54686839]  energy_before :  50  energy_after :  70  reward :  -203.54154945984948\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "action : 1  next_temperatures :  [-1.2992148  -1.62589026 -1.25003283 -1.33189372 -1.32977646 -1.08849487\n",
      " -1.1040232  -1.35912251 -0.99323953]  energy_before :  70  energy_after :  270  reward :  -409.3816881816183\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "action : 1  next_temperatures :  [-0.09541449 -0.3249581  -0.30760512 -0.22616367 -0.63189095 -0.01305889\n",
      " -0.03198241 -0.19892388 -0.14570986]  energy_before :  270  energy_after :  80  reward :  -9.975707375047477\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "action : 1  next_temperatures :  [ 0.10591073  0.40299428 -0.02335676  0.58470503  0.36508834 -0.28140577\n",
      " -0.22778895  0.87527724  0.16149705]  energy_before :  80  energy_after :  130  reward :  -246.03707880390917\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "action : 1  next_temperatures :  [-0.7616557  -0.57626502 -0.61161406 -1.14351008 -1.15231415 -0.91150884\n",
      " -1.20682164 -0.75099722 -1.29683224]  energy_before :  130  energy_after :  160  reward :  -236.41151893257813\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "action : 1  next_temperatures :  [-0.30296627  1.20633874  0.11800739  0.45365555 -0.43747999  1.18221139\n",
      " -0.96206346  0.73783478 -0.32099851]  energy_before :  160  energy_after :  40  reward :  -76.32546038483866\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "action : 1  next_temperatures :  [-0.30296627 -0.99762296 -1.17707069 -0.11968596  0.01116069 -0.93486116\n",
      " -0.22778895 -1.41133529 -0.59206344]  energy_before :  40  energy_after :  50  reward :  -213.7522340163575\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "action : 1  next_temperatures :  [2.28520439 1.9200504  2.18830827 1.36019037 2.19122209 0.97019687\n",
      " 2.27363956 1.36054894 2.44386372]  energy_before :  50  energy_after :  240  reward :  -371.00677539765\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "action : 1  next_temperatures :  [ 1.62103871 -0.23448761  1.1622781  -0.23435426  1.84227934 -0.63988444\n",
      "  1.78412322 -0.48225498  1.84752088]  energy_before :  240  energy_after :  60  reward :  -11.333741040892306\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "action : 1  next_temperatures :  [-0.3652318  -0.6022334  -0.49305057 -0.60293094 -0.18823517 -1.01679914\n",
      " -1.29982974 -0.92759926 -1.19382757]  energy_before :  60  energy_after :  110  reward :  -254.68973759795244\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "action : 1  next_temperatures :  [-1.19958995 -1.32432195 -0.72105728 -1.1934727  -1.1303806  -0.94838093\n",
      " -0.6634585  -1.30460623 -0.80891538]  energy_before :  110  energy_after :  80  reward :  -177.2941835041098\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "action : 1  next_temperatures :  [-1.36148033 -1.14589404 -1.29563417 -0.91417348 -1.2799275  -0.67245478\n",
      " -1.15297484 -1.01973945 -0.97697563]  energy_before :  80  energy_after :  310  reward :  -437.8192542232306\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "action : 1  next_temperatures :  [-1.00864231 -1.62589026 -0.88978224 -1.43263801 -1.23506343 -0.93091058\n",
      " -1.05507157 -1.25930396 -1.19382757]  energy_before :  310  energy_after :  40  reward :  61.3688700684084\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "action : 1  next_temperatures :  [1.93236637 1.74413555 1.09908767 2.17941348 2.10980211 1.64311253\n",
      " 2.12678465 1.24098606 2.33001645]  energy_before :  40  energy_after :  110  reward :  -251.5942951169012\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "action : 1  next_temperatures :  [ 0.31968906 -0.6022334  -0.20576213 -0.15244833  0.57777726 -0.48727495\n",
      "  0.87362282 -0.91101402  0.43256198]  energy_before :  110  energy_after :  100  reward :  -188.15508171023222\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "action : 1  next_temperatures :  [ 0.90083404 -1.04788434  0.21605028 -0.65739839  0.80874413 -0.62759374\n",
      "  0.85404217 -1.09114811  0.05849238]  energy_before :  100  energy_after :  120  reward :  -218.58586157783122\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "action : 1  next_temperatures :  [-0.42749733 -0.50631792 -1.16339028  0.51836123 -0.13340131 -0.84268094\n",
      "  0.16871929 -0.93681328  0.14342606]  energy_before :  120  energy_after :  240  reward :  -321.1795944899731\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "action : 1  next_temperatures :  [1.27395283 2.45289287 2.17006773 0.8121695  1.91259011 1.42641584\n",
      " 1.50149952 1.6875563  1.69046268]  energy_before :  240  energy_after :  20  reward :  36.927607377583485\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "action : 1  next_temperatures :  [-1.63129764  0.93157651 -1.02202613  0.90168098 -1.2799275   1.36964452\n",
      " -1.54458791  1.17473287 -1.35104523]  energy_before :  20  energy_after :  60  reward :  -240.4512495236923\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "action : 1  next_temperatures :  [ 0.39648322 -1.18107701  1.35988391 -2.21893493 -0.03370338 -0.86316543\n",
      "  0.94705027 -1.20632335  0.05849238]  energy_before :  60  energy_after :  40  reward :  -180.74129431410074\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "action : 1  next_temperatures :  [ 0.04572072  0.53786233 -0.46416972  0.8549946   0.23049614  0.09755738\n",
      "  0.26172739  0.12970949  0.64941392]  energy_before :  40  energy_after :  90  reward :  -245.6566877588609\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n",
      "action : 1  next_temperatures :  [-1.05015267 -0.74631603 -1.4324382   0.04166872 -0.71995746 -0.40226429\n",
      " -1.15297484 -0.58207352 -0.70591071]  energy_before :  90  energy_after :  110  reward :  -224.75041899728424\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "action : 1  next_temperatures :  [-0.24692729  0.91482271  0.16360874  0.48641792 -0.20485149  1.94116193\n",
      "  0.01696922  1.51181242  0.01632673]  energy_before :  110  energy_after :  100  reward :  -183.4006591116245\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "action : 1  next_temperatures :  [-0.86958262 -0.58547961  0.11800739 -1.18692022 -1.08053164 -0.6798292\n",
      "  0.59296678 -0.7748001  -0.97697563]  energy_before :  100  energy_after :  30  reward :  -133.44314483964675\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "action : 1  next_temperatures :  [ 0.63101673  0.31922531  0.98443287 -0.36540375  0.50965034 -0.01305889\n",
      "  1.14775197 -0.14440759  0.92047884]  energy_before :  30  energy_after :  90  reward :  -254.01031416975573\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "action : 1  next_temperatures :  [-0.98788713 -0.74631603 -1.39139699  0.05067837 -0.73657378 -0.44630596\n",
      " -1.15297484 -0.60510857 -0.70591071]  energy_before :  90  energy_after :  120  reward :  -234.72179563981302\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "action : 1  next_temperatures :  [-0.61429393 -0.88704791 -0.88978224 -0.0967523  -0.18823517 -1.48794253\n",
      "  0.07081602 -0.83216834  0.16149705]  energy_before :  120  energy_after :  70  reward :  -152.76390934935588\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "action : 1  next_temperatures :  [0.88007886 2.11271904 0.88867006 1.03354953 2.10980211 0.31469303\n",
      " 0.36452582 0.99198815 0.76326118]  energy_before :  70  energy_after :  50  reward :  -168.54071221603826\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "action : 1  next_temperatures :  [-1.11864475  1.29178309 -0.52041138  1.10071239 -0.88113578  1.54171428\n",
      " -0.85926503  1.7506091  -1.0799803 ]  energy_before :  50  energy_after :  60  reward :  -206.77461838533827\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "action : 1  next_temperatures :  [-0.49598942 -1.22128612 -1.28043373 -0.47188146 -0.38264613 -1.24212859\n",
      " -0.36974869 -1.0427745  -0.26678553]  energy_before :  60  energy_after :  50  reward :  -194.7736741588982\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "action : 1  next_temperatures :  [-0.05390414  0.03524849 -0.70737688  0.97785349  0.26040552  0.03712812\n",
      " -0.29142608 -0.1290509   0.16149705]  energy_before :  50  energy_after :  30  reward :  -177.70962530598118\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "action : 1  next_temperatures :  [ 0.31968906 -1.5731158   0.11800739 -1.5554969  -0.78143785 -1.09976135\n",
      "  0.07081602 -1.36756869 -0.86312836]  energy_before :  30  energy_after :  70  reward :  -244.73199648492067\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "action : 1  next_temperatures :  [-0.42749733 -0.81919504  0.39161544 -1.28275016 -0.23808413 -1.24212859\n",
      "  0.01696922 -0.97597286 -0.10956787]  energy_before :  70  energy_after :  50  reward :  -182.68661132805764\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n",
      "action : 1  next_temperatures :  [-0.11616967  1.53387543  0.16360874  1.07368343 -0.38264613  1.19347786\n",
      "  0.36452582  1.46804583 -0.53785045]  energy_before :  50  energy_after :  60  reward :  -203.23944913901119\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n",
      "action : 1  next_temperatures :  [-0.18466176 -0.71867227 -0.93538358  0.40287387 -0.03370338 -0.66139315\n",
      " -0.58187244 -0.53600343 -0.18004475]  energy_before :  60  energy_after :  100  reward :  -241.42886088791548\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n",
      "action : 1  next_temperatures :  [-0.82807226 -0.89458712 -0.83962076 -0.76019033 -0.93596964 -0.60915769\n",
      " -0.71730529 -0.88997534 -0.43484578]  energy_before :  100  energy_after :  390  reward :  -494.9097242289458\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "action : 1  next_temperatures :  [ 0.43799358 -0.89458712  0.22419337 -0.73164026 -0.671058   -0.40372747\n",
      " -0.41870032 -0.92241637 -0.01121003]  energy_before :  390  energy_after :  40  reward :  148.60884737481717\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "action : 1  next_temperatures :  [-0.18466176 -0.74631603 -0.82822043  0.02508277 -0.03370338 -0.56614025\n",
      " -0.0466679  -0.63044713 -0.26678553]  energy_before :  40  energy_after :  60  reward :  -221.27785963854762\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "action : 1  next_temperatures :  [1.78236304 2.86073789 1.57683948 2.45571686 2.43223428 1.9408826\n",
      " 1.46968614 2.11560049 1.72468696]  energy_before :  60  energy_after :  40  reward :  -159.64125226042052\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "action : 1  next_temperatures :  [ 2.12538953 -0.30904199  3.23105893 -2.07805673  1.94601266 -0.25887283\n",
      "  2.07783302 -0.35172303  1.98847464]  energy_before :  40  energy_after :  50  reward :  -199.62892581094596\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "action : 1  next_temperatures :  [ 0.06440038 -0.71867227  1.635012   -2.08706639 -0.08355234 -0.62759374\n",
      "  0.94705027 -0.95787389  0.05849238]  energy_before :  50  energy_after :  40  reward :  -189.76980360303855\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "action : 1  next_temperatures :  [-0.55825495 -0.51008753 -0.55081227 -0.4227379   0.26040552 -0.71977397\n",
      " -1.15297484 -0.76635392 -1.24804056]  energy_before :  40  energy_after :  90  reward :  -253.66863041216016\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "action : 1  next_temperatures :  [-0.18466176 -0.49500911 -0.38360736 -0.4227379  -0.63189095  0.0483946\n",
      " -0.50518155  0.10897794  0.26028516]  energy_before :  90  energy_after :  90  reward :  -200.20543092625346\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "action : 1  next_temperatures :  [ 0.0083614  -0.77982362  0.20464994 -0.97969822  1.59303451 -0.01305889\n",
      " -0.41870032 -0.34558035  0.31148631]  energy_before :  90  energy_after :  50  reward :  -158.4193292517912\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "action : 1  next_temperatures :  [1.99463191 1.86978901 1.24501196 2.14957632 2.15965108 1.68797357\n",
      " 2.17084113 1.30680049 2.34989454]  energy_before :  50  energy_after :  130  reward :  -261.0658299928017\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "action : 1  next_temperatures :  [-0.22617211  0.27734082 -0.40032785  0.65760131 -0.23808413 -0.90720709\n",
      "  0.11976765 -0.24576181  0.10728407]  energy_before :  130  energy_after :  40  reward :  -108.8555591415313\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "action : 1  next_temperatures :  [ 1.30971104 -1.67615164  1.30364226 -2.48021485  0.55949931 -1.3957623\n",
      "  1.19180844 -1.55184908  0.896083  ]  energy_before :  40  energy_after :  70  reward :  -229.84323383067814\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "action : 1  next_temperatures :  [-1.23694927 -0.14988094 -0.66177553 -0.16227704 -1.03068267  0.35258935\n",
      " -0.26042337 -0.76635392 -0.86312836]  energy_before :  70  energy_after :  30  reward :  -162.77888176637913\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "action : 1  next_temperatures :  [ 0.06440038 -0.74631603 -0.1404002  -0.52348219 -0.83128681 -0.22814609\n",
      "  0.98131641 -0.35402654 -0.19630865]  energy_before :  30  energy_after :  90  reward :  -259.9742497285106\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "action : 1  next_temperatures :  [-1.40714172 -0.52684132 -1.8474104   0.44300778 -1.08053164 -0.59993967\n",
      " -0.56555523 -0.63735764 -0.99323953]  energy_before :  90  energy_after :  70  reward :  -185.21500937331516\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "action : 1  next_temperatures :  [-0.55825495  0.76152549 -0.66177553  1.46928907 -0.33279717  0.21227056\n",
      " -0.61450686  0.84609951 -0.19630865]  energy_before :  70  energy_after :  70  reward :  -197.07445853690115\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "action : 1  next_temperatures :  [ 0.195158   -0.01668827 -0.38360736  0.76489808  0.26040552 -0.13903853\n",
      "  0.11976765 -0.15285378  0.43256198]  energy_before :  70  energy_after :  50  reward :  -176.91939672198276\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "action : 1  next_temperatures :  [-0.24692729  1.28256851  0.20464994  0.92870994 -0.73657378  1.78752822\n",
      "  0.31557419  1.26073039 -0.86312836]  energy_before :  50  energy_after :  240  reward :  -384.0668682486041\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "action : 1  next_temperatures :  [-1.65205282  0.12739436 -1.16339028 -0.05416122 -1.73355308 -0.0878273\n",
      " -1.59353955 -0.44386323 -1.80968708]  energy_before :  240  energy_after :  60  reward :  -26.410680190615608\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "action : 1  next_temperatures :  [-0.01239378 -1.02024058 -0.59641361 -0.32690796 -0.98581861 -0.86316543\n",
      " -0.41870032 -0.83545906 -0.01062918]  energy_before :  60  energy_after :  50  reward :  -193.06972853115485\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "action : 1  next_temperatures :  [-0.03314896 -0.38443407 -0.35320646 -0.03204662  0.55949931 -0.96866058\n",
      " -0.41870032 -0.25190449  0.05849238]  energy_before :  50  energy_after :  40  reward :  -189.82410981042648\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "action : 1  next_temperatures :  [-0.01239378  0.86456133  0.07240605  0.63384859  0.33767141  1.1991111\n",
      " -0.55086974  0.80002941  0.16149705]  energy_before :  40  energy_after :  30  reward :  -184.49413856793828\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "action : 1  next_temperatures :  [-0.57693461 -0.5452705  -0.74841808 -0.34902256 -0.73657378  0.19076184\n",
      " -0.90821667  0.01453424 -0.26076186]  energy_before :  30  energy_after :  100  reward :  -271.91990199005045\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "action : 1  next_temperatures :  [ 0.63101673 -0.16831012 -0.22096257  0.80585104  0.55949931  0.08833936\n",
      " -0.52149876  0.45450368  0.3295573 ]  energy_before :  100  energy_after :  300  reward :  -396.04200402428\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "action : 1  next_temperatures :  [-0.55825495  1.20801412 -0.20576213  1.31940122 -0.36602981  0.90874338\n",
      "  0.52443449  1.48186686  0.50087034]  energy_before :  300  energy_after :  110  reward :  -3.18671647141457\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "action : 1  next_temperatures :  [ 0.88007886 -1.44746234  0.33081365 -1.2336066   0.59605521 -0.87340768\n",
      "  0.9960019  -1.36756869  0.76326118]  energy_before :  110  energy_after :  40  reward :  -129.35583449980382\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "action : 1  next_temperatures :  [-0.49598942  0.43733956 -0.15560065  0.31441547 -0.73657378  1.64311253\n",
      " -1.27045876  1.02270155 -0.8929455 ]  energy_before :  40  energy_after :  700  reward :  -858.1339990082523\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "action : 1  next_temperatures :  [-0.49598942  1.16612963  0.02224458  0.70510675 -0.38264613  1.48947882\n",
      " -0.56555523  1.58322108 -0.16649151]  energy_before :  700  energy_after :  30  reward :  475.3554985683059\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "action : 1  next_temperatures :  [-1.672808   -0.67092396 -1.06762747 -0.72578984 -1.52917232  0.26040912\n",
      " -2.13200752 -0.19047769 -1.56789717]  energy_before :  30  energy_after :  60  reward :  -237.296294848121\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "action : 1  next_temperatures :  [-1.42997242  0.75398628 -0.74841808  0.69773522 -1.18521446  1.72709896\n",
      " -0.9261656   1.05955763 -1.24804056]  energy_before :  60  energy_after :  110  reward :  -249.299433033627\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "action : 1  next_temperatures :  [ 0.06440038 -1.12327642 -0.97642479  0.07975498 -0.20485149 -1.22369254\n",
      " -0.0466679  -1.17330645  0.05849238]  energy_before :  110  energy_after :  110  reward :  -202.54557184887437\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "action : 1  next_temperatures :  [ 1.52618485 -0.30421168  1.29206425 -0.59888883  1.3144198  -0.48692911\n",
      "  1.50395458 -0.04628427  0.95286582]  energy_before :  110  energy_after :  60  reward :  -142.84682458833805\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "action : 1  next_temperatures :  [ 0.0083614  -1.36536875  0.02224458 -1.22541601 -0.58204199 -1.30358207\n",
      " -0.6634585  -1.66702433 -0.86312836]  energy_before :  60  energy_after :  40  reward :  -185.63941403090826\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "action : 1  next_temperatures :  [ 0.43799358 -0.3165812   0.43265665 -0.3342795   0.31025448 -0.41250654\n",
      "  0.21277576  0.25333092  0.3295573 ]  energy_before :  40  energy_after :  60  reward :  -217.0867985529193\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n",
      "action : 1  next_temperatures :  [-0.9256216  -0.59301881 -1.16339028 -0.12787655 -0.68672482  0.33312908\n",
      " -0.69935636 -0.33099149 -0.80891538]  energy_before :  60  energy_after :  60  reward :  -203.0027662202935\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n",
      "action : 1  next_temperatures :  [-1.36148033 -1.1735378  -1.13298939 -1.08617593 -1.30841262 -0.77903268\n",
      " -1.20682164 -0.92068874 -1.04900145]  energy_before :  60  energy_after :  40  reward :  -188.0181405876792\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "action : 2  next_temperatures :  [-0.23694927 -0.31426968  0.67719443 -0.612012   -0.32977646 -0.1806751\n",
      "  0.85869227 -0.1372182   0.13687164]  energy_before :  40  energy_after :  140  reward :  -307.1381423664268\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "action : 1  next_temperatures :  [ 1.30971104 -0.01501289  2.54703882 -1.69309887  1.05798895 -0.50775944\n",
      "  1.63726831 -0.19047769  0.3295573 ]  energy_before :  140  energy_after :  40  reward :  -93.52478446277354\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "action : 1  next_temperatures :  [-1.23694927  1.33953141 -0.66177553  0.93608147 -1.18521446  1.73836543\n",
      " -0.82663061  1.38204831 -0.86312836]  energy_before :  40  energy_after :  380  reward :  -537.3776716129508\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "action : 1  next_temperatures :  [-0.24692729 -1.41395475 -0.43376883 -1.56942091  0.57777726 -1.408053\n",
      "  0.36452582 -1.74227216 -0.48363747]  energy_before :  380  energy_after :  40  reward :  135.64426867734932\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "action : 1  next_temperatures :  [-0.55825495 -1.38212254  0.49649852 -1.6783558  -0.47071263 -1.48794253\n",
      "  0.31557419 -1.50347548 -0.65169772]  energy_before :  40  energy_after :  50  reward :  -214.9204889490364\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "action : 1  next_temperatures :  [-0.3652318  -1.11322414 -0.40032785 -1.84216766 -1.03068267 -1.08849487\n",
      "  0.24541018 -1.45203054 -1.00950342]  energy_before :  50  energy_after :  140  reward :  -296.05625277436394\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "action : 1  next_temperatures :  [-0.86958262 -0.56788812 -1.08434796 -0.15490551 -0.68672482  0.3218626\n",
      " -0.61450686 -0.33099149 -0.78180889]  energy_before :  140  energy_after :  110  reward :  -172.76889366133892\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "action : 1  next_temperatures :  [-0.80731709  0.94749261 -0.35320646  0.8549946  -0.89941373  1.51201176\n",
      " -0.76625693  1.55788252 -1.0799803 ]  energy_before :  110  energy_after :  40  reward :  -127.03379301558004\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "action : 1  next_temperatures :  [-0.11616967 -0.20768153  1.47084717 -0.92400219  0.06100966 -0.77200943\n",
      "  0.93446271 -0.45209003  0.27534432]  energy_before :  40  energy_after :  90  reward :  -247.73028899344263\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "action : 1  next_temperatures :  [-0.49598942 -0.89458712 -0.26504387 -0.91417348 -0.86451946 -0.60915769\n",
      " -0.41870032 -0.82394154 -0.86312836]  energy_before :  90  energy_after :  90  reward :  -204.1492412596242\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n",
      "action : 1  next_temperatures :  [-0.28428661  0.49514016  0.07240605  0.31441547 -0.03370338  1.39729859\n",
      " -0.35343148  0.61574902 -0.3806328 ]  energy_before :  90  energy_after :  140  reward :  -246.15704497679204\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n",
      "action : 1  next_temperatures :  [ 0.68705571 -1.17186242  1.42372579 -2.03710377  0.31025448 -0.99631465\n",
      "  1.0498487  -1.23363634  0.3295573 ]  energy_before :  140  energy_after :  80  reward :  -139.63847518808367\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "action : 1  next_temperatures :  [ 0.12666591  0.53786233  0.41897624  0.20629964  0.41493731  1.13407283\n",
      " -0.17394215  0.91520466  0.37834899]  energy_before :  80  energy_after :  60  reward :  -174.04157424375322\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "action : 1  next_temperatures :  [-1.05015267 -0.02883478 -0.88978224  0.11784124 -0.83128681 -0.1666926\n",
      " -0.76503314  0.06809073 -0.65169772]  energy_before :  60  energy_after :  250  reward :  -392.19754798761835\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "action : 1  next_temperatures :  [0.9423444  1.18288343 0.88867006 0.88693791 0.50965034 1.79674624\n",
      " 0.41347746 2.21975626 0.45575309]  energy_before :  250  energy_after :  270  reward :  -208.7037808216327\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "action : 1  next_temperatures :  [ 0.74932124  1.18874726  0.52841946  0.91970028  0.96327592 -0.20971004\n",
      "  0.74580466  0.16784529  0.81747417]  energy_before :  270  energy_after :  90  reward :  -12.129121750450082\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "action : 1  next_temperatures :  [-0.80731709 -0.83594884 -0.33800601 -0.94120243 -1.36300911  0.26040912\n",
      " -1.88724935 -0.23654779 -1.07094481]  energy_before :  90  energy_after :  50  reward :  -165.21981630447866\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "action : 1  next_temperatures :  [-0.55825495  0.72969328 -0.20576213  0.46839861 -0.33556655  1.1079551\n",
      "  0.01696922  0.81461828 -0.50170846]  energy_before :  50  energy_after :  40  reward :  -186.46365760771283\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "action : 1  next_temperatures :  [ 0.5687512   0.26812624  1.07563555 -0.53822526  0.52211258 -0.02150874\n",
      "  1.14775197 -0.12137255  0.87168715]  energy_before :  40  energy_after :  50  reward :  -204.2270418566719\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "action : 1  next_temperatures :  [-0.49598942 -0.76139445 -0.43376883 -0.61931213 -0.2829482  -1.30358207\n",
      " -0.12499052 -1.09114811 -0.10956787]  energy_before :  50  energy_after :  390  reward :  -543.2227016013113\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "action : 1  next_temperatures :  [ 1.50273419 -0.06527428  1.03003421  0.09982193  1.75587446 -0.11752981\n",
      "  1.58831668 -0.15285378  1.46260869]  energy_before :  390  energy_after :  20  reward :  179.10373229574753\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "action : 1  next_temperatures :  [-0.24692729 -0.9616023  -0.53561182 -0.49645324 -0.48732896 -1.23291056\n",
      " -0.03198241 -1.22705489 -0.59206344]  energy_before :  20  energy_after :  100  reward :  -283.81193491379224\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n",
      "action : 1  next_temperatures :  [ 0.4172384  -0.26631982 -0.25136347  0.28738651  0.06100966 -0.10523912\n",
      " -0.22778895  0.20111814  0.16149705]  energy_before :  100  energy_after :  40  reward :  -137.72246159378486\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "action : 1  next_temperatures :  [ 0.25742353 -1.39720096 -0.29240467 -0.97969822  0.21554145 -0.93486116\n",
      "  0.75124373 -1.40475384  0.37834899]  energy_before :  40  energy_after :  40  reward :  -201.40636115580787\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "action : 1  next_temperatures :  [ 0.37572804  0.36194749 -0.25136347  0.91069063  1.11282282  0.21227056\n",
      "  0.94705027 -0.19047769  0.76326118]  energy_before :  40  energy_after :  90  reward :  -243.75807017083014\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "action : 1  next_temperatures :  [-0.24692729 -1.24892988 -0.20576213 -1.25162591 -0.71995746 -1.20320805\n",
      " -0.58187244 -1.52651053 -0.63465936]  energy_before :  90  energy_after :  40  reward :  -155.61945302626927\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "action : 1  next_temperatures :  [-0.61429393 -0.87196949 -1.16339028 -0.08856171 -1.11376428 -0.80376039\n",
      " -0.61450686 -0.95063431 -0.43484578]  energy_before :  40  energy_after :  60  reward :  -224.6557270481326\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "action : 1  next_temperatures :  [-1.49223795  0.97178562 -0.88978224  0.92870994 -1.23506343  1.46182475\n",
      " -1.45157981  1.23769534 -1.35104523]  energy_before :  60  energy_after :  30  reward :  -169.81969301247813\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "action : 1  next_temperatures :  [-1.2992148   0.19357185 -1.00682568  0.31441547 -1.25001812  0.41404283\n",
      " -0.85926503 -0.24422614 -0.92276265]  energy_before :  30  energy_after :  100  reward :  -272.6602822709457\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "action : 1  next_temperatures :  [-0.3652318  -0.80244125 -0.05071757 -1.25162591 -0.83128681 -0.27116353\n",
      "  0.01696922 -0.87461865 -0.77277339]  energy_before :  100  energy_after :  50  reward :  -153.20288967428974\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "action : 1  next_temperatures :  [1.44046866 1.81952763 0.61962214 2.32930133 1.96025522 1.58473172\n",
      " 1.29460687 1.44270728 1.7878866 ]  energy_before :  50  energy_after :  60  reward :  -193.72089255049642\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "action : 1  next_temperatures :  [ 0.63101673 -0.14988094 -0.20576213  0.77882209  0.50965034  0.08833936\n",
      " -0.48886433  0.46832471  0.3295573 ]  energy_before :  60  energy_after :  360  reward :  -496.0387968725497\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n",
      "action : 1  next_temperatures :  [0.81781333 2.57093532 2.17006773 0.91519546 1.59303451 2.34060958\n",
      " 1.35987572 1.86578434 1.57645596]  energy_before :  360  energy_after :  80  reward :  97.20977195570666\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "action : 1  next_temperatures :  [-0.49598942 -0.6432802  -0.97642479  0.06869768  0.14907616 -0.71977397\n",
      "  0.36452582 -0.88152916  0.16149705]  energy_before :  80  energy_after :  40  reward :  -160.97320081677765\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "action : 1  next_temperatures :  [-0.28428661  0.53786233 -0.00815632  0.35454937 -0.93596964  1.62467648\n",
      " -1.39773301  1.83660661 -0.75470239]  energy_before :  40  energy_after :  40  reward :  -197.02715316641672\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "action : 1  next_temperatures :  [-0.55825495 -0.79657742  0.16056865 -0.80032423 -0.18823517 -1.275928\n",
      " -0.0923561  -0.91377823 -0.10956787]  energy_before :  40  energy_after :  50  reward :  -212.57445333020573\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "action : 1  next_temperatures :  [-0.9256216  -1.47259304 -1.39139699 -0.71759925 -0.03370338 -1.275928\n",
      " -0.61450686 -1.41978147 -0.48363747]  energy_before :  50  energy_after :  60  reward :  -216.33476805058882\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "action : 1  next_temperatures :  [-0.18466176 -1.1735378  -0.43376883 -0.71759925 -0.45409631 -1.34557529\n",
      "  0.01696922 -1.30460623 -0.57399244]  energy_before :  60  energy_after :  20  reward :  -164.170868680153\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "action : 1  next_temperatures :  [ 1.99463191  1.99544247  4.03972271 -0.53822526  2.51073022  0.98775501\n",
      "  2.37154283  1.35287059  2.38965073]  energy_before :  20  energy_after :  70  reward :  -230.89587880277534\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "action : 1  next_temperatures :  [-0.80731709 -0.88704791 -0.83962076 -0.64634109 -0.33991845 -0.96866058\n",
      " -1.07138878 -0.63735764 -1.29683224]  energy_before :  70  energy_after :  60  reward :  -195.49448453799556\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "action : 1  next_temperatures :  [ 0.25742353 -0.79657742  0.3460141  -0.94857397 -0.03370338 -0.90720709\n",
      "  0.29762526 -0.82010236 -0.26678553]  energy_before :  60  energy_after :  120  reward :  -260.871886862618\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "action : 1  next_temperatures :  [ 0.9423444   0.0829968   0.3460141   0.44359282  1.21252075  0.02586165\n",
      "  1.14775197 -0.14440759  0.82521888]  energy_before :  120  energy_after :  40  reward :  -113.1181062298183\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "action : 1  next_temperatures :  [-0.30296627 -0.3165812  -0.79401942  0.5331043  -0.23808413 -0.62759374\n",
      " -0.41870032 -0.19047769 -0.14570986]  energy_before :  40  energy_after :  100  reward :  -260.50102834364935\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n",
      "action : 1  next_temperatures :  [ 0.195158    0.47671098  0.43265665  0.27182438  0.69741478 -0.1871771\n",
      "  0.41347746  0.33011441  0.64941392]  energy_before :  100  energy_after :  30  reward :  -124.72040652752983\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "action : 1  next_temperatures :  [ 0.12666591 -1.03866975 -0.70737688 -0.28349782  0.31025448 -0.90720709\n",
      "  0.49016835 -1.28080334  0.49219626]  energy_before :  30  energy_after :  70  reward :  -240.79826988117836\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "action : 1  next_temperatures :  [ 1.06064891 -1.62589026  0.66066335 -1.66770803  0.41493731 -1.14994836\n",
      "  1.0498487  -1.38830024  0.81747417]  energy_before :  70  energy_after :  50  reward :  -179.8282744438643\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n",
      "action : 1  next_temperatures :  [-1.42997242 -0.67092396 -1.23483239 -0.29250747 -0.88113578 -0.61969258\n",
      " -1.50053144 -0.33099149 -1.37273042]  energy_before :  50  energy_after :  40  reward :  -196.33331794087854\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "action : 1  next_temperatures :  [-0.3652318  -0.39017823 -0.02335676 -0.66845569 -0.7294525  -0.29925655\n",
      " -0.85926503 -0.56652487 -0.86312836]  energy_before :  40  energy_after :  100  reward :  -262.7648497871783\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "action : 1  next_temperatures :  [-0.61429393 -1.62589026 -1.02202613 -1.09846182  0.11584352 -1.24212859\n",
      " -0.41870032 -1.55184908 -0.3806328 ]  energy_before :  100  energy_after :  70  reward :  -175.83813941173585\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "action : 1  next_temperatures :  [ 0.39648322  1.19126033  0.39161544  1.00242527 -0.23808413  1.5509323\n",
      "  0.80509053  1.51181242 -0.49448007]  energy_before :  70  energy_after :  60  reward :  -181.88294468160046\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "action : 1  next_temperatures :  [ 0.0083614  -0.44223466 -0.38360736  0.09982193 -0.01874869 -0.5886732\n",
      " -0.22778895 -0.25958284 -0.04993359]  energy_before :  60  energy_after :  60  reward :  -199.86238595130476\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "action : 1  next_temperatures :  [ 0.37572804  1.09660139  0.11800739  1.01880646  0.36508834 -0.11650559\n",
      " -0.22778895  1.14555515  0.6909772 ]  energy_before :  60  energy_after :  60  reward :  -193.53353056434304\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "action : 1  next_temperatures :  [-0.40674216 -0.19092774 -0.02335676 -0.13688621 -0.26799351 -0.53541351\n",
      " -0.17394215 -0.04612472  0.99405361]  energy_before :  60  energy_after :  50  reward :  -188.7873331527911\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "action : 1  next_temperatures :  [-0.7616557  -0.02338979 -0.25136347 -1.33189372 -1.18521446 -0.88467415\n",
      "  0.01696922 -1.15794975 -0.92276265]  energy_before :  50  energy_after :  150  reward :  -304.5019344594958\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "action : 1  next_temperatures :  [-0.49598942  0.25891165 -0.82442032  1.16541807  0.16569248 -0.21892806\n",
      " -0.14130773 -0.01387565  0.7036269 ]  energy_before :  150  energy_after :  120  reward :  -167.4008720767001\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "action : 1  next_temperatures :  [ 0.0083614   0.695348    0.14840829  0.06705956 -0.18325027  1.27170303\n",
      " -1.17092377  1.7352524  -1.0799803 ]  energy_before :  120  energy_after :  60  reward :  -136.50802166907977\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "action : 1  next_temperatures :  [-0.11616967 -0.09040497 -0.29240467  0.11784124 -0.41920204  0.39560679\n",
      " -0.85926503  0.47523522 -0.79385622]  energy_before :  60  energy_after :  120  reward :  -259.5826193567715\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "action : 1  next_temperatures :  [-1.98413566 -0.11804873 -1.47803954 -0.09593324 -1.73355308 -0.01305889\n",
      " -1.74528961 -0.12137255 -1.47922021]  energy_before :  120  energy_after :  30  reward :  -116.76865151104568\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n",
      "action : 1  next_temperatures :  [ 0.29893389  0.04362539  0.39161544 -0.10330477  0.1001767   0.32361842\n",
      " -1.34878137  1.19853576 -1.0799803 ]  energy_before :  30  energy_after :  30  reward :  -198.17556086260277\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "action : 1  next_temperatures :  [ 0.06440038 -0.16831012  0.73666559 -0.30151712  0.47974096 -0.50775944\n",
      "  0.45753393 -0.1290509   0.12535506]  energy_before :  30  energy_after :  40  reward :  -207.24294166271196\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "action : 1  next_temperatures :  [-0.30296627 -0.70191848 -0.47937017 -0.30888866  0.52626666  0.2225128\n",
      " -0.56555523 -1.11187965 -0.48363747]  energy_before :  40  energy_after :  250  reward :  -411.2054364550321\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "action : 1  next_temperatures :  [-1.25770444  1.07314607 -0.58121317  0.80585104 -1.54578864  1.70456601\n",
      " -0.96206346  1.48340253 -1.7901704 ]  energy_before :  250  energy_after :  50  reward :  0.9300255370474986\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n",
      "action : 1  next_temperatures :  [2.12538953 1.96779871 1.44044628 2.05655459 2.05496825 1.83054566\n",
      " 2.21979276 1.46804583 2.38965073]  energy_before :  50  energy_after :  100  reward :  -230.44680766570988\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "action : 1  next_temperatures :  [-0.82807226 -1.14589404 -0.97642479 -0.71022771 -1.08053164 -0.50775944\n",
      " -1.29982974 -0.86079762 -0.59206344]  energy_before :  100  energy_after :  50  reward :  -156.00160067842694\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "action : 1  next_temperatures :  [-0.30296627 -0.21605843 -0.83962076  0.77882209  0.01116069 -0.2701393\n",
      " -0.12499052 -0.12137255  0.16149705]  energy_before :  50  energy_after :  50  reward :  -198.92366799968534\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "action : 1  next_temperatures :  [ 0.68705571 -0.81919504 -0.15560065 -0.11968596  0.06100966 -0.84268094\n",
      " -0.36974869 -0.48993333  0.60062223]  energy_before :  50  energy_after :  40  reward :  -189.448157011344\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "action : 1  next_temperatures :  [ 1.03989373 -1.32180888  0.75642617 -1.57129305  0.82441095 -1.89616925\n",
      "  1.29460687 -1.26275922  1.95594685]  energy_before :  40  energy_after :  50  reward :  -208.1807458288556\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "action : 1  next_temperatures :  [-1.11864475 -0.69354158 -0.88978224 -0.98788881 -0.93596964 -1.06084081\n",
      " -0.78094242 -1.32840911 -1.0799803 ]  energy_before :  50  energy_after :  40  reward :  -196.87599966253595\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "action : 1  next_temperatures :  [ 0.195158   -0.50254832 -0.41704834  0.22268083  0.31025448 -0.32032631\n",
      " -0.22778895  0.10897794  0.22113133]  energy_before :  40  energy_after :  70  reward :  -228.40950934233734\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "action : 1  next_temperatures :  [0.99838337 0.23629403 0.23201075 0.8191198  1.16267178 0.06887909\n",
      " 1.09880034 0.23797422 0.81747417]  energy_before :  70  energy_after :  30  reward :  -152.3283924542105\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "action : 1  next_temperatures :  [0.43799358 1.33282989 0.9342714  0.625658   1.36206764 0.67317169\n",
      " 0.36452582 1.05111145 0.60062223]  energy_before :  30  energy_after :  40  reward :  -200.61774830783523\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "action : 1  next_temperatures :  [ 0.50648566  0.01849469  1.11667676 -0.62832178  0.41493731 -0.25887283\n",
      "  0.60928399  0.16195856  0.72748061]  energy_before :  40  energy_after :  60  reward :  -215.33187702122044\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "action : 1  next_temperatures :  [ 0.74932124 -0.89458712  0.61962214 -1.01491777  0.31025448 -0.47396003\n",
      " -0.03198241 -0.10755152  0.3295573 ]  energy_before :  60  energy_after :  50  reward :  -188.51424367077513\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "action : 1  next_temperatures :  [-0.18466176 -0.36935565 -0.61161406  0.39550234 -0.08355234 -0.59148982\n",
      " -0.32079706 -0.21581625 -0.10956787]  energy_before :  50  energy_after :  410  reward :  -560.0913524639351\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n",
      "action : 1  next_temperatures :  [-0.69212585 -0.81919504 -1.13298939 -0.12787655 -1.08053164 -0.59993967\n",
      "  0.2470419  -0.70492712 -0.77277339]  energy_before :  410  energy_after :  60  reward :  146.316683249721\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "action : 1  next_temperatures :  [ 0.08515556  1.07314607  0.33081365  0.8549946  -0.08355234  1.67315645\n",
      " -0.17394215  1.57477489 -0.33093756]  energy_before :  60  energy_after :  70  reward :  -202.99639082956398\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "action : 1  next_temperatures :  [ 0.31968906 -1.23971529 -0.61161406 -0.47188146  0.55949931 -1.3957623\n",
      "  0.50648556 -1.59791918  0.76326118]  energy_before :  70  energy_after :  50  reward :  -181.16795717194853\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "action : 1  next_temperatures :  [-1.05015267 -1.37458334 -1.6467645  -0.41700448 -1.03068267 -0.96866058\n",
      " -0.8103134  -1.38138972 -0.70591071]  energy_before :  50  energy_after :  30  reward :  -187.38546206546872\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "action : 1  next_temperatures :  [-0.05390414 -0.79657742 -0.47937017 -0.32690796 -0.33279717 -0.74512353\n",
      " -0.24177513 -0.68408588 -0.19166182]  energy_before :  30  energy_after :  90  reward :  -261.8522032181934\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "action : 1  next_temperatures :  [ 0.63101673  2.34727216  0.39161544  2.15566076  1.25738481  0.54002247\n",
      "  0.46977184 -0.19047769  0.76326118]  energy_before :  90  energy_after :  500  reward :  -599.6344722908202\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "action : 1  next_temperatures :  [ 0.12666591  0.43608303 -0.46416972  1.42014551  0.66418213 -0.25887283\n",
      "  0.07081602  0.50057378  0.63315002]  energy_before :  500  energy_after :  50  reward :  255.12857384552495\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "action : 1  next_temperatures :  [ 0.5687512   0.3937797   0.02224458  0.77882209  1.53155412  0.41404283\n",
      "  1.06208661 -0.01195606  0.87168715]  energy_before :  50  energy_after :  70  reward :  -212.36898778931126\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "action : 1  next_temperatures :  [-1.61054246 -0.6432802  -1.50844043 -0.10330477 -1.03068267 -0.50775944\n",
      " -1.59353955 -0.43772055 -0.80891538]  energy_before :  70  energy_after :  180  reward :  -316.2441854575869\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "action : 1  next_temperatures :  [-0.9256216   0.77074008 -0.52041138  0.73152141 -0.93596964  1.68612997\n",
      " -1.59353955  1.90340826 -0.99595018]  energy_before :  180  energy_after :  270  reward :  -287.8796926263785\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "action : 1  next_temperatures :  [ 1.68330424  0.38456511  3.85731735 -1.71685158  1.99614647 -0.25887283\n",
      "  1.81675764  0.09285341  2.05895152]  energy_before :  270  energy_after :  80  reward :  1.9141713276464998\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "action : 1  next_temperatures :  [ 0.21591317 -0.53605591 -0.25136347  0.00317293 -0.29956452 -0.7627914\n",
      "  0.18130685 -0.20857666  0.27534432]  energy_before :  80  energy_after :  40  reward :  -159.38261468609227\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "action : 1  next_temperatures :  [-0.9256216  -0.49500911 -0.94906398 -0.17702011 -0.63189095  0.29420854\n",
      " -1.05507157  0.01453424 -0.48363747]  energy_before :  40  energy_after :  50  reward :  -212.40857202099528\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n",
      "action : 1  next_temperatures :  [-0.3652318   1.28256851  0.00704413  1.00897775 -0.53219302  1.7783102\n",
      " -0.6634585   2.0516004  -0.06981168]  energy_before :  50  energy_after :  250  reward :  -393.5021940200742\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "action : 1  next_temperatures :  [0.37572804 0.89806892 0.69106424 0.32915853 1.46176557 0.68341394\n",
      " 0.44494636 0.23007649 0.64941392]  energy_before :  250  energy_after :  50  reward :  7.763636016940126\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "action : 1  next_temperatures :  [-0.3652318  -0.77814824 -0.97642479 -0.03204662 -0.43747999 -0.81502687\n",
      " -0.52149876 -0.95063431 -0.70591071]  energy_before :  50  energy_after :  80  reward :  -233.58240207747636\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "action : 1  next_temperatures :  [ 2.16689988 -0.62820178  2.9407304  -2.14276242  1.96025522 -0.3817798\n",
      "  2.07783302 -0.52909291  2.1547278 ]  energy_before :  80  energy_after :  30  reward :  -140.38139059788466\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "action : 1  next_temperatures :  [ 0.31968906 -0.19930464  0.70626469 -0.94857397  0.06100966 -0.74230691\n",
      "  0.60928399 -0.53008013  0.3458212 ]  energy_before :  30  energy_after :  50  reward :  -218.37819703424069\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "action : 1  next_temperatures :  [ 1.72896563 -0.30150278  1.06043511 -0.17702011  1.71101039 -0.13903853\n",
      "  1.63726831 -0.37475808  1.49875068]  energy_before :  50  energy_after :  60  reward :  -201.35588938913125\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "action : 1  next_temperatures :  [-0.22617211  1.24738554  0.17728914  0.87137579 -0.63189095  2.34060958\n",
      " -1.29982974  1.72834188 -0.8480692 ]  energy_before :  60  energy_after :  70  reward :  -204.64096007809124\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "action : 1  next_temperatures :  [1.56499973 0.00760473 0.70626469 0.32915853 1.5564786  0.05863684\n",
      " 1.63726831 0.2771338  1.07304967]  energy_before :  70  energy_after :  50  reward :  -170.7894050904486\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "action : 1  next_temperatures :  [-1.54827693  1.71649179 -0.83962076  1.61671974 -1.23506343  1.85819973\n",
      " -1.34878137  2.11993772 -1.19382757]  energy_before :  50  energy_after :  100  reward :  -246.85422109437206\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n",
      "action : 1  next_temperatures :  [ 1.68330424  0.99607862  2.28276819 -0.72637488  2.07490784 -0.1789833\n",
      "  1.88202648  0.36850616  1.35960402]  energy_before :  100  energy_after :  60  reward :  -148.2581626291142\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "action : 1  next_temperatures :  [ 0.12666591 -1.39720096 -0.29240467 -1.04604202 -0.26799351 -1.38859273\n",
      "  0.07081602 -1.4973328  -0.32099851]  energy_before :  60  energy_after :  100  reward :  -244.0130832805015\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "action : 1  next_temperatures :  [ 0.0083614  -0.9448485  -0.18904163 -0.52348219  0.21554145 -1.54939601\n",
      "  0.41347746 -1.06580955  0.49219626]  energy_before :  100  energy_after :  50  reward :  -151.14300132961162\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "action : 1  next_temperatures :  [ 0.12666591  0.18603264  0.07240605  0.41925506  0.36508834 -0.22814609\n",
      "  0.36452582  0.36005998  0.49219626]  energy_before :  50  energy_after :  80  reward :  -225.84191602186527\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "action : 1  next_temperatures :  [ 0.74932124 -0.91301629 -0.02335676 -0.69548464  0.66418213 -1.70302972\n",
      "  0.68970454 -1.64398928  0.97469182]  energy_before :  80  energy_after :  60  reward :  -179.9009769670529\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "action : 1  next_temperatures :  [ 0.33369881 -0.34862283 -0.33800601  0.20629964  1.27400114 -0.61837572\n",
      "  0.65823563 -0.83545906  0.63315002]  energy_before :  60  energy_after :  40  reward :  -177.03507839258532\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "action : 1  next_temperatures :  [-0.03314896  0.34351831  0.25025128 -0.03941815  0.16569248  1.20474434\n",
      " -0.96206346  0.45450368 -0.21257254]  energy_before :  40  energy_after :  50  reward :  -206.82849302243278\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "action : 1  next_temperatures :  [ 1.27874     0.26060879  1.02929393  0.36675016  1.34963777 -0.07989953\n",
      "  1.30941951  0.1876561   0.92892762]  energy_before :  50  energy_after :  50  reward :  -191.36886565190758\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "action : 1  next_temperatures :  [ 1.12914099 -1.64850788  0.81722795 -1.85691072  0.41493731 -1.19194157\n",
      "  1.09880034 -1.41978147  0.81747417]  energy_before :  50  energy_after :  60  reward :  -209.8395608876201\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "action : 1  next_temperatures :  [ 0.5687512  -0.43469545  0.61962214 -0.4407572   0.35137988 -0.25887283\n",
      " -0.12499052  0.2771338   0.3295573 ]  energy_before :  60  energy_after :  50  reward :  -187.1128716807289\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "action : 1  next_temperatures :  [ 0.99838337 -0.52684132  2.88448874 -2.42943317  0.77551149 -0.74230691\n",
      "  1.63726831 -0.76635392  0.16149705]  energy_before :  50  energy_after :  80  reward :  -226.0077863523821\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "action : 1  next_temperatures :  [ 0.81781333 -0.41961704 -0.30760512  0.40287387  0.55949931 -0.53541351\n",
      " -0.07603889  0.39230905  0.05849238]  energy_before :  80  energy_after :  60  reward :  -177.1076866233422\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "action : 1  next_temperatures :  [1.50273419 1.90162122 0.66066335 2.54799016 1.5564786  1.09003116\n",
      " 1.24076008 1.53715098 1.7878866 ]  energy_before :  60  energy_after :  40  reward :  -164.1746836506581\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "action : 1  next_temperatures :  [-0.738825   -0.82757194 -0.29240467 -0.94120243 -1.32977646  0.28294206\n",
      " -1.88724935 -0.23654779 -1.02576732]  energy_before :  40  energy_after :  60  reward :  -224.99640290461502\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "action : 1  next_temperatures :  [-0.55825495 -1.32180888  0.30041276 -1.81595776 -0.43747999 -1.33430881\n",
      "  0.01696922 -1.05045285 -0.48363747]  energy_before :  60  energy_after :  110  reward :  -254.68451874643694\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "action : 1  next_temperatures :  [-1.2992148   0.21954023 -1.19417119  0.43727436 -1.03068267  0.40482481\n",
      " -1.15297484  0.27022329 -0.92276265]  energy_before :  110  energy_after :  310  reward :  -402.26794346018943\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "action : 1  next_temperatures :  [-0.45032803 -1.02945517 -0.29240467 -1.22541601 -0.48732896 -0.89594062\n",
      " -0.17394215 -1.31305241 -0.86312836]  energy_before :  310  energy_after :  60  reward :  45.26900361749841\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "action : 1  next_temperatures :  [0.14949661 1.06560687 0.11800739 1.30465815 0.36508834 0.75510967\n",
      " 0.11976765 1.14555515 0.10728407]  energy_before :  60  energy_after :  60  reward :  -192.86942610156916\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "action : 1  next_temperatures :  [-1.23694927  1.46518487 -0.70737688  1.33742053 -1.18521446  1.83054566\n",
      " -1.15297484  1.95178186 -1.13419329]  energy_before :  60  energy_after :  50  reward :  -186.83177582068566\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "action : 1  next_temperatures :  [-0.86958262  0.83691757 -0.38360736  0.65596319 -1.03068267  1.5509323\n",
      " -1.29982974  1.37590564 -0.75470239]  energy_before :  50  energy_after :  50  reward :  -197.91868608706062\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "action : 1  next_temperatures :  [ 1.12914099 -1.53374439  1.04306317 -1.9823438   1.00813999 -1.48794253\n",
      "  1.22444286 -1.28080334  1.68488193]  energy_before :  50  energy_after :  60  reward :  -208.1951651176785\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "action : 1  next_temperatures :  [ 2.37445166 -0.83594884  2.53031833 -2.28445968  1.50662964 -0.96866058\n",
      "  1.78412322 -0.82778071  1.46260869]  energy_before :  60  energy_after :  130  reward :  -263.2587182761331\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n",
      "action : 1  next_temperatures :  [-1.88035977 -0.8795087  -1.11778894 -1.12057642 -2.06089461 -0.45552398\n",
      " -1.23945606 -0.8208702  -1.43868955]  energy_before :  130  energy_after :  520  reward :  -599.0136682436703\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n",
      "action : 1  next_temperatures :  [ 1.75179633 -0.29396358  3.12769589 -1.6783558   1.91040625 -0.66139315\n",
      "  1.88202648 -0.29183191  1.84752088]  energy_before :  520  energy_after :  70  reward :  259.5939014018588\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "action : 1  next_temperatures :  [-0.42749733 -0.69354158 -1.16339028  0.03429719 -0.68672482 -0.44630596\n",
      " -0.27674059 -1.20632335 -0.80891538]  energy_before :  70  energy_after :  130  reward :  -263.6751421004035\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "action : 1  next_temperatures :  [ 1.06064891  0.66351579  1.45998971  0.09958791  1.00813999 -0.08475462\n",
      "  1.19180844  0.30093668  0.89259788]  energy_before :  130  energy_after :  30  reward :  -91.40752930318084\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step\n",
      "action : 1  next_temperatures :  [ 0.12666591  0.50267936 -0.35320646  1.4848512   0.61433317 -0.23838833\n",
      "  0.13608486  0.5297515   0.60062223]  energy_before :  30  energy_after :  60  reward :  -224.59660655989347\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "action : 1  next_temperatures :  [ 0.50648566  0.20865027  0.5740208  -0.14589586 -0.38264613  0.93639745\n",
      "  0.19809027  0.65337293 -0.04390992]  energy_before :  60  energy_after :  120  reward :  -255.49543452862522\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "action : 1  next_temperatures :  [ 0.74932124  0.72969328  0.39161544  0.56750479  2.05496825  1.30511836\n",
      "  0.94705027 -0.35172303  1.03432611]  energy_before :  120  energy_after :  50  reward :  -120.57212529079149\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "action : 1  next_temperatures :  [ 0.12666591 -0.9038017   1.33100306 -2.07805673  0.09756556 -0.9778786\n",
      "  0.9960019  -1.0970714   0.3295573 ]  energy_before :  50  energy_after :  80  reward :  -230.17601469811234\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "action : 1  next_temperatures :  [-0.07465931 -0.46736535 -0.33800601  0.04166872 -0.18823517 -0.3817798\n",
      " -0.03198241 -0.37475808  0.0042794 ]  energy_before :  80  energy_after :  60  reward :  -179.81083802764743\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "action : 1  next_temperatures :  [ 0.02704106 -0.5452705  -0.58121317 -0.08856171 -0.58204199 -0.44630596\n",
      " -0.0156652  -1.19787717 -0.56495695]  energy_before :  60  energy_after :  90  reward :  -231.99485157507164\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "action : 1  next_temperatures :  [-0.738825   -1.09563265 -0.75981842 -0.89758753 -1.03068267 -0.41250654\n",
      " -1.25577327 -0.58207352 -1.35104523]  energy_before :  90  energy_after :  110  reward :  -226.1239448336967\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "action : 1  next_temperatures :  [-0.42749733 -0.19092774 -1.02202613  0.87956638  0.06100966 -0.10523912\n",
      " -0.22778895 -0.14440759  0.07475628]  energy_before :  110  energy_after :  60  reward :  -149.10255455149587\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "action : 1  next_temperatures :  [ 0.37572804  1.01283241  0.49079836  0.69404945 -0.16691089  1.52327823\n",
      "  0.16871929  1.61316664 -0.26678553]  energy_before :  60  energy_after :  100  reward :  -232.55512399808362\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "action : 1  next_temperatures :  [ 0.88007886 -1.32180888  1.39028481 -2.10426663  0.36508834 -1.21447452\n",
      "  1.0498487  -1.34223014  0.68555591]  energy_before :  100  energy_after :  70  reward :  -169.61192355489658\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "action : 1  next_temperatures :  [-1.05015267  1.88654281 -0.33800601  1.19654233 -1.08053164  1.89199914\n",
      " -2.13200752  2.14009338 -0.20534415]  energy_before :  70  energy_after :  70  reward :  -195.69086432816778\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "action : 1  next_temperatures :  [-0.78448639  0.72047869 -0.23616302  0.19892811 -0.68672482  0.78276374\n",
      " -0.82663061  0.96127475 -0.23064354]  energy_before :  70  energy_after :  60  reward :  -188.10120308215653\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "action : 1  next_temperatures :  [ 0.81781333 -0.80411663  0.9038705  -1.26063556  0.42739955 -0.86572599\n",
      "  0.9960019  -1.12201507  0.64941392]  energy_before :  60  energy_after :  340  reward :  -478.25799404709903\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "action : 1  next_temperatures :  [ 0.50648566 -0.17417394  0.49497848 -0.0967523   0.36508834 -0.10523912\n",
      " -0.22778895  0.55432222  0.37834899]  energy_before :  340  energy_after :  130  reward :  13.695269387096346\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "action : 1  next_temperatures :  [-0.3652318   1.09073756 -0.29240467 -0.50628195 -0.75152847 -0.50468677\n",
      " -0.88374085  0.0398728  -1.13419329]  energy_before :  130  energy_after :  130  reward :  -201.3074574434586\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "action : 1  next_temperatures :  [0.74932124 2.23585943 0.36881477 1.90912391 1.49167495 0.50929573\n",
      " 0.65823563 0.6056136  0.49219626]  energy_before :  130  energy_after :  60  reward :  -118.97986448014237\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "action : 1  next_temperatures :  [-0.18466176 -1.19615542 -1.23483239  0.02692565 -0.29956452 -1.24212859\n",
      " -0.27674059 -1.21323386  0.0042794 ]  energy_before :  60  energy_after :  70  reward :  -213.61611207409376\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "action : 1  next_temperatures :  [-1.18091029 -0.49500911 -0.64505504 -0.46450992 -1.32977646  0.02586165\n",
      " -0.85926503 -0.62046527 -0.79084438]  energy_before :  70  energy_after :  90  reward :  -224.35997386556468\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "action : 1  next_temperatures :  [0.5687512  1.38979279 0.6044217  1.17442773 0.50965034 1.9729129\n",
      " 0.13608486 2.24893399 0.27534432]  energy_before :  90  energy_after :  50  reward :  -149.11968017641755\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "action : 1  next_temperatures :  [ 1.48197902  0.25304782  1.28844181  0.08507886  1.46176557 -0.04685831\n",
      "  1.34355851  0.48368141  2.00473854]  energy_before :  50  energy_after :  80  reward :  -219.6445667728766\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "action : 1  next_temperatures :  [-0.3652318  -0.26631982 -0.38360736  0.09081228 -0.18823517 -0.53541351\n",
      " -0.07603889 -0.63044713 -0.16378086]  energy_before :  80  energy_after :  80  reward :  -200.51826224151208\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "action : 1  next_temperatures :  [-0.3652318  -1.5731158  -0.35320646 -1.56286844 -1.03068267 -1.06084081\n",
      " -0.61450686 -1.32149859 -0.97697563]  energy_before :  80  energy_after :  50  reward :  -176.8589270726593\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "action : 1  next_temperatures :  [-0.18466176 -0.76893366 -0.88978224  0.04166872  0.01116069 -0.53541351\n",
      " -0.07603889 -0.65117867 -0.26678553]  energy_before :  50  energy_after :  30  reward :  -181.3199648346446\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "action : 1  next_temperatures :  [-0.67655947  0.36027211 -0.35320646 -0.23517332 -0.38264613  0.37614652\n",
      " -0.8103134  -0.02923235 -0.64838471]  energy_before :  30  energy_after :  30  reward :  -200.39909721134157\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "action : 1  next_temperatures :  [-0.30296627  0.20865027  0.02224458 -0.00501766 -0.48732896  0.99068136\n",
      " -0.56555523  0.63648056 -0.42882212]  energy_before :  30  energy_after :  50  reward :  -217.93163345617896\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "action : 1  next_temperatures :  [ 1.99463191  1.89240664  2.84105889 -0.00887894  3.25134341  0.97941489\n",
      "  1.78412322  1.33597822  1.68488193]  energy_before :  50  energy_after :  100  reward :  -232.24503984350994\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "action : 1  next_temperatures :  [ 1.56499973  0.3527329   2.31664347 -1.06406133  1.9901646  -0.59993967\n",
      "  1.78412322  0.18422577  1.22768575]  energy_before :  100  energy_after :  230  reward :  -320.24342555928797\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "action : 1  next_temperatures :  [ 0.06440038  0.44404108 -0.29240467  1.16377995  0.96327592  0.21227056\n",
      "  0.36452582  0.27022329  0.64941392]  energy_before :  230  energy_after :  90  reward :  -54.16047375871693\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "action : 1  next_temperatures :  [ 0.64969639  4.31332997  0.84648882  0.31871553  0.10213505  1.26978261\n",
      " -0.76625693  0.36005998 -0.06649867]  energy_before :  90  energy_after :  70  reward :  -170.97254725172166\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "action : 1  next_temperatures :  [-0.61429393 -0.6432802  -0.74841808 -0.32690796 -0.76648316  0.03712812\n",
      " -0.17394215 -0.58207352 -0.69042128]  energy_before :  70  energy_after :  60  reward :  -192.50869217175438\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "action : 1  next_temperatures :  [-1.49223795 -0.81165583 -1.47803954 -0.17702011 -1.23506343 -0.08475462\n",
      " -1.0110151  -0.58207352 -1.19382757]  energy_before :  60  energy_after :  50  reward :  -196.06568767807363\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "action : 1  next_temperatures :  [0.43799358 0.87963974 0.73970568 0.54948548 0.21554145 0.66292944\n",
      " 0.21277576 1.313711   0.05849238]  energy_before :  50  energy_after :  50  reward :  -192.92972548785133\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "action : 1  next_temperatures :  [ 0.43799358  1.18288343  0.52841946  1.02453987 -0.13340131  1.59497397\n",
      "  0.50648556  1.55788252 -0.48363747]  energy_before :  50  energy_after :  360  reward :  -501.78386038335645\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "action : 1  next_temperatures :  [-1.42997242 -0.8795087  -1.57380235 -0.15490551 -1.23506343 -0.78122745\n",
      " -0.74504455 -0.66807104 -1.19382757]  energy_before :  360  energy_after :  50  reward :  103.33857697260254\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "action : 1  next_temperatures :  [ 2.10463435 -0.08202807  3.5837093  -2.09607604  1.91040625 -0.20839318\n",
      "  2.07783302 -0.25958284  1.90173387]  energy_before :  50  energy_after :  10  reward :  -149.0677633402884\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "action : 1  next_temperatures :  [-0.11616967 -0.71867227 -0.79401942  0.00317293 -0.03370338 -0.56614025\n",
      " -0.03198241 -0.63044713 -0.26678553]  energy_before :  10  energy_after :  50  reward :  -241.15474713096427\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "action : 1  next_temperatures :  [0.85932368 1.69387417 1.09322464 1.25726972 1.12943914 0.75510967\n",
      " 1.46920104 1.38972666 1.24575675]  energy_before :  50  energy_after :  50  reward :  -187.1070745248096\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "action : 1  next_temperatures :  [-0.738825    0.58561065 -0.20576213  0.29803428 -0.88113578  1.35837805\n",
      " -0.11356847  0.93056136 -1.13419329]  energy_before :  50  energy_after :  70  reward :  -217.9009003330988\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "action : 1  next_temperatures :  [0.9423444  0.59650061 1.27324136 0.14241301 0.66418213 0.07912134\n",
      " 1.14775197 0.48444924 0.85000196]  energy_before :  70  energy_after :  70  reward :  -191.81999397224283\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "action : 1  next_temperatures :  [-2.48225993  0.68864648 -1.52364088  0.52573276 -1.93294894  1.36964452\n",
      " -2.52851576  1.69839632 -2.27808727]  energy_before :  70  energy_after :  60  reward :  -194.46303268366265\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "action : 1  next_temperatures :  [1.44046866 1.16612963 0.9342714  1.2127597  2.1762674  0.3218626\n",
      " 1.78412322 0.73092426 1.51682167]  energy_before :  60  energy_after :  40  reward :  -166.71637145106388\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "action : 1  next_temperatures :  [2.12538953 0.78916925 1.53164896 0.90168098 2.22231835 0.25645854\n",
      " 2.32259119 0.75165581 2.1366568 ]  energy_before :  40  energy_after :  360  reward :  -504.96243059199793\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "action : 1  next_temperatures :  [ 0.79498263 -0.08286576  0.39161544 -0.4227379   0.26040552 -0.68904722\n",
      "  0.88900762 -0.49717292  0.76326118]  energy_before :  360  energy_after :  90  reward :  73.40744859097524\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "action : 1  next_temperatures :  [-0.18466176 -0.70359386 -0.46416972 -0.22616367 -0.23808413 -0.50775944\n",
      " -0.10867331 -0.43618488 -0.0137916 ]  energy_before :  90  energy_after :  360  reward :  -470.8830823690661\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "action : 1  next_temperatures :  [-0.18466176  0.47838636  0.10280695  0.22268083 -0.68672482  1.67691195\n",
      " -1.15297484  0.96127475 -0.7167533 ]  energy_before :  360  energy_after :  60  reward :  102.70094611948298\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "action : 1  next_temperatures :  [ 0.90083404 -0.20768153  0.8324284  -0.32690796 -0.53219302  1.30819104\n",
      " -1.20682164  0.9359362  -0.65169772]  energy_before :  60  energy_after :  70  reward :  -206.94791220027614\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n",
      "action : 1  next_temperatures :  [ 0.31079399 -0.7886792   0.20464994 -0.72813001 -0.48732896 -0.57459011\n",
      " -0.27674059 -1.00394399  0.27534432]  energy_before :  70  energy_after :  40  reward :  -171.0686246006801\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "action : 1  next_temperatures :  [-1.13939993  1.2993223  -0.53561182  1.02453987 -0.93596964  1.46182475\n",
      " -0.99469789  1.63543385 -1.13419329]  energy_before :  40  energy_after :  60  reward :  -217.3187517927493\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "action : 1  next_temperatures :  [ 0.31968906  1.08822449  0.66066335  0.68299215 -0.13340131  1.56783201\n",
      " -0.36974869  1.9725134  -0.48363747]  energy_before :  60  energy_after :  60  reward :  -192.69487300147335\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "action : 1  next_temperatures :  [-1.74130008  1.66874348 -0.97642479  1.54300441 -1.36300911  1.79674624\n",
      " -1.41568194  2.01167299 -1.24804056]  energy_before :  60  energy_after :  60  reward :  -197.72428936440605\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "action : 1  next_temperatures :  [ 0.25742353 -0.50254832  0.43265665 -1.00590812  0.06100966  0.21124633\n",
      "  0.36452582 -0.100641   -0.80891538]  energy_before :  60  energy_after :  80  reward :  -219.09115083026506\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "action : 1  next_temperatures :  [-0.55825495  0.71126411 -0.29240467  0.69036368 -0.93596964  1.58473172\n",
      " -1.25577327  1.35287059 -0.53785045]  energy_before :  80  energy_after :  80  reward :  -197.24102289815693\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "action : 1  next_temperatures :  [-0.18466176 -1.12327642 -0.47937017 -0.65371262  0.27702184 -1.48794253\n",
      "  0.26172739 -0.94372379 -0.59206344]  energy_before :  80  energy_after :  70  reward :  -192.92600149090953\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "action : 1  next_temperatures :  [1.99463191 1.76675318 1.09205204 2.23101422 2.03835193 1.19347786\n",
      " 1.97503459 1.19162524 2.38965073]  energy_before :  70  energy_after :  60  reward :  -172.12740831005132\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "action : 1  next_temperatures :  [-0.42749733  0.81429994 -0.33800601  0.97785349 -0.18823517  0.90874338\n",
      " -0.47254712  1.28146193 -0.80891538]  energy_before :  60  energy_after :  100  reward :  -236.2528422586895\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "action : 1  next_temperatures :  [-0.18466176 -0.26631982 -0.32280557 -0.26875475 -0.53219302 -0.3817798\n",
      "  0.31557419 -0.67651722 -0.16378086]  energy_before :  100  energy_after :  130  reward :  -230.48123860742336\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n",
      "action : 1  next_temperatures :  [ 0.81781333 -1.31426968  0.43265665 -1.7004704   0.7140311  -1.82900937\n",
      "  0.80509053 -1.45740538  0.76326118]  energy_before :  130  energy_after :  60  reward :  -130.76830203902287\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "action : 1  next_temperatures :  [-0.4788664   1.05869593 -0.61161406  0.93444335 -0.25303882 -0.9778786\n",
      "  0.11976765 -0.24576181  0.10728407]  energy_before :  60  energy_after :  40  reward :  -178.3469686968073\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "action : 1  next_temperatures :  [-0.24692729  1.41743656  0.07240605  1.15640842 -0.05862786  1.64447816\n",
      " -0.43664926  1.72143137 -0.48363747]  energy_before :  40  energy_after :  60  reward :  -213.21368131272504\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "action : 1  next_temperatures :  [ 1.37197657  0.12571898  1.6383561  -0.76919998  1.11282282 -0.35412573\n",
      "  1.39251014 -0.19047769  0.54640924]  energy_before :  60  energy_after :  90  reward :  -223.12600954684277\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "action : 1  next_temperatures :  [-1.92187013  0.78916925 -1.20443149  0.90168098 -1.41618134  1.07159512\n",
      " -1.69633798  1.05111145 -1.46157948]  energy_before :  90  energy_after :  110  reward :  -221.88684361751282\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "action : 1  next_temperatures :  [-0.49598942  1.13094667 -0.06439797  0.58224786  0.09590393  1.9729129\n",
      "  0.07081602  0.86683105 -0.3806328 ]  energy_before :  110  energy_after :  130  reward :  -214.22136176570942\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "action : 1  next_temperatures :  [2.18765506 0.76152549 1.61829151 0.77145055 2.22744567 0.23275505\n",
      " 2.37154283 0.67717582 2.11858581]  energy_before :  130  energy_after :  50  reward :  -105.03357221752256\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "action : 1  next_temperatures :  [ 0.1723273   0.62833282 -0.03551712  1.16459901  0.80874413 -0.01305889\n",
      "  0.36452582  0.305434    0.64941392]  energy_before :  50  energy_after :  110  reward :  -253.95519899765821\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "action : 1  next_temperatures :  [-0.11616967 -0.84432573 -0.56601272 -0.16227704  0.13245984 -1.06084081\n",
      "  0.54494756 -1.15202645  0.22113133]  energy_before :  110  energy_after :  40  reward :  -131.00311368508295\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "action : 1  next_temperatures :  [ 0.31968906 -0.40118786 -0.66177553  0.41925506  0.11584352 -0.41250654\n",
      "  0.50648556 -0.60510857  0.54640924]  energy_before :  40  energy_after :  50  reward :  -208.17289606785695\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "action : 1  next_temperatures :  [ 0.31968906  0.44487877  0.39161544  0.35454937  0.52626666 -0.1871771\n",
      "  0.41347746  0.25502015  0.64941392]  energy_before :  50  energy_after :  80  reward :  -224.83226626150898\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "action : 1  next_temperatures :  [-0.3296515  -1.02024058 -0.56601272 -0.70812156 -0.68672482 -0.25887283\n",
      " -0.6634585  -0.79169247 -0.65944243]  energy_before :  80  energy_after :  50  reward :  -173.68421739712923\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "action : 1  next_temperatures :  [ 0.43799358  0.73765133  0.3460141   0.76407902 -0.08355234  0.93639745\n",
      "  0.11976765  1.72143137 -0.30550909]  energy_before :  50  energy_after :  310  reward :  -453.3257269298199\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n",
      "action : 1  next_temperatures :  [2.18765506 2.06245765 1.59093071 1.99856519 2.00511929 1.79674624\n",
      " 2.27363956 1.46804583 2.44386372]  energy_before :  310  energy_after :  130  reward :  -0.17297676448399102\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "action : 1  next_temperatures :  [ 0.195158    0.69618569 -0.25136347  1.22357128  0.46478627  0.11804188\n",
      "  0.07081602 -0.0545709   0.54640924]  energy_before :  130  energy_after :  50  reward :  -114.99096598525287\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "action : 1  next_temperatures :  [-0.05390414  0.93995341 -0.06439797  1.00242527 -0.08355234  1.46182475\n",
      "  0.31557419  1.19162524 -0.55953565]  energy_before :  50  energy_after :  60  reward :  -203.84998723414236\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "action : 1  next_temperatures :  [-0.49598942 -0.58547961 -0.43376883 -0.54723491 -0.43747999 -0.6798292\n",
      " -0.52149876 -0.86079762 -0.75470239]  energy_before :  60  energy_after :  50  reward :  -193.31678072627722\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "action : 1  next_temperatures :  [ 0.63101673  0.16090195  0.72298518 -0.10330477 -0.2829482   0.94766392\n",
      "  0.31557419  0.80002941  0.09373082]  energy_before :  50  energy_after :  220  reward :  -364.71435076642683\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "action : 1  next_temperatures :  [ 0.23666835 -0.09040497  0.80202751 -0.54559679  0.06100966 -0.29267225\n",
      "  0.3318914  -0.10755152  0.39641999]  energy_before :  220  energy_after :  40  reward :  -17.20820862222277\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "action : 1  next_temperatures :  [-0.61429393 -1.18945391 -1.6604449   0.09326946 -0.48732896 -1.31382432\n",
      " -0.61450686 -1.42400456 -0.26678553]  energy_before :  40  energy_after :  100  reward :  -265.47737351218444\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "action : 1  next_temperatures :  [ 0.5687512  -0.85814761  0.17728914 -0.60293094  0.26040552 -0.62759374\n",
      " -0.0156652   0.06905053  0.29341531]  energy_before :  100  energy_after :  650  reward :  -748.7354258086666\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "action : 1  next_temperatures :  [ 0.31968906  0.01598163  0.11800739  0.19892811 -0.11678498 -0.22814609\n",
      " -0.22778895 -0.45307725 -0.04993359]  energy_before :  650  energy_after :  20  reward :  431.5768753276149\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "action : 1  next_temperatures :  [ 0.06440038  0.0829968  -0.50673098  0.91069063  0.31025448  0.14057482\n",
      " -0.22778895 -0.100641    0.22113133]  energy_before :  20  energy_after :  50  reward :  -227.10511247423136\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "action : 1  next_temperatures :  [-0.55825495  0.23629403 -0.26504387  0.321787   -0.70808866 -0.02754435\n",
      " -1.54458791  0.98354197 -1.02576732]  energy_before :  50  energy_after :  100  reward :  -250.58766406991808\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n",
      "action : 1  next_temperatures :  [-0.18466176 -0.15909553 -0.05071757 -0.19503942 -0.58204199 -0.01305889\n",
      " -0.19189109 -0.08374863 -0.70591071]  energy_before :  100  energy_after :  520  reward :  -620.1661655707051\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "action : 1  next_temperatures :  [-2.29546333  0.00760473 -1.57380235  0.09081228 -2.02766197  0.16822889\n",
      " -2.47466896  0.20111814 -2.00702234]  energy_before :  520  energy_after :  60  reward :  252.08914507823567\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "action : 1  next_temperatures :  [-0.38598698 -0.07365118 -0.35320646 -0.15490551  0.39832099 -0.5886732\n",
      "  0.57664957 -0.83776257 -0.92276265]  energy_before :  60  energy_after :  100  reward :  -240.34197798045685\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n",
      "action : 1  next_temperatures :  [-0.26560695 -1.12327642 -0.94906398 -0.40799483 -1.08053164 -0.89594062\n",
      " -0.52149876 -0.92759926 -0.46737357]  energy_before :  100  energy_after :  50  reward :  -154.63888602721568\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "action : 1  next_temperatures :  [-0.48620484 -0.59301881 -0.45331226 -0.65511672 -0.07643106 -0.85584954\n",
      " -0.89423049 -0.81308216 -0.80891538]  energy_before :  50  energy_after :  90  reward :  -243.63616125492211\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "action : 1  next_temperatures :  [-1.13939993 -0.6432802  -1.72124669  0.48641792 -1.047299   -0.60915769\n",
      " -0.85926503 -0.91377823 -0.7221746 ]  energy_before :  90  energy_after :  240  reward :  -355.16918344914836\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "action : 1  next_temperatures :  [-1.42997242 -0.67092396 -1.23483239 -0.0967523  -1.03068267 -1.04957433\n",
      " -1.06730948 -0.75080526 -1.0799803 ]  energy_before :  240  energy_after :  20  reward :  13.589166891790455\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "action : 1  next_temperatures :  [0.195158   0.90560813 0.3460141  0.92707182 0.43155363 0.07912134\n",
      " 0.36452582 0.75165581 0.54640924]  energy_before :  20  energy_after :  590  reward :  -763.4528821159595\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "action : 1  next_temperatures :  [-1.54827693 -1.5002368  -1.4324382  -1.18692022 -1.23506343 -0.87340768\n",
      " -1.20682164 -1.27312499 -1.13419329]  energy_before :  590  energy_after :  90  reward :  290.6095168316443\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "action : 1  next_temperatures :  [ 0.63101673  0.56299302  1.13187721 -0.15490551  0.21554145  0.47549632\n",
      "  0.3318914   0.68485417  0.0042794 ]  energy_before :  90  energy_after :  140  reward :  -244.11695582358794\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "action : 1  next_temperatures :  [-1.05015267 -1.15971592 -1.19075109 -0.79131458 -0.89941373 -1.29538827\n",
      " -0.63082407 -1.38830024 -0.97697563]  energy_before :  140  energy_after :  50  reward :  -117.38283620434922\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "action : 1  next_temperatures :  [-1.18091029 -0.76893366 -0.70737688 -0.85683933 -1.57902129  0.07912134\n",
      " -1.99004778 -0.21581625 -1.29683224]  energy_before :  50  energy_after :  110  reward :  -266.51665636487184\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n",
      "action : 1  next_temperatures :  [-0.49598942 -0.71113307 -0.38360736 -0.7667428  -0.47071263 -0.74230691\n",
      " -0.48886433 -0.88152916 -0.77793653]  energy_before :  110  energy_after :  40  reward :  -133.71882221326166\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n",
      "action : 1  next_temperatures :  [ 0.02704106 -0.24370219  1.66845298 -1.43099989  0.11584352 -0.75357338\n",
      "  1.02830998 -0.56134198  0.29341531]  energy_before :  40  energy_after :  40  reward :  -197.8565545873893\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "action : 1  next_temperatures :  [-0.05390414 -1.04788434 -0.66177553 -0.37359434 -0.08355234 -0.96866058\n",
      " -0.19189109 -0.95063431 -0.59206344]  energy_before :  40  energy_after :  400  reward :  -562.9239601034687\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "action : 1  next_temperatures :  [-0.98788713 -1.31426968 -1.75164758 -0.08119017 -1.01572798 -0.6798292\n",
      " -0.76625693 -1.11187965 -0.86312836]  energy_before :  400  energy_after :  60  reward :  133.42818331104792\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "action : 1  next_temperatures :  [ 0.0083614   1.48361404  0.41897624  0.92870994 -0.08355234  2.04563285\n",
      " -0.22778895  1.69839632  0.23016683]  energy_before :  60  energy_after :  40  reward :  -171.49748366189888\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "action : 1  next_temperatures :  [ 0.37572804  0.25891165 -0.47937017  1.18917079  0.91342696 -0.04685831\n",
      "  0.31557419 -0.16250656  0.63315002]  energy_before :  40  energy_after :  190  reward :  -345.00277338783974\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "action : 1  next_temperatures :  [-1.672808   -0.30150278 -1.4324382   0.19892811 -1.18521446 -0.56614025\n",
      " -1.05833501 -0.29183191 -1.11612229]  energy_before :  190  energy_after :  50  reward :  -65.42546480255004\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "action : 1  next_temperatures :  [ 0.25742353  0.52864774  0.0876065   0.84598495  0.50965034 -0.00384087\n",
      "  0.56033236  0.31629338  0.64941392]  energy_before :  50  energy_after :  60  reward :  -204.24848814235844\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "action : 1  next_temperatures :  [-0.05390414 -0.56788812  1.03003421 -1.15989126 -0.18823517 -0.81502687\n",
      "  0.56033236 -0.79169247 -0.32099851]  energy_before :  60  energy_after :  50  reward :  -190.30726996639166\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "action : 1  next_temperatures :  [-1.80356562  0.83691757 -1.16339028  0.90168098 -1.34639278  1.18221139\n",
      " -1.64249118  1.11407391 -1.40525821]  energy_before :  50  energy_after :  110  reward :  -261.3262142267174\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "action : 1  next_temperatures :  [ 0.12666591 -0.5452705  -0.47937017  0.21367117  1.16267178 -0.59993967\n",
      "  0.54238343 -0.86079762  0.54640924]  energy_before :  110  energy_after :  50  reward :  -137.89357641918056\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "action : 1  next_temperatures :  [-1.58978729  0.45995719 -0.82442032  0.21367117 -1.047299    1.27746429\n",
      " -1.05507157  0.56967892 -0.80891538]  energy_before :  50  energy_after :  90  reward :  -240.80472197224475\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "action : 1  next_temperatures :  [-0.42749733  0.0260339  -0.06439797 -0.28513594 -0.53219302  1.03984415\n",
      " -0.52149876  0.67717582 -0.75470239]  energy_before :  90  energy_after :  50  reward :  -158.84237154398932\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "action : 1  next_temperatures :  [ 1.25367206 -0.17417394  3.21433844 -1.99778892  1.37868396 -0.59993967\n",
      "  1.34355851 -0.33099149  0.87168715]  energy_before :  50  energy_after :  40  reward :  -183.0409539032322\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "action : 1  next_temperatures :  [-0.42749733  0.78916925 -0.47937017  1.00242527 -0.2829482   1.02857768\n",
      "  0.07081602  0.52130532 -0.26678553]  energy_before :  40  energy_after :  60  reward :  -216.04430769234637\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "action : 1  next_temperatures :  [-2.17093226 -0.6432802  -1.61940369 -0.49809135 -1.82826611 -0.31110829\n",
      " -1.88724935 -0.51527188 -1.67632314]  energy_before :  60  energy_after :  40  reward :  -189.14992628040358\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "action : 1  next_temperatures :  [-0.55825495  0.73199693 -0.10999931  0.39550234 -0.23254536  1.28087838\n",
      " -0.45908542  0.71192035 -0.48363747]  energy_before :  40  energy_after :  60  reward :  -216.72322452415142\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "action : 1  next_temperatures :  [-0.05390414  0.99021479  0.30041276  0.77882209 -0.93596964  1.9729129\n",
      "  0.08713323  1.69839632 -0.16378086]  energy_before :  60  energy_after :  60  reward :  -193.32576255385104\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "action : 1  next_temperatures :  [ 0.43799358 -1.15510863  1.66845298 -2.38848021  0.23049614 -1.1806751\n",
      "  0.85404217 -1.25239345  1.30177683]  energy_before :  60  energy_after :  100  reward :  -239.48389568480027\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "action : 1  next_temperatures :  [ 0.12666591 -0.2755344   0.19096954 -0.80769577  0.07928761 -0.86316543\n",
      "  0.85404217 -0.83545906  0.74157599]  energy_before :  100  energy_after :  30  reward :  -128.78931344650275\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "action : 1  next_temperatures :  [-0.86958262 -0.45898845 -1.00682568 -0.03941815 -0.78143785  0.10677541\n",
      " -0.52149876 -0.53600343 -0.86312836]  energy_before :  30  energy_after :  110  reward :  -282.9701078937462\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "action : 1  next_temperatures :  [-0.67655947 -0.72788686 -0.38360736 -0.68647499 -1.23506343 -0.53541351\n",
      " -0.85926503 -0.61432259 -1.13419329]  energy_before :  110  energy_after :  110  reward :  -204.85278652820745\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "action : 1  next_temperatures :  [-0.90694194 -1.74232913 -0.93538358 -1.66934615 -1.2799275  -1.275928\n",
      " -0.96206346 -1.52651053 -0.48363747]  energy_before :  110  energy_after :  60  reward :  -158.7820677623635\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "action : 1  next_temperatures :  [-0.11616967 -0.49500911 -1.16339028  0.60927681  0.06100966 -0.65012668\n",
      "  0.60928399 -0.7735935   0.41449098]  energy_before :  60  energy_after :  60  reward :  -199.50422780758333\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "action : 1  next_temperatures :  [ 0.06440038  0.20865027 -0.70737688  1.46928907  0.91342696  0.0483946\n",
      " -0.07603889  0.40613008  0.54640924]  energy_before :  60  energy_after :  50  reward :  -185.12671517505035\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "action : 1  next_temperatures :  [ 0.1723273  -0.70191848 -0.61161406  0.09081228 -0.08355234 -0.75357338\n",
      " -0.52149876 -0.50260261 -0.04993359]  energy_before :  50  energy_after :  50  reward :  -200.96155363266976\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "action : 1  next_temperatures :  [ 0.43799358  1.22309254  0.64698295  0.7141164   0.11584352  1.83054566\n",
      " -0.30611157  2.02702968 -0.48363747]  energy_before :  50  energy_after :  100  reward :  -241.79414471066175\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "action : 1  next_temperatures :  [ 1.0834796  -0.12391256  0.16360874  0.70510675  0.84530004 -0.50775944\n",
      " -0.19189109 -0.15976429  0.10728407]  energy_before :  100  energy_after :  60  reward :  -156.07854818965401\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "action : 1  next_temperatures :  [-1.672808   -0.07365118 -1.16339028 -0.00501766 -1.62887025  0.16822889\n",
      " -1.29982974 -0.35940138 -1.62211015]  energy_before :  60  energy_after :  50  reward :  -195.65684975498039\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "action : 1  next_temperatures :  [1.93236637 1.79439694 1.30364226 2.01642068 2.10980211 0.78276374\n",
      " 2.07783302 1.63543385 2.27580346]  energy_before :  50  energy_after :  50  reward :  -182.07153756347878\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "action : 1  next_temperatures :  [-0.80731709 -1.04788434 -1.61940369  0.30540581 -0.88113578 -0.62759374\n",
      " -0.48886433 -1.14412872 -0.97697563]  energy_before :  50  energy_after :  50  reward :  -205.28789750643526\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "action : 1  next_temperatures :  [ 1.19140653 -0.59301881  1.92686058 -1.5554969   1.41191661 -0.35412573\n",
      "  1.50346718 -0.28492139  1.12571371]  energy_before :  50  energy_after :  50  reward :  -193.62819823306606\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "action : 1  next_temperatures :  [-0.55825495 -0.49500911 -0.56601272 -0.12787655 -0.18823517 -1.1806751\n",
      "  0.16871929 -0.63044713  0.16149705]  energy_before :  50  energy_after :  50  reward :  -201.41629439856968\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "action : 1  next_temperatures :  [ 0.195158    0.50267936  0.11800739  0.78783174  0.46478627 -0.03559183\n",
      "  0.56033236  0.31629338  0.60062223]  energy_before :  50  energy_after :  50  reward :  -194.4898810953447\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "action : 1  next_temperatures :  [ 0.5687512  -0.33333499  0.58922125 -0.32690796  0.36508834 -0.22814609\n",
      " -0.17394215  0.36850616  0.3458212 ]  energy_before :  50  energy_after :  70  reward :  -216.82494304477623\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "action : 1  next_temperatures :  [ 2.74804486 -0.13396484  2.22782943 -1.04686108  3.14238781 -1.19120999\n",
      "  2.27363956  0.28772992  3.27512948]  energy_before :  70  energy_after :  40  reward :  -156.41727483466468\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n",
      "action : 1  next_temperatures :  [ 0.37572804  0.7037249   1.48604762 -0.49645324  0.01116069  0.44784225\n",
      "  0.36452582  0.70558571 -0.08968978]  energy_before :  40  energy_after :  60  reward :  -214.49152797663507\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n",
      "action : 1  next_temperatures :  [ 0.68705571 -0.10883414  0.05568556  0.5109897   0.90345716 -0.71977397\n",
      "  0.87035938 -0.11446203 -0.10956787]  energy_before :  60  energy_after :  110  reward :  -246.02509050650113\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "action : 1  next_temperatures :  [ 1.06064891 -2.67048936  2.07430492 -3.78989066  0.36508834 -2.14549482\n",
      "  0.9029938  -2.13463582  0.76326118]  energy_before :  110  energy_after :  390  reward :  -483.574213503321\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "action : 1  next_temperatures :  [2.24369404 1.9200504  2.21566908 1.31940122 2.25436411 0.90874338\n",
      " 2.27363956 1.30680049 2.44386372]  energy_before :  390  energy_after :  30  reward :  178.88622598835312\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "action : 1  next_temperatures :  [-0.30296627 -1.06296275 -0.52041138 -0.71759925 -0.08355234 -1.48794253\n",
      "  0.15077035 -0.88997534 -0.59206344]  energy_before :  30  energy_after :  50  reward :  -223.50670294404281\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "action : 1  next_temperatures :  [ 0.06440038  0.41220887 -0.38360736  1.21456163  0.96327592  0.20202831\n",
      "  0.41347746  0.29095483  0.64941392]  energy_before :  50  energy_after :  30  reward :  -174.17328604344422\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "action : 1  next_temperatures :  [ 0.37572804 -0.34171189  0.25025128 -0.29250747  0.16569248 -0.35412573\n",
      "  0.22909297 -0.40009664  0.37834899]  energy_before :  30  energy_after :  50  reward :  -217.98932796205352\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "action : 1  next_temperatures :  [ 0.0083614  -1.32180888  0.00704413 -1.2336066  -0.58204199 -1.26466153\n",
      " -0.61450686 -1.56567011 -0.80891538]  energy_before :  50  energy_after :  40  reward :  -195.3758058296782\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "action : 1  next_temperatures :  [-1.02939749 -0.78736283 -1.52364088  0.01955412 -1.08053164 -0.41250654\n",
      " -0.99469789 -0.87461865 -0.97697563]  energy_before :  40  energy_after :  50  reward :  -215.66017742144678\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "action : 1  next_temperatures :  [ 0.12666591  1.06560687  0.3460141   0.82796564 -0.11124621  1.61750691\n",
      " -0.12499052  1.55788252 -0.32099851]  energy_before :  50  energy_after :  50  reward :  -193.0155932933147\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "action : 1  next_temperatures :  [-0.00942875 -0.53737228 -0.15560065 -0.76147742 -0.72233122 -0.55736118\n",
      " -0.12499052 -0.87634627 -0.92276265]  energy_before :  50  energy_after :  40  reward :  -192.66767095111157\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "action : 1  next_temperatures :  [ 0.195158   -1.00516216 -0.10999931 -0.71759925  0.18230881 -1.54017799\n",
      "  0.41347746 -1.07214419  0.43256198]  energy_before :  40  energy_after :  50  reward :  -211.22157666215074\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "action : 1  next_temperatures :  [-0.0850369  -0.12935754 -0.70737688  0.82059411  0.11584352 -0.32032631\n",
      " -0.12499052  0.31629338  0.37834899]  energy_before :  50  energy_after :  60  reward :  -207.73600815043378\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "action : 1  next_temperatures :  [-0.80731709  0.68864648 -0.25136347  0.16452762 -0.68672482  0.77354572\n",
      " -0.85926503  0.9359362  -0.26678553]  energy_before :  60  energy_after :  60  reward :  -198.3087999142777\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "action : 1  next_temperatures :  [0.63101673 0.55461613 0.70626469 0.35373031 0.11584352 1.38347155\n",
      " 0.21277576 0.50057378 0.37353006]  energy_before :  60  energy_after :  50  reward :  -183.16817747526767\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "action : 1  next_temperatures :  [-0.67655947  0.47838636 -0.52041138  0.57487632 -0.53219302  0.62913003\n",
      "  0.39716025  0.2617771  -0.52236103]  energy_before :  50  energy_after :  70  reward :  -217.91019484216173\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "action : 1  next_temperatures :  [0.50648566 1.41743656 0.5740208  1.19654233 0.50965034 1.98417937\n",
      " 0.01696922 2.27427254 0.22113133]  energy_before :  70  energy_after :  50  reward :  -169.29931184334873\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "action : 1  next_temperatures :  [ 0.29893389 -1.43992314 -0.18904163 -1.07143286  0.21554145 -0.93486116\n",
      "  0.80509053 -1.38830024  0.43256198]  energy_before :  50  energy_after :  50  reward :  -201.27143118966853\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "action : 1  next_temperatures :  [ 0.43799358 -0.60307109  0.70626469 -0.80257665 -0.48732896  0.14057482\n",
      " -0.30024946  0.45549902  0.42171938]  energy_before :  50  energy_after :  40  reward :  -188.03117466008055\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "action : 1  next_temperatures :  [ 0.12666591  1.71649179  0.33081365  1.50860392 -0.25303882  2.22999331\n",
      " -0.85926503  2.41248284  0.15246155]  energy_before :  40  energy_after :  110  reward :  -260.6347908827269\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "action : 1  next_temperatures :  [ 0.27817871 -0.72788686  0.98443287 -1.20903482 -0.08355234 -0.83346291\n",
      "  0.60928399 -0.83545906 -0.32099851]  energy_before :  110  energy_after :  80  reward :  -170.13849893908147\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "action : 1  next_temperatures :  [ 0.5687512  -0.89542481  1.48604762 -1.8896731   0.31025448 -1.01167802\n",
      "  1.0498487  -1.04343265  0.3295573 ]  energy_before :  80  energy_after :  80  reward :  -199.09574926392662\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "action : 1  next_temperatures :  [-0.65580429 -0.34171189 -0.46416972 -0.25073545 -0.43747999 -1.16019061\n",
      " -0.07603889 -0.64580383 -0.30292752]  energy_before :  80  energy_after :  100  reward :  -222.33486218204987\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "action : 1  next_temperatures :  [ 0.5687512  -1.1735378   1.53164896 -2.24350671  0.31025448 -1.14994836\n",
      "  0.85404217 -1.19787717  0.54640924]  energy_before :  100  energy_after :  60  reward :  -159.95376398770966\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "action : 1  next_temperatures :  [ 0.81781333  0.25137244  0.37641499  0.5331043   0.39832099  0.07912134\n",
      " -0.36974869  0.54664387  0.60062223]  energy_before :  60  energy_after :  120  reward :  -254.76633520249763\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "action : 1  next_temperatures :  [-0.55825495 -1.14589404 -0.97642479 -0.81834354 -0.63189095 -1.07466784\n",
      " -0.32079706 -1.1809848  -0.59206344]  energy_before :  120  energy_after :  70  reward :  -155.2993214049627\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "action : 1  next_temperatures :  [ 0.25742353  0.14163509  0.47939802  0.06132614  0.13245984 -0.24863058\n",
      "  0.16871929  0.08363939  0.16149705]  energy_before :  70  energy_after :  80  reward :  -206.76253223224015\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "action : 1  next_temperatures :  [-0.86958262 -0.64411789 -0.67697598 -1.22623507 -0.22146781 -1.03933209\n",
      " -0.53618425 -0.76635392 -0.68783971]  energy_before :  80  energy_after :  100  reward :  -224.6680893272744\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "action : 1  next_temperatures :  [-1.8596046  -0.3249581  -1.34579565 -0.25073545 -1.62887025  0.01459518\n",
      " -1.64249118 -0.16974615 -1.4648925 ]  energy_before :  100  energy_after :  40  reward :  -146.67249868676384\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "action : 1  next_temperatures :  [-0.30296627  0.19357185 -0.97642479  1.22357128  0.66418213  0.07912134\n",
      "  0.26172739 -0.16974615  0.43256198]  energy_before :  40  energy_after :  130  reward :  -286.5944012330135\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "action : 1  next_temperatures :  [-0.42749733  0.78916925 -0.47937017  1.01716834 -0.2829482   1.0623771\n",
      "  0.01696922  0.54664387 -0.26678553]  energy_before :  130  energy_after :  40  reward :  -106.02427345216552\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "action : 1  next_temperatures :  [-0.42749733  0.99021479 -0.10999931  0.84148012 -0.2829482   1.5509323\n",
      " -0.56555523  1.15937618 -0.3806328 ]  energy_before :  40  energy_after :  50  reward :  -205.22462948190136\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "action : 1  next_temperatures :  [ 0.68705571 -0.19092774  0.07240605  0.13422242  1.16267178 -0.41250654\n",
      "  0.93236478 -0.35172303  0.27534432]  energy_before :  50  energy_after :  240  reward :  -385.69109225057986\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "action : 1  next_temperatures :  [ 0.81781333  0.42896267  0.07240605  1.10071239  1.16267178 -0.32032631\n",
      "  0.26172739  0.62265954  0.87168715]  energy_before :  240  energy_after :  210  reward :  -162.98168601601245\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "action : 1  next_temperatures :  [ 1.25367206 -2.24578066  1.39028481 -2.93888805  0.50965034 -1.43877974\n",
      "  1.24076008 -1.50347548  0.79940317]  energy_before :  210  energy_after :  170  reward :  -160.9331534791026\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "action : 1  next_temperatures :  [ 2.32879027 -0.82757194  2.38287399 -1.6521459   1.50662964 -0.93486116\n",
      "  1.78412322 -0.78324628  1.55657786]  energy_before :  170  energy_after :  100  reward :  -122.63883031135896\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n",
      "action : 1  next_temperatures :  [-0.01239378 -0.01585058 -0.37220702 -0.38035158  0.55949931 -1.01679914\n",
      "  0.36452582 -1.41709405 -0.50170846]  energy_before :  100  energy_after :  60  reward :  -160.79237949039484\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "action : 1  next_temperatures :  [ 1.19140653 -1.01186368  1.0626066  -2.01358507  0.84007777 -1.58012275\n",
      "  1.25870901 -1.435906    1.68488193]  energy_before :  60  energy_after :  70  reward :  -208.0037956791607\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n",
      "action : 1  next_temperatures :  [ 0.43799358 -0.62066257  0.70626469 -0.80482906 -0.53219302  0.12930835\n",
      " -0.30931457  0.42802759  0.32654547]  energy_before :  70  energy_after :  180  reward :  -308.2388595512232\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "action : 1  next_temperatures :  [-0.49598942 -0.44223466  0.00451072 -0.59514988 -0.88113578  0.16822889\n",
      " -0.35464016  0.29067045 -1.02576732]  energy_before :  180  energy_after :  100  reward :  -121.33150715798689\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "action : 1  next_temperatures :  [-0.55825495  1.14937584 -0.10999931  0.58224786 -0.23808413  1.79674624\n",
      " -0.20984002  1.48109903 -0.17462345]  energy_before :  100  energy_after :  50  reward :  -144.28133290907584\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "action : 1  next_temperatures :  [-1.23694927 -0.93730929 -1.34579565 -0.38260399 -0.93596964 -0.88185753\n",
      " -1.22313885 -0.64426816 -0.32235384]  energy_before :  50  energy_after :  50  reward :  -205.91024621619692\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "action : 1  next_temperatures :  [-1.18091029 -0.92977009 -1.14818984 -0.73398043 -0.88113578 -0.53541351\n",
      " -0.90821667 -0.91377823 -0.66254032]  energy_before :  50  energy_after :  140  reward :  -295.89393514571884\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "action : 1  next_temperatures :  [1.93236637 1.15691505 0.99963332 1.33742053 1.80572343 0.97019687\n",
      " 1.73027642 1.28146193 2.19448399]  energy_before :  140  energy_after :  40  reward :  -84.59152210324194\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "action : 1  next_temperatures :  [ 1.56499973  0.34351831  2.30231162 -1.01491777  1.96025522 -0.61837572\n",
      "  1.78412322  0.18422577  1.24575675]  energy_before :  40  energy_after :  50  reward :  -200.24810286813573\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "action : 1  next_temperatures :  [ 0.27817871 -0.21605843 -0.29240467  0.45938896  0.46478627  0.16822889\n",
      "  0.21277576 -0.14440759  0.49219626]  energy_before :  50  energy_after :  60  reward :  -206.57731585002804\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n",
      "action : 1  next_temperatures :  [-0.11616967  0.3937797  -0.59641361  0.91069063  0.26040552  0.07912134\n",
      "  0.16871929  0.10897794  0.60062223]  energy_before :  60  energy_after :  80  reward :  -216.19026663830508\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "action : 1  next_temperatures :  [-0.67655947 -0.87196949 -0.70737688 -0.80933389 -0.88113578 -0.60915769\n",
      " -0.6634585  -0.88152916 -0.30550909]  energy_before :  80  energy_after :  80  reward :  -204.40602994164263\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n",
      "action : 1  next_temperatures :  [ 1.75179633 -0.88034639  0.87225357 -0.589826    0.80874413 -2.33804907\n",
      "  1.91349539 -0.67125207  2.24327567]  energy_before :  80  energy_after :  50  reward :  -164.88990843397596\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "action : 1  next_temperatures :  [-1.18091029  0.88717895 -0.54321205  0.71862123 -1.1303806   1.67691195\n",
      " -2.08305589  1.69839632 -1.56789717]  energy_before :  50  energy_after :  50  reward :  -199.5243475473834\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "action : 1  next_temperatures :  [-0.42749733  0.18603264 -1.16339028  1.59214797 -0.73657378 -0.32032631\n",
      " -0.03198241 -0.74562237 -0.53785045]  energy_before :  50  energy_after :  50  reward :  -200.1850623452281\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "action : 1  next_temperatures :  [ 0.31968906  0.00760473 -0.15560065  0.32915853  0.26040552 -0.22814609\n",
      "  0.21277576  0.05369383  0.27534432]  energy_before :  50  energy_after :  40  reward :  -186.92507499249888\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "action : 1  next_temperatures :  [1.91368671 1.71649179 1.05739502 2.17056764 2.1525298  1.58912125\n",
      " 2.10230884 1.19162524 2.33001645]  energy_before :  40  energy_after :  60  reward :  -201.77625726114195\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "action : 1  next_temperatures :  [ 0.37572804 -0.50254832  0.5740208  -0.79131458  0.09756556 -0.45552398\n",
      "  0.03491815 -0.48993333  0.05849238]  energy_before :  60  energy_after :  50  reward :  -189.09859526780434\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "action : 1  next_temperatures :  [-1.80356562  0.95503182 -1.06762747  0.80585104 -1.37962543  1.43109801\n",
      " -1.25577327  1.07645    -0.70591071]  energy_before :  50  energy_after :  180  reward :  -329.9440716226678\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "action : 1  next_temperatures :  [-0.5167446  -1.18107701 -1.29563417 -0.20404907 -1.03068267 -0.80376039\n",
      " -0.61450686 -1.00937368 -0.65169772]  energy_before :  180  energy_after :  20  reward :  -45.30752618098248\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "action : 1  next_temperatures :  [ 1.58367939  0.19357185  1.48604762 -0.14589586  1.46176557 -0.01305889\n",
      "  1.39251014  0.47523522  2.00473854]  energy_before :  20  energy_after :  100  reward :  -269.56140641761294\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "action : 1  next_temperatures :  [-0.49598942 -1.51699059 -0.38360736 -1.74306148 -0.73657378 -1.275928\n",
      " -0.33711427 -1.59791918 -0.88868591]  energy_before :  100  energy_after :  60  reward :  -166.9758699980388\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "action : 1  next_temperatures :  [-0.10060329  0.58561065  0.25025128  0.28001498  0.41493731  1.18221139\n",
      " -0.32079706  0.84609951  0.27534432]  energy_before :  60  energy_after :  70  reward :  -204.58693090715997\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "action : 1  next_temperatures :  [-0.61429393 -1.63342947 -0.56601272 -1.56286844 -1.08053164 -1.24212859\n",
      " -0.8103134  -1.1656281  -1.03932056]  energy_before :  70  energy_after :  100  reward :  -237.7145268408903\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n",
      "action : 1  next_temperatures :  [ 0.37572804 -0.15909553  0.13320784  0.09982193 -0.003794   -0.39202205\n",
      " -0.06135339 -0.02923235  0.83554516]  energy_before :  100  energy_after :  40  reward :  -137.20119433786303\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n",
      "action : 1  next_temperatures :  [ 0.1723273  -0.20768153 -0.33800601  0.39550234  0.26040552 -0.2701393\n",
      "  0.11976765 -0.21581625  0.37834899]  energy_before :  40  energy_after :  100  reward :  -257.7052912981669\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n",
      "action : 1  next_temperatures :  [-2.17093226 -0.19930464 -1.47803954 -0.12787655 -1.9827979   0.07912134\n",
      " -2.37676569  0.06060434 -1.94738806]  energy_before :  100  energy_after :  80  reward :  -188.14337896753398\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "action : 1  next_temperatures :  [ 0.12822255  0.49765322  0.51169897  0.07606921  0.88019431  0.83602343\n",
      "  0.26172739  0.70558571 -0.39508959]  energy_before :  80  energy_after :  20  reward :  -134.49791479558448\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "action : 1  next_temperatures :  [ 0.81781333  0.89806892  0.47825799  0.625658    1.74258141  1.22522883\n",
      "  0.9960019  -0.30565294  1.17760328]  energy_before :  20  energy_after :  590  reward :  -760.3444392801689\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "action : 1  next_temperatures :  [-0.61429393  0.96257103 -0.1404002   0.76407902 -0.98581861  1.36964452\n",
      " -0.58187244  1.58322108 -0.99052888]  energy_before :  590  energy_after :  80  reward :  313.36660158357336\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "action : 1  next_temperatures :  [-0.98788713  1.13848587 -0.43376883  0.95082454 -0.88113578  1.5509323\n",
      " -0.46765196  1.69609282 -1.0799803 ]  energy_before :  80  energy_after :  50  reward :  -166.51408847671405\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "action : 1  next_temperatures :  [ 0.43799358 -0.6432802  -0.43376883  0.36355902  0.55949931 -0.10523912\n",
      " -0.22778895 -0.100641    0.22113133]  energy_before :  50  energy_after :  220  reward :  -367.92853485543804\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "action : 1  next_temperatures :  [-0.30296627 -1.00516216 -0.38360736 -0.94120243 -0.48732896 -0.98709662\n",
      " -0.45908542 -0.83545906 -0.48363747]  energy_before :  220  energy_after :  50  reward :  -33.88554575467458\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "action : 1  next_temperatures :  [0.68705571 1.17450653 0.61962214 0.75670749 0.43155363 0.47549632\n",
      " 0.7022921  1.00734485 0.84070831]  energy_before :  50  energy_after :  50  reward :  -191.3047129288381\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "action : 1  next_temperatures :  [-0.26560695 -1.00516216 -1.17707069  0.07606921 -0.43747999 -1.08849487\n",
      "  0.01696922 -1.31305241 -0.24871453]  energy_before :  50  energy_after :  40  reward :  -193.44254317797342\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "action : 1  next_temperatures :  [ 1.19140653  0.20865027  0.84762885  0.09621807  1.05798895 -0.16116179\n",
      "  1.29460687 -0.02923235  0.94216403]  energy_before :  40  energy_after :  150  reward :  -302.5517305643507\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n",
      "action : 1  next_temperatures :  [ 0.74932124  0.13325819  0.07240605  0.80044525  1.16267178 -0.57290014\n",
      "  1.0498487  -0.30565294  1.68488193]  energy_before :  150  energy_after :  660  reward :  -703.2257199273708\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n",
      "action : 1  next_temperatures :  [-0.30296627 -0.23364992  1.50124807 -1.74306148  0.06100966 -1.24212859\n",
      "  0.01696922 -0.72661846 -0.16378086]  energy_before :  660  energy_after :  70  reward :  389.1670213778939\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "action : 1  next_temperatures :  [-1.11864475  1.40822197 -0.47937017  1.09170274 -1.32977646  1.53249626\n",
      " -0.90821667  1.74216291 -1.0799803 ]  energy_before :  70  energy_after :  30  reward :  -157.14140448289936\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "action : 1  next_temperatures :  [ 1.46122384  1.92842729  1.25804092  1.01716834  0.96327592  2.03436638\n",
      " -0.53618425  2.73497352  0.55243291]  energy_before :  30  energy_after :  30  reward :  -186.58627512169747\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "action : 1  next_temperatures :  [-1.00864231 -0.09961956 -1.02202613  0.1809088  -0.73657378  0.12930835\n",
      " -1.1040232   0.20879649 -0.54086229]  energy_before :  30  energy_after :  60  reward :  -231.9927336262353\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "action : 1  next_temperatures :  [ 0.63101673 -0.58631729  1.30364226 -1.4629432   2.1247568  -0.01510734\n",
      "  1.16537456 -0.9967044   0.54640924]  energy_before :  60  energy_after :  60  reward :  -195.28987264878444\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "action : 1  next_temperatures :  [-1.36148033 -1.13081562 -1.23483239 -1.01491777 -1.32977646 -0.81502687\n",
      " -1.29982974 -1.09805862 -1.02576732]  energy_before :  60  energy_after :  70  reward :  -218.31050511862745\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "action : 1  next_temperatures :  [ 1.06064891 -0.19092774  0.0876065   0.64122012  0.75889517 -0.50775944\n",
      " -0.22778895 -0.22272676  0.10728407]  energy_before :  70  energy_after :  260  reward :  -386.493548128503\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "action : 1  next_temperatures :  [ 0.0083614  -0.24537757 -0.15560065 -0.50417579 -0.78766897 -0.44323328\n",
      "  0.10578147 -1.02796626 -0.8929455 ]  energy_before :  260  energy_after :  340  reward :  -281.9428251646957\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "action : 1  next_temperatures :  [ 1.35641019 -2.73666685  1.84629821 -3.52697263  0.50965034 -1.85666344\n",
      "  0.94705027 -1.85533585  0.76326118]  energy_before :  340  energy_after :  50  reward :  87.4470314353905\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "action : 1  next_temperatures :  [ 0.31968906 -0.21605843 -0.25136347  0.45938896  0.46478627  0.16822889\n",
      "  0.23725157 -0.14440759  0.49219626]  energy_before :  50  energy_after :  60  reward :  -206.470288470677\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "action : 1  next_temperatures :  [-1.11864475  0.77995467 -0.47937017  0.19892811 -0.88113578  0.62913003\n",
      " -1.05507157  0.64492675 -0.4956848 ]  energy_before :  60  energy_after :  90  reward :  -229.77696752333947\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "action : 1  next_temperatures :  [-0.11616967 -1.28997667 -0.05071757 -1.2336066  -0.63189095 -1.275928\n",
      " -0.61450686 -1.48965445 -0.75470239]  energy_before :  90  energy_after :  80  reward :  -195.45715317522087\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "action : 1  next_temperatures :  [-0.3652318  -0.14066635 -0.88978224  0.73213571  0.01116069 -0.04685831\n",
      " -0.47254712 -0.100641   -0.10956787]  energy_before :  80  energy_after :  110  reward :  -229.3819982996026\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "action : 1  next_temperatures :  [ 1.44046866  0.11064057  1.00723354  0.27632921  1.41191661 -0.04685831\n",
      "  1.29460687  0.59041047  2.05895152]  energy_before :  110  energy_after :  80  reward :  -159.85630086120614\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n",
      "action : 1  next_temperatures :  [1.12914099 0.31838762 1.19571908 0.11538406 0.80874413 1.16377535\n",
      " 0.36452582 1.08182484 0.90963624]  energy_before :  80  energy_after :  60  reward :  -170.91286185679698\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "action : 1  next_temperatures :  [-0.05390414 -0.41961704 -0.47937017  0.26527191 -0.03370338 -0.59993967\n",
      " -0.22778895 -0.21581625 -0.04993359]  energy_before :  60  energy_after :  40  reward :  -179.81480126865227\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "action : 1  next_temperatures :  [-0.42749733 -0.73710145 -0.74841808 -0.38588023 -0.54880935 -0.71977397\n",
      "  0.24541018 -0.91224256 -0.80891538]  energy_before :  40  energy_after :  40  reward :  -203.04322816472376\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "action : 1  next_temperatures :  [-1.672808   -0.2512414  -1.34579565  0.19155657 -0.78143785 -0.28301527\n",
      " -1.59353955  0.06060434 -1.44103878]  energy_before :  40  energy_after :  100  reward :  -265.11671557974853\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "action : 1  next_temperatures :  [-1.11864475 -0.79657742 -1.61940369  0.10883158 -0.98581861 -0.41250654\n",
      " -1.05507157 -0.88152916 -1.02576732]  energy_before :  100  energy_after :  120  reward :  -225.78648747550733\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "action : 1  next_temperatures :  [-1.18091029 -1.24892988 -0.56601272 -1.38349445 -1.08053164 -1.08849487\n",
      " -0.74993972 -1.24394726 -1.19382757]  energy_before :  120  energy_after :  150  reward :  -237.73608839692616\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "action : 1  next_temperatures :  [-0.61429393 -0.01501289 -0.66177553  0.29639616 -0.43747999  0.50929573\n",
      " -1.0110151   0.49212759 -0.86312836]  energy_before :  150  energy_after :  50  reward :  -100.3048863317041\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "action : 1  next_temperatures :  [-1.13939993 -0.00747369 -0.56601272 -0.57262575 -0.57456465 -0.21431905\n",
      " -0.85926503 -0.48225498 -1.06190931]  energy_before :  50  energy_after :  350  reward :  -503.4778251025524\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "action : 1  next_temperatures :  [ 0.12666591 -0.79657742 -0.47937017 -0.14589586  0.31025448 -0.66139315\n",
      " -0.6634585  -0.23654779 -0.26678553]  energy_before :  350  energy_after :  50  reward :  99.18689197477488\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "action : 1  next_temperatures :  [ 0.88007886 -0.41961704  0.36121455 -0.38260399  1.46176557 -1.22369254\n",
      "  0.85404217 -0.84559448  1.05059   ]  energy_before :  50  energy_after :  80  reward :  -226.26381690961458\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "action : 1  next_temperatures :  [-1.672808   -0.84432573 -1.61940369 -0.25073545 -1.36300911 -0.20971004\n",
      " -1.1888727  -0.59743022 -1.28056835]  energy_before :  80  energy_after :  60  reward :  -187.02686329251242\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "action : 1  next_temperatures :  [-0.67655947 -1.05542355 -1.52364088 -0.07955205 -0.23808413 -1.29436405\n",
      " -0.41870032 -1.51883218 -0.65169772]  energy_before :  60  energy_after :  30  reward :  -175.45685435536834\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "action : 1  next_temperatures :  [ 0.25742353 -0.79657742  0.30041276 -0.89943041 -0.03370338 -0.93486116\n",
      "  0.31557419 -0.82778071 -0.21257254]  energy_before :  30  energy_after :  270  reward :  -440.83151514623125\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "action : 1  next_temperatures :  [1.44046866 0.03524849 0.49497848 0.54948548 1.61131247 0.20202831\n",
      " 1.43656661 0.06060434 0.60062223]  energy_before :  270  energy_after :  100  reward :  -21.56868493190771\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "action : 1  next_temperatures :  [0.5687512  1.17366884 0.77162661 0.33816819 1.05965059 0.10984808\n",
      " 0.60928399 0.30615796 0.7036269 ]  energy_before :  100  energy_after :  160  reward :  -252.35921763825434\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "action : 1  next_temperatures :  [-2.00696636  0.51021857 -1.17707069  0.321787   -1.93294894  1.3358451\n",
      " -2.47466896  1.76750147 -2.27808727]  energy_before :  160  energy_after :  50  reward :  -93.93439007361962\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "action : 1  next_temperatures :  [-0.42749733  1.45094414 -0.25136347  1.38574502  0.19892513  1.28770654\n",
      " -0.27674059  1.18317906 -0.61194153]  energy_before :  50  energy_after :  40  reward :  -184.0610430251408\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "action : 1  next_temperatures :  [2.12538953 1.9527203  1.43328036 2.07972226 2.07063507 1.83054566\n",
      " 2.21979276 1.44632707 2.42579272]  energy_before :  40  energy_after :  70  reward :  -210.41579428172653\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "action : 1  next_temperatures :  [-0.18466176 -1.47259304 -0.06439797 -1.48833404 -0.68672482 -1.36810823\n",
      "  0.11976765 -1.37447921 -0.08968978]  energy_before :  70  energy_after :  60  reward :  -194.60922118324672\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "action : 1  next_temperatures :  [-0.38598698  1.48361404 -0.25136347  1.47747966 -0.2829482   1.15455732\n",
      " -0.35343148  1.52025861 -0.59206344]  energy_before :  60  energy_after :  50  reward :  -184.22988392324265\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "action : 1  next_temperatures :  [-1.38431103 -0.09291804 -0.74841808 -0.91417348 -1.09714796 -1.10897937\n",
      " -0.9261656  -0.72028382 -1.13419329]  energy_before :  50  energy_after :  60  reward :  -216.12659066058734\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "action : 1  next_temperatures :  [ 0.14949661  1.13178435 -0.02335676  0.68135403  0.36508834 -0.25887283\n",
      " -0.24410616  0.85301002  0.16149705]  energy_before :  60  energy_after :  50  reward :  -185.18410534404637\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "action : 1  next_temperatures :  [-2.05262775 -0.28474899 -1.52364088 -0.34165103 -1.79503347 -0.15952303\n",
      " -1.78934608 -0.26802902 -1.5279767 ]  energy_before :  50  energy_after :  50  reward :  -207.74257694556624\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "action : 1  next_temperatures :  [-0.18466176 -0.29396358 -0.56601272  0.43727436  0.01116069 -0.49649297\n",
      " -0.17394215  0.06060434  0.64941392]  energy_before :  50  energy_after :  60  reward :  -208.55661986568464\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "action : 1  next_temperatures :  [-0.55825495 -1.29919126  0.17728914 -1.70866099 -0.38264613 -1.31382432\n",
      " -0.03198241 -1.0427745  -0.48363747]  energy_before :  60  energy_after :  390  reward :  -534.6436829045899\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "action : 1  next_temperatures :  [ 0.88007886 -0.20349309  0.80202751 -0.32690796 -0.51723834  1.31740906\n",
      " -1.20682164  0.9359362  -0.65169772]  energy_before :  390  energy_after :  50  reward :  143.02929288895822\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "action : 1  next_temperatures :  [ 0.06440038 -1.09563265  0.3156132  -1.23606378  1.46176557 -0.62964219\n",
      " -0.36974869 -0.31832221  0.16149705]  energy_before :  50  energy_after :  40  reward :  -189.6461333210981\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "action : 1  next_temperatures :  [-0.67655947  0.91482271 -0.26162377  0.76223614 -0.83128681  1.58473172\n",
      " -0.61450686  1.51181242 -1.02576732]  energy_before :  40  energy_after :  60  reward :  -216.63614123892404\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "action : 1  next_temperatures :  [-0.22617211 -0.59301881 -0.25136347 -0.35803221  0.21554145 -0.81502687\n",
      " -0.63082407  0.10897794 -0.21257254]  energy_before :  60  energy_after :  50  reward :  -190.76249069722024\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "action : 1  next_temperatures :  [ 0.08515556  0.51943316 -0.53561182  1.27926732  0.55949931 -0.04685831\n",
      "  0.45753393  0.10129959  0.60062223]  energy_before :  50  energy_after :  40  reward :  -184.97965904597916\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "action : 1  next_temperatures :  [-1.2992148  -1.03866975 -1.29563417 -0.76019033 -1.23506343 -0.58062572\n",
      " -1.54458791 -1.02895347 -0.92276265]  energy_before :  40  energy_after :  50  reward :  -217.70570223184112\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "action : 1  next_temperatures :  [-1.80356562 -0.6432802  -1.16339028 -0.69548464 -1.52917232  0.3218626\n",
      " -2.18585432 -0.19047769 -1.62211015]  energy_before :  50  energy_after :  50  reward :  -207.51147262606034\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "action : 1  next_temperatures :  [ 0.06440038 -0.3165812   0.88867006 -0.98788881 -0.03370338 -0.68904722\n",
      "  0.56033236 -0.42082818  0.16149705]  energy_before :  50  energy_after :  280  reward :  -428.77314894877713\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "action : 1  next_temperatures :  [-0.65580429 -0.9532254  -0.52041138 -1.03703237 -1.1303806  -0.87340768\n",
      " -1.20682164 -0.56134198 -1.26755723]  energy_before :  280  energy_after :  100  reward :  -26.205982564337518\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "action : 1  next_temperatures :  [-1.36148033  0.10058829 -0.90346264 -0.64634109 -1.06391532 -0.12572361\n",
      " -1.05507157 -0.40009664 -1.02576732]  energy_before :  100  energy_after :  50  reward :  -154.481270224216\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "action : 1  next_temperatures :  [-0.3652318   0.62163131 -0.49305057  0.8549946  -0.23808413 -0.93486116\n",
      "  0.11976765 -0.31578836  0.10728407]  energy_before :  50  energy_after :  110  reward :  -258.6433384039507\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "action : 1  next_temperatures :  [-1.2992148  -0.75385524 -0.74841808 -0.91417348 -0.54643559 -0.51566061\n",
      " -1.20682164 -0.87461865 -1.15123165]  energy_before :  110  energy_after :  50  reward :  -146.0104297259292\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "action : 1  next_temperatures :  [-0.3652318   0.88717895  0.07240605  0.48641792 -0.16995721  2.04563285\n",
      " -0.12499052  1.46804583 -0.04993359]  energy_before :  50  energy_after :  70  reward :  -213.7504315150481\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "action : 1  next_temperatures :  [0.37572804 0.92319961 0.70626469 0.60026716 0.21554145 0.66292944\n",
      " 0.21277576 1.3444244  0.05849238]  energy_before :  70  energy_after :  50  reward :  -172.9003770631886\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step\n",
      "action : 1  next_temperatures :  [-0.3652318  -1.04788434 -0.83962076 -0.82571507 -0.68672482 -1.17043285\n",
      " -0.0923561  -1.1372182  -0.48363747]  energy_before :  50  energy_after :  30  reward :  -184.64882141686027\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "action : 1  next_temperatures :  [-0.67655947  0.32676452 -0.27872427 -0.07218052 -0.73657378  0.62913003\n",
      " -0.76625693  0.26024143 -0.53785045]  energy_before :  30  energy_after :  110  reward :  -279.85200944399287\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "action : 1  next_temperatures :  [ 1.56499973 -0.06527428  1.66845298 -2.61781681  0.66418213 -1.65284271\n",
      "  0.94705027 -1.68161319  1.14275208]  energy_before :  110  energy_after :  50  reward :  -138.03010980008253\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "action : 1  next_temperatures :  [-0.05390414 -0.06527428  0.3460141  -0.32690796 -0.43747999  0.69365619\n",
      " -1.0110151   0.78467271 -1.35104523]  energy_before :  50  energy_after :  50  reward :  -199.4212836949875\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "action : 1  next_temperatures :  [-0.42749733 -0.81919504  0.39161544 -1.30076946 -0.23808413 -1.24212859\n",
      "  0.01696922 -0.97597286 -0.10956787]  energy_before :  50  energy_after :  40  reward :  -192.70463063254064\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "action : 1  next_temperatures :  [-0.47315873 -1.2305007  -1.17707069 -0.32690796 -0.98581861 -0.71977397\n",
      " -0.52149876 -1.11187965 -0.53785045]  energy_before :  40  energy_after :  220  reward :  -385.08445950680306\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "action : 1  next_temperatures :  [-0.55825495  0.01765701  0.07240605 -0.66845569 -0.78143785 -0.15952303\n",
      "  0.21277576 -0.27647521 -0.75470239]  energy_before :  220  energy_after :  60  reward :  -40.89601030530531\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "action : 1  next_temperatures :  [-0.49598942  0.86456133 -0.03703716  0.47740827 -0.13340131  2.04563285\n",
      " -0.22778895  1.44270728 -0.12462704]  energy_before :  60  energy_after :  70  reward :  -204.18853415190884\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "action : 1  next_temperatures :  [-0.3652318   1.00696858  0.16360874  0.36355902 -0.66844686  0.99068136\n",
      " -0.8103134   1.28146193  0.84518303]  energy_before :  70  energy_after :  350  reward :  -475.1925293927691\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "action : 1  next_temperatures :  [-2.54452546 -0.97919378 -1.75164758 -0.91417348 -2.1273599  -0.52619549\n",
      " -2.14995645 -0.69110609 -1.7901704 ]  energy_before :  350  energy_after :  220  reward :  -81.47432863918178\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "action : 1  next_temperatures :  [ 0.68705571 -0.79657742  0.41897624 -0.74217102  0.46478627 -0.70953172\n",
      "  0.96103645 -0.99078111  0.54640924]  energy_before :  220  energy_after :  100  reward :  -78.16079734577872\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "action : 1  next_temperatures :  [-0.98788713  0.47754867 -0.55081227 -0.79131458 -1.77841715  0.20202831\n",
      " -1.54458791  0.01453424 -0.72488525]  energy_before :  100  energy_after :  400  reward :  -503.6837930752048\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "action : 1  next_temperatures :  [-0.61429393 -0.2512414  -0.70737688  0.14896549 -0.23808413 -1.13151231\n",
      "  0.07081602 -0.51210456  0.12535506]  energy_before :  400  energy_after :  40  reward :  158.89052334830603\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "action : 1  next_temperatures :  [-0.42749733 -0.99762296 -0.61161406 -0.64634109 -0.68672482 -0.20049202\n",
      " -0.71730529 -0.76635392 -0.70591071]  energy_before :  40  energy_after :  80  reward :  -243.75986218637823\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "action : 1  next_temperatures :  [-1.82224528 -0.56788812 -1.6604449  -0.05416122 -0.98581861 -0.32032631\n",
      " -1.69633798 -0.40009664 -1.02576732]  energy_before :  80  energy_after :  240  reward :  -366.5330863668643\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "action : 1  next_temperatures :  [ 0.31968906 -0.16831012 -0.02335676  0.26527191  0.43155363 -0.42377301\n",
      "  0.75124373 -0.02923235  0.16149705]  energy_before :  240  energy_after :  30  reward :  13.284583144231107\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "action : 1  next_temperatures :  [-0.18466176 -1.11322414 -0.70737688 -0.71022771 -0.63189095 -1.23291056\n",
      "  0.26172739 -1.12877202 -0.43484578]  energy_before :  30  energy_after :  70  reward :  -243.88218241076254\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "action : 1  next_temperatures :  [ 0.31968906 -0.39197328 -0.38360736  0.21367117  1.25738481 -0.61837572\n",
      "  0.62886465 -0.83545906  0.60062223]  energy_before :  70  energy_after :  50  reward :  -177.20918348174663\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "action : 1  next_temperatures :  [0.25742353 0.52864774 0.07240605 0.91069063 0.50965034 0.00537716\n",
      " 0.56033236 0.29940102 0.61688612]  energy_before :  50  energy_after :  40  reward :  -184.2391850424609\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "action : 1  next_temperatures :  [ 0.50648566 -0.71867227  0.02224458 -0.34902256  0.61433317 -0.44630596\n",
      "  0.9029938  -0.92759926  0.43256198]  energy_before :  40  energy_after :  100  reward :  -257.9629808675867\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n",
      "action : 1  next_temperatures :  [ 0.50648566 -0.67092396 -0.00815632 -0.0304085   0.26040552 -0.63886021\n",
      " -0.07603889  0.08594289  0.27534432]  energy_before :  100  energy_after :  40  reward :  -138.2962094718664\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n",
      "action : 1  next_temperatures :  [0.77215194 1.38979279 0.43265665 1.76169324 1.36206764 0.90874338\n",
      " 1.14775197 1.14555515 1.57645596]  energy_before :  40  energy_after :  40  reward :  -187.50313128419154\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "action : 1  next_temperatures :  [-0.22617211  0.85534674  0.10280695  0.39550234  0.97656898  1.37681409\n",
      "  0.31557419  0.81385044 -0.40773929]  energy_before :  40  energy_after :  180  reward :  -333.7974476723924\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "action : 1  next_temperatures :  [-2.2331978   1.54309002 -1.31235466  1.44226011 -1.68370411  1.27746429\n",
      " -2.03410425  1.44270728 -1.62211015]  energy_before :  180  energy_after :  60  reward :  -81.1799492794193\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "action : 1  next_temperatures :  [0.74932124 0.86456133 0.74639387 0.85990896 1.05798895 0.07912134\n",
      " 1.29460687 0.85992054 1.19154376]  energy_before :  60  energy_after :  60  reward :  -190.29663313133403\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "action : 1  next_temperatures :  [-0.03314896  0.86456133  0.26697177  0.60927681 -0.78143785  1.91145941\n",
      " -1.56090512  1.75905528 -0.31497485]  energy_before :  60  energy_after :  50  reward :  -185.27914216871085\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "action : 1  next_temperatures :  [-0.11616967 -0.76139445  0.07240605 -0.80196235  1.16267178 -0.27116353\n",
      " -0.36974869 -0.16129996 -0.16378086]  energy_before :  50  energy_after :  30  reward :  -179.41044167419437\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "action : 1  next_temperatures :  [2.0402933  2.54580463 1.34468346 2.5995909  1.75587446 1.89199914\n",
      " 1.63726831 2.10458102 1.90173387]  energy_before :  30  energy_after :  30  reward :  -180.17817090987003\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "action : 1  next_temperatures :  [ 0.68705571 -0.96997919  0.10280695 -0.53085373  0.80874413 -0.57740673\n",
      "  0.80509053 -1.02895347 -0.23245064]  energy_before :  30  energy_after :  50  reward :  -218.935946440089\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "action : 1  next_temperatures :  [-0.18466176  0.27734082 -0.88978224  1.55774748 -0.73657378 -0.22814609\n",
      "  0.15240207 -0.42082818 -0.45924163]  energy_before :  50  energy_after :  80  reward :  -228.93174329540676\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "action : 1  next_temperatures :  [-6.35049112e-01  1.74090027e-03 -3.38006014e-01 -9.67522999e-02\n",
      " -5.02283646e-01  1.89097492e+00  3.13942467e-01 -4.44631065e-01\n",
      " -7.72773388e-01]  energy_before :  80  energy_after :  60  reward :  -178.58283724025927\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n",
      "action : 1  next_temperatures :  [-0.47315873 -0.81919504 -1.16339028 -0.10330477 -0.18823517 -0.90720709\n",
      " -0.03198241 -0.97597286  0.0042794 ]  energy_before :  60  energy_after :  50  reward :  -192.658166967437\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n",
      "action : 1  next_temperatures :  [-0.16183106  1.19879953  0.17728914  0.92870994 -0.08355234  1.79674624\n",
      " -0.96206346  1.49108088 -0.32099851]  energy_before :  50  energy_after :  80  reward :  -223.93581965025896\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "action : 1  next_temperatures :  [-2.29546333 -1.07050196 -1.61940369 -0.76919998 -1.9827979  -0.53541351\n",
      " -2.03410425 -0.65962486 -1.56502707]  energy_before :  80  energy_after :  40  reward :  -170.53153655685895\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "action : 1  next_temperatures :  [-1.4507276  -0.18422622 -1.19075109 -0.30888866 -0.95092433  0.28089361\n",
      " -1.39773301 -0.76635392 -1.0799803 ]  energy_before :  40  energy_after :  60  reward :  -225.04869150731628\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "action : 1  next_temperatures :  [-0.18466176 -0.26631982  0.55426022 -0.08938077  0.11584352 -0.85292318\n",
      "  0.71208243 -0.44616674  0.27534432]  energy_before :  60  energy_after :  390  reward :  -528.1819217687023\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "action : 1  next_temperatures :  [-1.11864475 -0.38443407 -0.52041138 -0.60293094 -1.03068267 -0.71977397\n",
      " -0.22778895 -0.76635392 -0.86312836]  energy_before :  390  energy_after :  60  reward :  125.76585098799455\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "action : 1  next_temperatures :  [ 1.72896563 -0.3249581   3.11249545 -1.64395531  1.91040625 -0.6798292\n",
      "  1.88202648 -0.30565294  1.84752088]  energy_before :  60  energy_after :  220  reward :  -350.4729808452992\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "action : 1  next_temperatures :  [-1.31996998  1.46518487 -0.74841808  1.37837349 -1.18521446  1.85819973\n",
      " -1.20682164  1.94410351 -1.13419329]  energy_before :  220  energy_after :  50  reward :  -26.94875585271396\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "action : 1  next_temperatures :  [ 0.48365497  0.26812624 -0.10999931  0.82796564  0.29363816  0.12930835\n",
      " -0.12499052 -0.1290509   0.27534432]  energy_before :  50  energy_after :  130  reward :  -276.0860030463057\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "action : 1  next_temperatures :  [-0.11616967 -1.32180888 -0.20576213 -1.30977912 -0.68672482 -1.08849487\n",
      " -0.71730529 -1.44358435 -0.92276265]  energy_before :  130  energy_after :  50  reward :  -125.81239177825623\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "action : 1  next_temperatures :  [-0.42749733  0.36194749 -0.02335676 -0.0484278  -0.01874869  0.6322027\n",
      " -1.1040232   0.45450368 -0.30593935]  energy_before :  50  energy_after :  60  reward :  -208.47933927339898\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "action : 1  next_temperatures :  [-0.24692729  0.88717895 -0.22096257  1.04255918 -0.13340131  1.39729859\n",
      "  0.07081602  1.15937618 -0.59206344]  energy_before :  60  energy_after :  40  reward :  -174.63612569317917\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "action : 1  next_temperatures :  [ 0.06440038  1.01283241  0.3460141   0.87956638  0.01116069  1.73836543\n",
      " -0.90821667  1.36054894 -0.26678553]  energy_before :  40  energy_after :  90  reward :  -243.76211386978017\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n",
      "action : 1  next_temperatures :  [ 0.08930659 -0.97550795 -0.20576213 -0.86502992 -0.73657378 -0.41250654\n",
      " -0.54903405 -0.86079762 -0.43484578]  energy_before :  90  energy_after :  90  reward :  -202.95075117113188\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "action : 1  next_temperatures :  [-1.61054246  0.16927885 -1.16339028  0.24889072 -1.45107561  0.29420854\n",
      " -1.17092377 -0.19892388 -1.22093406]  energy_before :  90  energy_after :  120  reward :  -234.10341196553537\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "action : 1  next_temperatures :  [-0.18466176 -1.31050007 -0.26504387 -1.34008431 -0.70334114 -1.06084081\n",
      " -0.71730529 -1.38830024 -0.92276265]  energy_before :  120  energy_after :  50  reward :  -135.8928401263432\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "action : 1  next_temperatures :  [ 0.37572804  0.16006426  1.07563555 -0.55378739  0.41493731 -0.15952303\n",
      "  1.13143476 -0.29797459  0.49219626]  energy_before :  50  energy_after :  280  reward :  -425.361288818888\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "action : 1  next_temperatures :  [ 1.68330424 -0.29396358  1.58789062 -0.79131458  1.46176557 -0.45321947\n",
      "  1.63726831  0.33932843  2.00473854]  energy_before :  280  energy_after :  50  reward :  39.175798076058925\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "action : 1  next_temperatures :  [-0.67655947 -0.6432802  -1.19075109  0.06869768 -1.08053164 -0.35412573\n",
      " -0.76625693 -0.86079762 -0.75470239]  energy_before :  50  energy_after :  440  reward :  -594.2583073815672\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "action : 1  next_temperatures :  [ 0.02704106  0.68864648  0.52841946  0.14241301 -0.2829482   1.45636222\n",
      "  0.75124373  0.80002941 -0.26678553]  energy_before :  440  energy_after :  40  reward :  205.84442164981374\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "action : 1  next_temperatures :  [-1.18091029 -1.17940163 -1.02202613 -1.15415785 -1.08053164 -1.06084081\n",
      " -1.05507157 -1.39674642 -1.19382757]  energy_before :  40  energy_after :  60  reward :  -228.32351389817688\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "action : 1  next_temperatures :  [ 0.5687512  -0.14066635  1.06043511 -0.75118068  0.46478627 -0.41250654\n",
      "  1.19180844 -0.30565294  0.54640924]  energy_before :  60  energy_after :  60  reward :  -195.77781624897216\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "action : 1  next_temperatures :  [-0.49598942  0.51273164 -0.06439797  0.14732737 -0.22562189  0.47549632\n",
      " -1.1040232   0.47523522 -0.32099851]  energy_before :  60  energy_after :  50  reward :  -188.60024045185224\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n",
      "action : 1  next_temperatures :  [0.77215194 1.07230838 0.41897624 1.24568588 1.67777775 0.32391105\n",
      " 0.34820861 0.61574902 1.04381338]  energy_before :  50  energy_after :  110  reward :  -250.48141773348178\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "action : 1  next_temperatures :  [ 1.81406186 -0.47657994  1.66845298 -0.92768795  1.21252075 -0.6137667\n",
      "  1.56384086 -0.43349746  0.97469182]  energy_before :  110  energy_after :  20  reward :  -103.21796378019141\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "action : 1  next_temperatures :  [ 0.63101673  0.93995341  0.70626469  0.5511236  -0.12232376  1.50637852\n",
      "  0.01696922  1.52025861 -0.16378086]  energy_before :  20  energy_after :  40  reward :  -212.41413983451767\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "action : 1  next_temperatures :  [-0.55825495 -0.96997919 -0.97642479 -0.15490551 -0.08355234 -1.499209\n",
      "  0.01696922 -0.92345295  0.16149705]  energy_before :  40  energy_after :  60  reward :  -222.98731246284856\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "action : 1  next_temperatures :  [-0.30296627 -0.35092648 -1.21963194  1.01716834  0.01116069 -0.84268094\n",
      "  0.36452582 -0.79998509  0.3295573 ]  energy_before :  60  energy_after :  80  reward :  -219.79377854700894\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "action : 1  next_temperatures :  [ 1.17584014  0.11503844  1.03003421 -1.46001799  0.9347908  -1.71751519\n",
      "  1.25870901 -1.22705489  1.7043986 ]  energy_before :  80  energy_after :  90  reward :  -206.1857768719413\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "action : 1  next_temperatures :  [-0.98788713  1.0052932  -0.52041138  0.70510675 -1.18521446  1.58473172\n",
      " -0.36974869  0.87950033 -1.13419329]  energy_before :  90  energy_after :  50  reward :  -158.0228229510406\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "action : 1  next_temperatures :  [-0.3652318   1.022047    0.07240605  0.3881308  -0.38264613  1.30819104\n",
      " -1.0110151   0.92902569 -0.30895118]  energy_before :  50  energy_after :  30  reward :  -176.34804363721693\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "action : 1  next_temperatures :  [-0.49598942 -1.22128612 -1.16339028 -0.48826264 -0.13340131 -1.02704139\n",
      " -0.52149876 -1.29616004 -0.26678553]  energy_before :  30  energy_after :  270  reward :  -444.61381548593044\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "action : 1  next_temperatures :  [-0.85401624 -1.77541788 -0.83962076 -1.75207113 -1.23506343 -1.36810823\n",
      " -0.9261656  -1.78219957 -0.23064354]  energy_before :  270  energy_after :  50  reward :  11.236693615873918\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "action : 1  next_temperatures :  [ 0.81781333  1.07314607  0.9342714   0.16698479  0.55949931 -0.06068534\n",
      "  1.12327615 -0.1490146   0.62501807]  energy_before :  50  energy_after :  80  reward :  -222.9096908213183\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "action : 1  next_temperatures :  [-0.98788713 -0.59301881 -1.20443149 -0.12787655 -0.73657378  0.3218626\n",
      " -0.76625693 -0.33099149 -0.86312836]  energy_before :  80  energy_after :  100  reward :  -223.2883019490298\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n",
      "action : 1  next_temperatures :  [ 0.25742353  0.63587203  0.13320784  0.80585104  0.66418213 -0.33159279\n",
      "  0.16871929  0.66949747  0.43256198]  energy_before :  100  energy_after :  110  reward :  -204.56427747867346\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "action : 1  next_temperatures :  [-0.18466176  1.71649179  0.07240605  1.65685365 -0.2829482   2.29144679\n",
      " -0.96206346  2.36410923  0.0042794 ]  energy_before :  110  energy_after :  70  reward :  -151.32408650193523\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "action : 1  next_temperatures :  [-1.92187013  0.45995719 -1.08434796  0.28738651 -1.99775259  1.35837805\n",
      " -2.44529798  1.82892826 -2.26814822]  energy_before :  70  energy_after :  100  reward :  -233.78276687803424\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "action : 1  next_temperatures :  [ 0.88007886 -0.14234173  0.26697177 -0.15244833  0.66418213 -1.79520995\n",
      "  0.76662853 -1.51005692  0.87168715]  energy_before :  100  energy_after :  50  reward :  -148.15050848652103\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "action : 1  next_temperatures :  [ 0.06440038  0.52781005 -0.32280557  1.48321308 -0.03370338 -0.20049202\n",
      "  0.16871929  0.11588846  0.10728407]  energy_before :  50  energy_after :  40  reward :  -186.08968563892725\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "action : 1  next_temperatures :  [ 0.06440038 -1.38966175 -0.15560065 -1.22541601 -0.48732896 -1.275928\n",
      " -0.36974869 -1.0581312  -0.21257254]  energy_before :  40  energy_after :  90  reward :  -254.1099874306352\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "action : 1  next_temperatures :  [0.68705571 1.13094667 0.6044217  0.77145055 0.43155363 0.47549632\n",
      " 0.71860931 0.99198815 0.85000196]  energy_before :  90  energy_after :  70  reward :  -171.3384760081244\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "action : 1  next_temperatures :  [1.87632739 1.96779871 3.4134643  0.11702218 2.96364367 1.50879277\n",
      " 2.21979276 1.42197573 2.38965073]  energy_before :  70  energy_after :  60  reward :  -170.12153176193848\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "action : 1  next_temperatures :  [2.37445166 1.37471438 2.5804798  0.24772064 2.90738555 0.36590427\n",
      " 1.88202648 1.47572418 1.90173387]  energy_before :  60  energy_after :  50  reward :  -172.8898591734024\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "action : 1  next_temperatures :  [ 0.68705571 -0.02422748  0.75642617 -0.28513594 -0.63189095  0.81656316\n",
      " -0.0466679   1.07645     0.22113133]  energy_before :  50  energy_after :  100  reward :  -245.43029591195244\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "action : 1  next_temperatures :  [-1.18091029 -0.51008753 -1.13146935 -0.17702011 -0.20485149 -0.35105306\n",
      " -0.84294782 -0.79169247 -0.75470239]  energy_before :  100  energy_after :  40  reward :  -143.9447345001178\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "action : 1  next_temperatures :  [-1.82224528  1.54309002 -1.11778894  1.46928907 -1.2799275   1.71583249\n",
      " -1.51521693  1.82124991 -1.25346185]  energy_before :  40  energy_after :  80  reward :  -238.43917901747457\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "action : 1  next_temperatures :  [-1.98413566  0.76152549 -1.25003283  0.87956638 -1.43445929  1.01935966\n",
      " -1.74528961  1.03729042 -1.4648925 ]  energy_before :  80  energy_after :  80  reward :  -202.18106794909767\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "action : 1  next_temperatures :  [ 0.63101673 -1.17940163 -0.02335676 -0.90680194  0.46478627 -1.14994836\n",
      "  0.56033236 -1.15180707 -0.48363747]  energy_before :  80  energy_after :  80  reward :  -201.23881786749507\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n",
      "action : 1  next_temperatures :  [-1.05015267 -1.32180888 -1.29563417 -1.05341356 -1.01786437 -0.63417804\n",
      " -1.05507157 -1.21169819 -0.70591071]  energy_before :  80  energy_after :  300  reward :  -427.34573215867226\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "action : 1  next_temperatures :  [-0.13900036  0.12739436 -0.29240467  0.17804209 -0.18823517 -0.56614025\n",
      " -0.07603889  0.04678331  0.3295573 ]  energy_before :  300  energy_after :  150  reward :  -48.58004227286898\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "action : 1  next_temperatures :  [-0.34447662  1.6503143  -0.20576213  1.60852915 -0.08355234  1.09003116\n",
      " -0.32079706  1.32753203 -0.59206344]  energy_before :  150  energy_after :  20  reward :  -63.87024493503958\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "action : 1  next_temperatures :  [ 1.44046866  0.15922657  1.53164896 -0.98788881  1.16267178 -0.61837572\n",
      "  1.31092408 -0.17665666  1.30539103]  energy_before :  20  energy_after :  60  reward :  -232.87259009955844\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "action : 1  next_temperatures :  [ 0.06440038 -0.14066635  1.25804092 -0.8814111  -0.03370338 -0.43503949\n",
      "  0.07081602 -0.0545709   0.05849238]  energy_before :  60  energy_after :  50  reward :  -188.0936415325031\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "action : 1  next_temperatures :  [ 0.31968906 -0.69354158 -0.47937017  0.11784124 -0.08355234 -0.75357338\n",
      " -0.43664926 -0.46689828  0.07475628]  energy_before :  50  energy_after :  50  reward :  -200.40129843776865\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "action : 1  next_temperatures :  [-0.88826228  0.14414816 -0.40032785 -0.09593324 -0.63521422  0.59123371\n",
      "  0.56033236 -0.45998776 -0.92276265]  energy_before :  50  energy_after :  60  reward :  -210.10677377033454\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "action : 1  next_temperatures :  [-0.05390414  0.51021857 -0.1404002   0.49460851 -0.48732896  0.44784225\n",
      "  0.16871929 -0.09910533 -0.65169772]  energy_before :  60  energy_after :  60  reward :  -197.81104773486055\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "action : 1  next_temperatures :  [-0.05390414  0.58561065  0.21985039  0.35373031  0.13522923  1.39729859\n",
      " -0.20984002  0.69176468 -0.32099851]  energy_before :  60  energy_after :  130  reward :  -265.20125882242024\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "action : 1  next_temperatures :  [-0.3652318  -0.49333373 -1.06762747  0.3881308   0.06100966 -0.464742\n",
      "  0.21277576 -0.89673229  0.18137515]  energy_before :  130  energy_after :  110  reward :  -180.44437593736717\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "action : 1  next_temperatures :  [ 1.12914099  0.3116861   1.89645969 -0.94120243  1.05798895 -0.1666926\n",
      "  1.29460687  0.12279897  0.97469182]  energy_before :  110  energy_after :  50  reward :  -132.320521621844\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "action : 1  next_temperatures :  [-0.98788713 -0.01501289 -0.61161406 -0.52348219 -0.98581861 -0.56614025\n",
      " -0.82663061 -1.05889904 -1.02576732]  energy_before :  50  energy_after :  80  reward :  -234.60125210281302\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "action : 1  next_temperatures :  [-1.18091029 -0.51762674  0.11800739 -1.09436652 -1.047299   -0.62759374\n",
      "  0.49016835 -0.72873    -0.97697563]  energy_before :  80  energy_after :  60  reward :  -183.565326165074\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n",
      "action : 1  next_temperatures :  [ 0.5687512   0.91482271  0.87498965  0.1809088   1.08540589 -0.04685831\n",
      "  0.51725492  0.25640226  0.7036269 ]  energy_before :  60  energy_after :  260  reward :  -392.9446959780515\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "action : 1  next_temperatures :  [ 0.88007886  2.39669586  0.84762885  1.61426257  0.69741478  1.00092361\n",
      "  1.09880034 -0.18356718  0.99854554]  energy_before :  260  energy_after :  40  reward :  31.350783218102265\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "action : 1  next_temperatures :  [-0.61429393 -0.46736535 -0.46416972 -0.63733143 -0.31618084 -0.51492902\n",
      " -0.85926503 -0.69724877 -1.0799803 ]  energy_before :  40  energy_after :  30  reward :  -193.65076440849955\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "action : 1  next_temperatures :  [-0.05390414 -0.42715624 -0.66177553  0.09982193  0.01116069 -0.50775944\n",
      "  0.3938968  -0.79998509  0.27534432]  energy_before :  30  energy_after :  50  reward :  -219.6703566985551\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "action : 1  next_temperatures :  [ 0.48365497  0.63587203  1.44044628 -0.44976686  0.01116069  0.47549632\n",
      "  0.36452582  0.66181912 -0.04993359]  energy_before :  50  energy_after :  110  reward :  -254.42672521808208\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n",
      "action : 1  next_temperatures :  [ 0.50648566  0.65430121  0.66066335  0.01955412  0.16569248  1.27746429\n",
      " -0.85926503  0.38539853 -0.1487217 ]  energy_before :  110  energy_after :  50  reward :  -135.33842708114403\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "action : 1  next_temperatures :  [ 0.195158    1.2834062  -0.33800601  2.06720236  1.36206764  0.88825889\n",
      "  0.56033236  0.59271397  0.49219626]  energy_before :  50  energy_after :  60  reward :  -200.89667034331967\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "action : 1  next_temperatures :  [-0.61429393 -0.77898593 -0.02335676 -1.20166329 -0.98581861 -0.61837572\n",
      "  0.60928399 -0.93527761 -1.02576732]  energy_before :  60  energy_after :  640  reward :  -783.574255171266\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "action : 1  next_temperatures :  [ 0.195158    0.72969328  1.57269017 -0.57262575 -0.03370338  0.43657578\n",
      "  0.31557419  0.7140319  -0.10956787]  energy_before :  640  energy_after :  50  reward :  395.24782630762\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "action : 1  next_temperatures :  [-0.18466176  1.41743656  0.20464994  0.8549946   0.06100966  1.81927919\n",
      " -0.61450686  1.81357156 -0.48363747]  energy_before :  50  energy_after :  70  reward :  -213.11186458060638\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "action : 1  next_temperatures :  [ 1.81406186 -1.78337593  2.25671028 -2.44663342  0.91342696 -1.02704139\n",
      "  1.53936504 -0.96752668  0.3295573 ]  energy_before :  70  energy_after :  50  reward :  -177.37145596398085\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "action : 1  next_temperatures :  [ 0.33836872  0.68026959  0.5740208   0.19155657 -0.31618084  1.22522883\n",
      " -1.1040232   0.39230905 -0.3806328 ]  energy_before :  50  energy_after :  110  reward :  -256.3990832824778\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "action : 1  next_temperatures :  [0.90083404 0.18603264 0.16360874 0.82796564 1.16267178 0.0483946\n",
      " 1.08248312 0.28404432 0.81747417]  energy_before :  110  energy_after :  50  reward :  -132.52649095315283\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "action : 1  next_temperatures :  [-0.18466176  1.41743656  0.20464994  0.8549946   0.11584352  1.79674624\n",
      " -0.59818965  1.82816043 -0.4866493 ]  energy_before :  50  energy_after :  60  reward :  -203.05166942046387\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "action : 1  next_temperatures :  [ 0.37572804 -0.05773507  0.20464994  0.19155657 -0.38264613  0.38638876\n",
      " -0.76625693  0.13815567 -0.7275959 ]  energy_before :  60  energy_after :  150  reward :  -288.6377550374556\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "action : 1  next_temperatures :  [-0.26560695 -0.99762296 -1.11778894 -0.16227704  0.04439334 -0.95739411\n",
      " -0.17394215 -1.41133529 -0.59206344]  energy_before :  150  energy_after :  50  reward :  -103.63363754019431\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "action : 1  next_temperatures :  [ 0.74932124 -1.82442273  1.11667676 -2.4892245   0.06100966 -1.06084081\n",
      "  0.9960019  -1.33393752  0.16149705]  energy_before :  50  energy_after :  510  reward :  -661.623918937867\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "action : 1  next_temperatures :  [ 0.81781333  0.26812624  0.39161544  0.51836123  0.36508834  0.07912134\n",
      " -0.36974869  0.54664387  0.63315002]  energy_before :  510  energy_after :  400  reward :  -84.74982888042459\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "action : 1  next_temperatures :  [-0.80731709 -1.79259052 -0.83962076 -1.80121469 -1.23506343 -1.36810823\n",
      " -0.87558224 -1.74227216 -0.0137916 ]  energy_before :  400  energy_after :  40  reward :  151.52443928155452\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "action : 1  next_temperatures :  [-2.00696636  1.24906092 -1.00682568  0.86318519 -2.32675576  1.4515825\n",
      " -2.62152386  2.20286389 -2.27808727]  energy_before :  40  energy_after :  100  reward :  -262.4734664301078\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "action : 1  next_temperatures :  [-0.24692729  1.74413555  0.05986568  1.68244925 -0.33279717  2.26891385\n",
      " -0.99469789  2.3502882  -0.04993359]  energy_before :  100  energy_after :  100  reward :  -191.51870338598707\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "action : 1  next_temperatures :  [ 0.5687512   0.18603264 -0.38360736  1.29728662  0.96327592 -0.13903853\n",
      "  0.11976765  0.48368141  0.7036269 ]  energy_before :  100  energy_after :  40  reward :  -134.20022355047482\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "action : 1  next_temperatures :  [ 0.12666591 -1.16264783  0.39161544 -1.51454394  1.10949955 -1.18272355\n",
      " -0.36974869 -0.45154158  0.05849238]  energy_before :  40  energy_after :  80  reward :  -240.99493231241507\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "action : 1  next_temperatures :  [-0.738825   -1.82442273 -0.56601272 -1.91342582 -1.1303806  -1.75628941\n",
      " -0.27674059 -1.41133529 -0.59206344]  energy_before :  80  energy_after :  50  reward :  -178.20949558399874\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "action : 1  next_temperatures :  [1.44046866 1.19879953 0.5740208  1.79609373 1.71101039 0.69058351\n",
      " 1.34355851 0.86683105 1.95594685]  energy_before :  50  energy_after :  60  reward :  -196.42268695250158\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "action : 1  next_temperatures :  [-1.5062477   0.12194938 -0.74841808 -0.14589586 -1.48430825  0.93639745\n",
      " -0.8103134   0.37541668 -1.19382757]  energy_before :  60  energy_after :  50  reward :  -192.45524735378905\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "action : 1  next_temperatures :  [-0.42749733  0.00760473 -0.03703716 -0.28513594 -0.53219302  1.0623771\n",
      " -0.52149876  0.66181912 -0.75470239]  energy_before :  50  energy_after :  70  reward :  -218.82626366848368\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "action : 1  next_temperatures :  [-1.36148033 -1.22128612 -1.11778894 -1.07880439 -1.2799275  -0.79474722\n",
      " -1.20682164 -0.88997534 -1.0799803 ]  energy_before :  70  energy_after :  110  reward :  -248.0308117831901\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "action : 1  next_temperatures :  [-0.42749733  0.23629403 -0.52041138  0.80585104 -0.2829482  -0.20049202\n",
      " -0.52149876  0.27022329 -0.10956787]  energy_before :  110  energy_after :  50  reward :  -138.75004720507616\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "action : 1  next_temperatures :  [ 0.68705571 -0.73542607  0.11800739 -0.34902256  0.80874413 -0.71977397\n",
      "  0.80509053 -0.89688586  0.0042794 ]  energy_before :  50  energy_after :  280  reward :  -428.2779312955709\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "action : 1  next_temperatures :  [-2.71679344  1.51544625 -1.52478091  1.15968466 -2.43143859  1.24366488\n",
      " -2.77327393  1.77287631 -2.30248311]  energy_before :  280  energy_after :  100  reward :  -24.057097876988877\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "action : 1  next_temperatures :  [ 1.93236637 -0.36935565  1.45564673 -0.55460645  1.61131247 -0.2701393\n",
      "  1.68132478 -0.37475808  1.57645596]  energy_before :  100  energy_after :  50  reward :  -141.31175317832336\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "action : 1  next_temperatures :  [-0.80731709 -0.87196949 -1.20443149 -0.15490551 -1.08053164 -0.62759374\n",
      "  0.26172739 -0.74562237 -0.80891538]  energy_before :  50  energy_after :  30  reward :  -184.0395593184607\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "action : 1  next_temperatures :  [ 0.23666835  1.09911446 -0.29240467  1.99266796  1.36206764  0.34439555\n",
      "  0.60928399  0.69176468  0.47231816]  energy_before :  30  energy_after :  60  reward :  -221.4841238760177\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "action : 1  next_temperatures :  [-1.11864475  0.46917177 -0.47937017  0.05067837 -0.73657378  0.81656316\n",
      " -1.0110151   0.80002941 -0.39569196]  energy_before :  60  energy_after :  70  reward :  -209.60485304844025\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n",
      "action : 1  next_temperatures :  [-0.30296627  0.61241672 -0.41704834 -0.04023721 -0.83128681 -0.53541351\n",
      " -0.76625693  0.00762373 -1.13419329]  energy_before :  70  energy_after :  60  reward :  -191.40736190892625\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "action : 1  next_temperatures :  [ 0.37572804 -0.35092648  1.1622781  -0.94120243  0.01116069 -0.39202205\n",
      "  0.16871929 -0.35172303  0.05849238]  energy_before :  60  energy_after :  100  reward :  -238.25949548989166\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "action : 1  next_temperatures :  [ 0.27817871 -1.10484724 -0.10999931 -0.83308661  0.21554145 -1.45721578\n",
      "  0.3938968  -1.04784221  0.54640924]  energy_before :  100  energy_after :  120  reward :  -221.118964951386\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "action : 1  next_temperatures :  [1.44046866 1.30853689 0.88867006 1.51155253 1.86055729 0.14979285\n",
      " 1.68132478 0.82076096 1.51682167]  energy_before :  120  energy_after :  100  reward :  -166.8215143157023\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "action : 1  next_temperatures :  [ 0.83856851 -0.37689486  0.43265665 -0.1712867   0.19892513 -0.42377301\n",
      "  0.41347746 -0.21581625  0.79940317]  energy_before :  100  energy_after :  60  reward :  -156.50473990525302\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "action : 1  next_temperatures :  [-0.67655947 -0.86275491 -0.21716246 -0.96945998 -1.26497281  0.31264458\n",
      " -1.83829772 -0.23654779 -0.93179814]  energy_before :  60  energy_after :  60  reward :  -204.68490869350074\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "action : 1  next_temperatures :  [-0.11616967 -1.01437675 -0.97642479 -0.11968596  0.54288298 -1.1806751\n",
      "  0.31557419 -1.40475384  0.49219626]  energy_before :  60  energy_after :  40  reward :  -181.46143267889656\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "action : 1  next_temperatures :  [-0.49598942 -0.76893366 -1.28043373  0.09081228 -0.78143785 -0.50775944\n",
      " -0.32079706 -1.22014438 -0.86312836]  energy_before :  40  energy_after :  70  reward :  -234.1478116166777\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "action : 1  next_temperatures :  [-0.24692729  0.75398628  0.11800739  0.41925506 -0.003794    0.71209223\n",
      " -0.41870032  0.9359362   0.20787927]  energy_before :  70  energy_after :  380  reward :  -505.5222651714756\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "action : 1  next_temperatures :  [0.02704106 2.07083455 0.16360874 1.44226011 0.06100966 1.74860768\n",
      " 0.07081602 2.11993772 0.0042794 ]  energy_before :  380  energy_after :  80  reward :  109.70839492037962\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "action : 1  next_temperatures :  [-0.32372145 -0.05773507 -0.36840691  0.28001498 -0.78143785 -0.25887283\n",
      " -0.48886433  0.12279897 -0.14570986]  energy_before :  80  energy_after :  70  reward :  -190.02193435129482\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "action : 1  next_temperatures :  [-0.11616967 -0.48579453  0.11800739 -0.66108415 -0.78143785  0.69365619\n",
      "  0.15240207  0.21647484 -0.16378086]  energy_before :  70  energy_after :  60  reward :  -189.0277265613974\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "action : 1  next_temperatures :  [-0.738825   -1.84955342 -0.61161406 -1.8896731  -1.1303806  -1.79520995\n",
      " -0.27674059 -1.41133529 -0.63181963]  energy_before :  60  energy_after :  70  reward :  -218.33515162679788\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "action : 1  next_temperatures :  [ 0.81781333 -0.51762674  2.98633174 -2.5113391   0.74394048 -0.78122745\n",
      "  1.57199947 -0.76635392  0.10728407]  energy_before :  70  energy_after :  90  reward :  -216.3491781283062\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "action : 1  next_temperatures :  [-1.05015267  1.18204574 -0.56601272  0.78018718 -1.18521446  1.71583249\n",
      " -0.55086974  1.03729042 -0.97697563]  energy_before :  90  energy_after :  250  reward :  -357.61386939279305\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "action : 1  next_temperatures :  [-0.42749733 -0.74631603 -0.88978224 -0.15490551 -0.43747999 -0.44630596\n",
      " -0.8103134  -0.63044713 -0.50170846]  energy_before :  250  energy_after :  240  reward :  -193.04475605642878\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "action : 1  next_temperatures :  [-0.09541449 -0.41961704 -0.46416972 -0.00501766  0.50965034 -0.99631465\n",
      " -0.45459819 -0.17665666  0.04042139]  energy_before :  240  energy_after :  90  reward :  -50.061716685270284\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "action : 1  next_temperatures :  [-0.11616967  0.25891165 -0.15560065  0.66497284  0.96327592  0.19895563\n",
      " -0.30611157  0.44682533  0.27534432]  energy_before :  90  energy_after :  110  reward :  -215.7695961889455\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "action : 1  next_temperatures :  [-0.13900036  0.08550987  0.21985039 -0.38260399  0.02777701  1.2364953\n",
      "  0.29762526  0.03142661 -0.80891538]  energy_before :  110  energy_after :  50  reward :  -137.4318352870493\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "action : 1  next_temperatures :  [ 0.12666591 -1.1735378  -0.61161406 -0.73398043 -0.03370338 -1.07927685\n",
      " -0.07603889 -1.1372182   0.16149705]  energy_before :  50  energy_after :  60  reward :  -212.5572066456833\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "action : 1  next_temperatures :  [ 0.68705571 -0.14066635 -0.20576213  0.76407902  0.50965034  0.10677541\n",
      " -0.47254712  0.47523522  0.3295573 ]  energy_before :  60  energy_after :  50  reward :  -185.94662260135343\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "action : 1  next_temperatures :  [ 0.37572804 -1.14589404  1.71405433 -2.42943317  0.18230881 -1.1929658\n",
      "  0.85404217 -1.2051716   0.05849238]  energy_before :  50  energy_after :  240  reward :  -390.78883888772236\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "action : 1  next_temperatures :  [-2.1522526   1.00445551 -1.22115198 -0.16964858 -1.92796404  0.80529668\n",
      " -2.31149685 -0.54444961 -1.94738806]  energy_before :  240  energy_after :  60  reward :  -26.46459952490821\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n",
      "action : 1  next_temperatures :  [ 0.5687512  -0.56034891  0.65040305 -0.61316919  0.34681039 -0.35412573\n",
      " -0.12499052  0.17577959  0.3295573 ]  energy_before :  60  energy_after :  120  reward :  -257.5813328229675\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "action : 1  next_temperatures :  [-0.09541449 -0.66003399 -0.33800601 -0.82407695 -0.33279717 -0.20049202\n",
      " -0.71730529 -0.24422614 -0.65169772]  energy_before :  120  energy_after :  50  reward :  -132.06404978932247\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "action : 1  next_temperatures :  [ 2.30595957e+00 -2.66319815e-01  2.69904329e+00 -1.30076946e+00\n",
      "  2.10980211e+00 -4.46305958e-01  2.33890840e+00  7.13213916e-04\n",
      "  2.11858581e+00]  energy_before :  50  energy_after :  90  reward :  -228.44038283930124\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "action : 1  next_temperatures :  [-1.05015267  0.55461613 -0.38360736  0.09081228 -0.63189095  0.80529668\n",
      " -1.0110151   0.77699436 -0.3806328 ]  energy_before :  90  energy_after :  80  reward :  -189.2295794199637\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "action : 1  next_temperatures :  [-1.18091029 -0.87196949 -1.61940369  0.06869768 -0.98581861 -0.54565576\n",
      " -0.41870032 -0.81242401 -1.02576732]  energy_before :  80  energy_after :  40  reward :  -165.39195181605265\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "action : 1  next_temperatures :  [-0.86958262 -0.89458712 -0.88978224 -0.76919998 -0.93596964 -0.62759374\n",
      " -0.76625693 -0.90686771 -0.48363747]  energy_before :  40  energy_after :  50  reward :  -215.14347744691625\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "action : 1  next_temperatures :  [-1.07298336 -0.62066257 -1.21963194 -0.10330477 -0.73657378  0.35566202\n",
      " -0.8103134  -0.37475808 -0.88300646]  energy_before :  50  energy_after :  100  reward :  -253.4655723486443\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "action : 1  next_temperatures :  [-0.34447662 -1.12327642 -1.02202613 -0.4006233  -1.08053164 -0.87340768\n",
      " -0.52149876 -0.95063431 -0.50170846]  energy_before :  100  energy_after :  20  reward :  -124.81818330922849\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "action : 1  next_temperatures :  [ 0.06440038 -0.5779404  -0.20576213 -0.68647499 -0.0503197  -1.34557529\n",
      "  0.56033236 -1.12723635 -0.59206344]  energy_before :  20  energy_after :  90  reward :  -271.96063955002336\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "action : 1  next_temperatures :  [-0.55825495  0.81429994 -0.47937017  1.38574502 -0.33279717  0.26040912\n",
      " -0.61450686  0.87527724 -0.18004475]  energy_before :  90  energy_after :  40  reward :  -146.82924258071245\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "action : 1  next_temperatures :  [ 0.12666591  0.56299302 -0.32280557  1.32841087  0.75889517  0.26040912\n",
      "  0.60928399  0.38539853  0.49219626]  energy_before :  40  energy_after :  60  reward :  -213.7985526919741\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n",
      "action : 1  next_temperatures :  [-1.54827693  0.9810002  -0.83962076  0.88693791 -1.23506343  1.67691195\n",
      " -2.11569031  1.74216291 -1.56789717]  energy_before :  60  energy_after :  260  reward :  -400.01953562937047\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "action : 1  next_temperatures :  [ 0.35704838 -0.26631982  0.36121455 -0.25073545  0.26040552 -0.44630596\n",
      "  0.11976765  0.22415319  0.3295573 ]  energy_before :  260  energy_after :  70  reward :  -7.31121462974059\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "action : 1  next_temperatures :  [2.12538953 2.0180601  1.79248863 1.78331641 1.86055729 1.4433887\n",
      " 2.17084113 1.63712309 2.66071566]  energy_before :  70  energy_after :  190  reward :  -300.5081194790226\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "action : 1  next_temperatures :  [-0.55825495 -0.88704791 -0.10999931 -1.20903482 -0.93596964 -0.73104044\n",
      "  0.50648556 -1.0581312  -1.02576732]  energy_before :  190  energy_after :  50  reward :  -64.00876003235607\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "action : 1  next_temperatures :  [-0.55825495 -0.5452705  -0.94906398  0.04166872 -0.63189095 -0.71977397\n",
      " -0.0156652  -0.64426816 -0.70591071]  energy_before :  50  energy_after :  170  reward :  -322.7284296995638\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "action : 1  next_temperatures :  [ 1.06064891 -0.38443407  0.43265665 -0.13688621  0.55949931 -0.20971004\n",
      "  0.07081602 -0.100641    0.37834899]  energy_before :  170  energy_after :  70  reward :  -96.32970144676366\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "action : 1  next_temperatures :  [ 0.21591317  0.36948669  1.07563555 -0.4006233   0.39832099 -0.13903853\n",
      "  1.22444286  0.01453424  0.47231816]  energy_before :  70  energy_after :  50  reward :  -174.7690101507215\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "action : 1  next_temperatures :  [ 0.12666591 -0.55280971 -0.15560065 -0.47188146 -0.53219302 -0.07451237\n",
      " -0.53618425  0.29095483  0.79639134]  energy_before :  50  energy_after :  70  reward :  -219.10916937667156\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "action : 1  next_temperatures :  [2.30595957 2.32046609 2.08147084 1.48438316 2.03835193 1.16377535\n",
      " 2.27363956 1.50490191 2.44386372]  energy_before :  70  energy_after :  60  reward :  -170.383187870581\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "action : 1  next_temperatures :  [-1.75686647  1.03168043 -0.97642479  0.87956638 -1.18521446  1.78752822\n",
      " -1.17092377  1.18317906 -1.33297423]  energy_before :  60  energy_after :  50  reward :  -189.5404496341141\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "action : 1  next_temperatures :  [-0.30296627  0.30330921 -0.79401942  1.14739877  0.46478627  0.20202831\n",
      " -0.12499052 -0.0545709   0.40932784]  energy_before :  50  energy_after :  40  reward :  -186.74969672015985\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "action : 1  next_temperatures :  [-0.3652318  -1.49102221 -0.10999931 -1.93881665 -0.38264613 -1.36810823\n",
      " -0.12499052 -1.39674642 -0.3806328 ]  energy_before :  40  energy_after :  60  reward :  -225.55819407480013\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "action : 1  next_temperatures :  [ 0.68705571 -0.06527428  0.16360874  0.32915853  0.26040552  0.01459518\n",
      "  0.41347746 -0.06839193  0.67264805]  energy_before :  60  energy_after :  20  reward :  -155.59271702922095\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "action : 1  next_temperatures :  [ 2.74804486  0.3770259   2.67168248 -0.48826264  3.1556334  -1.12536697\n",
      "  2.30301054  0.59041047  3.08899824]  energy_before :  20  energy_after :  120  reward :  -284.67882372811385\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n",
      "action : 1  next_temperatures :  [-1.02939749  0.57053223 -0.36840691  0.09982193 -0.63189095  0.77585022\n",
      " -0.99469789  0.80693993 -0.32099851]  energy_before :  120  energy_after :  50  reward :  -129.09224744115573\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "action : 1  next_temperatures :  [-0.11616967 -0.14988094  0.00704413 -0.19503942 -0.58204199  0.01459518\n",
      " -0.26042337 -0.11446203 -0.70591071]  energy_before :  50  energy_after :  50  reward :  -200.1022888169393\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "action : 1  next_temperatures :  [ 1.06064891  0.56173649  1.39302089  0.05149743  0.97823061 -0.10523912\n",
      "  1.19180844  0.28557999  0.87168715]  energy_before :  50  energy_after :  110  reward :  -251.71102920987855\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "action : 1  next_temperatures :  [1.93236637 1.75083707 1.67483717 1.91158109 2.14303476 1.19552631\n",
      " 1.92608295 1.44777499 2.38965073]  energy_before :  110  energy_after :  70  reward :  -141.6283085509177\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "action : 1  next_temperatures :  [-0.24692729 -0.45898845 -0.40032785  0.10801252 -0.18823517 -0.71977397\n",
      " -0.2082083  -0.26188634 -0.08968978]  energy_before :  70  energy_after :  60  reward :  -190.46602461921702\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "action : 1  next_temperatures :  [ 0.25742353  0.16844116 -0.26504387  0.98604409  0.50965034 -0.3817798\n",
      "  0.65823563 -0.0061973   0.64941392]  energy_before :  60  energy_after :  100  reward :  -235.42381230792833\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "action : 1  next_temperatures :  [-0.11616967  0.05200228 -0.15560065  0.04166872 -0.68672482  0.54002247\n",
      " -0.74993972  0.32397173 -0.92276265]  energy_before :  100  energy_after :  50  reward :  -149.67353228429843\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "action : 1  next_temperatures :  [-0.18466176  0.73890787 -0.12519976  0.82796564 -0.18823517  0.8472899\n",
      "  0.03491815  1.11407391 -0.75470239]  energy_before :  50  energy_after :  390  reward :  -535.6896435965897\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "action : 1  next_temperatures :  [ 1.50273419 -0.56788812  0.88867006 -0.4006233   1.11282282 -0.44630596\n",
      "  1.43656661 -0.51527188  0.81747417]  energy_before :  390  energy_after :  20  reward :  175.8281785873301\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "action : 1  next_temperatures :  [ 0.50648566  0.12571898  1.07563555 -0.50546289  0.41493731 -0.20049202\n",
      "  0.60928399  0.22415319  0.72066527]  energy_before :  20  energy_after :  50  reward :  -225.0290749514532\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "action : 1  next_temperatures :  [-0.05390414 -0.92977009 -0.20576213 -0.53085373  0.26040552 -1.58319543\n",
      "  0.41347746 -1.11187965  0.49219626]  energy_before :  50  energy_after :  20  reward :  -171.24928591898598\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "action : 1  next_temperatures :  [ 0.63101673 -0.76893366  0.30041276 -0.59474035  0.55949931 -0.59993967\n",
      "  0.96802954 -0.94076214  0.49219626]  energy_before :  20  energy_after :  20  reward :  -197.95322122715288\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "action : 1  next_temperatures :  [-0.86958262  0.55461613 -0.46416972  0.3881308  -0.68672482  1.5509323\n",
      " -1.45157981  1.06800381 -1.02576732]  energy_before :  20  energy_after :  40  reward :  -218.93614124010932\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "action : 1  next_temperatures :  [1.77104204 2.93101245 1.54561694 2.55893309 2.45235514 2.0090401\n",
      " 1.46086603 2.15453179 1.71394204]  energy_before :  40  energy_after :  50  reward :  -189.4026603896006\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "action : 1  next_temperatures :  [-0.05390414 -0.22395665 -0.12954274 -0.41782354 -0.78143785 -0.32032631\n",
      "  0.07081602 -1.0427745  -0.86312836]  energy_before :  50  energy_after :  60  reward :  -211.76207808081784\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "action : 1  next_temperatures :  [-0.90694194 -0.23448761 -1.06762747  0.19892811 -0.58204199  0.47549632\n",
      " -0.56555523 -0.16974615 -0.65169772]  energy_before :  60  energy_after :  60  reward :  -201.50367368015895\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "action : 1  next_temperatures :  [-0.30296627 -0.10715877 -0.29240467 -0.51447254  0.21554145 -0.19844357\n",
      " -1.25577327 -0.90686771 -1.19382757]  energy_before :  60  energy_after :  50  reward :  -192.55637292250964\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "action : 1  next_temperatures :  [ 1.06064891 -0.05019586  0.96771238 -0.18602976 -0.38264613  1.17299337\n",
      " -0.90821667  1.40661903 -0.32099851]  energy_before :  50  energy_after :  50  reward :  -195.24011324709102\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "action : 1  next_temperatures :  [-0.3652318  -0.25794292  0.39161544 -0.94693585 -0.25303882 -0.27935732\n",
      "  0.26172739 -0.77633577 -0.53785045]  energy_before :  50  energy_after :  60  reward :  -210.76335010555863\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "action : 1  next_temperatures :  [0.12666591 1.08068528 0.02224458 1.37100196 0.39001283 0.76893671\n",
      " 0.11976765 1.14555515 0.10728407]  energy_before :  60  energy_after :  60  reward :  -192.8678458782621\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "action : 1  next_temperatures :  [ 0.31968906 -1.5002368  -0.09479886 -1.17627245  0.31025448 -0.94612763\n",
      "  0.85404217 -1.41133529  0.49219626]  energy_before :  60  energy_after :  110  reward :  -251.15258906180546\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "action : 1  next_temperatures :  [-0.49598942 -0.50087294 -0.44896928 -0.44812874 -0.40092408 -0.62042416\n",
      " -0.52149876 -0.86079762 -0.75470239]  energy_before :  110  energy_after :  40  reward :  -133.05230739221415\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n",
      "action : 1  next_temperatures :  [-1.18091029 -1.12327642 -1.25003283 -0.64634109 -1.1303806  -0.41250654\n",
      " -1.45157981 -0.88152916 -0.75470239]  energy_before :  40  energy_after :  80  reward :  -246.83125912523928\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "action : 1  next_temperatures :  [-1.19958995 -0.53605591 -0.47937017 -0.62832178 -1.77841715  0.14057482\n",
      " -0.78094242 -0.23654779 -1.4648925 ]  energy_before :  80  energy_after :  110  reward :  -234.96356283706967\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "action : 1  next_temperatures :  [2.30595957 0.58561065 1.95346137 0.22657136 2.20950004 0.07912134\n",
      " 2.46455093 0.63648056 2.17279879]  energy_before :  110  energy_after :  270  reward :  -345.3659453922286\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "action : 1  next_temperatures :  [-0.67655947 -0.98003147 -1.29563417  0.01955412 -0.33279717 -1.32662713\n",
      " -0.61450686 -0.9967044  -0.32099851]  energy_before :  270  energy_after :  40  reward :  25.475694933929162\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "action : 1  next_temperatures :  [-0.61429393  0.58561065 -0.15560065  0.01136353 -0.48732896  0.6403965\n",
      " -0.6634585   0.46832471 -0.37069375]  energy_before :  40  energy_after :  50  reward :  -208.58568040651505\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "action : 1  next_temperatures :  [ 1.25367206 -2.21981228  1.39028481 -3.11826204  0.50965034 -1.40702877\n",
      "  1.24076008 -1.44358435  0.74338309]  energy_before :  50  energy_after :  20  reward :  -171.0509370727841\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "action : 1  next_temperatures :  [ 0.68705571 -1.30673047  0.02224458 -0.97969822  0.36508834 -0.93486116\n",
      "  0.80509053 -1.22705489  0.87168715]  energy_before :  20  energy_after :  80  reward :  -259.697178429572\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "action : 1  next_temperatures :  [-0.53749978  0.62079362 -0.61161406  1.24814306 -0.33279717  0.07912134\n",
      " -0.61450686  0.66949747 -0.16378086]  energy_before :  80  energy_after :  50  reward :  -167.64264323763743\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "action : 1  next_temperatures :  [-0.94637678 -0.12391256 -0.93538358 -0.02303696 -1.03068267 -0.01305889\n",
      " -1.07954739 -0.46805003 -0.90107745]  energy_before :  50  energy_after :  120  reward :  -273.52112631519685\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "action : 1  next_temperatures :  [1.92387562 1.98230598 1.96712123 1.165514   2.1807236  1.08891383\n",
      " 1.57993757 1.62895914 1.85899841]  energy_before :  120  energy_after :  60  reward :  -122.62365064566976\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "action : 1  next_temperatures :  [ 0.77215194  1.99544247  0.70626469 -0.0705424  -0.03370338  0.52773178\n",
      " -1.08770599  1.94410351 -0.97697563]  energy_before :  60  energy_after :  400  reward :  -534.2232330129136\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "action : 1  next_temperatures :  [ 0.25742353  0.17765574 -0.47937017  1.14739877  0.66418213 -0.33159279\n",
      "  0.60928399 -0.28492139  0.78649532]  energy_before :  400  energy_after :  70  reward :  134.5465551402362\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "action : 1  next_temperatures :  [-0.09541449  0.36194749 -0.79401942  1.31202969  0.7140311   0.07912134\n",
      "  0.36452582 -0.02923235  0.54640924]  energy_before :  70  energy_after :  40  reward :  -165.5406015878829\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "action : 1  next_temperatures :  [-1.02939749 -1.24892988 -0.38360736 -1.47932439 -1.1303806  -1.14073034\n",
      " -0.55086974 -1.15794975 -1.19382757]  energy_before :  40  energy_after :  60  reward :  -227.3150171053701\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "action : 1  next_temperatures :  [ 0.35704838  1.68465958  0.43265665  1.38738314 -0.18823517  1.94321038\n",
      "  0.45753393  1.45959965 -0.53785045]  energy_before :  60  energy_after :  30  reward :  -161.0039939141148\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "action : 1  next_temperatures :  [-0.80731709 -0.04265666 -0.72105728  0.28001498 -0.78143785 -0.13903853\n",
      " -0.90821667  0.0398728  -0.43484578]  energy_before :  30  energy_after :  50  reward :  -221.5146820796548\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "action : 1  next_temperatures :  [-0.03314896 -1.02024058 -0.31194811 -0.8688912  -0.73657378 -0.40482486\n",
      " -0.56555523 -0.86079762 -0.48966113]  energy_before :  50  energy_after :  80  reward :  -233.2916414529793\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "action : 1  next_temperatures :  [-1.8596046   0.81429994 -1.16339028  0.90168098 -1.37962543  1.18221139\n",
      " -1.64249118  1.09718154 -1.40525821]  energy_before :  80  energy_after :  50  reward :  -171.45499584191907\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "action : 1  next_temperatures :  [1.703116   3.35265977 1.3582817  3.17823046 2.57308027 2.41798511\n",
      " 1.40794534 2.38811964 1.64947254]  energy_before :  50  energy_after :  70  reward :  -197.971109164681\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "action : 1  next_temperatures :  [-0.49598942  0.62833282 -0.06439797 -0.05416122 -0.33279717  0.50929573\n",
      " -0.41870032  0.29940102 -0.32099851]  energy_before :  70  energy_after :  380  reward :  -508.2500150402931\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "action : 1  next_temperatures :  [ 0.74932124 -1.35615416  0.17728914 -1.26800709  0.11584352 -1.275928\n",
      "  0.19809027 -1.00515059  0.49219626]  energy_before :  380  energy_after :  60  reward :  118.82750057696862\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "action : 1  next_temperatures :  [ 0.52724084 -0.07365118  0.25025128  0.24889072 -0.0503197  -0.22814609\n",
      " -0.07603889  0.56967892  0.22113133]  energy_before :  60  energy_after :  50  reward :  -186.61096274187173\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "action : 1  next_temperatures :  [-0.24692729  1.22309254  0.11800739  0.92870994 -0.08355234  1.83054566\n",
      " -0.96206346  1.49108088 -0.32099851]  energy_before :  50  energy_after :  80  reward :  -224.02210520301784\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "action : 1  next_temperatures :  [-1.13939993  1.26413933 -0.56601272  1.03805435 -0.95258596  1.46182475\n",
      " -1.0110151   1.62698767 -1.13419329]  energy_before :  80  energy_after :  100  reward :  -217.41220089488957\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "action : 1  next_temperatures :  [ 0.52724084 -1.24892988 -0.15560065 -0.79131458  0.41493731 -0.73104044\n",
      "  0.75124373 -1.25239345  0.76326118]  energy_before :  100  energy_after :  50  reward :  -149.72259592936214\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "action : 1  next_temperatures :  [0.83856851 1.22309254 0.81722795 0.943453   0.46478627 1.8220958\n",
      " 0.36452582 2.23511296 0.42653831]  energy_before :  50  energy_after :  50  reward :  -188.86459882827577\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "action : 1  next_temperatures :  [-0.26560695  0.0754576  -0.50673098  0.78946986  0.66418213 -0.41250654\n",
      "  0.03235402 -0.29972964  0.45244007]  energy_before :  50  energy_after :  100  reward :  -247.47067042783672\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "action : 1  next_temperatures :  [ 0.06440038  0.59482523 -0.35320646  1.14739877  0.39832099  0.14057482\n",
      "  0.01696922 -0.0061973   0.49219626]  energy_before :  100  energy_after :  70  reward :  -165.50471809390368\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "action : 1  next_temperatures :  [ 1.44046866 -1.37458334  0.39161544 -0.99947265  0.90630568 -1.2184251\n",
      "  1.53936504 -1.45740538  2.22701178]  energy_before :  70  energy_after :  40  reward :  -166.5451198753772\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "action : 1  next_temperatures :  [ 0.85932368 -0.6106103   1.17899859 -1.36547515  0.36508834 -0.98709662\n",
      "  0.80509053 -0.56134198  0.3295573 ]  energy_before :  40  energy_after :  50  reward :  -207.98646559435096\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "action : 1  next_temperatures :  [ 0.25742353 -0.53438053 -0.25136347 -0.28349782 -0.48732896 -0.24863058\n",
      "  0.31557419 -0.7594434  -0.97697563]  energy_before :  50  energy_after :  70  reward :  -220.96862266817462\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "action : 1  next_temperatures :  [-0.98788713  0.84613215 -0.53561182  0.82796564 -0.93596964  1.62467648\n",
      " -1.64249118  1.88267671 -0.94685731]  energy_before :  70  energy_after :  60  reward :  -187.86736609176023\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "action : 1  next_temperatures :  [-0.96713196 -0.81919504 -1.52364088  0.14978455 -0.98581861 -0.56614025\n",
      " -0.76625693 -0.97597286 -0.53785045]  energy_before :  60  energy_after :  60  reward :  -204.99222242733177\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "action : 1  next_temperatures :  [1.78519329 2.84316926 1.58464511 2.4299128  2.42720407 1.92384322\n",
      " 1.47189117 2.10586766 1.72737319]  energy_before :  60  energy_after :  50  reward :  -169.70090022812548\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "action : 1  next_temperatures :  [-0.09541449 -0.76893366 -0.49305057 -0.52348219  0.11584352 -0.90720709\n",
      "  0.7022921  -1.1372182   0.37834899]  energy_before :  50  energy_after :  30  reward :  -180.7288216034945\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "action : 1  next_temperatures :  [ 0.12666591  0.84780753  0.11800739  0.64122012  0.16569248  0.72131026\n",
      " -0.56555523  0.73092426  0.10728407]  energy_before :  30  energy_after :  30  reward :  -195.10664319326204\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n",
      "action : 1  next_temperatures :  [ 0.50648566 -0.22611071  1.48604762 -1.15251973  0.41493731 -0.3817798\n",
      "  0.7022921  -0.23654779  0.72918445]  energy_before :  30  energy_after :  80  reward :  -246.15801088627276\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n",
      "action : 1  next_temperatures :  [-0.98788713  1.11586825 -0.38360736  0.90168098 -1.2799275   1.44134025\n",
      " -0.85926503  1.69839632 -1.06492114]  energy_before :  80  energy_after :  40  reward :  -157.41832235580034\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "action : 1  next_temperatures :  [ 0.88007886 -0.43553314  0.39161544 -0.2597451   0.06100966 -0.47396003\n",
      "  0.36452582 -0.28492139  0.60062223]  energy_before :  40  energy_after :  90  reward :  -247.15630764979798\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "action : 1  next_temperatures :  [1.93236637 1.79439694 1.30364226 1.98529643 2.10980211 0.80690618\n",
      " 2.07783302 1.62007715 2.27580346]  energy_before :  90  energy_after :  500  reward :  -592.0938760754686\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "action : 1  next_temperatures :  [ 0.12666591  0.38456511 -0.35320646  1.18179926  0.96327592  0.20202831\n",
      "  0.41347746  0.29095483  0.64941392]  energy_before :  500  energy_after :  60  reward :  245.85897425055092\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "action : 1  next_temperatures :  [ 0.63101673 -0.99762296  0.02224458 -0.44976686 -0.08355234 -1.02704139\n",
      " -0.27674059 -1.08270192 -0.55592145]  energy_before :  60  energy_after :  50  reward :  -191.8200861894477\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "action : 1  next_temperatures :  [-1.11864475  0.74644708 -0.50673098  0.21367117 -0.83128681  0.60147596\n",
      " -1.05507157  0.82306446 -0.47279487]  energy_before :  50  energy_after :  440  reward :  -589.5998703146699\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "action : 1  next_temperatures :  [ 0.25742353  0.91482271 -0.38360736  1.76169324  1.21252075  0.54002247\n",
      "  0.16871929  0.82076096  0.64941392]  energy_before :  440  energy_after :  30  reward :  217.94176950576784\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "action : 1  next_temperatures :  [-1.11864475 -0.84432573 -1.57380235  0.04166872 -0.98581861 -0.59993967\n",
      " -0.32079706 -0.8055135  -0.97697563]  energy_before :  30  energy_after :  60  reward :  -235.184148579557\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "action : 1  next_temperatures :  [-0.05390414  1.22078889  0.30041276  1.00979681 -0.90855271  2.01183344\n",
      " -1.50053144  1.76750147 -0.48092682]  energy_before :  60  energy_after :  50  reward :  -184.63358174629298\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "action : 1  next_temperatures :  [-0.18466176 -1.05542355 -0.33800601 -0.90680194 -0.48732896 -0.99631465\n",
      " -0.41870032 -0.87461865 -0.43484578]  energy_before :  50  energy_after :  100  reward :  -253.69670161587263\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "action : 1  next_temperatures :  [-1.36148033 -0.04935817 -1.70604624  0.65022978 -1.1303806  -0.67061118\n",
      " -0.8103134  -1.10496913 -1.11612229]  energy_before :  100  energy_after :  120  reward :  -225.29905157683478\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "action : 1  next_temperatures :  [-0.18466176 -0.62820178 -0.03703716 -0.57262575  0.94499797  0.50622306\n",
      " -0.41870032 -0.0545709  -0.21257254]  energy_before :  120  energy_after :  60  reward :  -138.65714919815488\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "action : 1  next_temperatures :  [ 0.0083614  -1.12767429 -0.29240467 -1.02884178 -0.50228365 -1.04752589\n",
      " -0.40238311 -0.96752668 -0.32099851]  energy_before :  60  energy_after :  60  reward :  -203.68127717474056\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n",
      "action : 1  next_temperatures :  [ 0.50648566  0.96257103 -0.10999931  1.647844    1.21252075  0.51953798\n",
      "  0.31557419  0.91520466  0.87168715]  energy_before :  60  energy_after :  50  reward :  -181.15857389684638\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "action : 1  next_temperatures :  [-0.11616967 -0.3249581  -0.29240467 -0.12787655 -0.71995746 -0.34285926\n",
      " -0.45459819  0.30093668 -0.57579954]  energy_before :  50  energy_after :  380  reward :  -530.6536867578181\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "action : 1  next_temperatures :  [-1.74130008 -0.41961704 -1.06762747 -0.52348219 -1.77841715  0.24197307\n",
      " -1.54458791 -0.21581625 -1.74680002]  energy_before :  380  energy_after :  70  reward :  103.20432496889833\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "action : 1  next_temperatures :  [ 0.12666591  1.022047    0.11800739  0.95082454 -0.13340131  1.46182475\n",
      "  0.68760661  1.39894068 -0.53785045]  energy_before :  70  energy_after :  100  reward :  -222.9053348762971\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "action : 1  next_temperatures :  [-1.21826961 -1.03113054 -1.16339028 -0.85683933 -1.08053164 -0.32032631\n",
      " -1.22313885 -0.5528958  -1.40525821]  energy_before :  100  energy_after :  20  reward :  -126.85178056727312\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "action : 1  next_temperatures :  [-0.49598942  0.41220887 -0.85634126  1.3218584   0.14907616 -0.23121876\n",
      " -0.36974869 -0.10755152  0.31406788]  energy_before :  20  energy_after :  50  reward :  -227.86363833223248\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "action : 1  next_temperatures :  [ 0.70781089 -0.10045725 -0.02335676  0.08344074  0.24545083 -0.47396003\n",
      "  0.7022921  -0.74976868  0.76326118]  energy_before :  50  energy_after :  40  reward :  -186.8452869744479\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "action : 1  next_temperatures :  [-0.738825    0.93995341 -0.29240467  0.80585104 -0.88113578  1.5509323\n",
      " -0.6634585   1.55097201 -1.04082648]  energy_before :  40  energy_after :  50  reward :  -206.7689416727311\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "action : 1  next_temperatures :  [-1.40714172 -0.56034891 -1.8474104   0.39365945 -1.08053164 -0.61837572\n",
      " -0.56555523 -0.66807104 -1.02576732]  energy_before :  50  energy_after :  90  reward :  -245.37954252026137\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "action : 1  next_temperatures :  [-0.738825   -0.04098128 -0.33800601 -0.19503942 -0.81467049  0.26245757\n",
      " -0.27674059 -0.37475808 -0.80891538]  energy_before :  90  energy_after :  40  reward :  -151.3254786781944\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n",
      "action : 1  next_temperatures :  [-0.98788713 -0.19930464 -1.10106845  0.15715608 -0.78143785 -0.00588932\n",
      " -0.6634585  -0.5221824  -0.63181963]  energy_before :  40  energy_after :  110  reward :  -272.7358918254995\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "action : 1  next_temperatures :  [ 0.43799358 -0.01501289  0.52841946 -0.20404907 -0.73657378  0.79403021\n",
      " -0.32079706  1.00734485  0.0042794 ]  energy_before :  110  energy_after :  50  reward :  -136.50436530048324\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "action : 1  next_temperatures :  [-0.49598942  0.27650313 -1.06762747  1.23995247  0.21554145 -0.17795907\n",
      " -0.17394215 -0.01387565  0.3440141 ]  energy_before :  50  energy_after :  60  reward :  -207.85338261564544\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "action : 1  next_temperatures :  [-1.23694927  1.44256725 -0.64505504  1.29728662 -1.18521446  1.79674624\n",
      " -1.1040232   1.89649774 -1.13419329]  energy_before :  60  energy_after :  60  reward :  -196.87233741636854\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "action : 1  next_temperatures :  [ 1.1063103   0.26980162  1.71253428 -0.62832178  1.30723378 -0.25887283\n",
      "  1.43656661  0.07672888 -0.10956787]  energy_before :  60  energy_after :  60  reward :  -193.08758702134608\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "action : 1  next_temperatures :  [-0.45032803 -1.32180888 -0.43376883 -1.30977912 -0.58204199 -1.59241345\n",
      " -0.22778895 -1.27312499 -0.32099851]  energy_before :  60  energy_after :  20  reward :  -165.51205275729222\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "action : 1  next_temperatures :  [ 0.25742353 -0.41961704 -0.05071757 -0.299879    0.09756556 -0.47396003\n",
      "  0.16871929 -0.44616674  0.3295573 ]  energy_before :  20  energy_after :  110  reward :  -288.83707468477553\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "action : 1  next_temperatures :  [-0.18466176 -0.6432802  -0.09479886 -0.48007205  0.21554145 -0.81502687\n",
      " -0.50518155  0.06905053 -0.21257254]  energy_before :  110  energy_after :  50  reward :  -140.65100184747553\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "action : 1  next_temperatures :  [ 0.25742353 -1.44746234  0.02224458 -1.18692022 -0.68672482 -0.91642512\n",
      "  0.10345044 -1.06580955  0.90602204]  energy_before :  50  energy_after :  40  reward :  -192.01420145672938\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "action : 1  next_temperatures :  [-0.49598942 -0.8795087  -0.93538358 -0.20404907 -0.53219302 -0.92666736\n",
      " -0.61450686 -1.06580955 -0.70591071]  energy_before :  40  energy_after :  40  reward :  -204.36001828081837\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "action : 1  next_temperatures :  [-1.82224528  1.19126033 -1.02202613  0.91970028 -1.52917232  1.43877969\n",
      " -1.20682164  1.31217533 -2.23833108]  energy_before :  40  energy_after :  50  reward :  -210.95668080790307\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "action : 1  next_temperatures :  [ 0.06440038 -1.30673047 -0.56601272 -0.69548464  0.36508834 -0.75357338\n",
      "  0.60928399 -1.34223014  0.27534432]  energy_before :  50  energy_after :  80  reward :  -231.3499143183555\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "action : 1  next_temperatures :  [ 0.25742353 -0.9205555  -0.15560065 -0.60375    -0.03370338 -1.23291056\n",
      "  0.31557419 -1.41133529 -0.57399244]  energy_before :  80  energy_after :  80  reward :  -202.35885010471443\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "action : 1  next_temperatures :  [ 2.68577932 -0.30987968  2.17006773 -0.75118068  2.65814073 -1.71224775\n",
      "  2.25825476  0.25574411  2.83781141]  energy_before :  80  energy_after :  80  reward :  -187.90751004252346\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n",
      "action : 1  next_temperatures :  [-0.86958262  0.83691757 -0.38360736  0.65596319 -1.03068267  1.58473172\n",
      " -1.29982974  1.37590564 -0.7438598 ]  energy_before :  80  energy_after :  50  reward :  -167.8740440733885\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "action : 1  next_temperatures :  [-0.24692729  1.18288343  0.13320784  0.87956638 -1.047299    1.92272588\n",
      " -0.17394215  1.86732001 -0.21257254]  energy_before :  50  energy_after :  60  reward :  -203.69503743491518\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "action : 1  next_temperatures :  [ 0.63101673  0.76320087  0.66066335 -0.07218052 -0.13340131  1.32662708\n",
      " -0.9261656   1.86732001 -0.15835956]  energy_before :  60  energy_after :  40  reward :  -174.0412789410321\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "action : 1  next_temperatures :  [2.43671719 1.61848209 2.62608114 0.68299215 2.00511929 1.32399336\n",
      " 2.34217185 1.1225201  2.44386372]  energy_before :  40  energy_after :  50  reward :  -191.39805911938925\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "action : 1  next_temperatures :  [-1.05015267 -1.50610063 -0.56753276 -1.17627245 -1.03068267 -1.21140184\n",
      " -0.50518155 -1.41133529 -0.75470239]  energy_before :  50  energy_after :  80  reward :  -237.21336224793163\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "action : 1  next_temperatures :  [-1.42997242 -0.25878061 -0.96274438 -0.26875475 -1.68370411 -0.11650559\n",
      " -1.39773301 -0.19047769 -1.21189857]  energy_before :  80  energy_after :  90  reward :  -215.5205711323489\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "action : 1  next_temperatures :  [-0.30296627 -0.12558794 -0.44896928  0.3881308  -0.01874869 -0.50775944\n",
      " -0.17394215  0.12970949  0.43256198]  energy_before :  90  energy_after :  40  reward :  -148.62757150166496\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "action : 1  next_temperatures :  [-2.36395542  0.04362539 -1.60420325  0.13340336 -2.07751094  0.17949536\n",
      " -2.47466896  0.24488473 -2.00702234]  energy_before :  40  energy_after :  70  reward :  -237.92595205985822\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "action : 1  next_temperatures :  [ 0.31968906 -0.19092774  0.10280695 -0.67910346 -0.01874869 -0.6798292\n",
      "  0.71627828 -0.55673497  0.56448024]  energy_before :  70  energy_after :  90  reward :  -218.42208952457608\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "action : 1  next_temperatures :  [ 0.06440038  0.368649   -0.33800601  1.43488858 -0.03370338 -0.22814609\n",
      "  0.16871929  0.08594289  0.16149705]  energy_before :  90  energy_after :  30  reward :  -136.31575828113478\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "action : 1  next_temperatures :  [-0.24692729  0.66351579 -0.03703716 -0.68483687 -0.73657378  0.03712812\n",
      " -0.47254712 -0.55136013 -0.86312836]  energy_before :  30  energy_after :  130  reward :  -300.89176680267\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "action : 1  next_temperatures :  [-0.67655947  0.91482271 -0.25136347  0.74851689 -0.83128681  1.5509323\n",
      " -0.56555523  1.51181242 -1.02576732]  energy_before :  130  energy_after :  350  reward :  -416.62444796288486\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "action : 1  next_temperatures :  [-0.20541693 -0.02422748 -0.70737688  0.96802478  0.06100966 -0.50775944\n",
      " -0.41870032  0.23797422  0.10728407]  energy_before :  350  energy_after :  40  reward :  111.51081166731288\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "action : 1  next_temperatures :  [-0.11616967  1.19126033  0.20464994  0.95082454 -0.03370338  1.73836543\n",
      " -0.90821667  1.49108088 -0.32099851]  energy_before :  40  energy_after :  60  reward :  -213.80290710954196\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "action : 1  next_temperatures :  [-0.98788713  1.23230712 -0.47937017  1.02453987 -0.88113578  1.53249626\n",
      " -0.41870032  1.58322108 -1.0980513 ]  energy_before :  60  energy_after :  50  reward :  -186.49258037656503\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "action : 1  next_temperatures :  [1.73990927 3.12426747 1.45975496 2.84277772 2.50768749 2.19647323\n",
      " 1.43661071 2.26159289 1.68439352]  energy_before :  50  energy_after :  60  reward :  -188.74653274484575\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "action : 1  next_temperatures :  [-1.16015511 -0.80244125 -0.77881898 -1.06406133 -1.2799275  -0.84268094\n",
      " -0.41870032 -0.81242401 -1.12644858]  energy_before :  60  energy_after :  50  reward :  -196.28565800513041\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "action : 1  next_temperatures :  [-0.11616967 -0.01668827 -0.00815632 -0.37359434  0.39832099 -0.24043678\n",
      "  0.42816295 -1.25776829 -0.51977946]  energy_before :  50  energy_after :  90  reward :  -239.70610920075868\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "action : 1  next_temperatures :  [-0.49598942 -0.47657994  1.66845298 -1.43263801  0.09756556 -1.46745803\n",
      " -0.19189109 -0.60510857 -0.16378086]  energy_before :  90  energy_after :  30  reward :  -141.06742736914535\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "action : 1  next_temperatures :  [-1.19958995 -0.48579453 -0.43376883 -0.75118068 -1.48430825  0.09755738\n",
      " -0.3240605  -0.41391767 -1.00980461]  energy_before :  30  energy_after :  130  reward :  -304.0048676203275\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "action : 2  next_temperatures :  [-0.09581406 -0.33856268  0.49326902 -0.51208676 -0.39790338 -0.56988051\n",
      "  0.92396111 -0.25239345 -0.02576732]  energy_before :  130  energy_after :  50  reward :  -127.77517801132541\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "action : 1  next_temperatures :  [-1.11864475  0.7037249  -0.47937017  0.19892811 -0.88113578  0.69365619\n",
      " -1.05507157  0.69176468 -0.51375579]  energy_before :  50  energy_after :  60  reward :  -209.75990419236464\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "action : 1  next_temperatures :  [ 1.12914099  0.34351831  0.87840975  0.19984955  1.05798895 -0.10523912\n",
      "  1.14775197  0.2771338   1.65235414]  energy_before :  60  energy_after :  30  reward :  -161.41909164605153\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n",
      "action : 1  next_temperatures :  [ 1.06064891 -0.13396484  0.21605028  0.47228915  1.25738481 -0.44630596\n",
      "  1.17712295 -0.100641   -0.16842769]  energy_before :  30  energy_after :  50  reward :  -214.66584338577343\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "action : 1  next_temperatures :  [ 0.99838337  0.50435474  0.98899301  0.56925992  1.05798895 -0.20049202\n",
      "  1.09880034  0.2310637   0.97469182]  energy_before :  50  energy_after :  100  reward :  -241.7769561615278\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "action : 1  next_temperatures :  [ 1.06064891 -0.51762674  1.98766237 -1.5776115   1.36206764 -0.30189027\n",
      "  1.45288382 -0.32254531 -0.16378086]  energy_before :  100  energy_after :  60  reward :  -155.02019193017435\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "action : 1  next_temperatures :  [-0.65580429 -1.26400829 -0.72105728 -0.65453168 -0.43747999 -1.54017799\n",
      "  0.36452582 -1.55184908 -0.61194153]  energy_before :  60  energy_after :  30  reward :  -175.07232431341353\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "action : 1  next_temperatures :  [ 1.62103871 -0.20768153  0.98443287 -0.12787655  1.86055729 -0.51697747\n",
      "  1.83307485 -0.58207352  1.90173387]  energy_before :  30  energy_after :  50  reward :  -211.23377149315482\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "action : 1  next_temperatures :  [2.37445166 2.26182781 2.3524731  1.46928907 1.96025522 1.92272588\n",
      " 2.32259119 1.25151637 2.4980767 ]  energy_before :  50  energy_after :  220  reward :  -349.5867929962419\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "action : 1  next_temperatures :  [ 0.81781333 -1.04788434  0.16360874 -0.61931213  0.80874413 -0.62759374\n",
      "  0.85404217 -1.06580955  0.0042794 ]  energy_before :  220  energy_after :  530  reward :  -508.71211200460755\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "action : 1  next_temperatures :  [-0.42749733  0.96257103 -0.06439797  0.82059411 -0.2829482   1.52327823\n",
      " -0.56555523  1.13019845 -0.37069375]  energy_before :  530  energy_after :  130  reward :  204.72554933605215\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "action : 1  next_temperatures :  [ 0.37572804  1.18288343  0.33081365  1.01716834 -0.18823517  1.5509323\n",
      "  0.75124373  1.48340253 -0.51616526]  energy_before :  130  energy_after :  80  reward :  -142.01222839763201\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "action : 1  next_temperatures :  [-1.25770444  1.20633874 -0.66177553  1.03354953 -0.95258596  1.41983153\n",
      " -1.1040232   1.62698767 -1.13419329]  energy_before :  80  energy_after :  40  reward :  -157.8235749613999\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "action : 1  next_temperatures :  [ 1.12914099 -0.85437801  0.93557429 -1.44562595  1.00813999 -1.30358207\n",
      "  1.22444286 -1.38215756  1.95594685]  energy_before :  40  energy_after :  90  reward :  -246.73249859746656\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "action : 1  next_temperatures :  [-0.11616967 -0.39364866 -0.70737688 -0.12787655 -0.2829482  -0.90720709\n",
      "  0.26172739 -0.42806777  0.16149705]  energy_before :  90  energy_after :  230  reward :  -340.54007037378426\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "action : 1  next_temperatures :  [ 0.5687512  -0.14988094 -0.02335676  0.3881308   0.24545083  0.0483946\n",
      "  0.36452582 -0.12137255  0.60062223]  energy_before :  230  energy_after :  260  reward :  -226.07873477637105\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "action : 1  next_temperatures :  [ 1.44046866  0.07713298  1.80069687 -0.92989941  1.16267178 -0.20049202\n",
      "  1.39251014 -0.021554    1.08853909]  energy_before :  260  energy_after :  60  reward :  7.810074093110359\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "action : 1  next_temperatures :  [-0.18466176  0.85534674  0.21985039  0.32014888 -0.43747999  1.17299337\n",
      " -1.05507157  0.50057378 -0.3806328 ]  energy_before :  60  energy_after :  70  reward :  -206.9889329569327\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "action : 1  next_temperatures :  [1.79934455 2.75532606 1.62367329 2.30089252 2.402053   1.83864634\n",
      " 1.48291631 2.05720352 1.74080433]  energy_before :  70  energy_after :  50  reward :  -159.9991400666504\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "action : 1  next_temperatures :  [ 1.75179633 -0.82840963  1.54532936 -1.49570558  1.28729419 -0.84268094\n",
      "  1.68132478 -0.28492139  0.93596826]  energy_before :  50  energy_after :  50  reward :  -194.25000460079846\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "action : 1  next_temperatures :  [-0.05390414  1.52466084  0.16360874  1.22357128 -0.33279717  1.41983153\n",
      "  0.7022921   1.28146193 -0.55333988]  energy_before :  50  energy_after :  50  reward :  -192.6246147522644\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "action : 1  next_temperatures :  [ 0.50648566 -1.74232913  0.40529584 -1.94618819  0.61433317 -1.07005883\n",
      "  1.0094636  -1.40557652  0.90421494]  energy_before :  50  energy_after :  130  reward :  -280.72435945075466\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "action : 1  next_temperatures :  [-0.40674216 -0.05773507 -0.36840691 -0.23517332  0.50965034 -0.49649297\n",
      "  0.62560121 -0.67651722 -0.92276265]  energy_before :  130  energy_after :  60  reward :  -130.02857875204992\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "action : 1  next_temperatures :  [-5.39041355e-02 -1.18048732e-01  1.17899859e+00 -8.00324234e-01\n",
      " -8.35523410e-02 -4.64742003e-01  6.52008481e-04  1.45342433e-02\n",
      "  5.84923801e-02]  energy_before :  60  energy_after :  50  reward :  -188.26789422149642\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n",
      "action : 1  next_temperatures :  [-2.54452546  0.87963974 -1.5890028   0.66661096 -1.9827979   1.24366488\n",
      " -2.00473327  1.72834188 -2.27808727]  energy_before :  50  energy_after :  20  reward :  -173.88088923933338\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "action : 1  next_temperatures :  [ 0.0083614   1.16612963  0.22745061  0.94652448  0.01116069  1.73648768\n",
      " -0.27674059  1.62698767 -0.3806328 ]  energy_before :  20  energy_after :  60  reward :  -232.93427121643808\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "action : 1  next_temperatures :  [-0.18466176 -0.43469545 -0.90498269  0.43727436  0.09756556 -0.10523912\n",
      " -0.47254712 -0.02923235  0.0042794 ]  energy_before :  60  energy_after :  70  reward :  -209.59223916223178\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "action : 1  next_temperatures :  [ 0.31968906 -1.5898696  -0.08415855 -1.50389617  1.00813999 -1.32509079\n",
      "  0.07081602 -1.27312499 -0.75470239]  energy_before :  70  energy_after :  60  reward :  -193.13219742364157\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "action : 1  next_temperatures :  [ 0.195158   -1.09563265 -0.38360736 -0.54559679 -0.18823517 -1.13612133\n",
      " -0.0466679  -0.97597286 -0.59206344]  energy_before :  60  energy_after :  30  reward :  -172.76873950316318\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "action : 1  next_temperatures :  [-0.09541449 -0.59301881  1.14707765 -1.82332929  0.11584352 -1.24212859\n",
      "  0.01696922 -0.93604544 -0.0137916 ]  energy_before :  30  energy_after :  60  reward :  -231.42383783394376\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "action : 1  next_temperatures :  [ 0.08515556  0.50435474  1.10299636 -0.36540375  0.36508834 -0.14825656\n",
      "  1.34355851  0.11588846  0.43256198]  energy_before :  60  energy_after :  270  reward :  -404.56405636493014\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "action : 1  next_temperatures :  [-0.738825   -0.81919504 -1.16339028 -0.12787655 -1.08053164 -0.59993967\n",
      "  0.31557419 -0.73717619 -0.80891538]  energy_before :  270  energy_after :  40  reward :  26.23972443539455\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "action : 1  next_temperatures :  [ 0.25742353  0.06037918 -0.70737688  1.15640842  0.86357799 -0.15747458\n",
      "  0.21277576 -0.21581625  0.60062223]  energy_before :  40  energy_after :  60  reward :  -215.92948058980173\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "action : 1  next_temperatures :  [ 0.74932124 -0.68600237  0.91907095 -1.20166329  2.32415266 -0.5763825\n",
      "  0.9960019  -1.0427745   0.64941392]  energy_before :  60  energy_after :  50  reward :  -185.86886199107025\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "action : 1  next_temperatures :  [-2.73754861  0.64508662 -1.80180906  0.63384859 -2.2769068   0.54002247\n",
      " -2.69005615  0.73783478 -2.1732755 ]  energy_before :  50  energy_after :  50  reward :  -207.122803654742\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "action : 1  next_temperatures :  [-1.11864475 -0.96243999 -0.93082345 -0.57016857 -1.18521446 -0.93486116\n",
      " -0.3860659  -0.95063431 -0.92276265]  energy_before :  50  energy_after :  40  reward :  -195.96161524017793\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "action : 1  next_temperatures :  [-1.05015267 -0.56788812 -0.35320646 -0.69548464 -1.76346246  0.10677541\n",
      " -0.45459819 -0.40009664 -1.36610439]  energy_before :  40  energy_after :  60  reward :  -224.54421816054122\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "action : 1  next_temperatures :  [ 0.43799358 -1.30673047 -0.22096257 -0.96331703  0.01116069 -1.09976135\n",
      "  0.07081602 -1.1372182   0.27534432]  energy_before :  60  energy_after :  130  reward :  -271.9326750191717\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n",
      "action : 1  next_temperatures :  [-0.3652318  -0.76893366 -0.15560065 -0.8067597  -0.99222776 -0.43664898\n",
      "  0.50648556 -0.8659805  -0.90572428]  energy_before :  130  energy_after :  40  reward :  -112.7906217689195\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "action : 1  next_temperatures :  [-0.45240355 -1.1735378   0.11800739 -1.60218328 -1.03068267 -0.95739411\n",
      "  0.08713323 -1.14259305 -0.88300646]  energy_before :  40  energy_after :  320  reward :  -485.0366602944954\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "action : 1  next_temperatures :  [-0.42749733 -0.56788812 -0.21640244 -0.3342795  -0.08355234 -1.08849487\n",
      "  0.33515484 -0.88152916  0.05849238]  energy_before :  320  energy_after :  80  reward :  38.79400345718625\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "action : 1  next_temperatures :  [ 1.19140653 -1.60829877  0.91603086 -2.21352914  0.94191208 -1.54939601\n",
      "  1.08248312 -1.65934598  1.68488193]  energy_before :  80  energy_after :  60  reward :  -179.21385538621368\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "action : 1  next_temperatures :  [-0.53749978 -0.47657994  1.54532936 -1.09600464  0.13245984 -1.41829524\n",
      " -0.27674059 -0.54444961 -0.16378086]  energy_before :  60  energy_after :  60  reward :  -200.83556144866978\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "action : 1  next_temperatures :  [-0.9256216  -0.40118786 -0.87306175 -0.34902256 -0.68672482 -0.07451237\n",
      " -0.58187244 -0.36707973 -0.92276265]  energy_before :  60  energy_after :  40  reward :  -183.1818457824822\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "action : 1  next_temperatures :  [-0.55825495  1.06560687 -0.06439797  0.47740827 -0.33279717  1.6990352\n",
      " -0.17394215  1.30680049 -0.21257254]  energy_before :  40  energy_after :  100  reward :  -254.793113967058\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "action : 1  next_temperatures :  [ 0.63101673 -0.14988094  0.66066335 -0.5636161   0.9466596  -0.67061118\n",
      "  0.80509053 -0.19546862  0.64941392]  energy_before :  100  energy_after :  30  reward :  -125.88673271057266\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "action : 1  next_temperatures :  [-0.49598942  0.57430184 -0.06439797 -0.00501766 -0.23808413  0.62913003\n",
      " -0.3240605   0.63648056 -0.32099851]  energy_before :  30  energy_after :  60  reward :  -227.6086357662984\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "action : 1  next_temperatures :  [-0.11616967 -0.44223466 -0.74841808 -0.10330477 -0.2829482  -0.90720709\n",
      "  0.26172739 -0.48993333  0.16149705]  energy_before :  60  energy_after :  50  reward :  -190.66699136644803\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "action : 1  next_temperatures :  [ 1.21216171  1.27419161  1.08931596 -0.75199974  0.86357799 -0.33159279\n",
      "  0.31557419 -0.0061973   0.3295573 ]  energy_before :  50  energy_after :  60  reward :  -204.00541106651227\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "action : 1  next_temperatures :  [ 1.74451854 -0.80258267  1.52392042 -1.45092324  1.28334512 -0.84607285\n",
      "  1.67560316 -0.25270224  0.97398776]  energy_before :  60  energy_after :  70  reward :  -204.15090600283563\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "action : 1  next_temperatures :  [-0.98788713 -0.55280971 -0.82442032 -0.45713839 -0.83128681 -0.71977397\n",
      " -0.50518155 -0.77633577 -0.73379167]  energy_before :  70  energy_after :  60  reward :  -194.38862531059598\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "action : 1  next_temperatures :  [-0.49598942 -0.99762296 -1.02202613 -0.22616367 -0.03370338 -0.79249392\n",
      " -0.36974869 -1.02204296 -0.65169772]  energy_before :  60  energy_after :  20  reward :  -163.61148884252194\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "action : 1  next_temperatures :  [-0.69731464 -1.28997667 -0.29240467 -1.39823752 -1.08053164 -1.1806751\n",
      " -0.41870032 -1.15794975 -1.19382757]  energy_before :  20  energy_after :  70  reward :  -256.7096178948926\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "action : 1  next_temperatures :  [-0.30296627 -1.04788434 -1.16339028 -0.02303696 -0.48732896 -1.08849487\n",
      " -0.03198241 -1.31305241 -0.39870379]  energy_before :  70  energy_after :  150  reward :  -283.8568403041363\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "action : 1  next_temperatures :  [1.23810568 0.90791177 1.07563555 0.52362661 1.05798895 0.23275505\n",
      " 1.40719563 0.84609951 0.81747417]  energy_before :  150  energy_after :  80  reward :  -119.89320706982991\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "action : 1  next_temperatures :  [-0.55825495  0.76152549 -0.66177553  1.42014551 -0.33279717  0.16822889\n",
      " -0.61450686  0.82076096 -0.19630865]  energy_before :  80  energy_after :  50  reward :  -167.19298231258057\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "action : 1  next_temperatures :  [-0.3652318  -0.72872455 -0.35320646 -0.84045814 -0.86451946 -0.69928947\n",
      " -0.47254712 -0.88997534  0.07800905]  energy_before :  50  energy_after :  40  reward :  -193.1359432926342\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "action : 1  next_temperatures :  [-0.9256216  -0.78736283 -1.34579565  0.01955412 -0.78143785 -0.50775944\n",
      " -1.1040232  -0.63044713 -0.70591071]  energy_before :  40  energy_after :  40  reward :  -204.76880428894512\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "action : 1  next_temperatures :  [-2.17093226 -0.16831012 -1.3609961  -0.34165103 -1.87811508  0.24197307\n",
      " -1.82198051 -0.22272676 -1.89317508]  energy_before :  40  energy_after :  70  reward :  -237.6159138494922\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "action : 1  next_temperatures :  [ 0.88007886  0.3937797   0.9342714   0.05067837 -0.23808413  1.28770654\n",
      "  0.02186438  1.35171883  0.39943182]  energy_before :  70  energy_after :  50  reward :  -172.91855422727735\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "action : 1  next_temperatures :  [-0.05390414 -0.2998274  -0.70737688  0.57651444  0.06100966 -0.34285926\n",
      " -0.17394215 -0.48993333  0.27534432]  energy_before :  50  energy_after :  110  reward :  -259.15497473895874\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "action : 1  next_temperatures :  [-0.67655947  0.83691757 -0.70737688  1.19654233 -0.38264613  0.89184368\n",
      " -0.32079706  0.63648056 -0.3806328 ]  energy_before :  110  energy_after :  50  reward :  -136.90622819265218\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "action : 1  next_temperatures :  [1.7965143  2.7728947  1.61586765 2.32669657 2.40708321 1.85568572\n",
      " 1.48071128 2.06693635 1.7381181 ]  energy_before :  50  energy_after :  110  reward :  -239.9394920989454\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "action : 1  next_temperatures :  [ 0.43799358  1.19126033  0.41897624  1.00242527 -0.18823517  1.58473172\n",
      "  0.73492652  1.54329366 -0.48363747]  energy_before :  110  energy_after :  40  reward :  -121.7582653185784\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "action : 1  next_temperatures :  [1.70613494 3.16737041 1.42372579 3.14017003 2.83925863 2.22896908\n",
      " 1.43656661 2.43321438 1.68488193]  energy_before :  40  energy_after :  470  reward :  -607.9397081908128\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "action : 1  next_temperatures :  [-0.86958262  0.72508599 -0.49305057  0.70510675 -0.89941373  1.72709896\n",
      " -1.60985676  1.87423053 -1.05287381]  energy_before :  470  energy_after :  90  reward :  182.10674472842507\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "action : 1  next_temperatures :  [-0.42749733 -0.83594884 -0.20576213 -0.89205888 -0.83128681 -0.66139315\n",
      " -0.41870032 -0.7748001  -0.86312836]  energy_before :  90  energy_after :  50  reward :  -163.9105759286646\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "action : 1  next_temperatures :  [-0.24692729 -0.71867227  0.20464994 -1.19265364 -0.33279717 -0.53541351\n",
      "  0.21277576 -1.00515059 -0.53785045]  energy_before :  50  energy_after :  50  reward :  -202.1520392181714\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "action : 1  next_temperatures :  [ 0.12666591 -1.22128612 -0.46416972 -0.72578984 -0.76648316 -0.90720709\n",
      " -0.20984002 -1.1372182  -0.34087661]  energy_before :  50  energy_after :  40  reward :  -193.64620485180208\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "action : 1  next_temperatures :  [1.81406186 1.13848587 0.84762885 1.46928907 1.86055729 1.12383058\n",
      " 1.58831668 1.0303799  2.11858581]  energy_before :  40  energy_after :  70  reward :  -215.00886409145622\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "action : 1  next_temperatures :  [-0.42749733 -0.2755344  -0.83962076  0.6739825  -0.23808413 -0.56614025\n",
      " -0.47254712 -0.16974615 -0.16378086]  energy_before :  70  energy_after :  70  reward :  -200.4789685187582\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "action : 1  next_temperatures :  [-1.61054246  1.49282863 -0.67697598  1.17442773 -1.29654382  1.66564547\n",
      " -2.18585432  1.9725134  -1.01733419]  energy_before :  70  energy_after :  20  reward :  -148.48183554061208\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "action : 1  next_temperatures :  [ 0.25742353 -0.39197328 -0.76361853  0.52573276  0.06100966 -0.50775944\n",
      "  0.56033236 -0.50006875  0.54640924]  energy_before :  20  energy_after :  50  reward :  -228.21251244246199\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "action : 1  next_temperatures :  [ 0.88007886  0.03524849  2.88448874 -1.66770803  0.96327592 -0.62759374\n",
      "  1.34355851 -0.12137255  0.01976882]  energy_before :  50  energy_after :  70  reward :  -214.29025496912945\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "action : 1  next_temperatures :  [-0.18466176 -1.19615542 -1.20443149  0.05968803 -0.2829482  -1.22369254\n",
      " -0.27674059 -1.21323386  0.0042794 ]  energy_before :  70  energy_after :  270  reward :  -403.51789644128326\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "action : 1  next_temperatures :  [ 0.52724084 -1.42484472 -0.20576213 -0.87403957  0.63094949 -0.67061118\n",
      "  0.80509053 -1.41133529  0.64941392]  energy_before :  270  energy_after :  370  reward :  -299.9738981047341\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "action : 1  next_temperatures :  [-0.67655947  0.54623923 -0.20576213  0.06869768 -0.63189095  0.48676279\n",
      " -0.79562791  0.49059192 -0.3806328 ]  energy_before :  370  energy_after :  50  reward :  120.90181836230357\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "action : 1  next_temperatures :  [ 0.43799358 -0.37689486  2.39807444 -2.15095301  0.46478627 -0.50775944\n",
      "  0.9960019  -0.33099149  0.54640924]  energy_before :  50  energy_after :  40  reward :  -186.52333336841846\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "action : 1  next_temperatures :  [-1.98413566  0.48760095 -1.16339028  0.28738651 -1.9827979   1.35837805\n",
      " -2.45998347  1.81357156 -2.27808727]  energy_before :  40  energy_after :  30  reward :  -193.9214575214182\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "action : 1  next_temperatures :  [ 0.25742353 -0.3165812  -0.33800601  0.23169048  0.01116069 -0.13903853\n",
      "  0.42816295 -0.42082818  0.05849238]  energy_before :  30  energy_after :  250  reward :  -418.22752390162907\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "action : 1  next_temperatures :  [ 0.72856606 -0.52684132  1.24284047 -1.11975736  0.21554145 -0.25887283\n",
      "  0.56033236 -0.53600343  0.64941392]  energy_before :  250  energy_after :  70  reward :  -17.044780679688103\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "action : 1  next_temperatures :  [-0.98788713 -0.28474899 -0.97642479 -0.10330477 -1.03068267 -0.03354338\n",
      " -1.13665763 -0.63044713 -0.61374863]  energy_before :  70  energy_after :  50  reward :  -183.79744512762412\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "action : 1  next_temperatures :  [-0.9256216  -0.84432573 -1.05242702 -0.24254485 -0.003794   -1.59241345\n",
      " -0.6634585  -0.95063431 -0.53785045]  energy_before :  50  energy_after :  30  reward :  -184.81306991417455\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "action : 1  next_temperatures :  [-0.18466176 -1.2715475  -0.06439797 -1.19429175 -1.06628908 -0.84004721\n",
      " -0.6634585  -0.68342774 -1.27731557]  energy_before :  30  energy_after :  40  reward :  -215.24543707293216\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "action : 1  next_temperatures :  [ 0.06440038 -1.82442273 -0.25136347 -1.86592038  0.54454462 -1.3875685\n",
      " -0.52149876 -1.63477526 -1.29683224]  energy_before :  40  energy_after :  60  reward :  -226.17343633492914\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "action : 1  next_temperatures :  [1.99463191 1.022047   1.30364226 1.31366781 2.10980211 0.38638876\n",
      " 2.21979276 0.84609951 2.11858581]  energy_before :  60  energy_after :  30  reward :  -154.6853420801269\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "action : 1  next_temperatures :  [-0.80731709  0.20111106 -0.29240467 -0.40799483 -0.34941349  0.57894302\n",
      " -0.8103134  -0.02923235 -0.64507169]  energy_before :  30  energy_after :  50  reward :  -220.5616934450905\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n",
      "action : 1  next_temperatures :  [-1.00864231 -0.44223466 -0.83962076 -0.26875475 -1.18521446 -0.43503949\n",
      "  0.11976765 -0.41391767 -0.80891538]  energy_before :  50  energy_after :  50  reward :  -203.2825718305579\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "action : 1  next_temperatures :  [-0.61429393 -0.11637335 -0.26504387 -0.43174755  0.01116069  0.14057482\n",
      "  0.75124373 -0.70569495 -0.93050736]  energy_before :  50  energy_after :  80  reward :  -230.16068177053108\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "action : 1  next_temperatures :  [ 0.0083614   0.3937797   0.39161544  0.02610659  0.16569248 -0.01305889\n",
      "  0.16871929  0.48368141  0.27534432]  energy_before :  80  energy_after :  60  reward :  -176.0997582650151\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "action : 1  next_temperatures :  [-1.18091029 -0.31783773 -0.61161406 -0.87403957 -0.98581861 -0.82424489\n",
      " -0.85926503 -0.84467308 -0.77458049]  energy_before :  60  energy_after :  150  reward :  -295.2729837477995\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "action : 1  next_temperatures :  [1.70613494 3.40192354 1.33100306 3.35885886 2.68971174 2.55569678\n",
      " 1.39251014 2.49617685 1.64615837]  energy_before :  150  energy_after :  260  reward :  -287.42182572368995\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "action : 1  next_temperatures :  [ 0.37572804 -0.13312715  0.6758638  -0.52348219  0.16569248 -0.25887283\n",
      "  0.36452582 -0.19047769  0.37834899]  energy_before :  260  energy_after :  50  reward :  12.854199277743078\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "action : 1  next_temperatures :  [ 0.195158   -0.44223466 -0.20576213 -0.25073545  0.01116069 -0.50775944\n",
      "  0.11976765 -0.35940138  0.27534432]  energy_before :  50  energy_after :  60  reward :  -209.16446239946964\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "action : 1  next_temperatures :  [-0.3652318  -1.22191438 -0.40032785 -0.94120243 -1.18521446 -0.81932861\n",
      " -1.05507157 -0.65962486 -0.32099851]  energy_before :  60  energy_after :  60  reward :  -204.96891447848589\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "action : 1  next_temperatures :  [ 0.5687512   0.7447717   0.54361991  0.68872556  1.57475656 -0.51697747\n",
      "  0.7022921   0.4213588   0.54640924]  energy_before :  60  energy_after :  50  reward :  -182.72629239721726\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "action : 1  next_temperatures :  [2.22501438 1.69387417 2.38097394 0.8549946  2.22445473 0.90874338\n",
      " 2.28995677 1.30680049 2.38965073]  energy_before :  50  energy_after :  150  reward :  -281.7255368122369\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "action : 1  next_temperatures :  [-0.61429393  0.43733956 -0.35320646  0.46839861 -0.53219302  0.56767654\n",
      "  0.31557419  0.29940102 -0.53785045]  energy_before :  150  energy_after :  70  reward :  -117.94915395072985\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n",
      "action : 1  next_temperatures :  [-0.7616557   0.75398628 -0.40032785  0.74851689 -0.88113578  1.58473172\n",
      " -1.39773301  1.42197573 -0.59537645]  energy_before :  70  energy_after :  100  reward :  -227.52701815848224\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "action : 1  next_temperatures :  [ 0.63101673 -0.26631982  0.13320784 -0.2777644   1.30723378 -0.99631465\n",
      "  0.80509053 -0.88152916  0.81747417]  energy_before :  100  energy_after :  60  reward :  -156.72790497782935\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "action : 1  next_temperatures :  [-0.40674216 -1.45583924 -0.10999931 -1.92407359 -0.38264613 -1.34557529\n",
      " -0.12499052 -1.35067632 -0.39870379]  energy_before :  60  energy_after :  50  reward :  -195.49924634664558\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "action : 1  next_temperatures :  [-1.11864475 -1.14589404 -1.16339028 -0.79131458 -0.93596964 -1.31382432\n",
      " -0.6634585  -1.38830024 -0.97697563]  energy_before :  50  energy_after :  70  reward :  -227.49777198150005\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n",
      "action : 1  next_temperatures :  [-0.20541693 -0.38443407 -0.29240467 -0.08119017 -0.68672482 -0.34285926\n",
      " -0.19189109  0.07749671  0.54640924]  energy_before :  70  energy_after :  100  reward :  -229.56101505388725\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "action : 1  next_temperatures :  [ 0.50648566  1.52466084  0.54361991  1.31940122 -0.23808413  2.20950881\n",
      " -0.71730529  2.47928448  0.3295573 ]  energy_before :  100  energy_after :  330  reward :  -420.04287119340415\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n",
      "action : 1  next_temperatures :  [ 0.5687512  -0.92809471  2.06062452 -1.80776717  0.75889517 -1.12229429\n",
      "  1.0498487  -0.74562237  0.0042794 ]  energy_before :  330  energy_after :  410  reward :  -278.16137956176163\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n",
      "action : 1  next_temperatures :  [-0.3652318  -0.11553566  0.30041276 -0.34902256 -0.08355234 -0.39202205\n",
      " -0.17394215 -0.14440759  0.21261215]  energy_before :  410  energy_after :  110  reward :  100.88931074760202\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n",
      "action : 1  next_temperatures :  [-1.74130008  0.00760473 -1.16339028  0.01136353 -1.62887025  0.20202831\n",
      " -1.25577327 -0.27647521 -1.62211015]  energy_before :  110  energy_after :  70  reward :  -165.46692268748308\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "action : 1  next_temperatures :  [ 0.68705571 -0.1167922   0.41506756  0.04974231  1.16267178 -0.59028269\n",
      "  1.24076008 -0.23654779  1.63066894]  energy_before :  70  energy_after :  80  reward :  -203.75765631041386\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n",
      "action : 1  next_temperatures :  [-2.54452546  0.25137244 -1.70604624  0.33653007 -2.18219376  0.31264458\n",
      " -2.57257223  0.43146863 -2.08894419]  energy_before :  80  energy_after :  40  reward :  -167.76226616586194\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "action : 1  next_temperatures :  [-0.18466176  0.88717895 -0.15560065  1.02453987 -0.13340131  1.41983153\n",
      "  0.11976765  1.16628669 -0.59206344]  energy_before :  40  energy_after :  20  reward :  -174.4481224491995\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n",
      "action : 1  next_temperatures :  [ 0.43799358  0.55461613  0.61962214  0.15715608 -0.2829482   1.15455732\n",
      " -0.29142608  0.33932843 -0.3806328 ]  energy_before :  20  energy_after :  60  reward :  -235.69173338829015\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n",
      "action : 1  next_temperatures :  [-2.2331978  -0.24956602 -1.46283909 -0.47188146 -1.93294894  0.12930835\n",
      " -1.88724935 -0.44616674 -1.92630523]  energy_before :  60  energy_after :  40  reward :  -188.48084627096893\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n",
      "action : 1  next_temperatures :  [ 0.33836872  1.26497702  0.54209986  0.3037677   0.09756556  0.66292944\n",
      " -0.61450686  0.61574902  0.03138589]  energy_before :  40  energy_after :  110  reward :  -264.75766363789234\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "action : 1  next_temperatures :  [1.56499973 1.73324559 1.57269017 1.40949774 1.66116143 1.02857768\n",
      " 1.34355851 1.45883181 1.90173387]  energy_before :  110  energy_after :  100  reward :  -174.32570348120416\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "action : 1  next_temperatures :  [1.19140653 0.51943316 0.65480032 0.72055187 1.11282282 0.20202831\n",
      " 1.29460687 0.28404432 0.81747417]  energy_before :  100  energy_after :  60  reward :  -151.20283164420218\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n",
      "action : 1  next_temperatures :  [1.3512214  2.13533666 0.87134155 1.53809005 1.74091977 0.20202831\n",
      " 1.68132478 0.89216961 1.51682167]  energy_before :  60  energy_after :  210  reward :  -336.07074620020114\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n",
      "action : 1  next_temperatures :  [ 0.195158    0.52864774  0.10280695  0.8549946   0.80874413 -0.12777206\n",
      "  0.36452582  0.32945627  0.64941392]  energy_before :  210  energy_after :  50  reward :  -34.29402463332863\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n",
      "action : 1  next_temperatures :  [ 1.68330424  1.30853689  2.06518465 -0.79131458  2.64152441 -0.10523912\n",
      "  1.83307485  0.27022329  1.46260869]  energy_before :  50  energy_after :  70  reward :  -207.63209668840688\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n",
      "action : 1  next_temperatures :  [ 0.25742353 -0.75385524  0.20464994 -0.84045814 -0.68672482 -0.20049202\n",
      "  0.01696922 -0.78171061 -0.43484578]  energy_before :  70  energy_after :  50  reward :  -181.21904392071343\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n",
      "action : 1  next_temperatures :  [-0.71806982 -0.67092396 -1.32907516  0.321787    0.36508834 -0.78122745\n",
      " -0.76625693 -0.54444961 -0.16378086]  energy_before :  50  energy_after :  60  reward :  -212.28690844138924\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n",
      "action : 1  next_temperatures :  [2.37445166 2.26350319 1.80069687 1.70517815 1.84227934 1.07261934\n",
      " 1.63726831 1.34365657 2.23677011]  energy_before :  60  energy_after :  50  reward :  -171.72357645981887\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n",
      "action : 1  next_temperatures :  [ 0.99838337 -0.13312715  0.80202751 -0.49645324  0.23049614  1.51303599\n",
      " -0.03198241  0.26254494 -0.3806328 ]  energy_before :  50  energy_after :  50  reward :  -195.23570765203132\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n",
      "action : 1  next_temperatures :  [-0.67655947 -1.19615542 -0.79401942 -0.78394305 -1.18521446 -0.61574199\n",
      " -1.20682164 -0.81242401 -0.48363747]  energy_before :  50  energy_after :  100  reward :  -255.75451693894445\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n",
      "action : 1  next_temperatures :  [-0.30296627  0.24383323  0.42049629  0.10146005  0.01116069 -0.25887283\n",
      "  0.16871929 -0.0061973   0.49219626]  energy_before :  100  energy_after :  40  reward :  -137.13017058769793\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n",
      "action : 1  next_temperatures :  [-1.18091029 -0.37689486 -0.59641361 -0.57999728 -1.03068267 -0.66139315\n",
      " -0.27674059 -0.68342774 -0.80891538]  energy_before :  40  energy_after :  60  reward :  -224.19537557462587\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n",
      "action : 1  next_temperatures :  [1.75179633 2.02727468 0.84762885 2.45216023 2.00511929 1.7783102\n",
      " 1.43656661 1.65232622 1.84752088]  energy_before :  60  energy_after :  110  reward :  -232.2012967176776\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n",
      "action : 1  next_temperatures :  [ 0.195158    0.68864648  0.39161544  0.36355902  0.11584352  1.43963321\n",
      " -0.07603889  0.73092426 -0.25775003]  energy_before :  110  energy_after :  110  reward :  -194.40840897650642\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n",
      "action : 1  next_temperatures :  [-0.98788713 -1.44746234 -1.41875779 -0.66845569 -0.08355234 -1.24212859\n",
      " -0.61450686 -1.38830024 -0.53785045]  energy_before :  110  energy_after :  310  reward :  -406.3889014380554\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step\n",
      "action : 1  next_temperatures :  [ 1.75179633 -0.9038017   2.14400983 -1.63798788  1.21252075 -1.60163147\n",
      "  2.02888139 -0.82229618  2.41133592]  energy_before :  310  energy_after :  50  reward :  66.5828269769288\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n",
      "action : 1  next_temperatures :  [-0.24692729 -0.7758446  -0.88978224 -0.05416122 -0.38264613 -0.81502687\n",
      " -0.47254712 -0.92759926 -0.70591071]  energy_before :  50  energy_after :  50  reward :  -203.27044542644109\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n",
      "action : 1  next_temperatures :  [-0.82807226 -0.74380297 -0.58121317 -0.66272227 -1.1303806  -0.59993967\n",
      " -0.90821667 -0.45077375 -1.0799803 ]  energy_before :  50  energy_after :  80  reward :  -234.98510165634605\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n",
      "action : 1  next_temperatures :  [-0.54935988 -0.92223088 -0.66177553 -0.54945807 -0.63189095 -0.1666926\n",
      " -0.73129147 -0.71041165 -0.75470239]  energy_before :  80  energy_after :  70  reward :  -193.6778134426895\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n",
      "action : 1  next_temperatures :  [-0.3652318  -0.9616023  -0.83962076 -0.20404907 -1.06391532 -0.84268094\n",
      " -0.52149876 -0.98288338 -0.41677479]  energy_before :  70  energy_after :  50  reward :  -184.19825710160006\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n",
      "action : 1  next_temperatures :  [ 1.34424011  0.11109749  1.09885078  0.11113984  1.34031537 -0.18764265\n",
      "  1.36091409  0.12573071  0.9352642 ]  energy_before :  50  energy_after :  60  reward :  -201.7600900762568\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n",
      "action : 1  next_temperatures :  [2.12538953 1.86057443 2.52380385 0.76618517 1.91040625 1.39729859\n",
      " 2.21979276 1.25414895 2.38965073]  energy_before :  60  energy_after :  50  reward :  -171.5527497461064\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n",
      "action : 1  next_temperatures :  [ 0.31968906 -1.57562887  0.09824681 -1.74961396  0.87853268 -1.54222644\n",
      "  0.07081602 -1.27312499 -0.7221746 ]  energy_before :  50  energy_after :  50  reward :  -203.49548428735136\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "action : 1  next_temperatures :  [-0.61429393 -1.64096867 -0.59641361 -1.56123032 -1.08053164 -1.24888847\n",
      " -0.85926503 -1.1372182  -1.05674617]  energy_before :  50  energy_after :  60  reward :  -217.79555605002074\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n",
      "action : 1  next_temperatures :  [ 2.78955521  0.50267936  2.66028215 -0.44300962  2.94299196 -0.97041639\n",
      "  2.27363956  0.5604649   3.08899824]  energy_before :  60  energy_after :  40  reward :  -164.59481463451908\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n",
      "action : 1  next_temperatures :  [-0.20541693 -0.01668827  0.10280695 -0.69384653 -0.003794    0.10984808\n",
      "  0.31557419 -1.07425574 -0.48363747]  energy_before :  40  energy_after :  80  reward :  -239.94940971811258\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n",
      "action : 1  next_temperatures :  [ 2.16689988 -0.92223088  2.67168248 -2.20992528  1.96025522 -0.50775944\n",
      "  2.02888139 -0.74562237  2.48000571]  energy_before :  80  energy_after :  120  reward :  -231.07781329764492\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n",
      "action : 1  next_temperatures :  [1.48197902 0.21116333 0.84762885 0.59207657 1.32551173 0.01664363\n",
      " 1.24076008 0.52360882 2.57036068]  energy_before :  120  energy_after :  300  reward :  -369.19026729248026\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n",
      "action : 1  next_temperatures :  [ 1.62103871 -0.46736535  1.11667676 -0.59474035  2.05496825 -0.29267225\n",
      "  1.86454376 -0.65117867  2.00473854]  energy_before :  300  energy_after :  20  reward :  88.65600939426812\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n",
      "action : 1  next_temperatures :  [-0.06947052  1.69952857  0.14840829  1.59214797 -0.31618084  2.26891385\n",
      " -0.96206346  2.36410923  0.01331489]  energy_before :  20  energy_after :  30  reward :  -201.2612920224483\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step\n",
      "action : 1  next_temperatures :  [-0.22617211 -0.37689486  0.31814661 -0.59474035 -0.88113578  0.3218626\n",
      " -0.34104249  0.33187759 -1.00137147]  energy_before :  30  energy_after :  60  reward :  -230.44947025481\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step\n",
      "action : 1  next_temperatures :  [ 0.12666591  1.77680545  0.43265665  1.21374257  0.07928761  1.98417937\n",
      "  0.08713323  1.89803341 -0.04993359]  energy_before :  60  energy_after :  310  reward :  -440.4514293883411\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n",
      "action : 1  next_temperatures :  [1.01137019 2.78289476 2.17006773 0.9226255  1.85353096 1.70266388\n",
      " 1.45427559 1.79595653 1.6075487 ]  energy_before :  310  energy_after :  130  reward :  -2.6990661706275887\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step\n",
      "action : 1  next_temperatures :  [1.50273419 1.89240664 0.70740473 2.50007519 1.5564786  1.02857768\n",
      " 1.24076008 1.50490191 1.7878866 ]  energy_before :  130  energy_after :  90  reward :  -144.27877438548418\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step\n",
      "action : 1  next_temperatures :  [ 0.50648566 -1.39720096 -0.25136347 -0.84660108  0.64756581 -0.66139315\n",
      "  0.80509053 -1.41133529  0.64941392]  energy_before :  90  energy_after :  270  reward :  -379.9593380313056\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n",
      "action : 1  next_temperatures :  [-0.05390414  0.07713298  1.44044628 -0.89779229  0.11584352 -0.20971004\n",
      "  0.31557419 -0.07530245  1.33683456]  energy_before :  270  energy_after :  40  reward :  34.04912261383538\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n",
      "action : 1  next_temperatures :  [-0.05390414 -0.79657742 -0.66177553 -0.05416122  0.31025448 -0.62759374\n",
      " -0.71730529 -0.30565294 -0.28485652]  energy_before :  40  energy_after :  60  reward :  -221.1915723166523\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n",
      "action : 1  next_temperatures :  [-1.42997242 -0.49500911 -1.73644714  0.48641792 -1.1303806  -0.66139315\n",
      " -0.71730529 -0.89151101 -1.0799803 ]  energy_before :  60  energy_after :  40  reward :  -185.6555811182493\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n",
      "action : 1  next_temperatures :  [1.87632739 2.9730264  1.80069687 2.63071515 2.00511929 1.95037995\n",
      " 1.63726831 2.47928448 1.79640578]  energy_before :  40  energy_after :  50  reward :  -188.85077637340765\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n",
      "action : 1  next_temperatures :  [-0.98788713  0.91482271 -0.38360736  0.68299215 -1.08053164  1.5509323\n",
      " -1.29982974  1.41352955 -0.80891538]  energy_before :  50  energy_after :  100  reward :  -247.99849453437062\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n",
      "action : 1  next_temperatures :  [-0.47315873  0.42896267 -0.15560065  0.28738651 -0.73657378  1.62467648\n",
      " -1.25577327  1.0303799  -0.86312836]  energy_before :  100  energy_after :  120  reward :  -218.11282923071693\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n",
      "action : 1  next_temperatures :  [-1.74130008 -0.59301881 -1.61940369 -0.09777612 -0.98581861 -0.3817798\n",
      " -1.64249118 -0.41391767 -0.95890464]  energy_before :  120  energy_after :  50  reward :  -136.43441060173367\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n",
      "action : 1  next_temperatures :  [ 1.72896563 -0.30150278  1.03003421 -0.17702011  1.71101039 -0.13903853\n",
      "  1.63726831 -0.36324056  1.46260869]  energy_before :  50  energy_after :  120  reward :  -261.4109147485243\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step\n",
      "action : 1  next_temperatures :  [0.58431758 0.82058262 0.98443287 0.10146005 1.80572343 0.07912134\n",
      " 0.41347746 0.75165581 0.64941392]  energy_before :  120  energy_after :  110  reward :  -181.80981493442516\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n",
      "action : 1  next_temperatures :  [-1.61054246  1.74413555 -0.85634126  1.63146281 -1.23506343  1.88073267\n",
      " -1.34878137  2.14220493 -1.19382757]  energy_before :  110  energy_after :  60  reward :  -146.8460201321555\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n",
      "action : 1  next_temperatures :  [ 0.25742353 -0.46987842 -0.22096257 -0.23435426 -0.48732896 -0.20971004\n",
      "  0.29762526 -0.7594434  -0.97697563]  energy_before :  60  energy_after :  40  reward :  -180.80360449896557\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n",
      "action : 1  next_temperatures :  [-1.19958995 -0.53605591 -0.64505504 -0.83390567 -1.03068267 -0.90720709\n",
      " -0.85926503 -0.76635392 -1.13419329]  energy_before :  40  energy_after :  110  reward :  -275.9123085684512\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step\n",
      "action : 1  next_temperatures :  [-0.24692729 -1.24892988 -0.90498269 -0.51447254 -0.93596964 -0.71977397\n",
      " -0.45459819 -1.1656281  -0.41677479]  energy_before :  110  energy_after :  90  reward :  -184.60805707127844\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step\n",
      "action : 1  next_temperatures :  [ 0.88007886 -0.21605843  0.49497848 -0.53822526  1.69439407 -1.24212859\n",
      "  0.9029938  -0.83545906  0.64941392]  energy_before :  90  energy_after :  70  reward :  -176.21001221151937\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step\n",
      "action : 1  next_temperatures :  [-0.7616557  -1.31426968 -0.52041138 -1.43263801 -1.1303806  -0.41250654\n",
      " -0.61450686 -1.14412872 -0.94083364]  energy_before :  70  energy_after :  110  reward :  -246.27133112469176\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step\n",
      "action : 1  next_temperatures :  [-0.18466176  0.28655541 -0.88978224  1.54300441 -0.73657378 -0.20049202\n",
      "  0.11976765 -0.42082818 -0.43484578]  energy_before :  110  energy_after :  60  reward :  -148.91785628701422\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n",
      "action : 1  next_temperatures :  [ 0.37572804  0.55210306  0.14840829  0.30922809 -0.68672482  0.43094254\n",
      "  0.21277576 -0.49837951 -0.10956787]  energy_before :  60  energy_after :  130  reward :  -267.26548642684656\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step\n",
      "action : 1  next_temperatures :  [-0.18466176  0.22624175 -0.20576213 -0.49645324  0.13245984 -0.25067903\n",
      " -1.20682164 -0.97482111 -1.19382757]  energy_before :  130  energy_after :  50  reward :  -122.15432487261154\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step\n",
      "action : 1  next_temperatures :  [-0.55825495 -0.48948036 -0.23312293 -0.59031743 -0.78143785 -0.33384608\n",
      " -0.90821667 -0.60510857 -0.86312836]  energy_before :  50  energy_after :  40  reward :  -193.362913209324\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step\n",
      "action : 1  next_temperatures :  [-0.05390414 -1.52285442 -0.35320646 -1.40560905 -0.66844686 -1.31382432\n",
      " -0.55086974 -1.41133529 -0.26678553]  energy_before :  40  energy_after :  50  reward :  -215.5468358036266\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step\n",
      "action : 1  next_temperatures :  [ 0.88007886 -0.38443407  0.43265665 -0.49645324  1.5564786  -1.21447452\n",
      "  0.85404217 -0.86079762  0.64941392]  energy_before :  50  energy_after :  50  reward :  -196.58348924642985\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step\n",
      "action : 1  next_temperatures :  [-0.80731709  0.09388677 -0.33800601 -0.19503942 -0.84790314 -0.07451237\n",
      " -0.29142608 -0.35940138 -0.80891538]  energy_before :  50  energy_after :  50  reward :  -201.62863409350237\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step\n",
      "action : 1  next_temperatures :  [-0.42749733  1.25827551  0.02224458  0.79684139 -0.33279717  1.3358451\n",
      " -0.47254712  1.74216291  0.24793664]  energy_before :  50  energy_after :  60  reward :  -203.82953548671148\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step\n",
      "action : 1  next_temperatures :  [2.24369404 0.71126411 1.71405433 0.58224786 2.23513665 0.16032773\n",
      " 2.46455093 0.61574902 2.1366568 ]  energy_before :  60  energy_after :  90  reward :  -215.13631853857055\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step\n",
      "action : 1  next_temperatures :  [-0.24692729  0.49597784 -0.06439797 -0.75199974 -0.76648316 -0.14928078\n",
      " -0.47254712 -0.62814362 -0.86312836]  energy_before :  90  energy_after :  70  reward :  -181.44693019622306\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step\n",
      "action : 2  next_temperatures :  [-0.23694927 -0.33102347  0.50694943 -0.5374776  -0.37962543 -0.1806751\n",
      "  0.80810891 -0.08116625  0.13687164]  energy_before :  70  energy_after :  40  reward :  -177.29498713917675\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step\n",
      "action : 1  next_temperatures :  [-0.42749733 -1.62589026 -0.38360736 -1.5776115  -0.99863691 -1.09815185\n",
      " -0.61450686 -1.34223014 -0.97697563]  energy_before :  40  energy_after :  660  reward :  -827.0451078457533\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n",
      "action : 1  next_temperatures :  [ 0.25742353 -0.51762674  0.11800739 -0.48007205  0.06100966 -0.50775944\n",
      " -0.07603889 -0.48225498  0.0042794 ]  energy_before :  660  energy_after :  40  reward :  420.3769678844508\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step\n",
      "action : 1  next_temperatures :  [ 0.74932124 -0.56034891 -0.00815632 -0.6119406  -0.23808413 -1.26261308\n",
      "  0.60928399 -1.58256248 -0.43484578]  energy_before :  40  energy_after :  140  reward :  -301.3399460676553\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step\n",
      "action : 1  next_temperatures :  [-0.30296627 -1.19615542 -0.29240467 -0.89943041 -0.2829482  -1.1806751\n",
      " -0.3860659  -0.88997534 -0.16378086]  energy_before :  140  energy_after :  100  reward :  -163.59440218073746\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step\n",
      "action : 1  next_temperatures :  [0.61026155 1.32529068 0.3156132  1.34479206 1.72596508 0.57791879\n",
      " 0.65823563 0.56967892 0.51026725]  energy_before :  100  energy_after :  170  reward :  -260.361976821178\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n",
      "action : 1  next_temperatures :  [ 0.81781333 -1.42484472  0.16360874 -1.09436652  0.55949931 -0.81502687\n",
      "  0.94705027 -1.41133529  0.76326118]  energy_before :  170  energy_after :  490  reward :  -519.4943405706948\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n",
      "action : 1  next_temperatures :  [ 0.31968906 -0.5509249   0.81722795 -0.97969822  0.80874413 -1.14994836\n",
      "  0.75124373 -0.82010236  0.60062223]  energy_before :  490  energy_after :  60  reward :  231.7968532650512\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n",
      "action : 1  next_temperatures :  [-0.90694194  0.54623923 -0.47937017  0.41700264 -0.68672482  1.56219877\n",
      " -1.45157981  1.07645    -1.04685015]  energy_before :  60  energy_after :  50  reward :  -188.96957623481845\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n",
      "action : 1  next_temperatures :  [-0.9256216  -0.30987968 -0.85634126 -0.20404907 -0.76648316 -0.13903853\n",
      " -0.58187244 -0.34558035 -0.88300646]  energy_before :  50  energy_after :  70  reward :  -223.01187254940794\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n",
      "action : 1  next_temperatures :  [ 0.1723273   0.57974682  0.37641499  0.46839861 -0.79805417  1.60521621\n",
      " -1.15419863  1.96272351 -0.0228271 ]  energy_before :  70  energy_after :  330  reward :  -454.8102524510859\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step\n",
      "action : 1  next_temperatures :  [ 1.0834796  -1.1735378  -0.06439797 -0.40504622  1.00813999 -0.70748327\n",
      "  1.34355851 -1.1372182   2.00473854]  energy_before :  330  energy_after :  20  reward :  113.95223317910734\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n",
      "action : 1  next_temperatures :  [-1.49223795 -0.30904199 -1.16339028 -0.23435426 -1.2799275   0.43657578\n",
      " -1.07138878 -0.19892388 -1.35104523]  energy_before :  20  energy_after :  50  reward :  -234.663734097359\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n",
      "action : 1  next_temperatures :  [-0.42749733 -0.71867227 -0.43376883 -0.84045814 -0.88113578 -0.69928947\n",
      " -0.47254712 -0.88152916  0.0042794 ]  energy_before :  50  energy_after :  50  reward :  -203.35061871434252\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n",
      "action : 1  next_temperatures :  [ 0.25742353  0.83691757  0.55882036  0.5331043  -0.33279717  1.64311253\n",
      " -0.6634585   1.92030062 -0.97697563]  energy_before :  50  energy_after :  50  reward :  -194.2235523871478\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n",
      "action : 1  next_temperatures :  [-0.61429393  2.04319079 -0.06439797  1.54955688 -0.83128681  1.9980064\n",
      " -1.15297484  1.67305777 -1.13419329]  energy_before :  50  energy_after :  50  reward :  -194.53333500203263\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n",
      "action : 1  next_temperatures :  [ 0.64969639  1.16612963  0.84762885  0.75670749  0.01116069  1.83054566\n",
      " -0.22778895  2.00476247 -0.43484578]  energy_before :  50  energy_after :  140  reward :  -281.39600355582013\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n",
      "action : 1  next_temperatures :  [ 0.54799602 -0.30150278 -0.05071757 -0.09593324  1.32551173 -0.87340768\n",
      "  0.75124373 -0.85066219  0.74338309]  energy_before :  140  energy_after :  40  reward :  -96.8040888903339\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n",
      "action : 1  next_temperatures :  [-0.55825495 -0.93730929 -0.97642479 -0.16227704 -1.18521446 -0.50775944\n",
      "  0.11976765 -0.84390525 -0.68783971]  energy_before :  40  energy_after :  30  reward :  -193.73921729356783\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n",
      "action : 1  next_temperatures :  [0.63101673 0.62079362 0.70626469 0.42089317 0.14630677 1.42546477\n",
      " 0.22909297 0.52130532 0.38587857]  energy_before :  30  energy_after :  40  reward :  -202.9129833842522\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n",
      "action : 1  next_temperatures :  [ 0.06440038  0.0754576  -0.02335676  0.23169048 -0.53219302  0.33312908\n",
      "  0.11976765 -0.18356718  0.491112  ]  energy_before :  40  energy_after :  60  reward :  -217.42355978596635\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "action : 1  next_temperatures :  [ 1.37197657 -0.59301881  0.70626469 -0.32690796  1.05798895 -0.464742\n",
      "  1.39251014 -0.53600343  0.81747417]  energy_before :  60  energy_after :  50  reward :  -184.57445767311725\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n",
      "action : 1  next_temperatures :  [-1.23694927 -0.99762296 -1.20443149 -0.49645324 -1.03068267 -1.07005883\n",
      " -1.25577327 -0.63044713 -0.55592145]  energy_before :  50  energy_after :  20  reward :  -176.47834029658094\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n",
      "action : 1  next_temperatures :  [ 0.12666591 -0.06527428  0.30041276 -0.22616367 -0.88113578  0.77354572\n",
      " -0.56555523  0.96127475 -0.21257254]  energy_before :  20  energy_after :  60  reward :  -237.78880235754798\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step\n",
      "action : 1  next_temperatures :  [0.70781089 1.92842729 0.3460141  2.04099246 1.21252075 0.44784225\n",
      " 0.50648556 0.14583402 0.7036269 ]  energy_before :  60  energy_after :  110  reward :  -239.9604457827518\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n",
      "action : 1  next_temperatures :  [ 0.0083614  -0.30150278  0.26697177 -0.64634109  0.11584352 -0.45552398\n",
      "  0.22909297 -0.30565294  0.27534432]  energy_before :  110  energy_after :  50  reward :  -138.813406809644\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n",
      "action : 1  next_temperatures :  [ 0.4172384   0.78916925  0.52841946 -0.22739226  0.06100966 -0.75357338\n",
      "  0.60928399 -0.52711848  0.94035693]  energy_before :  50  energy_after :  50  reward :  -196.1626064190641\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n",
      "action : 1  next_temperatures :  [ 0.74932124  0.35943442  0.3460141  -0.60293094  0.23049614 -0.75357338\n",
      "  0.80509053 -0.56134198  0.60062223]  energy_before :  50  energy_after :  80  reward :  -226.82686764970506\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "action : 1  next_temperatures :  [-1.52959727  0.3284399  -1.03722657  0.40287387 -1.43445929  0.29420854\n",
      " -1.22313885 -0.16129996 -1.24804056]  energy_before :  80  energy_after :  80  reward :  -203.60824019935353\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "action : 1  next_temperatures :  [ 0.52724084  1.74329786  0.77162661  0.74605971 -0.2829482   2.0845534\n",
      " -0.3860659   2.42783954 -0.88300646]  energy_before :  80  energy_after :  50  reward :  -161.25140259721258\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n",
      "action : 1  next_temperatures :  [ 0.04572072  0.25137244  0.23809093  0.59207657  0.41493731 -0.29267225\n",
      "  0.6712894   0.17577959  0.64941392]  energy_before :  50  energy_after :  40  reward :  -185.25399138751365\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n",
      "action : 1  next_temperatures :  [ 1.44046866 -0.47657994  1.64337225 -1.36588468  1.16267178 -0.49444452\n",
      "  1.34355851 -0.1290509   1.24575675]  energy_before :  40  energy_after :  70  reward :  -223.63013208714943\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "action : 1  next_temperatures :  [ 0.9423444   1.68382189  1.11667676  0.77882209  0.16569248  1.79742906\n",
      " -0.03198241  2.24893399  0.24372008]  energy_before :  70  energy_after :  60  reward :  -179.05454167314767\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "action : 1  next_temperatures :  [-0.42749733 -1.23971529 -1.16339028 -0.30888866 -0.58204199 -1.24212859\n",
      " -0.12499052 -1.32149859 -0.53785045]  energy_before :  60  energy_after :  40  reward :  -184.94800171034143\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n",
      "action : 1  next_temperatures :  [1.50273419 1.86978901 0.9342714  2.22282362 1.5564786  1.02857768\n",
      " 1.24076008 1.46804583 1.7878866 ]  energy_before :  40  energy_after :  50  reward :  -194.38863298697822\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n",
      "action : 1  next_temperatures :  [ 0.04572072 -0.33333499  0.00704413 -0.63733143  1.14605546 -0.73206466\n",
      " -0.59818965 -0.32254531 -0.43484578]  energy_before :  50  energy_after :  240  reward :  -389.85949152133946\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n",
      "action : 1  next_temperatures :  [-1.11864475  0.65430121 -0.52041138  0.46839861 -1.23506343  1.5509323\n",
      " -0.71730529  0.77699436 -1.19382757]  energy_before :  240  energy_after :  50  reward :  -9.334625942095613\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n",
      "action : 1  next_temperatures :  [-0.55825495 -0.51008753 -0.56601272 -0.18602976 -0.18823517 -1.25339506\n",
      "  0.21277576 -0.58207352  0.16149705]  energy_before :  50  energy_after :  160  reward :  -311.46981590732787\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "action : 1  next_temperatures :  [-0.11616967  0.41220887 -0.61161406  0.90168098  0.26040552  0.07912134\n",
      "  0.16871929  0.10897794  0.54640924]  energy_before :  160  energy_after :  320  reward :  -356.25026054820285\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n",
      "action : 1  next_temperatures :  [-0.80731709 -0.71992881 -0.43376883 -0.84864873 -1.03068267 -0.75357338\n",
      " -0.17394215 -1.15794975 -0.86312836]  energy_before :  320  energy_after :  60  reward :  55.21106022274006\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n",
      "action : 1  next_temperatures :  [-0.3652318  -1.18861622 -1.39139699  0.09081228 -0.33279717 -1.14994836\n",
      " -0.41870032 -1.29616004 -0.10956787]  energy_before :  60  energy_after :  100  reward :  -244.16160649094374\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n",
      "action : 1  next_temperatures :  [-1.07298336  0.91482271 -0.64505504  0.65596319 -1.18521446  1.73836543\n",
      " -0.71730529  0.91520466 -1.02576732]  energy_before :  100  energy_after :  50  reward :  -148.42196948909177\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n",
      "action : 1  next_temperatures :  [-0.67655947 -0.76139445 -0.15560065 -0.84864873 -0.38264613 -0.88467415\n",
      " -0.07603889 -0.60933167 -0.26678553]  energy_before :  50  energy_after :  50  reward :  -202.66167966014268\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "action : 1  next_temperatures :  [1.50273419 1.9200504  0.66066335 2.54799016 1.62792879 1.0623771\n",
      " 1.27665794 1.58322108 1.7878866 ]  energy_before :  50  energy_after :  50  reward :  -184.03049039870672\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n",
      "action : 1  next_temperatures :  [-1.18091029 -1.15971592 -0.40184789 -1.16890092 -1.32977646 -1.16019061\n",
      " -0.17394215 -1.00515059 -0.86312836]  energy_before :  50  energy_after :  80  reward :  -236.44356318995864\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n",
      "action : 1  next_temperatures :  [ 0.10591073 -0.6022334   1.34468346 -1.51372488  0.21554145 -1.02704139\n",
      "  0.9029938  -0.83545906  0.22113133]  energy_before :  80  energy_after :  40  reward :  -159.18819795212488\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n",
      "action : 1  next_temperatures :  [ 0.31968906 -0.3165812  -0.30760512  0.23169048 -0.003794   -0.14825656\n",
      "  0.50648556 -0.40009664  0.05849238]  energy_before :  40  energy_after :  60  reward :  -218.05997602795492\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n",
      "action : 1  next_temperatures :  [ 0.81781333 -0.14066635  0.10280695  0.26527191  1.49381133 -0.50775944\n",
      "  1.24076008 -0.51527188  1.76078011]  energy_before :  60  energy_after :  50  reward :  -183.4824539804977\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n",
      "action : 1  next_temperatures :  [-0.22617211 -1.02945517 -0.79401942 -0.34902256 -0.08355234 -0.87340768\n",
      " -0.27674059 -0.97597286 -0.59206344]  energy_before :  50  energy_after :  50  reward :  -203.20040616563082\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n",
      "action : 1  next_temperatures :  [-1.23694927 -0.81919504 -1.75164758  0.19155657 -0.84790314 -0.41250654\n",
      " -1.13665763 -0.89842153 -1.0799803 ]  energy_before :  50  energy_after :  50  reward :  -205.99170445285324\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n",
      "action : 1  next_temperatures :  [-0.53749978 -0.88704791 -1.23483239 -0.08692359 -0.18823517 -0.87340768\n",
      " -0.07603889 -1.00515059  0.0042794 ]  energy_before :  50  energy_after :  60  reward :  -212.88485658461235\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n",
      "action : 1  next_temperatures :  [0.81781333 1.38979279 0.40529584 1.75595982 1.36206764 0.90874338\n",
      " 1.11511755 1.14555515 1.57645596]  energy_before :  60  energy_after :  340  reward :  -467.52319853561556\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n",
      "action : 1  next_temperatures :  [1.94934788 1.82418823 2.03737194 0.93327748 2.13545167 0.93555945\n",
      " 1.59978283 1.54136369 1.88317447]  energy_before :  340  energy_after :  100  reward :  56.839517644985364\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n",
      "action : 1  next_temperatures :  [0.31968906 0.88131512 0.55882036 0.3881308  0.74560211 0.1272599\n",
      " 0.41347746 0.29095483 0.64941392]  energy_before :  100  energy_after :  110  reward :  -203.6253364415618\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "action : 1  next_temperatures :  [ 1.06064891 -0.47657994  2.02870358 -1.51372488  1.34378969 -0.29267225\n",
      "  1.43656661 -0.37475808 -0.16378086]  energy_before :  110  energy_after :  60  reward :  -144.95180722133372\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n",
      "action : 1  next_temperatures :  [ 0.68705571 -0.20768153  0.61962214 -0.19667753  1.16267178 -0.58545421\n",
      "  1.22444286 -0.41545334  1.63066894]  energy_before :  60  energy_after :  30  reward :  -164.08080516977327\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n",
      "action : 1  next_temperatures :  [2.24369404 1.66874348 2.37071363 0.84418302 2.25436411 0.88621044\n",
      " 2.28995677 1.30680049 2.38965073]  energy_before :  30  energy_after :  40  reward :  -191.74568329430733\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n",
      "action : 1  next_temperatures :  [ 0.0083614  -1.2715475  -1.02202613 -0.17702011 -0.33279717 -1.02704139\n",
      "  0.26172739 -1.35067632 -0.53785045]  energy_before :  40  energy_after :  40  reward :  -203.4488702817764\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step\n",
      "action : 1  next_temperatures :  [ 0.12666591  0.13325819  0.41897624  0.01136353 -0.73657378  0.89184368\n",
      " -0.17394215  0.82076096  0.27534432]  energy_before :  40  energy_after :  50  reward :  -206.23230311229622\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n",
      "action : 1  next_temperatures :  [-0.67655947  0.96257103 -0.16814102  0.77882209 -1.03068267  1.30819104\n",
      " -0.6634585   1.59089943 -1.01492472]  energy_before :  50  energy_after :  40  reward :  -186.91328280187122\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n",
      "action : 1  next_temperatures :  [ 0.60818603  1.85135984  0.75642617 -0.00501766 -0.45409631  1.19245364\n",
      " -0.47254712  1.32753203  0.54038558]  energy_before :  40  energy_after :  80  reward :  -232.65531780433923\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n",
      "action : 1  next_temperatures :  [ 0.25742353 -0.3165812   1.51644852 -1.17053904  0.38170466 -0.49649297\n",
      "  0.64191842 -0.25958284  0.95300663]  energy_before :  80  energy_after :  40  reward :  -156.49269428671016\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n",
      "action : 1  next_temperatures :  [ 2.12538953 -0.30904199  1.95726148 -0.71759925  1.5564786  -0.61837572\n",
      "  1.78412322 -0.42716282  2.17099169]  energy_before :  40  energy_after :  70  reward :  -220.4779352602138\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step\n",
      "action : 1  next_temperatures :  [-3.04887628  1.35796058 -1.93405295  1.24814306 -2.48128755  1.21601081\n",
      " -2.8173304   1.22924916 -2.28892987]  energy_before :  70  energy_after :  120  reward :  -255.51911343405698\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n",
      "action : 1  next_temperatures :  [-1.18091029 -0.76893366 -1.34579565 -0.11968596 -0.88113578 -0.75357338\n",
      " -1.20682164 -0.48993333 -0.80891538]  energy_before :  120  energy_after :  70  reward :  -155.55570505483334\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n",
      "action : 1  next_temperatures :  [0.81781333 0.71126411 0.30041276 1.12528417 1.11282282 0.07912134\n",
      " 0.9029938  0.43146863 1.20703319]  energy_before :  70  energy_after :  260  reward :  -381.3117858672883\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n",
      "action : 1  next_temperatures :  [0.81781333 0.67189269 0.3460141  1.1077329  1.05798895 0.0483946\n",
      " 1.03189977 0.62957005 1.19154376]  energy_before :  260  energy_after :  150  reward :  -81.09714985178533\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "action : 1  next_temperatures :  [-0.42749733  0.06037918 -0.88978224  0.92870994 -0.23808413 -0.3817798\n",
      " -0.52149876 -0.07530245 -0.10956787]  energy_before :  150  energy_after :  70  reward :  -119.65442346276004\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "action : 1  next_temperatures :  [-0.61429393 -1.62589026 -1.00682568 -1.1451482   0.11584352 -1.24212859\n",
      " -0.41870032 -1.5587596  -0.3806328 ]  energy_before :  70  energy_after :  240  reward :  -375.8765358592483\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n",
      "action : 1  next_temperatures :  [ 0.0083614   0.82937836  0.30041276  0.60927681 -0.78143785  1.80801271\n",
      " -1.59353955  1.74216291 -0.26678553]  energy_before :  240  energy_after :  50  reward :  -5.344157970578863\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n",
      "action : 1  next_temperatures :  [ 0.29893389  0.3116861  -0.33800601  0.93608147  1.00813999  0.10677541\n",
      "  0.85404217 -0.21581625  0.76326118]  energy_before :  50  energy_after :  40  reward :  -184.27490205630514\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n",
      "action : 1  next_temperatures :  [-0.18466176 -0.56788812 -0.61161406 -0.03204662  0.16569248 -0.82424489\n",
      " -0.76625693 -0.07530245 -0.23064354]  energy_before :  40  energy_after :  30  reward :  -191.12696587212622\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n",
      "action : 1  next_temperatures :  [-0.55825495 -1.69123006 -0.59641361 -1.5776115  -1.03068267 -1.34557529\n",
      " -0.74993972 -1.48274394 -1.19382757]  energy_before :  30  energy_after :  60  reward :  -238.2262793138143\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n",
      "action : 1  next_temperatures :  [-0.3652318   0.36194749  0.07240605 -0.10330477  0.06100966  1.16377535\n",
      " -1.05507157  0.45450368 -0.26678553]  energy_before :  60  energy_after :  60  reward :  -197.67675145230646\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n",
      "action : 1  next_temperatures :  [-1.05015267 -1.14589404 -1.20443149 -0.74217102 -0.86451946 -1.17043285\n",
      " -0.50518155 -1.35912251 -0.92276265]  energy_before :  60  energy_after :  60  reward :  -206.9646682322102\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n",
      "action : 1  next_temperatures :  [ 0.50648566 -0.34171189 -0.43376883  0.28738651  0.11584352 -0.35412573\n",
      "  0.52802428 -0.72028382  0.60062223]  energy_before :  60  energy_after :  50  reward :  -187.81152806911737\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "action : 1  next_temperatures :  [ 0.195158    0.36194749 -0.33800601  1.14739877  0.93004328  0.20202831\n",
      "  0.41347746  0.27022329  0.64941392]  energy_before :  50  energy_after :  50  reward :  -194.16831551656338\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n",
      "action : 1  next_temperatures :  [-1.2992148  -0.83678653 -1.37619654 -0.16227704 -1.23506343 -0.82424489\n",
      "  0.62560121 -1.05045285 -1.19382757]  energy_before :  50  energy_after :  50  reward :  -205.35246244789698\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n",
      "action : 1  next_temperatures :  [ 0.0083614  -1.07050196  0.43265665 -1.61856447  0.06100966 -1.34557529\n",
      "  0.80509053 -1.12997862  0.27534432]  energy_before :  50  energy_after :  90  reward :  -241.58215778322665\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n",
      "action : 1  next_temperatures :  [ 0.88007886  0.36948669  2.30383167 -0.82653413  0.96327592 -0.20971004\n",
      "  1.09880034  0.3078472   0.87168715]  energy_before :  90  energy_after :  90  reward :  -192.241236337262\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n",
      "action : 1  next_temperatures :  [ 0.195158    1.05304152  0.30041276  0.65022978  0.31025448  1.33772285\n",
      "  0.31557419  0.2771338  -0.3806328 ]  energy_before :  90  energy_after :  50  reward :  -153.9411054251141\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n",
      "action : 1  next_temperatures :  [ 0.83856851 -0.03344207  0.61962214  0.01136353  0.36508834 -0.10523912\n",
      "  0.52443449 -0.07530245  1.05756024]  energy_before :  50  energy_after :  40  reward :  -184.7973463729534\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step\n",
      "action : 1  next_temperatures :  [ 0.99838337 -1.51531521  0.84762885 -2.07805673  0.55949931 -1.04957433\n",
      "  0.94705027 -1.22705489  1.34153302]  energy_before :  40  energy_after :  60  reward :  -219.17590635264503\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step\n",
      "action : 1  next_temperatures :  [ 1.12914099 -0.87867101  1.03003421 -1.88770735  0.93336654 -1.77677391\n",
      "  1.29460687 -1.24394726  1.68488193]  energy_before :  60  energy_after :  40  reward :  -177.71506898617113\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n",
      "action : 1  next_temperatures :  [ 0.06440038  1.08822449  0.30041276  0.86318519 -0.03370338  1.69842067\n",
      " -0.17394215  1.58897984 -0.37400677]  energy_before :  40  energy_after :  40  reward :  -192.97802897549508\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n",
      "action : 1  next_temperatures :  [-0.3652318   1.14937584 -0.02335676  0.5511236   0.27702184  1.0623771\n",
      "  0.07081602  0.9140529  -0.38665646]  energy_before :  40  energy_after :  30  reward :  -184.75047772841614\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n",
      "action : 1  next_temperatures :  [ 0.64969639 -0.25878061  0.16360874 -0.29250747  1.36206764 -0.99631465\n",
      "  0.80509053 -0.86079762  0.81747417]  energy_before :  30  energy_after :  60  reward :  -226.6104628782219\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n",
      "action : 1  next_temperatures :  [ 0.01636697 -0.82278514  0.00270115 -0.75761614 -0.60073535 -0.61722346\n",
      " -0.22778895 -1.01570832  0.44417904]  energy_before :  60  energy_after :  90  reward :  -231.57861021122955\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "action : 1  next_temperatures :  [ 1.62103871 -0.46736535  1.58789062 -0.9559455   1.50662964 -0.20971004\n",
      "  1.58831668  0.44605749  1.95594685]  energy_before :  90  energy_after :  60  reward :  -160.92714090908387\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n",
      "action : 1  next_temperatures :  [ 0.5687512  -1.00516216 -0.10999931 -0.4407572  -0.23808413 -1.0065569\n",
      " -0.29142608 -1.05045285 -0.59206344]  energy_before :  60  energy_after :  110  reward :  -252.1657508744425\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step\n",
      "action : 1  next_temperatures :  [-0.05390414 -1.2305007  -0.38360736 -0.80933389 -0.88113578 -1.08849487\n",
      " -0.47254712 -1.30460623 -0.41722656]  energy_before :  110  energy_after :  100  reward :  -194.64135664348302\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n",
      "action : 1  next_temperatures :  [-0.55825495 -0.91385398 -1.06762747 -0.48007205 -0.33279717 -1.26466153\n",
      " -0.52149876 -1.15794975 -0.43484578]  energy_before :  100  energy_after :  50  reward :  -154.73156143769134\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n",
      "action : 1  next_temperatures :  [ 0.68705571 -0.80411663  1.27324136 -1.5554969   2.45874487 -0.04378563\n",
      "  1.14775197 -1.05922811  0.60062223]  energy_before :  50  energy_after :  80  reward :  -225.2952111305662\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n",
      "action : 1  next_temperatures :  [ 1.19140653 -0.67846317  0.68672126 -0.51575963  1.00813999 -0.87340768\n",
      "  1.58831668 -0.76635392  1.84752088]  energy_before :  80  energy_after :  120  reward :  -234.51187905471792\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n",
      "action : 1  next_temperatures :  [2.12538953 1.09743908 1.34468346 1.01716834 1.71101039 0.78276374\n",
      " 1.60463389 1.17473287 2.33001645]  energy_before :  120  energy_after :  50  reward :  -114.81216224772083\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n",
      "action : 1  next_temperatures :  [-0.18466176 -0.13312715  1.77333607 -1.70866099 -0.08355234 -0.57740673\n",
      "  0.80509053 -0.63044713  0.05849238]  energy_before :  50  energy_after :  50  reward :  -198.68093710796404\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n",
      "action : 1  next_temperatures :  [-1.49223795  0.10142598 -0.74841808 -0.17702011 -1.48430825  0.86572594\n",
      " -0.90821667  0.22415319 -1.24804056]  energy_before :  50  energy_after :  50  reward :  -202.8669365095069\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n",
      "action : 1  next_temperatures :  [ 0.06440038 -0.39197328 -0.66177553  0.51836123  0.06100966 -0.32032631\n",
      " -0.12499052 -0.51527188  0.3295573 ]  energy_before :  50  energy_after :  130  reward :  -279.0410089562507\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n",
      "action : 1  next_temperatures :  [-0.3652318  -0.10715877  0.08608646  0.04248778 -0.23808413 -0.52619549\n",
      " -0.12499052  0.03756929  0.59907329]  energy_before :  130  energy_after :  40  reward :  -108.59644389156202\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n",
      "action : 1  next_temperatures :  [-0.67655947 -1.64850788 -0.44440914 -1.72586124 -1.18521446 -1.64157624\n",
      " -0.22778895 -1.40365694 -0.43484578]  energy_before :  40  energy_after :  50  reward :  -217.3884201014782\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n",
      "action : 1  next_temperatures :  [ 1.56499973  0.41220887  2.67168248 -1.30977912  2.30421308 -0.31110829\n",
      "  1.73027642  0.35314946  1.08853909]  energy_before :  50  energy_after :  80  reward :  -219.49581827413\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n",
      "action : 1  next_temperatures :  [ 0.5687512  -0.81919504  0.00704413 -0.32690796 -0.18823517 -0.87340768\n",
      "  0.80509053 -0.43772055 -0.10956787]  energy_before :  80  energy_after :  60  reward :  -179.37414841360302\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n",
      "action : 1  next_temperatures :  [1.44046866 1.19879953 0.5740208  1.83786575 1.64454511 0.62913003\n",
      " 1.34355851 0.89984796 1.95594685]  energy_before :  60  energy_after :  90  reward :  -216.47581679641203\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n",
      "action : 1  next_temperatures :  [ 0.5687512   0.96257103 -0.06439797  1.63883435  1.21252075  0.47549632\n",
      "  0.34820861  0.91520466  0.87168715]  energy_before :  90  energy_after :  80  reward :  -181.07112391639998\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n",
      "action : 1  next_temperatures :  [-0.49598942 -0.87196949 -0.12519976 -0.98788881 -0.23808413 -1.275928\n",
      " -0.0466679  -0.97597286 -0.14570986]  energy_before :  80  energy_after :  30  reward :  -153.1634102497173\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n",
      "action : 1  next_temperatures :  [ 0.54799602 -1.11406183  0.3460141  -1.00590812  0.16569248 -1.17043285\n",
      " -0.24410616 -0.37475808 -0.3806328 ]  energy_before :  30  energy_after :  50  reward :  -221.23019724372637\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n",
      "action : 1  next_temperatures :  [-0.05390414 -0.70191848  0.84762885 -1.15989126  0.21554145 -1.08849487\n",
      "  0.75124373 -0.97597286  0.22113133]  energy_before :  50  energy_after :  90  reward :  -239.94463624906757\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step\n",
      "action : 1  next_temperatures :  [-0.9256216  -0.46736535 -1.20443149  0.16452762 -0.59865831 -0.63886021\n",
      " -0.27674059 -0.60510857 -0.75470239]  energy_before :  90  energy_after :  50  reward :  -163.30696090185256\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step\n",
      "action : 1  next_temperatures :  [ 1.85557221 -1.78337593  2.22934948 -2.46465272  0.9466596  -1.0065569\n",
      "  1.53936504 -0.95063431  0.37834899]  energy_before :  50  energy_after :  20  reward :  -167.25592452371498\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step\n",
      "action : 1  next_temperatures :  [0.74932124 0.33430373 0.54361991 0.27182438 0.61433317 0.0483946\n",
      " 0.94705027 0.0398728  0.85361616]  energy_before :  20  energy_after :  120  reward :  -293.59766375124633\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n",
      "action : 1  next_temperatures :  [-0.24692729 -0.74631603 -0.74841808 -0.25073545  0.16569248 -0.82424489\n",
      "  0.52802428 -1.06580955  0.27534432]  energy_before :  120  energy_after :  120  reward :  -200.91339020976744\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n",
      "action : 1  next_temperatures :  [-0.42749733 -0.2512414  -0.79401942  0.24807166 -0.96920228 -0.42377301\n",
      "  0.10345044 -0.70646279 -0.51074396]  energy_before :  120  energy_after :  110  reward :  -191.73141810112133\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step\n",
      "action : 1  next_temperatures :  [-0.18466176 -0.41961704 -0.29240467 -0.12787655 -0.71995746 -0.34285926\n",
      " -0.12499052  0.12970949  0.38196319]  energy_before :  110  energy_after :  20  reward :  -109.70069457800054\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n",
      "action : 1  next_temperatures :  [ 1.68330424 -1.02945517  1.21895405 -1.11531104  1.05798895 -1.9112034\n",
      "  1.92608295 -0.83545906  2.16195619]  energy_before :  20  energy_after :  80  reward :  -254.8431422726846\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n",
      "action : 1  next_temperatures :  [ 0.68705571 -1.05542355 -0.17232114 -0.36540375  0.11584352 -1.20320805\n",
      " -0.12499052 -1.08116625  0.12716216]  energy_before :  80  energy_after :  450  reward :  -571.0724518666781\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n",
      "action : 1  next_temperatures :  [ 0.0083614  -1.14589404  0.56262047 -1.7453139   0.06100966 -1.36810823\n",
      "  0.80509053 -1.15794975  0.31148631]  energy_before :  450  energy_after :  60  reward :  188.33130245079656\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n",
      "action : 1  next_temperatures :  [ 0.63101673 -0.59301881 -0.27872427  0.24070013  0.50965034 -0.13903853\n",
      " -0.12499052 -0.0545709   0.27534432]  energy_before :  60  energy_after :  60  reward :  -197.5336315205824\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n",
      "action : 1  next_temperatures :  [ 0.63101673  1.13848587  0.81722795  0.75670749  0.01116069  1.83054566\n",
      " -0.26042337  1.93642516 -0.43484578]  energy_before :  60  energy_after :  60  reward :  -191.57369960563872\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n",
      "action : 1  next_temperatures :  [-0.98788713  0.86456133 -0.33800601  0.65596319 -1.18521446  1.61545846\n",
      " -2.08305589  1.67305777 -1.55163327]  energy_before :  60  energy_after :  60  reward :  -199.3367560241267\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n",
      "action : 1  next_temperatures :  [ 0.74932124 -0.41961704  0.81505646 -0.5954424   1.16267178 -0.6411135\n",
      "  1.09880034 -0.72028382  1.63066894]  energy_before :  60  energy_after :  80  reward :  -214.9199379977365\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n",
      "action : 1  next_temperatures :  [1.93236637 2.57344839 3.2123841  0.77671593 1.44752301 2.37835958\n",
      " 2.38916541 1.58322108 2.27580346]  energy_before :  80  energy_after :  50  reward :  -149.43101266393973\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step\n",
      "action : 1  next_temperatures :  [ 1.68330424 -0.13312715  1.57269017 -0.57999728  1.50662964 -0.00384087\n",
      "  1.46920104  0.49212759  1.95594685]  energy_before :  50  energy_after :  90  reward :  -230.0370657727498\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n",
      "action : 1  next_temperatures :  [-0.11616967 -0.41040245 -0.20576213 -0.57999728  0.34681039 -0.79249392\n",
      " -1.20682164 -1.02895347 -1.13419329]  energy_before :  90  energy_after :  30  reward :  -143.12798345839906\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "action : 1  next_temperatures :  [-0.738825   -0.00747369 -0.74841808  0.26527191 -0.41920204  0.48676279\n",
      " -1.05507157  0.47523522 -0.90951058]  energy_before :  30  energy_after :  100  reward :  -270.6512310423818\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n",
      "action : 1  next_temperatures :  [-0.30296627 -0.36935565 -0.83962076  0.60927681 -0.13340131 -0.71977397\n",
      " -0.61450686 -0.33099149 -0.04993359]  energy_before :  100  energy_after :  80  reward :  -180.75127308665384\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n",
      "action : 1  next_temperatures :  [ 0.31968906  0.16090195 -0.27872427  0.82796564  0.26040552  0.14057482\n",
      " -0.17394215 -0.100641    0.23662076]  energy_before :  80  energy_after :  100  reward :  -216.60714967006984\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "action : 1  next_temperatures :  [-2.09413811 -0.48579453 -1.57380235 -0.50546289 -1.82826611 -0.20049202\n",
      " -1.82198051 -0.36707973 -1.58822704]  energy_before :  100  energy_after :  30  reward :  -138.46524327812114\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "action : 1  next_temperatures :  [-0.9256216  -0.81919504 -1.49323998  0.16452762 -0.98581861 -0.54565576\n",
      " -0.74178111 -0.96330358 -0.53785045]  energy_before :  30  energy_after :  460  reward :  -634.847938521674\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "action : 1  next_temperatures :  [-0.67655947 -0.67092396 -1.25003283  0.28738651  0.36508834 -0.81502687\n",
      " -0.7336225  -0.53600343 -0.16378086]  energy_before :  460  energy_after :  20  reward :  237.80652493861174\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n",
      "action : 1  next_temperatures :  [-0.63504911  0.59650061 -0.09479886  0.23169048 -0.88113578  1.18221139\n",
      "  0.21522334  0.72458963 -1.13419329]  energy_before :  20  energy_after :  60  reward :  -237.79496159401447\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n",
      "action : 1  next_temperatures :  [ 0.195158   -0.82757194  0.14840829 -0.89042076 -0.71995746 -0.25887283\n",
      " -0.10867331 -0.90686771 -0.48363747]  energy_before :  60  energy_after :  50  reward :  -191.85243518875498\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n",
      "action : 1  next_temperatures :  [ 0.71818848 -0.05270893  0.00704413  0.06869768  0.26040552 -0.50775944\n",
      "  0.74425064 -0.72061289  0.76326118]  energy_before :  50  energy_after :  80  reward :  -226.71923363709251\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n",
      "action : 1  next_temperatures :  [-1.49223795 -0.04265666 -1.06762747  0.01136353 -1.61225393  0.08833936\n",
      " -1.25577327 -0.31832221 -1.69620123]  energy_before :  80  energy_after :  100  reward :  -225.38536983350585\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n",
      "action : 1  next_temperatures :  [ 0.72856606 -1.858768    1.11667676 -2.50396757  0.06100966 -1.08849487\n",
      "  0.98201572 -1.37513735  0.12535506]  energy_before :  100  energy_after :  220  reward :  -321.81274453180094\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "action : 1  next_temperatures :  [ 0.88007886 -0.27469671  0.30041276 -0.05579934  0.66418213 -1.86792991\n",
      "  0.80509053 -1.50347548  0.87168715]  energy_before :  220  energy_after :  60  reward :  -38.180450001063406\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n",
      "action : 1  next_temperatures :  [-0.49598942 -0.24202681 -0.50673098 -0.1712867  -0.31618084 -0.3612953\n",
      " -0.52149876 -0.79169247 -0.75470239]  energy_before :  60  energy_after :  70  reward :  -212.16140367208152\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n",
      "action : 1  next_temperatures :  [-0.11616967  0.91230964  0.25025128  0.47658921  0.01116069  0.20202831\n",
      " -0.03198241 -0.25190449  0.22113133]  energy_before :  70  energy_after :  50  reward :  -176.32658610412665\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "action : 1  next_temperatures :  [-0.3652318  -1.47259304 -0.10999931 -2.01417011 -0.38264613 -1.36810823\n",
      " -0.12499052 -1.44204868 -0.3806328 ]  energy_before :  50  energy_after :  80  reward :  -235.66042061860284\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "action : 1  next_temperatures :  [-0.18466176 -1.23971529 -0.83962076 -0.50546289 -0.93596964 -0.75357338\n",
      " -0.41870032 -1.24394726 -0.3806328 ]  energy_before :  80  energy_after :  60  reward :  -184.50228410486187\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "action : 1  next_temperatures :  [-0.38598698 -0.97919378 -1.25003283 -0.08119017  0.01116069 -0.93486116\n",
      " -0.27674059 -1.38830024 -0.59206344]  energy_before :  60  energy_after :  70  reward :  -213.87720849689748\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "action : 1  next_temperatures :  [ 1.87632739 -0.40872707  1.71405433 -1.07143286  1.86055729 -0.68085343\n",
      "  1.97503459 -0.77326443  2.31194545]  energy_before :  70  energy_after :  40  reward :  -161.19635873808238\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n",
      "action : 1  next_temperatures :  [ 0.52724084  0.61325441  1.39028481 -0.44976686  0.02777701  0.44784225\n",
      "  0.36452582  0.66181912 -0.04993359]  energy_before :  40  energy_after :  50  reward :  -204.46695618931125\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n",
      "action : 1  next_temperatures :  [-1.56903211  0.96257103 -0.97642479  0.90168098 -1.2799275   1.38808057\n",
      " -1.50053144  1.21235679 -1.35104523]  energy_before :  50  energy_after :  30  reward :  -180.2122716998718\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n",
      "action : 1  next_temperatures :  [-0.30296627 -0.16831012 -0.43376883  0.33653007 -0.0503197  -0.50775944\n",
      " -0.17394215  0.20111814  0.43256198]  energy_before :  30  energy_after :  90  reward :  -258.66685632623876\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n",
      "action : 1  next_temperatures :  [1.99463191 1.94518109 2.14270693 1.2997438  1.86055729 1.40695557\n",
      " 2.13559595 1.35287059 2.33001645]  energy_before :  90  energy_after :  50  reward :  -141.53174044105697\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n",
      "action : 1  next_temperatures :  [-1.05015267  0.57053223 -0.61617419  0.50406492 -1.23506343  1.64311253\n",
      " -0.8103134   0.82920714 -1.0799803 ]  energy_before :  50  energy_after :  100  reward :  -249.24476716766742\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "action : 1  next_temperatures :  [ 0.25742353 -0.09961956 -0.43376883  0.81158446  0.50965034 -0.464742\n",
      "  0.56033236 -0.26879686  0.67109911]  energy_before :  100  energy_after :  50  reward :  -146.4568374515712\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n",
      "action : 1  next_temperatures :  [ 1.56499973 -0.07365118  1.03003421  0.12603183  1.75587446 -0.08987575\n",
      "  1.55568226 -0.18356718  1.46260869]  energy_before :  50  energy_after :  60  reward :  -200.85186292420877\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n",
      "action : 1  next_temperatures :  [-2.54452546  0.20111106 -1.70604624  0.31441547 -2.1273599   0.31494909\n",
      " -2.57257223  0.39921956 -2.05912705]  energy_before :  60  energy_after :  40  reward :  -187.7799357107655\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "action : 1  next_temperatures :  [-0.65580429 -0.53605591 -0.53561182 -0.66845569 -0.27653905 -0.75357338\n",
      " -1.0110151  -0.72028382 -1.24804056]  energy_before :  40  energy_after :  100  reward :  -264.40537961491015\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "action : 1  next_temperatures :  [-0.42749733  0.20865027 -1.02202613  1.05156883  0.36508834  0.10677541\n",
      " -0.07603889  0.00762373  0.37834899]  energy_before :  100  energy_after :  140  reward :  -237.40750678217827\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "action : 1  next_temperatures :  [-0.18466176  0.36194749 -0.70737688  0.96884384  0.26040552  0.0483946\n",
      "  0.11976765  0.12970949  0.49219626]  energy_before :  140  energy_after :  60  reward :  -116.51077379010351\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "action : 1  next_temperatures :  [1.1063103  1.33953141 1.41894851 0.6229668  1.11282282 0.6403965\n",
      " 1.39251014 0.96127475 2.63686194]  energy_before :  60  energy_after :  50  reward :  -176.7683768291791\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n",
      "action : 1  next_temperatures :  [-1.61054246  1.39900738 -0.88978224  1.18917079 -1.2799275   1.63389451\n",
      " -1.29982974  1.51181242 -1.29683224]  energy_before :  50  energy_after :  70  reward :  -218.6430290815881\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n",
      "action : 1  next_temperatures :  [ 0.5687512   0.93157651  0.88867006  0.14241301  1.12943914 -0.02432536\n",
      "  0.49949247  0.19749835  0.7036269 ]  energy_before :  70  energy_after :  60  reward :  -182.962857732095\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "action : 1  next_temperatures :  [ 0.14378893 -0.39197328 -0.56601272  0.5109897   0.06100966 -0.35412573\n",
      " -0.07603889 -0.48993333  0.37834899]  energy_before :  60  energy_after :  50  reward :  -188.78394666149765\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n",
      "action : 1  next_temperatures :  [ 0.31968906 -1.24892988 -0.73473768 -0.4227379  -0.43747999 -1.14073034\n",
      "  0.50648556 -1.43667384 -0.43484578]  energy_before :  50  energy_after :  50  reward :  -203.02996078080326\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n",
      "action : 1  next_temperatures :  [ 1.06064891 -0.06527428  0.26697177  0.51836123  1.21252075 -0.47396003\n",
      "  1.17712295 -0.0545709   0.32800836]  energy_before :  50  energy_after :  40  reward :  -184.03017123605113\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n",
      "action : 1  next_temperatures :  [-0.98788713 -1.15594632 -1.4324382  -0.43911909 -0.26799351 -1.56988051\n",
      " -0.6634585  -1.28157118 -0.53785045]  energy_before :  40  energy_after :  790  reward :  -956.3361448731814\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n",
      "action : 1  next_temperatures :  [ 2.43671719  0.89639354  2.49991743 -0.62013119  2.07846848 -0.31242515\n",
      "  2.32259119  0.17577959  2.1547278 ]  energy_before :  790  energy_after :  60  reward :  543.6320388750147\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n",
      "action : 1  next_temperatures :  [ 0.0083614  -0.76893366 -0.09479886 -0.52184407  0.47974096 -0.44323328\n",
      " -0.56555523 -1.11187965 -0.43484578]  energy_before :  60  energy_after :  40  reward :  -181.4529881771133\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "action : 1  next_temperatures :  [-0.3652318  -0.67092396 -0.83962076 -0.08119017  0.11584352 -0.77200943\n",
      "  0.45753393 -0.97597286  0.22113133]  energy_before :  40  energy_after :  90  reward :  -250.91044020433037\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "action : 1  next_temperatures :  [-1.2992148   0.19273416 -1.16339028  0.37912115 -0.96920228  0.44784225\n",
      " -1.15297484  0.27022329 -0.90951058]  energy_before :  90  energy_after :  560  reward :  -672.2043719441566\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "action : 1  next_temperatures :  [-0.46174338 -0.6432802  -0.96274438  0.04166872  0.14907616 -0.71977397\n",
      "  0.36452582 -0.90686771  0.16149705]  energy_before :  560  energy_after :  60  reward :  299.0223581181806\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n",
      "action : 1  next_temperatures :  [-0.86958262  1.06560687 -0.32280557  0.8369753  -1.18521446  1.36964452\n",
      " -0.79562791  1.67305777 -1.02576732]  energy_before :  60  energy_after :  50  reward :  -187.2537134294297\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n",
      "action : 1  next_temperatures :  [-0.18466176  0.51021857  0.0876065   0.31441547 -1.03068267  1.52327823\n",
      " -1.3814158   1.84351713 -0.69988704]  energy_before :  50  energy_after :  40  reward :  -187.0176113701084\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n",
      "action : 2  next_temperatures :  [ 0.32344053 -1.05897585  0.43398728 -1.14399101 -0.2799275  -0.98981265\n",
      "  0.87500948 -0.35067632  0.2778254 ]  energy_before :  40  energy_after :  280  reward :  -448.9131206412674\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n",
      "action : 1  next_temperatures :  [ 0.06440038 -0.19092774 -0.38360736  0.45938896  0.21554145 -0.53541351\n",
      "  0.50648556 -0.28492139  0.10728407]  energy_before :  280  energy_after :  330  reward :  -248.0417695826368\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step\n",
      "action : 1  next_temperatures :  [1.94651763 1.84175687 2.02956631 0.95908154 2.14048189 0.95259883\n",
      " 1.5975778  1.55109652 1.88048824]  energy_before :  330  energy_after :  90  reward :  56.899165612690354\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step\n",
      "action : 1  next_temperatures :  [ 0.39648322 -0.34171189 -0.10999931  0.15715608 -0.10016866 -0.30189027\n",
      "  0.83772495 -0.33790201  0.16149705]  energy_before :  90  energy_after :  50  reward :  -157.63881083050177\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "action : 1  next_temperatures :  [-0.42749733 -0.97919378 -0.88978224 -0.21510637 -1.047299   -0.5886732\n",
      "  0.21277576 -1.06580955 -0.34087661]  energy_before :  50  energy_after :  480  reward :  -633.3414623195185\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n",
      "action : 1  next_temperatures :  [ 0.2885563   1.08822449  0.5740208   0.58224786 -0.23808413  1.92272588\n",
      "  0.26172739  1.40508336  0.3458212 ]  energy_before :  480  energy_after :  100  reward :  188.2303231517097\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n",
      "action : 1  next_temperatures :  [-1.09581406 -1.28076209 -1.32907516 -1.01491777 -1.03068267 -0.69343676\n",
      " -0.82499889 -1.10266563 -0.70591071]  energy_before :  100  energy_after :  60  reward :  -167.07826372611208\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "action : 1  next_temperatures :  [-0.9256216  -0.12558794 -1.11778894  0.28001498 -0.78143785  0.0483946\n",
      " -0.63082407 -0.45307725 -0.7384385 ]  energy_before :  60  energy_after :  50  reward :  -192.4443665820172\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n",
      "action : 1  next_temperatures :  [-0.90694194 -0.38610945 -1.20443149  0.01054447  0.44816995 -1.06801038\n",
      " -0.64714128 -1.01359677 -0.53785045]  energy_before :  50  energy_after :  90  reward :  -243.30536735221017\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n",
      "action : 1  next_temperatures :  [-0.34447662  1.52633622  0.17728914  1.13183664 -0.76648316  1.92272588\n",
      " -0.45133475  1.63696952 -0.74657045]  energy_before :  90  energy_after :  50  reward :  -153.913707568192\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "action : 1  next_temperatures :  [ 1.12914099 -1.33018578  1.33647522 -1.90245042  0.96327592 -1.50146229\n",
      "  1.48551825 -1.25930396  1.95594685]  energy_before :  50  energy_after :  40  reward :  -187.12304522077645\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "action : 1  next_temperatures :  [-0.55825495  0.72969328 -0.61161406  1.02453987 -0.23808413  1.0623771\n",
      " -0.12499052  0.5581614  -0.32099851]  energy_before :  40  energy_after :  130  reward :  -286.47917052929677\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n",
      "action : 1  next_temperatures :  [ 0.29893389 -0.10883414  0.11800739  0.10801252 -0.03370338 -0.3817798\n",
      " -0.12499052 -0.09219482  0.3458212 ]  energy_before :  130  energy_after :  330  reward :  -397.87072765182313\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n",
      "action : 1  next_temperatures :  [ 2.43671719  0.83105374  2.44367578 -0.43338567  2.10980211 -0.27915248\n",
      "  2.32259119  0.25486659  2.1366568 ]  energy_before :  330  energy_after :  60  reward :  83.82282525495367\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "action : 1  next_temperatures :  [ 1.17065135 -0.2755344   0.54361991 -0.20404907  0.63094949 -0.21892806\n",
      "  0.15240207 -0.02923235  0.37834899]  energy_before :  60  energy_after :  100  reward :  -235.85177206945028\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n",
      "action : 1  next_temperatures :  [ 0.0083614  -0.36935565 -0.61161406  0.31441547  0.09756556 -0.05607633\n",
      "  0.07081602 -0.42082818 -0.04993359]  energy_before :  100  energy_after :  40  reward :  -139.01664936676474\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n",
      "action : 1  next_temperatures :  [ 0.1723273   1.22309254  0.44785709  0.8369753   0.16569248  1.79674624\n",
      " -0.47254712  1.93642516 -0.48363747]  energy_before :  40  energy_after :  80  reward :  -232.37706848044405\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "action : 1  next_temperatures :  [ 0.37572804 -0.7886792   0.07240605 -0.76919998 -0.72233122 -0.40372747\n",
      " -0.45908542 -0.85129566 -0.21257254]  energy_before :  80  energy_after :  40  reward :  -161.7587574021404\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "action : 1  next_temperatures :  [ 0.33836872 -0.67846317  0.03896507 -0.53822526 -0.08355234 -0.88467415\n",
      "  0.2470419  -0.42082818 -0.21257254]  energy_before :  40  energy_after :  50  reward :  -210.19393994811185\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n",
      "action : 1  next_temperatures :  [ 0.4172384   1.37471438  0.69106424  0.64859166 -0.2829482   1.89199914\n",
      " -0.61450686  2.24893399 -0.96191647]  energy_before :  50  energy_after :  100  reward :  -242.58682971857607\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n",
      "action : 1  next_temperatures :  [ 0.06440038  1.06560687 -0.06439797  1.46027942  0.36508834  0.75510967\n",
      "  0.10345044  1.1378768   0.10728407]  energy_before :  100  energy_after :  480  reward :  -573.0053019888445\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "action : 1  next_temperatures :  [ 1.30971104 -0.62066257  1.89645969 -1.45475261  1.41191661 -0.36334375\n",
      "  1.53936504 -0.25958284  0.43256198]  energy_before :  480  energy_after :  50  reward :  235.8916725786719\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "action : 1  next_temperatures :  [-0.42749733 -1.5655766  -0.06439797 -1.66197461 -0.96920228 -1.40702877\n",
      "  0.01696922 -1.67393484 -0.48363747]  energy_before :  50  energy_after :  60  reward :  -216.2362806600991\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "action : 1  next_temperatures :  [ 0.74932124  0.0829968   0.15057978  0.61980757  1.1427322  -0.62759374\n",
      "  0.9960019  -0.28492139  1.68488193]  energy_before :  60  energy_after :  100  reward :  -233.48619370245333\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "action : 1  next_temperatures :  [-0.61429393 -0.9532254  -1.29563417 -0.03204662 -0.33279717 -1.36810823\n",
      " -0.61450686 -1.22705489 -0.32099851]  energy_before :  100  energy_after :  660  reward :  -764.7586657885108\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n",
      "action : 1  next_temperatures :  [ 1.44046866 -0.01668827  1.77138173 -1.07915542  1.1792881  -0.22814609\n",
      "  1.39251014 -0.02923235  1.09628381]  energy_before :  660  energy_after :  60  reward :  407.5267103056265\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n",
      "action : 1  next_temperatures :  [0.68705571 1.11586825 0.11800739 1.61671974 1.11282282 0.35566202\n",
      " 0.41347746 1.07645    1.08853909]  energy_before :  60  energy_after :  60  reward :  -190.41539751659363\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n",
      "action : 1  next_temperatures :  [ 1.12914099 -0.49500911  0.56099185 -0.11032528  1.83314036  0.26194546\n",
      "  1.43656661 -0.68342774  1.98847464]  energy_before :  60  energy_after :  360  reward :  -492.0785022229627\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "action : 1  next_temperatures :  [-0.05390414  0.0260339  -0.71763718  0.97785349  0.26040552  0.01459518\n",
      " -0.29142608 -0.1290509   0.20409297]  energy_before :  360  energy_after :  110  reward :  52.29096277745907\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n",
      "action : 1  next_temperatures :  [-0.16183106  0.94749261  0.25025128  0.48641792 -0.33279717  1.83976368\n",
      "  0.13608486  1.49108088  0.09915212]  energy_before :  110  energy_after :  40  reward :  -123.24438486934588\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n",
      "action : 1  next_temperatures :  [ 0.5687512   0.57053223 -0.1404002   0.88693791  0.96327592 -0.01305889\n",
      "  0.36452582 -0.1124876   0.64941392]  energy_before :  40  energy_after :  70  reward :  -224.2625096908474\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n",
      "action : 1  next_temperatures :  [-0.40674216 -1.18861622 -1.4324382   0.09081228 -0.33279717 -1.13151231\n",
      " -0.41870032 -1.29616004 -0.10956787]  energy_before :  70  energy_after :  150  reward :  -284.2257220077172\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n",
      "action : 1  next_temperatures :  [-0.18466176  0.15168736 -0.66177553  1.12528417  0.06100966 -0.35412573\n",
      " -0.15925666  0.39921956  0.14342606]  energy_before :  150  energy_after :  90  reward :  -137.47919287879006\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n",
      "action : 1  next_temperatures :  [-2.2331978   1.57575992 -1.31235466  0.89430945 -1.36300911  2.21770261\n",
      " -0.59818965  1.09948505 -2.27808727]  energy_before :  90  energy_after :  20  reward :  -129.99758146410997\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "action : 1  next_temperatures :  [ 0.58950637 -0.98003147  1.30364226 -1.88230156  0.31025448 -1.07005883\n",
      "  0.80509053 -0.93527761  0.37834899]  energy_before :  20  energy_after :  50  reward :  -229.48082683557658\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "action : 1  next_temperatures :  [-0.24692729 -0.50254832 -0.47937017 -0.4227379  -0.63189095  0.05863684\n",
      " -0.61450686  0.09285341  0.10728407]  energy_before :  50  energy_after :  50  reward :  -200.6392071768091\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n",
      "action : 1  next_temperatures :  [-1.672808   -0.09040497 -1.16339028  0.01136353 -1.62887025  0.16822889\n",
      " -1.34878137 -0.40009664 -1.66728764]  energy_before :  50  energy_after :  260  reward :  -415.7920467385585\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n",
      "action : 1  next_temperatures :  [ 0.21591317 -0.18338853 -0.20576213  0.37994021 -0.16995721 -0.29267225\n",
      " -0.22778895 -0.07530245  0.27534432]  energy_before :  260  energy_after :  40  reward :  21.716326189002643\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n",
      "action : 1  next_temperatures :  [0.74932124 1.10665366 0.70626469 1.0705242  1.05798895 0.26040912\n",
      " 1.48551825 0.89216961 1.19154376]  energy_before :  40  energy_after :  80  reward :  -229.4796065078608\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n",
      "action : 1  next_temperatures :  [ 0.0083614   0.81429994 -0.02335676  0.93608147 -0.38264613  0.94766392\n",
      "  0.36452582  1.05111145 -0.04993359]  energy_before :  80  energy_after :  60  reward :  -174.3338924766812\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n",
      "action : 1  next_temperatures :  [2.18765506 2.06245765 1.39028481 2.30227237 2.15965108 1.61545846\n",
      " 2.12678465 1.57308565 2.44386372]  energy_before :  60  energy_after :  50  reward :  -170.1384865467742\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "action : 1  next_temperatures :  [-0.3652318  -1.22128612 -0.33800601 -0.96331703 -0.2829482  -1.275928\n",
      " -0.41870032 -0.89842153 -0.21257254]  energy_before :  50  energy_after :  60  reward :  -213.97641156728554\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "action : 1  next_temperatures :  [-0.98788713 -1.12327642 -1.41875779 -0.39161365 -0.2829482  -1.48794253\n",
      " -0.6634585  -1.22168005 -0.53785045]  energy_before :  60  energy_after :  70  reward :  -216.11541471448288\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n",
      "action : 1  next_temperatures :  [-0.61429393 -0.45061156 -0.29240467 -0.41536637 -0.93596964  0.65166297\n",
      " -0.06135339 -0.42927437 -1.02576732]  energy_before :  70  energy_after :  50  reward :  -181.57337827745317\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "action : 1  next_temperatures :  [-0.55825495 -1.22128612 -1.57380235  0.44464589 -0.2829482  -0.99631465\n",
      " -0.56555523 -1.34223014 -0.16378086]  energy_before :  50  energy_after :  50  reward :  -204.2595266000146\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "action : 1  next_temperatures :  [-0.88826228 -1.60746108 -0.80921987 -1.43263801 -1.23506343 -0.88789314\n",
      " -0.96206346 -1.29616004 -1.19382757]  energy_before :  50  energy_after :  90  reward :  -248.31258889155055\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "action : 1  next_temperatures :  [-1.05015267 -0.52579421 -0.56601272 -0.62013119 -1.23506343 -0.35412573\n",
      "  0.29403547 -0.54107114 -0.86312836]  energy_before :  90  energy_after :  50  reward :  -163.4614439762387\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "action : 1  next_temperatures :  [ 0.25742353  0.82183915 -0.27872427  1.27025766  0.75889517 -0.01305889\n",
      "  0.56033236  0.20879649  0.7036269 ]  energy_before :  50  energy_after :  50  reward :  -193.7106119001794\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n",
      "action : 1  next_temperatures :  [ 0.195158   -0.5452705   0.16360874 -0.43174755 -0.31618084 -0.53541351\n",
      "  0.50648556 -0.7594434   0.0042794 ]  energy_before :  50  energy_after :  50  reward :  -199.71852411482087\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "action : 1  next_temperatures :  [-0.11616967 -0.91134091 -0.52041138 -0.43911909  0.64756581 -1.14994836\n",
      " -0.61450686 -0.99824007 -0.65169772]  energy_before :  50  energy_after :  40  reward :  -192.75386825181184\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n",
      "action : 1  next_temperatures :  [-1.05015267 -1.02024058 -1.00682568 -0.74217102 -1.04492524 -0.32032631\n",
      " -1.39773301 -0.58207352 -1.40525821]  energy_before :  40  energy_after :  70  reward :  -236.56970624338342\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n",
      "action : 1  next_temperatures :  [-0.11616967 -1.1735378  -0.83962076 -0.59474035  0.01116069 -1.08849487\n",
      " -0.17394215 -1.08270192  0.09102017]  energy_before :  70  energy_after :  540  reward :  -672.9670266700416\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "action : 1  next_temperatures :  [-0.61429393 -1.08725576  0.16360874 -1.54648725 -1.03068267 -0.91642512\n",
      "  0.11976765 -1.05045285 -0.90288455]  energy_before :  540  energy_after :  50  reward :  285.13489424907857\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "action : 1  next_temperatures :  [ 0.63101673 -1.27845844 -0.03703716 -0.91417348  0.36508834 -0.88467415\n",
      "  0.80509053 -1.22705489  0.81747417]  energy_before :  50  energy_after :  40  reward :  -189.72272835262348\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "action : 1  next_temperatures :  [ 0.06440038 -0.36935565  0.02224458  0.02692565  0.26040552 -0.62759374\n",
      " -0.27674059 -0.07530245  0.43256198]  energy_before :  40  energy_after :  870  reward :  -1028.5424543219735\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n",
      "action : 1  next_temperatures :  [-0.71806982 -0.93730929 -0.77881898  0.10146005 -0.68672482 -1.71634465\n",
      " -0.36974869 -1.53495671 -0.32099851]  energy_before :  870  energy_after :  80  reward :  585.0384885749891\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "action : 1  next_temperatures :  [-1.58978729 -0.37689486 -0.88978224 -0.53085373 -1.73355308  0.17949536\n",
      " -1.39773301 -0.22963728 -1.67632314]  energy_before :  80  energy_after :  60  reward :  -186.2450692489488\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n",
      "action : 1  next_temperatures :  [-0.18466176 -0.21605843 -1.11778894  1.0663119   0.57777726 -0.3612953\n",
      "  0.04773882 -0.30565294  0.49219626]  energy_before :  60  energy_after :  50  reward :  -188.00143313446878\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "action : 1  next_temperatures :  [-1.8596046   0.06037918 -1.4324382   0.14241301 -1.52917232  0.20202831\n",
      " -1.39773301 -0.16974615 -1.51609365]  energy_before :  50  energy_after :  50  reward :  -205.4999674168186\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "action : 1  next_temperatures :  [ 0.06440038  1.33953141  0.39161544  0.8549946   0.14907616  1.79674624\n",
      " -0.47254712  1.92874681 -0.48363747]  energy_before :  50  energy_after :  50  reward :  -192.43107355176406\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n",
      "action : 1  next_temperatures :  [ 0.0083614  -1.1735378  -0.74841808 -0.66108415 -0.03370338 -1.08849487\n",
      " -0.12499052 -1.11187965  0.10728407]  energy_before :  50  energy_after :  40  reward :  -192.82646299215978\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n",
      "action : 1  next_temperatures :  [-1.05015267 -0.43553314 -0.95590418 -0.8785444  -0.98581861 -1.30358207\n",
      " -0.71730529 -1.38830024 -1.02576732]  energy_before :  40  energy_after :  120  reward :  -286.7409079137168\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n",
      "action : 1  next_temperatures :  [ 0.06440038  2.0013063   0.39161544  1.51024204  0.01116069  2.10401367\n",
      " -0.0923561   1.94410351 -0.09300279]  energy_before :  120  energy_after :  120  reward :  -190.158516869634\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "action : 1  next_temperatures :  [-1.88035977 -0.55280971 -1.6604449  -0.05416122 -0.98581861 -0.29267225\n",
      " -1.69633798 -0.40009664 -1.02576732]  energy_before :  120  energy_after :  50  reward :  -136.54846838102046\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n",
      "action : 1  next_temperatures :  [-0.18466176 -0.59301881 -0.06439797 -0.53822526  0.47807933 -0.06631858\n",
      " -0.43664926  0.04678331 -0.21257254]  energy_before :  50  energy_after :  50  reward :  -199.57098153264363\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n",
      "action : 1  next_temperatures :  [ 0.25742353 -0.96997919  0.17728914 -0.78558117  0.26040552 -0.89594062\n",
      " -0.56555523 -1.15794975 -0.43484578]  energy_before :  50  energy_after :  60  reward :  -212.11473355555435\n",
      "Total Reward on Test Set: -781681.2374135145\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the model on the test set\n",
    "\n",
    "def evaluate_model():\n",
    "    total_reward = 0\n",
    "    for current_index in range(len(X_test)):\n",
    "        state = X_test[current_index]  # Use a sample from the test set\n",
    "        state_input = np.expand_dims(state, axis=0)\n",
    "        \n",
    "        # Predict action\n",
    "        action_probs = actor_model.predict(state_input)\n",
    "        action = np.argmax(action_probs[0])  # Choose the most probable action\n",
    "        \n",
    "        # Simulate environment using the selected action\n",
    "        next_state, reward = simulate_environment(state.copy(), action, current_index)\n",
    "        \n",
    "        # calculate rewards for test set\n",
    "        total_reward += reward\n",
    "    \n",
    "    # Print the total reward obtained on the test set\n",
    "    print(f\"Total Reward on Test Set: {total_reward}\")\n",
    "\n",
    "evaluate_model()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "SwvZUqIuer7Q",
   "metadata": {
    "id": "SwvZUqIuer7Q"
   },
   "source": [
    "### Plot the convergence of Actor and Critic losses (1 M)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d262ae2d",
   "metadata": {
    "id": "d262ae2d"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1200x600 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot the convergence of Actor and Critic losses\n",
    "def plot_losses(actor_losses, critic_losses):\n",
    "    plt.figure(figsize=(12, 6))\n",
    "\n",
    "    # Plot Actor Losses\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.plot(actor_losses, label='Actor Loss')\n",
    "    plt.xlabel('Training Steps')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.title('Actor Losses Over Time')\n",
    "    plt.legend()\n",
    "\n",
    "    # Plot Critic Losses\n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.plot(critic_losses, label='Critic Loss')\n",
    "    plt.xlabel('Training Steps')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.title('Critic Losses Over Time')\n",
    "    plt.legend()\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "plot_losses(actor_losses, critic_losses)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "xzis8NiEe21A",
   "metadata": {
    "id": "xzis8NiEe21A"
   },
   "source": [
    "### Plot the learned policy - by showing the action probabilities across different state values (1 M)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "fc20a76c",
   "metadata": {
    "id": "fc20a76c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1200x800 with 10 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot the learned policy - by showing the action probabilities across different state values\n",
    "\n",
    "# From the trained actor model, for each state in training set,\n",
    "# plot the probability of each action (increasing/decreasing/maintaining) the temperature\n",
    "def plot_learned_policy(actor_model, X_train, num_states=10):\n",
    "    \"\"\"\n",
    "    Plots the action probabilities for a few states from the training set to visualize the learned policy.\n",
    "    \n",
    "    Parameters:\n",
    "    - actor_model: Trained actor model that predicts action probabilities.\n",
    "    - X_train: Training set.\n",
    "    - num_states: Number of random states from the training set to plot.\n",
    "    \"\"\"\n",
    "    # Randomly select a few states from the training set\n",
    "    indices = np.random.choice(len(X_train), num_states, replace=False)\n",
    "    sampled_states = X_train[indices]\n",
    "\n",
    "    # Action labels\n",
    "    actions = ['Decrease Temp', 'Maintain Temp', 'Increase Temp']\n",
    "\n",
    "    plt.figure(figsize=(12, 8))\n",
    "\n",
    "    for i, state in enumerate(sampled_states):\n",
    "        # Get the action probabilities from the actor model\n",
    "        state_input = state.reshape(1, -1)\n",
    "        action_probs = actor_model.predict(state_input)[0]\n",
    "\n",
    "        # Plot the action probabilities for this state\n",
    "        plt.subplot(2, 5, i+1)  # Adjust this for the number of subplots (2 rows of 5 columns in this case)\n",
    "        plt.bar(actions, action_probs, color=['blue', 'green', 'red'])\n",
    "        plt.ylim([0, 1])\n",
    "        plt.title(f'State {i+1}')\n",
    "        plt.xlabel('Action')\n",
    "        plt.ylabel('Probability')\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# Call the function to plot the learned policy\n",
    "plot_learned_policy(actor_model, X_train, num_states=10)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93cee383",
   "metadata": {
    "id": "93cee383"
   },
   "source": [
    "#### Conclusion (0.5 M)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f844e0c",
   "metadata": {
    "id": "dc218d2a"
   },
   "source": [
    "#Provide an analysis on a comparison of the energy consumption before and after applying the reinforcement learning algorithm.\n",
    "\n",
    "\n",
    "The Actor-Critic reinforcement learning algorithm tries to optimized energy consumption while maintaining \n",
    "comfortable indoor temperatures close to the given target of 22°C. It learned policy dynamically adjusted \n",
    "temperature settings based on the actions and minimizing energy usage and temperature deviations.\n",
    "\n",
    "Energy Consumption Comparison:\n",
    "\n",
    "Total Energy Consumption Before RL: The building’s energy consumption without RL-based optimization relied \n",
    "        on static temperature settings, leading to inefficient energy use and less optimal indoor comfort.\n",
    "Total Energy Consumption After RL: The RL agent learned to adjust temperature settings based on environmental\n",
    "        factors, resulting in more efficient energy usage. On average, the energy consumption decreased after \n",
    "        the agent's interventions, with a noticeable improvement in maintaining comfortable indoor temperatures.\n",
    "Energy Savings: The RL algorithm provided significant savings in energy consumption, particularly during episodes where temperature adjustments were frequent in response to environmental changes.\n",
    "    Comfort Maintenance: The RL model was able to maintain indoor temperatures closer to the desired target, \n",
    "    leading to improved occupant comfort. Temperature deviations were minimized over time as the agent learned \n",
    "    the most effective policy.\n",
    "\n",
    "The total reward function, combining both energy savings and deviations, demonstrated a clear improvement in \n",
    "performance as the training progressed. The convergence of actor and critic losses further indicated the \n",
    "stabilization of learning, while the learned policy effectively balanced exploration and exploitation of \n",
    "different temperature settings.\n",
    "\n",
    "Overall, the RL-based optimization proved to be an effective strategy for reducing energy consumption in \n",
    "buildings while maintaining a comfortable indoor climate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3562953",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
